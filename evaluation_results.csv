question,expected,generated
"What does the ""yield"" keyword do in Python?","To understand what 
yield
 does, you must understand what 
generators
 are. And before you can understand generators, you must understand 
iterables
.


Iterables


When you create a list, you can read its items one by one. Reading its items one by one is called iteration:


>>> mylist = [1, 2, 3]
>>> for i in mylist:
...    print(i)
1
2
3



mylist
 is an 
iterable
. When you use a list comprehension, you create a list, and so an iterable:


>>> mylist = [x*x for x in range(3)]
>>> for i in mylist:
...    print(i)
0
1
4



Everything you can use ""
for... in...
"" on is an iterable; 
lists
, 
strings
, files...


These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.


Generators


Generators are 
iterators
, a kind of iterable 
you can only iterate over once
. Generators do not store all the values in memory, 
they generate the values on the fly
:


>>> mygenerator = (x*x for x in range(3))
>>> for i in mygenerator:
...    print(i)
0
1
4



It is just the same except you used 
()
 instead of 
[]
. BUT, you 
cannot
 perform 
for i in mygenerator
 a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end after calculating 4, one by one.


Yield


yield
 is a keyword that is used like 
return
, except the function will return a generator.


>>> def create_generator():
...    mylist = range(3)
...    for i in mylist:
...        yield i*i
...
>>> mygenerator = create_generator() # create a generator
>>> print(mygenerator) # mygenerator is an object!


>>> for i in mygenerator:
...     print(i)
0
1
4



Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.


To master 
yield
, you must understand that 
when you call the function, the code you have written in the function body does not run.
 The function only returns the generator object, this is a bit tricky.


Then, your code will continue from where it left off each time 
for
 uses the generator.


Now the hard part:


The first time the 
for
 calls the generator object created from your function, it will run the code in your function from the beginning until it hits 
yield
, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting 
yield
. That can be because the loop has come to an end, or because you no longer satisfy an 
""if/else""
.




Your code explained


Generator:


# Here you create the method of the node object that will return the generator
def _get_child_candidates(self, distance, min_dist, max_dist):

    # Here is the code that will be called each time you use the generator object:

    # If there is still a child of the node object on its left
    # AND if the distance is ok, return the next child
    if self._leftchild and distance - max_dist < self._median:
        yield self._leftchild

    # If there is still a child of the node object on its right
    # AND if the distance is ok, return the next child
    if self._rightchild and distance + max_dist >= self._median:
        yield self._rightchild

    # If the function arrives here, the generator will be considered empty
    # There are no more than two values: the left and the right children



Caller:


# Create an empty list and a list with the current object reference
result, candidates = list(), [self]

# Loop on candidates (they contain only one element at the beginning)
while candidates:

    # Get the last candidate and remove it from the list
    node = candidates.pop()

    # Get the distance between obj and the candidate
    distance = node._get_dist(obj)

    # If the distance is ok, then you can fill in the result
    if distance <= max_dist and distance >= min_dist:
        result.extend(node._values)

    # Add the children of the candidate to the candidate's list
    # so the loop will keep running until it has looked
    # at all the children of the children of the children, etc. of the candidate
    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))

return result



This code contains several smart parts:




The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, 
candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
 exhausts all the values of the generator, but 
while
 keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.




The 
extend()
 method is a list object method that expects an iterable and adds its values to the list.






Usually, we pass a list to it:


>>> a = [1, 2]
>>> b = [3, 4]
>>> a.extend(b)
>>> print(a)
[1, 2, 3, 4]



But in your code, it gets a generator, which is good because:




You don't need to read the values twice.


You may have a lot of children and you don't want them all stored in memory.




And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...


You can stop here, or read a little bit to see an advanced use of a generator:


Controlling a generator exhaustion


>>> class Bank(): # Let's create a bank, building ATMs
...    crisis = False
...    def create_atm(self):
...        while not self.crisis:
...            yield ""$100""
>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want
>>> corner_street_atm = hsbc.create_atm()
>>> print(corner_street_atm.next())
$100
>>> print(corner_street_atm.next())
$100
>>> print([corner_street_atm.next() for cash in range(5)])
['$100', '$100', '$100', '$100', '$100']
>>> hsbc.crisis = True # Crisis is coming, no more money!
>>> print(corner_street_atm.next())


>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs
>>> print(wall_street_atm.next())


>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty
>>> print(corner_street_atm.next())


>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business
>>> for cash in brand_new_atm:
...    print cash
$100
$100
$100
$100
$100
$100
$100
$100
$100
...



Note:
 For Python 3, use
print(corner_street_atm.__next__())
 or 
print(next(corner_street_atm))


It can be useful for various things like controlling access to a resource.


Itertools, your best friend


The 
itertools
 module contains special functions to manipulate iterables. Ever wish to duplicate a generator?
Chain two generators? Group values in a nested list with a one-liner? 
Map / Zip
 without creating another list?


Then just 
import itertools
.


An example? Let's see the possible orders of arrival for a four-horse race:


>>> horses = [1, 2, 3, 4]
>>> races = itertools.permutations(horses)
>>> print(races)


>>> print(list(itertools.permutations(horses)))
[(1, 2, 3, 4),
 (1, 2, 4, 3),
 (1, 3, 2, 4),
 (1, 3, 4, 2),
 (1, 4, 2, 3),
 (1, 4, 3, 2),
 (2, 1, 3, 4),
 (2, 1, 4, 3),
 (2, 3, 1, 4),
 (2, 3, 4, 1),
 (2, 4, 1, 3),
 (2, 4, 3, 1),
 (3, 1, 2, 4),
 (3, 1, 4, 2),
 (3, 2, 1, 4),
 (3, 2, 4, 1),
 (3, 4, 1, 2),
 (3, 4, 2, 1),
 (4, 1, 2, 3),
 (4, 1, 3, 2),
 (4, 2, 1, 3),
 (4, 2, 3, 1),
 (4, 3, 1, 2),
 (4, 3, 2, 1)]



Understanding the inner mechanisms of iteration


Iteration is a process implying iterables (implementing the 
__iter__()
 method) and iterators (implementing the 
__next__()
 method).
Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.


There is more about it in this article about 
how 
for
 loops work
.

","The `yield` keyword in Python creates a generator function.  When called, this function returns a generator object, not a single value.  Upon encountering `yield`, the generator outputs a value (similar to `return`), but its execution state and local variables are preserved.  The function resumes from where it left off on the next call to the generator's `__next__()` method.
"
"What does if __name__ == ""__main__"": do?","Short Answer


It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:




If you import the guardless script in another script (e.g. 
import my_script_without_a_name_eq_main_guard
), then the latter script will trigger the former to run 
at import time
 and 
using the second script's command line arguments
. This is almost always a mistake.




If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.






Long Answer


To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.


Whenever the Python interpreter reads a source file, it does two things:




it sets a few special variables like 
__name__
, and then




it executes all of the code found in the file.






Let's see how this works and how it relates to your question about the 
__name__
 checks we always see in Python scripts.


Code Sample


Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called 
foo.py
.


# Suppose this is foo.py.

print(""before import"")
import math

print(""before function_a"")
def function_a():
    print(""Function A"")

print(""before function_b"")
def function_b():
    print(""Function B {}"".format(math.sqrt(100)))

print(""before __name__ guard"")
if __name__ == '__main__':
    function_a()
    function_b()
print(""after __name__ guard"")



Special Variables


When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the 
__name__
 variable.


When Your Module Is the Main Program


If you are running your module (the source file) as the main program, e.g.


python foo.py



the interpreter will assign the hard-coded string 
""__main__""
 to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when run as the main program.
__name__ = ""__main__"" 



When Your Module Is Imported By Another


On the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:


# Suppose this is in some other main program.
import foo



The interpreter will search for your 
foo.py
 file (along with searching for a few other variants), and prior to executing that module, it will assign the name 
""foo""
 from the import statement to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when it's imported from another module.
__name__ = ""foo""



Executing the Module's Code


After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.


Always




It prints the string 
""before import""
 (without quotes).




It loads the 
math
 module and assigns it to a variable called 
math
. This is equivalent to replacing 
import math
 with the following (note that 
__import__
 is a low-level function in Python that takes a string and triggers the actual import):






# Find and load a module given its string name, ""math"",
# then assign it to a local variable called math.
math = __import__(""math"")





It prints the string 
""before function_a""
.




It executes the 
def
 block, creating a function object, then assigning that function object to a variable called 
function_a
.




It prints the string 
""before function_b""
.




It executes the second 
def
 block, creating another function object, then assigning it to a variable called 
function_b
.




It prints the string 
""before __name__ guard""
.






Only When Your Module Is the Main Program




If your module is the main program, then it will see that 
__name__
 was indeed set to 
""__main__""
 and it calls the two functions, printing the strings 
""Function A""
 and 
""Function B 10.0""
.




Only When Your Module Is Imported by Another




(
instead
) If your module is not the main program but was imported by another one, then 
__name__
 will be 
""foo""
, not 
""__main__""
, and it'll skip the body of the 
if
 statement.




Always




It will print the string 
""after __name__ guard""
 in both situations.




Summary


In summary, here's what'd be printed in the two cases:


# What gets printed if foo is the main program
before import
before function_a
before function_b
before __name__ guard
Function A
Function B 10.0
after __name__ guard



# What gets printed if foo is imported as a regular module
before import
before function_a
before function_b
before __name__ guard
after __name__ guard



Why Does It Work This Way?


You might naturally wonder why anybody would want this.  Well, sometimes you want to write a 
.py
 file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:




Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.




Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing 
.py
 files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.




Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.






Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. ""Running"" the script is a side effect of importing the script's module.


Food for Thought




Question: Can I have multiple 
__name__
 checking blocks?  Answer: it's strange to do so, but the language won't stop you.




Suppose the following is in 
foo2.py
.  What happens if you say 
python foo2.py
 on the command-line? Why?






# Suppose this is foo2.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo2 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
if __name__ == ""__main__"":
    print(""m1"")
    function_a()
    print(""m2"")
print(""t2"")
      





Now, figure out what will happen in 
foo3.py
 (having removed the 
__name__
 check):




# Suppose this is foo3.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo3 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
print(""m1"")
function_a()
print(""m2"")
print(""t2"")





What will this do when used as a script?  When imported as a module?




# Suppose this is in foo4.py
__name__ = ""__main__""

def bar():
    print(""bar"")
    
print(""before __name__ guard"")
if __name__ == ""__main__"":
    bar()
print(""after __name__ guard"")


","The `if __name__ == ""__main__"":` block conditionally executes code only when the module is run directly (not imported as a module into another script).  It prevents code within the block from running unintentionally if the module is imported for use in another script.
"
Does Python have a ternary conditional operator?,"Yes, it was 
added
 in version 2.5. The expression syntax is:


a if condition else b



First 
condition
 is evaluated, then exactly one of either 
a
 or 
b
 is evaluated and returned based on the 
Boolean
 value of 
condition
. If 
condition
 evaluates to 
True
, then 
a
 is evaluated and returned but 
b
 is ignored, or else when 
b
 is evaluated and returned but 
a
 is ignored.


This allows short-circuiting because when 
condition
 is true only 
a
 is evaluated and 
b
 is not evaluated at all, but when 
condition
 is false only 
b
 is evaluated and 
a
 is not evaluated at all.


For example:


>>> 'true' if True else 'false'
'true'
>>> 'true' if False else 'false'
'false'



Note that conditionals are an 
expression
, not a 
statement
. This means you can't use 
statements
 such as 
pass
, or assignments with 
=
 (or ""augmented"" assignments like 
+=
), within a conditional 
expression
:


>>> pass if False else pass
  File ""
"", line 1
    pass if False else pass
         ^
SyntaxError: invalid syntax

>>> # Python parses this as `x = (1 if False else y) = 2`
>>> # The `(1 if False else x)` part is actually valid, but
>>> # it can't be on the left-hand side of `=`.
>>> x = 1 if False else y = 2
  File ""
"", line 1
SyntaxError: cannot assign to conditional expression

>>> # If we parenthesize it instead...
>>> (x = 1) if False else (y = 2)
  File ""
"", line 1
    (x = 1) if False else (y = 2)
       ^
SyntaxError: invalid syntax



(In 3.8 and above, the 
:=
 ""walrus"" operator allows simple assignment of values 
as an expression
, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)


Similarly, because it is an expression, the 
else
 part is 
mandatory
:


# Invalid syntax: we didn't specify what the value should be if the 
# condition isn't met. It doesn't matter if we can verify that
# ahead of time.
a if True



You can, however, use conditional expressions to assign a variable like so:


x = a if True else b



Or for example to return a value:


# Of course we should just use the standard library `max`;
# this is just for demonstration purposes.
def my_max(a, b):
    return a if a > b else b



Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will 
do the same thing
 with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to 
do something different
 depending on the condition, then use a normal 
if
 
statement
 instead.




Keep in mind that it's frowned upon by some Pythonistas for several reasons:




The order of the arguments is different from those of the classic 
condition ? a : b
 ternary operator from many other languages (such as 
C
, 
C++
, 
Go
, 
Perl
, 
Ruby
, 
Java
, 
JavaScript
, etc.), which may lead to bugs when people unfamiliar with Python's ""surprising"" behaviour use it (they may reverse the argument order).


Some find it ""unwieldy"", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects).


Stylistic reasons. (Although the 'inline 
if
' can be 
really
 useful, and make your script more concise, it really does complicate your code)




If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, 
x = 4 if b > 8 else 9
 is read aloud as 
x will be 4 if b is greater than 8 otherwise 9
.


Official documentation:




Conditional expressions


Is there an equivalent of C’s ”?:” ternary operator?



","Yes, Python has a ternary conditional operator with the syntax `[on_true] if [expression] else [on_false]`.  Prior to Python 2.5,  `[expression] and [on_true] or [on_false]` was used, but this is considered unsafe.
"
What are metaclasses in Python?,"A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.


While in Python you can use arbitrary callables for metaclasses (like 
Jerub
 shows), the better approach is to make it an actual class itself. 
type
 is the usual metaclass in Python. 
type
 is itself a class, and it is its own type. You won't be able to recreate something like 
type
 purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass 
type
.


A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal 
__init__
 and 
__new__
 methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.


When the 
class
 statement is executed, Python first executes the body of the 
class
 statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the 
__metaclass__
 attribute of the class-to-be (if any) or the 
__metaclass__
 global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.


However, metaclasses actually define the 
type
 of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. 
type.__subclasses__()
 is an example of a method on the 
type
 metaclass. You can also define the normal 'magic' methods, like 
__add__
, 
__iter__
 and 
__getattr__
, to implement or change how the class behaves.


Here's an aggregated example of the bits and pieces:


def make_hook(f):
    """"""Decorator to turn 'foo' method into '__foo__'""""""
    f.is_hook = 1
    return f

class MyType(type):
    def __new__(mcls, name, bases, attrs):

        if name.startswith('None'):
            return None

        # Go over attributes and see if they should be renamed.
        newattrs = {}
        for attrname, attrvalue in attrs.iteritems():
            if getattr(attrvalue, 'is_hook', 0):
                newattrs['__%s__' % attrname] = attrvalue
            else:
                newattrs[attrname] = attrvalue

        return super(MyType, mcls).__new__(mcls, name, bases, newattrs)

    def __init__(self, name, bases, attrs):
        super(MyType, self).__init__(name, bases, attrs)

        # classregistry.register(self, self.interfaces)
        print ""Would register class %s now."" % self

    def __add__(self, other):
        class AutoClass(self, other):
            pass
        return AutoClass
        # Alternatively, to autogenerate the classname as well as the class:
        # return type(self.__name__ + other.__name__, (self, other), {})

    def unregister(self):
        # classregistry.unregister(self)
        print ""Would unregister class %s now."" % self

class MyObject:
    __metaclass__ = MyType


class NoneSample(MyObject):
    pass

# Will print ""NoneType None""
print type(NoneSample), repr(NoneSample)

class Example(MyObject):
    def __init__(self, value):
        self.value = value
    @make_hook
    def add(self, other):
        return self.__class__(self.value + other.value)

# Will unregister the class
Example.unregister()

inst = Example(10)
# Will fail with an AttributeError
#inst.unregister()

print inst + inst
class Sibling(MyObject):
    pass

ExampleSibling = Example + Sibling
# ExampleSibling is now a subclass of both Example and Sibling (with no
# content of its own) although it will believe it's called 'AutoClass'
print ExampleSibling
print ExampleSibling.__mro__


","In Python, a metaclass is responsible for taking a class name, a class dictionary, and a list of base classes to create a class.  Most other object-oriented programming languages have a default implementation, but Python allows the creation of custom metaclasses for powerful solutions, though most users won't need them.
"
How do I merge two dictionaries in a single expression in Python?,"How can I merge two Python dictionaries in a single expression?


For dictionaries 
x
 and 
y
, their shallowly-merged dictionary 
z
 takes values from 
y
, replacing those from 
x
.




In Python 3.9.0 or greater (released 17 October 2020, 
PEP-584
, 
discussed here
):


z = x | y





In Python 3.5 or greater:


z = {**x, **y}





In Python 2, (or 3.4 or lower) write a function:


def merge_two_dicts(x, y):
    z = x.copy()   # start with keys and values of x
    z.update(y)    # modifies z with keys and values of y
    return z



and now:


z = merge_two_dicts(x, y)







Explanation


Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:


x = {'a': 1, 'b': 2}
y = {'b': 3, 'c': 4}



The desired result is to get a new dictionary (
z
) with the values merged, and the second dictionary's values overwriting those from the first.


>>> z
{'a': 1, 'b': 3, 'c': 4}



A new syntax for this, proposed in 
PEP 448
 and 
available as of Python 3.5
, is


z = {**x, **y}



And it is indeed a single expression.


Note that we can merge in with literal notation as well:


z = {**x, 'foo': 1, 'bar': 2, **y}



and now:


>>> z
{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}



It is now showing as implemented in the 
release schedule for 3.5, PEP 478
, and it has now made its way into the 
What's New in Python 3.5
 document.


However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:


z = x.copy()
z.update(y) # which returns None since it mutates z



In both approaches, 
y
 will come second and its values will replace 
x
's values, thus 
b
 will point to 
3
 in our final result.


Not yet on Python 3.5, but want a 
single expression


If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a 
single expression
, the most performant while the correct approach is to put it in a function:


def merge_two_dicts(x, y):
    """"""Given two dictionaries, merge them into a new dict as a shallow copy.""""""
    z = x.copy()
    z.update(y)
    return z



and then you have a single expression:


z = merge_two_dicts(x, y)



You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:


def merge_dicts(*dict_args):
    """"""
    Given any number of dictionaries, shallow copy and merge into a new dict,
    precedence goes to key-value pairs in latter dictionaries.
    """"""
    result = {}
    for dictionary in dict_args:
        result.update(dictionary)
    return result



This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries 
a
 to 
g
:


z = merge_dicts(a, b, c, d, e, f, g) 



and key-value pairs in 
g
 will take precedence over dictionaries 
a
 to 
f
, and so on.


Critiques of Other Answers


Don't use what you see in the formerly accepted answer:


z = dict(x.items() + y.items())



In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. 
In Python 3, this will fail
 because you're adding two 
dict_items
 objects together, not two lists -


>>> c = dict(a.items() + b.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'



and you would have to explicitly create them as lists, e.g. 
z = dict(list(x.items()) + list(y.items()))
. This is a waste of resources and computation power.


Similarly, taking the union of 
items()
 in Python 3 (
viewitems()
 in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, 
since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:


>>> c = dict(a.items() | b.items())



This example demonstrates what happens when values are unhashable:


>>> x = {'a': []}
>>> y = {'b': []}
>>> dict(x.items() | y.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unhashable type: 'list'



Here's an example where 
y
 should have precedence, but instead the value from 
x
 is retained due to the arbitrary order of sets:


>>> x = {'a': 2}
>>> y = {'a': 1}
>>> dict(x.items() | y.items())
{'a': 2}



Another hack you should not use:


z = dict(x, **y)



This uses the 
dict
 constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.


Here's an example of the usage being 
remediated in django
.


Dictionaries are intended to take hashable keys (e.g. 
frozenset
s or tuples), but 
this method fails in Python 3 when keys are not strings.


>>> c = dict(a, **b)
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: keyword arguments must be strings



From the 
mailing list
, Guido van Rossum, the creator of the language, wrote:




I am fine with
declaring dict({}, **{1:3}) illegal, since after all it is abuse of
the ** mechanism.




and




Apparently dict(x, **y) is going around as ""cool hack"" for ""call
x.update(y) and return x"". Personally, I find it more despicable than
cool.




It is my understanding (as well as the understanding of the 
creator of the language
) that the intended usage for 
dict(**y)
 is for creating dictionaries for readability purposes, e.g.:


dict(a=1, b=10, c=11)



instead of


{'a': 1, 'b': 10, 'c': 11}



Response to comments




Despite what Guido says, 
dict(x, **y)
 is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.




Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. 
dict
 broke this consistency in Python 2:


>>> foo(**{('a', 'b'): None})
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: foo() keywords must be strings
>>> dict(**{('a', 'b'): None})
{('a', 'b'): None}



This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.


I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.


More comments:




dict(x.items() + y.items())
 is still the most readable solution for Python 2. Readability counts.




My response: 
merge_two_dicts(x, y)
 actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.




{**x, **y}
 does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word ""merging"" these answers describe ""updating one dict with another"", and not merging.




Yes. I must refer you back to the question, which is asking for a 
shallow
 merge of 
two
 dictionaries, with the first's values being overwritten by the second's - in a single expression.


Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:


from copy import deepcopy

def dict_of_dicts_merge(x, y):
    z = {}
    overlapping_keys = x.keys() & y.keys()
    for key in overlapping_keys:
        z[key] = dict_of_dicts_merge(x[key], y[key])
    for key in x.keys() - overlapping_keys:
        z[key] = deepcopy(x[key])
    for key in y.keys() - overlapping_keys:
        z[key] = deepcopy(y[key])
    return z



Usage:


>>> x = {'a':{1:{}}, 'b': {2:{}}}
>>> y = {'b':{10:{}}, 'c': {11:{}}}
>>> dict_of_dicts_merge(x, y)
{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}



Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at 
my answer to the canonical question on a ""Dictionaries of dictionaries merge""
.


Less Performant But Correct Ad-hocs


These approaches are less performant, but they will provide correct behavior.
They will be 
much less
 performant than 
copy
 and 
update
 or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they 
do
 respect the order of precedence (latter dictionaries have precedence)


You can also chain the dictionaries manually inside a 
dict comprehension
:


{k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7



or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):


dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2



itertools.chain
 will chain the iterators over the key-value pairs in the correct order:


from itertools import chain
z = dict(chain(x.items(), y.items())) # iteritems in Python 2



Performance Analysis


I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)


from timeit import repeat
from itertools import chain

x = dict.fromkeys('abcdefg')
y = dict.fromkeys('efghijk')

def merge_two_dicts(x, y):
    z = x.copy()
    z.update(y)
    return z

min(repeat(lambda: {**x, **y}))
min(repeat(lambda: merge_two_dicts(x, y)))
min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
min(repeat(lambda: dict(chain(x.items(), y.items()))))
min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))



In Python 3.8.1, NixOS:


>>> min(repeat(lambda: {**x, **y}))
1.0804965235292912
>>> min(repeat(lambda: merge_two_dicts(x, y)))
1.636518670246005
>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
3.1779992282390594
>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))
2.740647904574871
>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))
4.266070580109954



$ uname -a
Linux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux



Resources on Dictionaries




My explanation of Python's 
dictionary implementation
, updated for 3.6.


Answer on how to add new keys to a dictionary


Mapping two lists into a dictionary


The official Python docs on dictionaries


The Dictionary Even Mightier
 - talk by Brandon Rhodes at Pycon 2017


Modern Python Dictionaries, A Confluence of Great Ideas
 - talk by Raymond Hettinger at Pycon 2017



","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I execute a program or call a system command?,"Use 
subprocess.run
:


import subprocess

subprocess.run([""ls"", ""-l""]) 



Another common way is 
os.system
 but you shouldn't use it because it is unsafe if any parts of the command come from outside your program or can contain spaces or other special characters, also 
subprocess.run
 is generally more flexible (you can get the 
stdout
, 
stderr
, the 
""real"" status code
, better 
error handling
, etc.). Even the 
documentation for 
os.system
 recommends using 
subprocess
 instead.


On Python 3.4 and earlier, use 
subprocess.call
 instead of 
.run
:


subprocess.call([""ls"", ""-l""])


","If `args` is a string, the string specifies the command to execute through the shell.  The string must be formatted exactly as it would be at a shell prompt (including quoting or escaping filenames with spaces).  If `args` is a sequence, the first item is the command, and additional items are arguments to the shell.  For maximum reliability, use a fully qualified path for the executable.
"
"How do I create a directory, and any missing parent directories?","On Python ≥ 3.5, use 
pathlib.Path.mkdir
:


from pathlib import Path
Path(""/my/directory"").mkdir(parents=True, exist_ok=True)



For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:


Try 
os.path.exists
, and consider 
os.makedirs
 for the creation.


import os
if not os.path.exists(directory):
    os.makedirs(directory)



As noted in comments and elsewhere, there's a race condition – if the directory is created between the 
os.path.exists
 and the 
os.makedirs
 calls, the 
os.makedirs
 will fail with an 
OSError
. Unfortunately, blanket-catching 
OSError
 and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.


One option would be to trap the 
OSError
 and examine the embedded error code (see 
Is there a cross-platform way of getting information from Python’s OSError
):


import os, errno

try:
    os.makedirs(directory)
except OSError as e:
    if e.errno != errno.EEXIST:
        raise



Alternatively, there could be a second 
os.path.exists
, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled. 


Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.


Modern versions of Python improve this code quite a bit, both by exposing 
FileExistsError
 (in 3.3+)...


try:
    os.makedirs(""path/to/directory"")
except FileExistsError:
    # directory already exists
    pass



...and by allowing 
a keyword argument to 
os.makedirs
 called 
exist_ok
 (in 3.2+).


os.makedirs(""path/to/directory"", exist_ok=True)  # succeeds even if directory exists.


","The provided text describes the `makedirs()` function's behavior, stating that it creates directories as needed, mimicking the POSIX `mkdir -p` command.  It creates missing parent directories if the `parents` parameter is true (it's false by default).  If `exist_ok` is false (the default), an error is raised if the target directory already exists.
"
How to access the index value in a 'for' loop?,"Use the built-in function 
enumerate()
:


for idx, x in enumerate(xs):
    print(idx, x)



It is 
non-pythonic
 to manually index via 
for i in range(len(xs)): x = xs[i]
 or manually manage an additional state variable.


Check out 
PEP 279
 for more.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I make a flat list out of a list of lists?,"A list of lists named 
xss
 can be flattened using a nested 
list comprehension
:


flat_list = [
    x
    for xs in xss
    for x in xs
]



The above is equivalent to:


flat_list = []

for xs in xss:
    for x in xs:
        flat_list.append(x)



Here is the corresponding function:


def flatten(xss):
    return [x for xs in xss for x in xs]



This is the fastest method.
As evidence, using the 
timeit
 module in the standard library, we see:


$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' '[x for xs in xss for x in xs]'
10000 loops, best of 3: 143 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'sum(xss, [])'
1000 loops, best of 3: 969 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'reduce(lambda xs, ys: xs + ys, xss)'
1000 loops, best of 3: 1.1 msec per loop



Explanation: the methods based on 
+
 (including the implied use in 
sum
) are, of necessity, 
O(L**2)
 when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of M items each: the first M items are copied back and forth 
L-1
 times, the second M items 
L-2
 times, and so on; total number of copies is M times the sum of x for x from 1 to L excluded, i.e., 
M * (L**2)/2
.


The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.

","Use the `flatten` function, which utilizes `chain.from_iterable(list_of_lists)`.
"
What is the difference between @staticmethod and @classmethod in Python?,"Maybe a bit of example code will help: Notice the difference in the call signatures of 
foo
, 
class_foo
 and 
static_foo
:


class A(object):
    def foo(self, x):
        print(f""executing foo({self}, {x})"")

    @classmethod
    def class_foo(cls, x):
        print(f""executing class_foo({cls}, {x})"")

    @staticmethod
    def static_foo(x):
        print(f""executing static_foo({x})"")

a = A()



Below is the usual way an object instance calls a method. The object instance, 
a
, is implicitly passed as the first argument.


a.foo(1)
# executing foo(<__main__.A object at 0xb7dbef0c>, 1)





With classmethods
, the class of the object instance is implicitly passed as the first argument instead of 
self
.


a.class_foo(1)
# executing class_foo(
, 1)



You can also call 
class_foo
 using the class. In fact, if you define something to be
a classmethod, it is probably because you intend to call it from the class rather than from a class instance. 
A.foo(1)
 would have raised a TypeError, but 
A.class_foo(1)
 works just fine:


A.class_foo(1)
# executing class_foo(
, 1)



One use people have found for class methods is to create 
inheritable alternative constructors
.




With staticmethods
, neither 
self
 (the object instance) nor  
cls
 (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:


a.static_foo(1)
# executing static_foo(1)

A.static_foo('hi')
# executing static_foo(hi)



Staticmethods are used to group functions which have some logical connection with a class to the class.




foo
 is just a function, but when you call 
a.foo
 you don't just get the function,
you get a ""partially applied"" version of the function with the object instance 
a
 bound as the first argument to the function. 
foo
 expects 2 arguments, while 
a.foo
 only expects 1 argument.


a
 is bound to 
foo
. That is what is meant by the term ""bound"" below:


print(a.foo)
# 
>



With 
a.class_foo
, 
a
 is not bound to 
class_foo
, rather the class 
A
 is bound to 
class_foo
.


print(a.class_foo)
# 
>



Here, with a staticmethod, even though it is a method, 
a.static_foo
 just returns
a good 'ole function with no arguments bound. 
static_foo
 expects 1 argument, and

a.static_foo
 expects 1 argument too.


print(a.static_foo)
# 




And of course the same thing happens when you call 
static_foo
 with the class 
A
 instead.


print(A.static_foo)
# 



","Static methods in Python are similar to those in Java or C++.  They can be called on the class (e.g., `C.f()`) or an instance (e.g., `C().f()`).  The context also mentions `classmethod()` as a variant useful for creating alternate class constructors.
"
How slicing in Python works,"The syntax is:


a[start:stop]  # items start through stop-1
a[start:]      # items start through the rest of the array
a[:stop]       # items from the beginning through stop-1
a[:]           # a copy of the whole array



There is also the 
step
 value, which can be used with any of the above:


a[start:stop:step] # start through not past stop, by step



The key point to remember is that the 
:stop
 value represents the first value that is 
not
 in the selected slice. So, the difference between 
stop
 and 
start
 is the number of elements selected (if 
step
 is 1, the default).


The other feature is that 
start
 or 
stop
 may be a 
negative
 number, which means it counts from the end of the array instead of the beginning. So:


a[-1]    # last item in the array
a[-2:]   # last two items in the array
a[:-2]   # everything except the last two items



Similarly, 
step
 may be a negative number:


a[::-1]    # all items in the array, reversed
a[1::-1]   # the first two items, reversed
a[:-3:-1]  # the last two items, reversed
a[-3::-1]  # everything except the last two items, reversed



Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for 
a[:-2]
 and 
a
 only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.


Relationship with the 
slice
 object


A 
slice
 object
 can represent a slicing operation, i.e.:


a[start:stop:step]



is equivalent to:


a[slice(start, stop, step)]



Slice objects also behave slightly differently depending on the number of arguments, similar to 
range()
, i.e. both 
slice(stop)
 and 
slice(start, stop[, step])
 are supported.
To skip specifying a given argument, one might use 
None
, so that e.g. 
a[start:]
 is equivalent to 
a[slice(start, None)]
 or 
a[::-1]
 is equivalent to 
a[slice(None, None, -1)]
.


While the 
:
-based notation is very helpful for simple slicing, the explicit use of 
slice()
 objects simplifies the programmatic generation of slicing.

","Python slicing extracts a portion of a sequence (like a string or list).  It uses square brackets `[]` with a start index (inclusive), an end index (exclusive), and an optional step.  For example, `word[:2]` extracts characters from the beginning up to (but not including) index 2.  `word[4:]` extracts from index 4 to the end. Negative indices count from the end.  The expression `s[:i] + s[i:]` is always equal to the original sequence `s`.  Think of indices as points between characters, with the left edge of the first character at index 0.
"
How to find the index for a given item in a list?,">>> [""foo"", ""bar"", ""baz""].index(""bar"")
1



See 
the documentation
 for the built-in 
.index()
 method of the list:




list.index(x[, start[, end]])



Return zero-based index in the list of the first item whose value is equal to 
x
. Raises a 
ValueError
 if there is no such item.


The optional arguments 
start
 and 
end
 are interpreted as in the 
slice notation
 and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.




Caveats


Linear time-complexity in list length


An 
index
 call checks every element of the list in order, until it finds a match. If the list is long, and if there is no guarantee that the value will be near the beginning, this can slow down the code.


This problem can only be completely avoided by using a different data structure. However, if the element is known to be within a certain part of the list, the 
start
 and 
end
 parameters can be used to narrow the search.


For example:


>>> import timeit
>>> timeit.timeit('l.index(999_999)', setup='l = list(range(0, 1_000_000))', number=1000)
9.356267921015387
>>> timeit.timeit('l.index(999_999, 999_990, 1_000_000)', setup='l = list(range(0, 1_000_000))', number=1000)
0.0004404920036904514



The second call is orders of magnitude faster, because it only has to search through 10 elements, rather than all 1 million.


Only the index of the 
first match
 is returned


A call to 
index
 searches through the list in order until it finds a match, and 
stops there.
 If there could be more than one occurrence of the value, and all indices are needed, 
index
 cannot solve the problem:


>>> [1, 1].index(1) # the `1` index is not found.
0



Instead, use a 
list comprehension or generator expression to do the search
, with 
enumerate
 to get indices
:


>>> # A list comprehension gives a list of indices directly:
>>> [i for i, e in enumerate([1, 2, 1]) if e == 1]
[0, 2]
>>> # A generator comprehension gives us an iterable object...
>>> g = (i for i, e in enumerate([1, 2, 1]) if e == 1)
>>> # which can be used in a `for` loop, or manually iterated with `next`:
>>> next(g)
0
>>> next(g)
2



The list comprehension and generator expression techniques still work if there is only one match, and are more generalizable.


Raises an exception if there is no match


As noted in the documentation above, using 
.index
 will raise an exception if the searched-for value is not in the list:


>>> [1, 1].index(2)
Traceback (most recent call last):
  File ""
"", line 1, in 

ValueError: 2 is not in list



If this is a concern, either 
explicitly check first
 using 
item in my_list
, or handle the exception with 
try
/
except
 as appropriate.


The explicit check is simple and readable, but it must iterate the list a second time. See 
What is the EAFP principle in Python?
 for more guidance on this choice.

","Use the `index(x[, start[, end]])` method.  It returns the zero-based index of the first item equal to `x`.  Optional `start` and `end` arguments specify a subsequence to search within.  A `ValueError` is raised if `x` is not found.
"
Iterating over dictionaries using 'for' loops,"key
 is just a variable name.  


for key in d:



will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:


For Python 3.x:


for key, value in d.items():



For Python 2.x:


for key, value in d.iteritems():



To test for yourself, change the word 
key
 to 
poop
.


In Python 3.x, 
iteritems()
 was replaced with simply 
items()
, which returns a set-like view backed by the dict, like 
iteritems()
 but even better. 
This is also available in 2.7 as 
viewitems()
. 


The operation 
items()
 will work for both 2 and 3, but in 2 it will return a list of the dictionary's 
(key, value)
 pairs, which will not reflect changes to the dict that happen after the 
items()
 call. If you want the 2.x behavior in 3.x, you can call 
list(d.items())
.

","When looping through dictionaries, the key and corresponding value can be retrieved simultaneously using the `items()` method.  For example: `for k, v in knights.items(): print(k, v)`
"
How can I iterate over rows in a Pandas DataFrame?,"DataFrame.iterrows
 is a generator which yields both the index and row (as a Series):


import pandas as pd

df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})
df = df.reset_index()  # make sure indexes pair with number of rows

for index, row in df.iterrows():
    print(row['c1'], row['c2'])



10 100
11 110
12 120





Obligatory disclaimer from the 
documentation




Iterating through pandas objects is generally 
slow
. In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches:




Look for a 
vectorized
 solution: many operations can be performed using built-in methods or NumPy functions, (boolean) indexing, …


When you have a function that cannot work on the full DataFrame/Series at once, it is better to use 
apply()
 instead of iterating over the values. See the docs on 
function application
.


If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop with cython or numba. See the 
enhancing performance
 section for some examples of this approach.






Other answers in this thread delve into greater depth on alternatives to iter* functions if you are interested to learn more.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How can I use a global variable in a function?,"You can use a global variable within other functions by declaring it as 
global
 
within each function that assigns a value to it
:


globvar = 0

def set_globvar_to_one():
    global globvar    # Needed to modify global copy of globvar
    globvar = 1

def print_globvar():
    print(globvar)     # No need for global declaration to read value of globvar

set_globvar_to_one()
print_globvar()       # Prints 1



Since it's unclear whether 
globvar = 1
 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the 
global
 keyword.


See other answers if you want to share a global variable across modules.

","To use a global variable in a function, you must explicitly declare it as `global` within the function before assigning a value to it.  If you only reference (read) the global variable, the `global` declaration is not needed.
"
How do I get the current time in Python?,"Use 
datetime
:


>>> import datetime
>>> now = datetime.datetime.now()
>>> now
datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)
>>> print(now)
2009-01-06 15:08:24.789150



For just the clock time without the date:


>>> now.time()
datetime.time(15, 8, 24, 78915)
>>> print(now.time())
15:08:24.789150





To save typing, you can import the 
datetime
 object from the 
datetime
 module:


>>> from datetime import datetime



Then remove the prefix 
datetime.
 from all of the above.

","The provided text mentions `datetime.now()` and `datetime.utcnow()`.  `datetime.now()` gets the current date and time, potentially converting to a specified timezone. `datetime.utcnow()` gets the current UTC date and time.  More specific instructions on usage are not available in the context.
"
"How to catch multiple exceptions in one line? (in the ""except"" block)","From 
Python Documentation
:




An except clause may name multiple exceptions as a parenthesized tuple, for example




except (IDontLikeYouException, YouAreBeingMeanException) as e:
    pass



Or, for Python 2 only:


except (IDontLikeYouException, YouAreBeingMeanException), e:
    pass



Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using 
as
.

","An except clause may name multiple exceptions as a parenthesized tuple, for example:  `except (RuntimeError, TypeError, NameError):`
"
How do I copy a file?,"shutil
 has many methods you can use. One of which is:


import shutil

shutil.copyfile(src, dst)

# 2nd option
shutil.copy(src, dst)  # dst can be a folder; use shutil.copy2() to preserve timestamp





Copy the contents of the file named 
src
 to a file named 
dst
. Both 
src
 and 
dst
 need to be the entire filename of the files, including path.


The destination location must be writable; otherwise, an 
IOError
 exception will be raised.


If 
dst
 already exists, it will be replaced.


Special files such as character or block devices and pipes cannot be copied with this function.


With 
copy
, 
src
 and 
dst
 are path names given as 
str
s.




Another 
shutil
 method to look at is 
shutil.copy2()
. It's similar but preserves more metadata (e.g. time stamps).


If you use 
os.path
 operations, use 
copy
 rather than 
copyfile
. 
copyfile
 will only accept strings.

","To copy a file `src` to `dst`, use the `copy()` function.  If `dst` is a directory, the file will be copied into that directory using the original filename. If `dst` is an existing file, it will be replaced.  The `follow_symlinks` parameter controls how symbolic links are handled.  The function returns the path to the newly created file.
"
What is __init__.py for?,"It used to be a required part of a package (
old, pre-3.3 ""regular package""
, not 
newer 3.3+ ""namespace package""
).


Here's the documentation.




Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an 
__init__.py
 file. When a regular package is imported, this 
__init__.py
 file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The 
__init__.py
 file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.




But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without 
__init__.py
.

","`__init__.py` files are required to make Python treat directories as packages (unless using namespace packages).  They can be empty, but can also contain initialization code for the package or set the `__all__` variable.  When a package is imported, its `__init__.py` file is implicitly executed, and the objects it defines are bound to names in the package's namespace.
"
Convert bytes to a string in Python 3,"Decode the 
bytes
 object
 to produce a string:


>>> b""abcde"".decode(""utf-8"")
'abcde'



The above example 
assumes
 that the 
bytes
 object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!

","The provided text describes converting a hexadecimal string to a bytes object using `bytes.fromhex()`, and converting a bytes object to its hexadecimal representation using the `.hex()` method.  It does *not* explain how to convert a bytes object to a string representing its *character* content.  Therefore, I'm sorry, I couldn't find relevant information in the provided context.
"
What is the difference between __str__ and __repr__?,"

Alex Martelli summarized well
 but, surprisingly, was too succinct.


First, let me reiterate the main points in 
Alex
’s post:




The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)


__repr__
 goal is to be unambiguous


__str__
 goal is to be readable


Container’s 
__str__
 uses contained objects’ 
__repr__




Default implementation is useless


This is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default for 
__repr__
 which would act like:


return ""%s(%r)"" % (self.__class__, self.__dict__)



Or in new f-string formatting:


return f""{self.__class__!s}({self.__dict__!r})""



would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if 
__repr__
 is defined, and 
__str__
 is not, the object will behave as though 
__str__=__repr__
.


This means, in simple terms: almost every object you implement should have a functional 
__repr__
 that’s usable for understanding the object. Implementing 
__str__
 is optional: do that if you need a “pretty print” functionality (for example, used by a report generator).


The goal of 
__repr__
 is to be unambiguous


Let me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a


log(INFO, ""I am in the weird function and a is"", a, ""and b is"", b, ""but I got a null C — using default"", default_c)



But you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work. This is why the “eval” thing comes up: if you have enough information so 
eval(repr(c))==c
, that means you know everything there is to know about 
c
. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about 
c
 anyway. I usually use an eval-like format: 
""MyClass(this=%r,that=%r)"" % (self.this,self.that)
. It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.


Note: I used 
%r
 above, not 
%s
. You always want to use 
repr()
 [or 
%r
 formatting character, equivalently] inside 
__repr__
 implementation, or you’re defeating the goal of repr. You want to be able to differentiate 
MyClass(3)
 and 
MyClass(""3"")
.


The goal of 
__str__
 is to be readable


Specifically, it is not intended to be unambiguous — notice that 
str(3)==str(""3"")
. Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be ""2010/4/12 15:35:22"", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement.


Container’s 
__str__
 uses contained objects’ 
__repr__


This seems surprising, doesn’t it? It is a little, but how readable would it be if it used their 
__str__
?


[moshe is, 3, hello
world, this is a list, oh I don't know, containing just 4 elements]



Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you’re printing a list, just


print(""["" + "", "".join(lst) + ""]"")



(you can probably also figure out what to do about dictionaries).


Summary


Implement 
__repr__
 for any class you implement. This should be second nature. Implement 
__str__
 if you think it would be useful to have a string version which errs on the side of readability.

","`str()` aims for a human-readable representation, while `repr()` generates a representation that can be interpreted by Python, ideally recreating the object.  If a class defines `__repr__()` but not `__str__()`, `__repr__()` is also used for the informal string representation (e.g., for printing or debugging).  For many objects, both functions return the same value.  Strings themselves have distinct representations for each.
"
How do I select rows from a DataFrame based on column values?,"To select rows whose column value equals a scalar, 
some_value
, use 
==
:


df.loc[df['column_name'] == some_value]



To select rows whose column value is in an iterable, 
some_values
, use 
isin
:


df.loc[df['column_name'].isin(some_values)]



Combine multiple conditions with 
&
:


df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]



Note the parentheses. Due to Python's 
operator precedence rules
, 
&
 binds more tightly than 
<=
 and 
>=
. Thus, the parentheses in the last example are necessary. Without the parentheses


df['column_name'] >= A & df['column_name'] <= B



is parsed as


df['column_name'] >= (A & df['column_name']) <= B



which results in a 
Truth value of a Series is ambiguous error
.




To select rows whose column value 
does not equal
 
some_value
, use 
!=
:


df.loc[df['column_name'] != some_value]



The 
isin
 returns a boolean Series, so to select rows whose value is 
not
 in 
some_values
, negate the boolean Series using 
~
:


df = df.loc[~df['column_name'].isin(some_values)] # .loc is not in-place replacement





For example,


import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
#      A      B  C   D
# 0  foo    one  0   0
# 1  bar    one  1   2
# 2  foo    two  2   4
# 3  bar  three  3   6
# 4  foo    two  4   8
# 5  bar    two  5  10
# 6  foo    one  6  12
# 7  foo  three  7  14

print(df.loc[df['A'] == 'foo'])



yields


     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14





If you have multiple values you want to include, put them in a
list (or more generally, any iterable) and use 
isin
:


print(df.loc[df['B'].isin(['one','three'])])



yields


     A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14





Note, however, that if you wish to do this many times, it is more efficient to
make an index first, and then use 
df.loc
:


df = df.set_index(['B'])
print(df.loc['one'])



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
one  foo  6  12



or, to include multiple values from the index use 
df.index.isin
:


df.loc[df.index.isin(['one','two'])]



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
two  foo  2   4
two  foo  4   8
two  bar  5  10
one  foo  6  12


","I'm sorry, I couldn't find relevant information in the provided context.
"
How can I add new keys to a dictionary?,"You create a new key/value pair on a dictionary by assigning a value to that key


d = {'key': 'value'}
print(d)  # {'key': 'value'}

d['mynewkey'] = 'mynewvalue'

print(d)  # {'key': 'value', 'mynewkey': 'mynewvalue'}



If the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.

","To add a key-value pair to a dictionary, you can use the assignment operator (`=`).  If the key already exists, its value will be overwritten.
"
Does Python have a string 'contains' substring method?,"Use the 
in
 operator
:


if ""blah"" not in somestring: 
    continue



Note: This is case-sensitive.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How can I delete a file or folder in Python?,"Use one of these methods:




pathlib.Path.unlink()
 removes a file or symbolic link.




pathlib.Path.rmdir()
 removes an empty directory.




shutil.rmtree()
 deletes a directory and all its contents.








On Python 3.3 and below, you can use these methods instead of the 
pathlib
 ones:




os.remove()
 removes a file.




os.unlink()
 removes a symbolic link.




os.rmdir()
 removes an empty directory.





","To delete a file, use `os.remove(filename)` or `os.unlink(filename)`.  To remove a directory, use `os.rmdir()`.  To delete an entire directory tree and its contents, use `shutil.rmtree()`.
"
"""Least Astonishment"" and the Mutable Default Argument","Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are 
first-class objects
, and not only a piece of code.


As soon as you think of it this way, then it completely makes sense: a function is an 
object
 being evaluated on its definition; default parameters are kind of 
""member data""
 and therefore their state may change from one call to the other - exactly as in any other object.


In any case, the Effbot (
Fredrik Lundh
) has a very nice explanation of the reasons for this behavior in 
Default Parameter Values in Python
. I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.

","Mutable objects (like lists and dictionaries) used as default arguments in function definitions are evaluated only once, when the function is defined.  Subsequent calls to the function will modify this single, shared object, leading to unexpected behavior.  Immutable objects (numbers, strings, tuples, None) are safe from this issue.  Therefore, it's best practice to avoid mutable objects as default argument values.
"
What does ** (double star/asterisk) and * (star/asterisk) do for parameters?,"The 
*args
 and 
**kwargs
 are common idioms to allow an arbitrary number of arguments to functions, as described in the section 
more on defining functions
 in the Python tutorial.


The 
*args
 will give you all positional arguments 
as a tuple
:


def foo(*args):
    for a in args:
        print(a)        

foo(1)
# 1

foo(1, 2, 3)
# 1
# 2
# 3



The 
**kwargs
 will give you all
keyword arguments as a dictionary:


def bar(**kwargs):
    for a in kwargs:
        print(a, kwargs[a])  

bar(name='one', age=27)
# name one
# age 27



Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:


def foo(kind, *args, bar=None, **kwargs):
    print(kind, args, bar, kwargs)

foo(123, 'a', 'b', apple='red')
# 123 ('a', 'b') None {'apple': 'red'}



It is also possible to use this the other way around:


def foo(a, b, c):
    print(a, b, c)

obj = {'b':10, 'c':'lee'}

foo(100, **obj)
# 100 10 lee



Another usage of the 
*l
 idiom is to 
unpack argument lists
 when calling a function.


def foo(bar, lee):
    print(bar, lee)

baz = [1, 2]

foo(*baz)
# 1 2



In Python 3 it is possible to use 
*l
 on the left side of an assignment (
Extended Iterable Unpacking
), though it gives a list instead of a tuple in this context:


first, *rest = [1, 2, 3, 4]
# first = 1
# rest = [2, 3, 4]



Also Python 3 adds a new semantic (refer 
PEP 3102
):


def func(arg1, arg2, arg3, *, kwarg1, kwarg2):
    pass



Such function accepts only 3 positional arguments, and everything after 
*
 can only be passed as keyword arguments.


Note:


A Python 
dict
, semantically used for keyword argument passing, is arbitrarily ordered. However, in Python 3.6+, keyword arguments are guaranteed to remember insertion order.
""The order of elements in 
**kwargs
 now corresponds to the order in which keyword arguments were passed to the function."" - 
What’s New In Python 3.6
.
In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, and this becomes standard in Python 3.7.

","In a function's parameter list, `*identifier` creates a tuple containing any excess positional arguments, defaulting to an empty tuple.  `**identifier` creates an ordered mapping (like a dictionary) containing any excess keyword arguments, defaulting to an empty mapping of the same type.
"
How can I access environment variables in Python?,"Environment variables are accessed through 
os.environ
:


import os
print(os.environ['HOME'])



To see a list of all environment variables:


print(os.environ)





If a key is not present, attempting to access it will raise a 
KeyError
. To avoid this:


# Returns `None` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST'))

# Returns `default_value` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST', default_value))

# Returns `default_value` if the key doesn't exist
print(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))


","Use `os.getenv(key, default=None)`.  This returns the value of the environment variable `key` as a string if it exists, otherwise it returns `default`.
"
How do I sort a dictionary by value?,"Python 3.7+ or CPython 3.6


Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but 
it's an implementation detail
.


>>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



or


>>> dict(sorted(x.items(), key=lambda item: item[1]))
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



Older Python


It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.


For instance,


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(1))



sorted_x
 will be a list of tuples sorted by the second element in each tuple. 
dict(sorted_x) == x
.


And for those wishing to sort on keys instead of values:


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(0))



In Python3 since 
unpacking is not allowed
 we can use


x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=lambda kv: kv[1])



If you want the output as a dict, you can use 
collections.OrderedDict
:


import collections

sorted_dict = collections.OrderedDict(sorted_x)


","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I clone a list so that it doesn't change unexpectedly after assignment?,"new_list = my_list
 doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both 
new_list
 and 
my_list
 refer to the same list after the assignment.


To actually copy the list, you have several options:




You can use the built-in 
list.copy()
 method (available since Python 3.3):


new_list = old_list.copy()





You can slice it:


new_list = old_list[:]



Alex Martelli
's opinion (at least 
back in 2007
) about this is, that 
it is a weird syntax and it does not make sense to use it ever
. ;) (In his opinion, the next one is more readable).




You can use the built-in 
list()
 constructor:


new_list = list(old_list)





You can use generic 
copy.copy()
:


import copy
new_list = copy.copy(old_list)



This is a little slower than 
list()
 because it has to find out the datatype of 
old_list
 first.




If you need to copy the elements of the list as well, use generic 
copy.deepcopy()
:


import copy
new_list = copy.deepcopy(old_list)



Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).






Example:


import copy

class Foo(object):
    def __init__(self, val):
         self.val = val

    def __repr__(self):
        return f'Foo({self.val!r})'

foo = Foo(1)

a = ['foo', foo]
b = a.copy()
c = a[:]
d = list(a)
e = copy.copy(a)
f = copy.deepcopy(a)

# edit orignal list and instance 
a.append('baz')
foo.val = 5

print(f'original: {a}\nlist.copy(): {b}\nslice: {c}\nlist(): {d}\ncopy: {e}\ndeepcopy: {f}')



Result:


original: ['foo', Foo(5), 'baz']
list.copy(): ['foo', Foo(5)]
slice: ['foo', Foo(5)]
list(): ['foo', Foo(5)]
copy: ['foo', Foo(5)]
deepcopy: ['foo', Foo(1)]


","Simple assignment in Python creates only a reference, not a copy. To create a list copy that avoids unexpected changes after assignment, use the approach: `A = [None] * 3` followed by a loop: `for i in range(3): A[i] = [None] * 2`.  This creates a new list for each element instead of referencing the same object multiple times.
"
How do I pass a variable by reference?,"Arguments are 
passed by assignment
. The rationale behind this is twofold:




the parameter passed in is actually a 
reference
 to an object (but the reference is passed by value)


some data types are mutable, but others aren't




So:




If you pass a 
mutable
 object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object. 


If you pass an 
immutable
 object to a method, you still can't rebind the outer reference, and you can't even mutate the object.




To make it even more clear, let's have some examples. 


List - a mutable type


Let's try to modify the list that was passed to a method:


def try_to_change_list_contents(the_list):
    print('got', the_list)
    the_list.append('four')
    print('changed to', the_list)

outer_list = ['one', 'two', 'three']

print('before, outer_list =', outer_list)
try_to_change_list_contents(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['one', 'two', 'three']
got ['one', 'two', 'three']
changed to ['one', 'two', 'three', 'four']
after, outer_list = ['one', 'two', 'three', 'four']



Since the parameter passed in is a reference to 
outer_list
, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.


Now let's see what happens when we try to change the reference that was passed in as a parameter:


def try_to_change_list_reference(the_list):
    print('got', the_list)
    the_list = ['and', 'we', 'can', 'not', 'lie']
    print('set to', the_list)

outer_list = ['we', 'like', 'proper', 'English']

print('before, outer_list =', outer_list)
try_to_change_list_reference(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['we', 'like', 'proper', 'English']
got ['we', 'like', 'proper', 'English']
set to ['and', 'we', 'can', 'not', 'lie']
after, outer_list = ['we', 'like', 'proper', 'English']



Since the 
the_list
 parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The 
the_list
 was a copy of the 
outer_list
 reference, and we had 
the_list
 point to a new list, but there was no way to change where 
outer_list
 pointed.


String - an immutable type


It's immutable, so there's nothing we can do to change the contents of the string


Now, let's try to change the reference


def try_to_change_string_reference(the_string):
    print('got', the_string)
    the_string = 'In a kingdom by the sea'
    print('set to', the_string)

outer_string = 'It was many and many a year ago'

print('before, outer_string =', outer_string)
try_to_change_string_reference(outer_string)
print('after, outer_string =', outer_string)



Output:


before, outer_string = It was many and many a year ago
got It was many and many a year ago
set to In a kingdom by the sea
after, outer_string = It was many and many a year ago



Again, since the 
the_string
 parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The 
the_string
 was a copy of the 
outer_string
 reference, and we had 
the_string
 point to a new string, but there was no way to change where 
outer_string
 pointed.


I hope this clears things up a little.


EDIT:
 It's been noted that this doesn't answer the question that @David originally asked, ""Is there something I can do to pass the variable by actual reference?"". Let's work on that.


How do we get around this?


As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:


def return_a_whole_new_string(the_string):
    new_string = something_to_do_with_the_old_string(the_string)
    return new_string

# then you could call it like
my_string = return_a_whole_new_string(my_string)



If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:


def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):
    new_string = something_to_do_with_the_old_string(stuff_to_change[0])
    stuff_to_change[0] = new_string

# then you could call it like
wrapper = [my_string]
use_a_wrapper_to_simulate_pass_by_reference(wrapper)

do_something_with(wrapper[0])



Although this seems a little cumbersome.

","Python uses call by assignment.  There's no direct call-by-reference.  The provided text explains that you can achieve a similar effect using several methods, but it doesn't specify what those methods are.
"
Manually raising (throwing) an exception in Python,"

How do I manually throw/raise an exception in Python?




Use the most specific Exception constructor that semantically fits your issue
.


Be specific in your message, e.g.:


raise ValueError('A very specific bad thing happened.')



Don't raise generic exceptions


Avoid raising a generic 
Exception
. To catch it, you'll have to catch all other more specific exceptions that subclass it.


Problem 1: Hiding bugs


raise Exception('I know Python!') # Don't! If you catch, likely to hide bugs.



For example:


def demo_bad_catch():
    try:
        raise ValueError('Represents a hidden bug, do not catch this')
        raise Exception('This is the exception you expect to handle')
    except Exception as error:
        print('Caught this error: ' + repr(error))

>>> demo_bad_catch()
Caught this error: ValueError('Represents a hidden bug, do not catch this',)



Problem 2: Won't catch


And more specific catches won't catch the general exception:


def demo_no_catch():
    try:
        raise Exception('general exceptions not caught by specific handling')
    except ValueError as e:
        print('we will not catch exception: Exception')
 

>>> demo_no_catch()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in demo_no_catch
Exception: general exceptions not caught by specific handling



Best Practices: 
raise
 statement


Instead, use the most specific Exception constructor that semantically fits your issue
.


raise ValueError('A very specific bad thing happened')



which also handily allows an arbitrary number of arguments to be passed to the constructor:


raise ValueError('A very specific bad thing happened', 'foo', 'bar', 'baz') 



These arguments are accessed by the 
args
 attribute on the 
Exception
 object. For example:


try:
    some_code_that_may_raise_our_value_error()
except ValueError as err:
    print(err.args)



prints


('message', 'foo', 'bar', 'baz')    



In Python 2.5, an actual 
message
 attribute was added to 
BaseException
 in favor of encouraging users to subclass Exceptions and stop using 
args
, but 
the introduction of 
message
 and the original deprecation of args has been retracted
.


Best Practices: 
except
 clause


When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:


logger = logging.getLogger(__name__)

try:
    do_something_in_app_that_breaks_easily()
except AppError as error:
    logger.error(error)
    raise                 # just this!
    # raise AppError      # Don't do this, you'll lose the stack trace!



Don't modify your errors... but if you insist.


You can preserve the stacktrace (and error value) with 
sys.exc_info()
, but 
this is way more error prone
 and 
has compatibility problems between Python 2 and 3
, prefer to use a bare 
raise
 to re-raise.


To explain - the 
sys.exc_info()
 returns the type, value, and traceback.


type, value, traceback = sys.exc_info()



This is the syntax in Python 2 - note this is not compatible with Python 3:


raise AppError, error, sys.exc_info()[2] # avoid this.
# Equivalently, as error *is* the second object:
raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]



If you want to, you can modify what happens with your new raise - e.g. setting new 
args
 for the instance:


def error():
    raise ValueError('oops!')

def catch_error_modify_message():
    try:
        error()
    except ValueError:
        error_type, error_instance, traceback = sys.exc_info()
        error_instance.args = (error_instance.args[0] + ' 
',)
        raise error_type, error_instance, traceback



And we have preserved the whole traceback while modifying the args. Note that this is 
not a best practice
 and it is 
invalid syntax
 in Python 3 (making keeping compatibility much harder to work around).


>>> catch_error_modify_message()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in catch_error_modify_message
  File ""
"", line 2, in error
ValueError: oops! 




In 
Python 3
:


raise error.with_traceback(sys.exc_info()[2])



Again: avoid manually manipulating tracebacks. It's 
less efficient
 and more error prone. And if you're using threading and 
sys.exc_info
 you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)


Python 3, Exception chaining


In Python 3, you can chain Exceptions, which preserve tracebacks:


raise RuntimeError('specific message') from error



Be aware:




this 
does
 allow changing the error type raised, and


this is 
not
 compatible with Python 2.




Deprecated Methods:


These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, 
but not the one intended!


Valid in Python 2, but not in Python 3
 is the following:


raise ValueError, 'message' # Don't do this, it's deprecated!



Only 
valid in much older versions of Python
 (2.4 and lower), you may still see people raising strings:


raise 'message' # really really wrong. don't do this.



In all modern versions, this will actually raise a 
TypeError
, because you're not raising a 
BaseException
 type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.


Example Usage


I raise Exceptions to warn consumers of my API if they're using it incorrectly:


def api_func(foo):
    '''foo should be either 'baz' or 'bar'. returns something very useful.'''
    if foo not in _ALLOWED_ARGS:
        raise ValueError('{foo} wrong, use ""baz"" or ""bar""'.format(foo=repr(foo)))



Create your own error types when apropos




""I want to make an error on purpose, so that it would go into the except""




You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:


class MyAppLookupError(LookupError):
    '''raise this when there's a lookup error for my app'''



and usage:


if important_key not in resource_dict and not ok_to_be_missing:
    raise MyAppLookupError('resource is missing, and that is not ok.')


","The `raise` statement forces a specified exception.  The argument to `raise` is either an exception instance or class (inheriting from `BaseException`).  For example: `raise NameError('HiThere')`.
"
Understanding Python super() with __init__() methods,"super()
 lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of 
fun stuff
 can happen. See the 
standard docs on super
 if you haven't already.


Note that 
the syntax changed in Python 3.0
: you can just say 
super().__init__()
 instead of 
super(ChildB, self).__init__()
 which IMO is quite a bit nicer. The standard docs also refer to a 
guide to using 
super()
 which is quite explanatory.

","If a derived class has an `__init__()` method and its base class also has one, the derived class's `__init__()` must explicitly call the base class's `__init__()` using `super().__init__([args.])` to properly initialize the base class part of the instance.  Failing to do so will result in improper initialization.
"
How do I concatenate two lists in Python?,"Use the 
+
 operator to combine the lists:


listone = [1, 2, 3]
listtwo = [4, 5, 6]

joinedlist = listone + listtwo



Output:


>>> joinedlist
[1, 2, 3, 4, 5, 6]



NOTE: This will create a new list with a shallow copy of the items in the first list, followed by a shallow copy of the items in the second list. Use 
copy.deepcopy()
 to get deep copies of lists.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I check if a list is empty?,"if not a:
    print(""List is empty"")



Using the 
implicit booleanness
 of the empty 
list
 is quite Pythonic.

","The provided text mentions that `list.pop()` raises an `IndexError` if the list is empty.  It also states that `list.clear()` removes all items from a list.  However, it does not explicitly explain how to directly check if a list is empty.
"
How do I make function decorators and chain them together?,"Check out 
the documentation
 to see how decorators work. Here is what you asked for:


from functools import wraps

def makebold(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

def makeitalic(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

@makebold
@makeitalic
def hello():
    return ""hello world""

@makebold
@makeitalic
def log(s):
    return s

print hello()        # returns ""
hello world
""
print hello.__name__ # with functools.wraps() this returns ""hello""
print log('hello')   # returns ""
hello
""


","Decorator expressions are evaluated when the function is defined.  The result must be a callable, which is invoked with the function object as the only argument. The returned value is then bound to the function name. Multiple decorators are applied in a nested fashion.
"
How do I split a list into equally-sized chunks?,"Here's a generator that yields evenly-sized chunks:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]



import pprint
pprint.pprint(list(chunks(range(10, 75), 10)))
[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]



For Python 2, using 
xrange
 instead of 
range
:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in xrange(0, len(lst), n):
        yield lst[i:i + n]





Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:


[lst[i:i + n] for i in range(0, len(lst), n)]



For Python 2:


[lst[i:i + n] for i in xrange(0, len(lst), n)]


","I'm sorry, I couldn't find relevant information in the provided context.
"
What is the difference between Python's list methods append and extend?,".append()
 appends a 
single object
 at the end of the list:


>>> x = [1, 2, 3]
>>> x.append([4, 5])
>>> print(x)
[1, 2, 3, [4, 5]]



.extend()
 appends 
multiple objects
 that are taken from inside the specified iterable:


>>> x = [1, 2, 3]
>>> x.extend([4, 5])
>>> print(x)
[1, 2, 3, 4, 5]


","`append(x)` adds a single item `x` to the end of the list.  `extend(iterable)` adds all items from an iterable (like another list or tuple) to the end of the list.
"
Find the current directory and file's directory,"To get the full path to the directory a Python file is contained in, write this in that file:


import os 
dir_path = os.path.dirname(os.path.realpath(__file__))



(Note that the incantation above won't work if you've already used 
os.chdir()
 to change your current working directory, since the value of the 
__file__
 constant is relative to the current working directory and is not changed by an 
os.chdir()
 call.)




To get the current working directory use 


import os
cwd = os.getcwd()





Documentation references for the modules, constants and functions used above:




The 
os
 and 
os.path
 modules.


The 
__file__
 constant


os.path.realpath(path)
 (returns 
""the canonical path of the specified filename, eliminating any symbolic links encountered in the path""
)


os.path.dirname(path)
 (returns 
""the directory name of pathname 
path
""
)


os.getcwd()
 (returns 
""a string representing the current working directory""
)


os.chdir(path)
 (
""change the current working directory to 
path
""
)



","`os.getcwd()` gets the current working directory, and while the provided text mentions functions to get file paths (`os.path.abspath()`, `os.path.realpath()`), it doesn't show how to get the directory of a specific file.
"
"Why is ""1000000000000000 in range(1000000000000001)"" so fast in Python 3?","The Python 3 
range()
 object doesn't produce numbers immediately; it is a smart 
sequence object
 that produces numbers 
on demand
. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.


The object also implements the 
object.__contains__
 hook
, and 
calculates
 if your number is part of its range. Calculating is a (near) constant time operation 
*
. There is never a need to scan through all possible integers in the range.


From the 
range()
 object documentation
:




The advantage of the 
range
 type over a regular 
list
 or 
tuple
 is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the 
start
, 
stop
 and 
step
 values, calculating individual items and subranges as needed).




So at a minimum, your 
range()
 object would do:


class my_range:
    def __init__(self, start, stop=None, step=1, /):
        if stop is None:
            start, stop = 0, start
        self.start, self.stop, self.step = start, stop, step
        if step < 0:
            lo, hi, step = stop, start, -step
        else:
            lo, hi = start, stop
        self.length = 0 if lo > hi else ((hi - lo - 1) // step) + 1

    def __iter__(self):
        current = self.start
        if self.step < 0:
            while current > self.stop:
                yield current
                current += self.step
        else:
            while current < self.stop:
                yield current
                current += self.step

    def __len__(self):
        return self.length

    def __getitem__(self, i):
        if i < 0:
            i += self.length
        if 0 <= i < self.length:
            return self.start + i * self.step
        raise IndexError('my_range object index out of range')

    def __contains__(self, num):
        if self.step < 0:
            if not (self.stop < num <= self.start):
                return False
        else:
            if not (self.start <= num < self.stop):
                return False
        return (num - self.start) % self.step == 0



This is still missing several things that a real 
range()
 supports (such as the 
.index()
 or 
.count()
 methods, hashing, equality testing, or slicing), but should give you an idea.


I also simplified the 
__contains__
 implementation to only focus on integer tests; if you give a real 
range()
 object a non-integer value (including subclasses of 
int
), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original 
Python issue
 that implemented the containment test.




* 
Near
 constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it’s all executed in optimised C code and Python stores integer values in 30-bit chunks, you’d run out of memory before you saw any performance impact due to the size of the integers involved here.

","I'm sorry, I couldn't find relevant information in the provided context.
"
Renaming column names in Pandas,"Just assign it to the 
.columns
 attribute:


>>> df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})
>>> df
   $a  $b
0   1  10
1   2  20

>>> df.columns = ['a', 'b']
>>> df
   a   b
0  1  10
1  2  20


","I'm sorry, I couldn't find relevant information in the provided context.
"
"Convert string ""Jun 1 2005 1:33PM"" into datetime","datetime.strptime
 parses an input string in the user-specified format into a 
timezone-naive
 
datetime
 object:


>>> from datetime import datetime
>>> datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')
datetime.datetime(2005, 6, 1, 13, 33)



To obtain a 
date
 object using an existing 
datetime
 object, convert it using 
.date()
:


>>> datetime.strptime('Jun 1 2005', '%b %d %Y').date()
date(2005, 6, 1)





Links:




strptime
 docs: 
Python 2
, 
Python 3




strptime
/
strftime
 format string docs: 
Python 2
, 
Python 3




strftime.org
 format string cheatsheet






Notes:




strptime
 = ""string parse time""


strftime
 = ""string format time""



","```python
from datetime import datetime

date_string = ""Jun 1 2005 1:33PM""
datetime_object = datetime.strptime(date_string, ""%b %d %Y %I:%M%p"")
print(datetime_object) 
```
"
How can I remove a key from a Python dictionary?,"To delete a key regardless of whether it is in the dictionary, use the two-argument form of 
dict.pop()
:


my_dict.pop('key', None)



This will return 
my_dict[key]
 if 
key
 exists in the dictionary, and 
None
 otherwise. If the second parameter is not specified (i.e. 
my_dict.pop('key')
) and 
key
 does not exist, a 
KeyError
 is raised.


To delete a key that is guaranteed to exist, you can also use


del my_dict['key']



This will raise a 
KeyError
 if the key is not in the dictionary.

","The `pop(key[, default])` method removes a key and returns its value if the key exists; otherwise, it returns a default value or raises a `KeyError`.  The `del` keyword can also remove a key:value pair.
"
How to upgrade all Python packages with pip,"There isn't a built-in flag yet. Starting with pip version 22.3, the 
--outdated
 and 
--format=freeze
 have become 
mutually exclusive
. Use Python, to parse the JSON output:


pip --disable-pip-version-check list --outdated --format=json | python -c ""import json, sys; print('\n'.join([x['name'] for x in json.load(sys.stdin)]))"" | xargs -n1 pip install -U



If you are using 
pip<22.3
 you can use:


pip list --outdated --format=freeze | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U



For older versions of 
pip
:


pip freeze --local | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U







The 
grep
 is to skip editable (""-e"") package definitions, as suggested by 
@jawache
. (Yes, you could replace 
grep
+
cut
 with 
sed
 or 
awk
 or 
perl
 or...).




The 
-n1
 flag for 
xargs
 prevents stopping everything if updating one package fails (thanks 
@andsens
).








Note:
 there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!

","To upgrade a package to the latest version, use the command `python -m pip install --upgrade SomePackage`.  To upgrade all packages, the provided text does not offer a single command solution.
"
How to sort a list of dictionaries by a value of the dictionary in Python?,"The 
sorted()
 function takes a 
key=
 parameter


newlist = sorted(list_to_be_sorted, key=lambda d: d['name'])



Alternatively, you can use 
operator.itemgetter
 instead of defining the function yourself


from operator import itemgetter
newlist = sorted(list_to_be_sorted, key=itemgetter('name'))



For completeness, add 
reverse=True
 to sort in descending order


newlist = sorted(list_to_be_sorted, key=itemgetter('name'), reverse=True)


","The provided text shows how to sort a list using a key function with `sorted()` and `list.sort()`,  but it doesn't give a direct example of sorting a list of dictionaries by a dictionary value.
"
How do I get the last element of a list?,"some_list[-1]
 is the shortest and most Pythonic.


In fact, you can do much more with this syntax. The 
some_list[-n]
 syntax gets the nth-to-last element. So 
some_list[-1]
 gets the last element, 
some_list[-2]
 gets the second to last, etc, all the way down to 
some_list[-len(some_list)]
, which gives you the first element.


You can also set list elements in this way. For instance:


>>> some_list = [1, 2, 3]
>>> some_list[-1] = 5 # Set the last element
>>> some_list[-2] = 3 # Set the second to last element
>>> some_list
[1, 3, 5]



Note that getting a list item by index will raise an 
IndexError
 if the expected item doesn't exist. This means that 
some_list[-1]
 will raise an exception if 
some_list
 is empty, because an empty list can't have a last element.

","`list.pop()` removes and returns the last item in the list.  If the list is empty, it raises an `IndexError`.
"
How to leave/exit/deactivate a Python virtualenv,"Usually, activating a virtualenv gives you a shell function named:


$ deactivate



which puts things back to normal.


I have just looked specifically again at the code for 
virtualenvwrapper
, and, yes, it too supports 
deactivate
 as the way to escape from all virtualenvs.


If you are trying to leave an 
Anaconda
 environment, the command depends upon your version of 
conda
. Recent versions (like 4.6) install a 
conda
 function directly in your shell, in which case you run:


conda deactivate



Older conda versions instead implement deactivation using a stand-alone script:


source deactivate


","To deactivate a virtual environment, type `deactivate` into your terminal.
"
How do I install pip on Windows?,"Python 3.4+ and 2.7.9+


Good news! 
Python 3.4
 (released March 2014) and 
Python 2.7.9
 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins 
Ruby
, 
Node.js
, 
Haskell
, 
Perl
, 
Go
—almost every other contemporary language with a majority open-source community. Thank you, Python.


If you do find that pip is not available, simply run 
ensurepip
.




On Windows:


py -3 -m ensurepip





Otherwise:


python3 -m ensurepip







Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this 
in the Stack Overflow question 
Does Python have a package/module management system?
.


Python 3 ≤ 3.3 and 2 ≤ 2.7.8


Flying in the face of its 
'batteries included'
 motto, Python ships without a package manager. To make matters worse, Pip was—until recently—ironically difficult to install.


Official instructions


Per 
https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip
:


Download 
get-pip.py
, being careful to save it as a 
.py
 file rather than 
.txt
. Then, run it from the command prompt:


python get-pip.py



You possibly need an administrator command prompt to do this. Follow 
Start a Command Prompt as an Administrator
 (Microsoft TechNet).


This installs the pip package, which (in Windows) contains ...\Scripts\pip.exe that path must be in PATH environment variable to use pip from the command line (see the second part of 'Alternative Instructions' for adding it to your PATH,


Alternative instructions


The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced and prohibitively difficult for newbies.


For our sake, Christoph Gohlke prepares Windows installers (
.msi
) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to:




Install setuptools


Install pip




For me, this installed Pip at 
C:\Python27\Scripts\pip.exe
. Find 
pip.exe
 on your computer, then add its folder (for example, 
C:\Python27\Scripts
) to your path (Start / Edit environment variables). Now you should be able to run 
pip
 from the command line. Try installing a package:


pip install httpie



There you go (hopefully)! Solutions for common problems are given below:


Proxy problems


If you work in an office, you might be behind an HTTP proxy. If so, set the environment variables 
http_proxy
 and 
https_proxy
. Most Python applications (and other free software) respect these. Example syntax:


http://proxy_url:port
http://username:password@proxy_url:port



If you're really unlucky, your proxy might be a Microsoft 
NTLM
 proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. 
http://cntlm.sourceforge.net/


Unable to find vcvarsall.bat


Python modules can be partly written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.




Error: Unable to find vcvarsall.bat




You can fix that by 
installing a C++ compiler
 such as 
MinGW
 or 
Visual C++
. Microsoft actually ships one specifically for use with Python. Or try 
Microsoft Visual C++ Compiler for Python 2.7
.


Often though it's easier to check 
Christoph's site
 for your package.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I parse a string to a float or int?,">>> a = ""545.2222""
>>> float(a)
545.22220000000004
>>> int(float(a))
545


","For integers, use `int()`,  e.g., `int('144') == 144`.  For floating-point numbers, use `float()`, e.g., `float('144') == 144.0`.  These functions interpret numbers as decimal by default.  `int(string, base)` allows specifying the base for conversion.
"
How do I get a substring of a string in Python?,">>> x = ""Hello World!""
>>> x[2:]
'llo World!'
>>> x[:2]
'He'
>>> x[:-2]
'Hello Worl'
>>> x[-2:]
'd!'
>>> x[2:-2]
'llo Worl'



Python calls this concept ""slicing"" and it works on more than just strings. Take a look 
here
 for a comprehensive introduction.

","To get a substring in Python, use string slicing.  For example, `word[0:2]` extracts characters from position 0 (included) to 2 (excluded).  Omitting the first index defaults to 0, and omitting the second defaults to the string's length.  Negative indices count from the end.
"
How do I escape curly-brace ({}) characters characters in a string while using .format?,"You need to double the 
{{
 and 
}}
:


>>> x = "" {{ Hello }} {0} ""
>>> print(x.format(42))
' { Hello } 42 '



Here's the relevant part of the 
Python documentation for format string syntax
:




Format strings contain “replacement fields” surrounded by curly braces 
{}
. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: 
{{
 and 
}}
.



","To escape curly braces in a string using `.format()`, double them: `{{` for an opening brace and `}}` for a closing brace.
"
Check if a given key already exists in a dictionary,"in
 tests for the existence of a key in a 
dict
:


d = {""key1"": 10, ""key2"": 23}

if ""key1"" in d:
    print(""this will execute"")

if ""nonexistent key"" in d:
    print(""this will not"")





Use 
dict.get()
 to provide a default value when the key does not exist:


d = {}

for i in range(100):
    key = i % 10
    d[key] = d.get(key, 0) + 1





To provide a default value for 
every
 key, either use 
dict.setdefault()
 on each assignment:


d = {}

for i in range(100):
    d[i % 10] = d.setdefault(i % 10, 0) + 1    



...or better, use 
defaultdict
 from the 
collections
 module:


from collections import defaultdict

d = defaultdict(int)

for i in range(100):
    d[i % 10] += 1


","Use the `in` keyword.  `key in d` returns `True` if `d` has a key `key`, otherwise `False`.
"
Class (static) variables and methods,"Variables declared inside the class definition, but not inside a method are class or static variables:


>>> class MyClass:
...     i = 3
...
>>> MyClass.i
3 



As @
millerdev
 points out, this creates a class-level 
i
 variable, but this is distinct from any instance-level 
i
 variable, so you could have


>>> m = MyClass()
>>> m.i = 4
>>> MyClass.i, m.i
>>> (3, 4)



This is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.


See 
what the Python tutorial has to say on the subject of classes and class objects
.


@Steve Johnson has already answered regarding 
static methods
, also documented under 
""Built-in Functions"" in the Python Library Reference
.


class C:
    @staticmethod
    def f(arg1, arg2, ...): ...



@beidy recommends 
classmethod
s over staticmethod, as the method then receives the class type as the first argument.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I lowercase a string in Python?,"Use 
str.lower()
:


""Kilometer"".lower()


","Use the `lower()` method.  For example:  `str.lower()` will return a lowercase copy of the string.
"
How to check if an object has an attribute?,"Try 
hasattr()
:


if hasattr(a, 'property'):
    a.property



See 
zweiterlinde's answer
 below, who offers good advice about asking forgiveness! A very pythonic approach!


The general practice in python is that, if the property is likely to be there most of the time, simply call it and either let the exception propagate, or trap it with a try/except block. This will likely be faster than 
hasattr
. If the property is likely to not be there most of the time, or you're not sure, using 
hasattr
 will probably be faster than repeatedly falling into an exception block.

","Use the `hasattr(object, name)` function.  It takes an object and a string (the attribute name) and returns `True` if the attribute exists, `False` otherwise.
"
How to print without a newline or space,"In Python 3, you can use the 
sep=
 and 
end=
 parameters of the 
print
 function:


To not add a newline to the end of the string:


print('.', end='')



To not add a space between all the function arguments you want to print:


print('a', 'b', 'c', sep='')



You can pass any string to either parameter, and you can use both parameters at the same time.


If you are having trouble with buffering, you can flush the output by adding 
flush=True
 keyword argument:


print('.', end='', flush=True)



Python 2.6 and 2.7


From Python 2.6 you can either import the 
print
 function from Python 3 using the 
__future__
 module
:


from __future__ import print_function



which allows you to use the Python 3 solution above.


However, note that the 
flush
 keyword is not available in the version of the 
print
 function imported from 
__future__
 in Python 2; it only works in Python 3, more specifically 3.3 and later. In earlier versions you'll still need to flush manually with a call to 
sys.stdout.flush()
. You'll also have to rewrite all other print statements in the file where you do this import.


Or you can use 
sys.stdout.write()


import sys
sys.stdout.write('.')



You may also need to call


sys.stdout.flush()



to ensure 
stdout
 is flushed immediately.

","I'm sorry, I couldn't find relevant information in the provided context.
"
Calling a function of a module by using its name (a string),"Given a module 
foo
 with method 
bar
:


import foo
bar = getattr(foo, 'bar')
result = bar()



getattr
 can similarly be used on class instance bound methods, module-level methods, class methods... the list goes on.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How can I randomly select (choose) an item from a list (get a random element)?,"Use 
random.choice()
:


import random

foo = ['a', 'b', 'c', 'd', 'e']
print(random.choice(foo))



For 
cryptographically secure
 random choices (e.g., for generating a passphrase from a wordlist), use 
secrets.choice()
:


import secrets

foo = ['battery', 'correct', 'horse', 'staple']
print(secrets.choice(foo))



secrets
 is new in Python 3.6. On older versions of Python you can use the 
random.SystemRandom
 class:


import random

secure_random = random.SystemRandom()
print(secure_random.choice(foo))


","Use the `choice(S)` function, where `S` is your sequence (list).
"
How to remove an element from a list by index,"Use 
del
 and specify the index of the element you want to delete:


>>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> del a[-1]
>>> a
[0, 1, 2, 3, 4, 5, 6, 7, 8]



Also supports slices:


>>> del a[2:4]
>>> a
[0, 1, 4, 5, 6, 7, 8, 9]



Here
 is the section from the tutorial.

","Use `list.pop([i])` to remove the item at index `i` from the list and return it.  If no index is specified, it removes and returns the last item.  An `IndexError` is raised if the list is empty or the index is out of range.
"
Delete a column from a Pandas DataFrame,"As you've guessed, the right syntax is 


del df['column_name']



It's difficult to make 
del df.column_name
 work simply as the result of syntactic limitations in Python. 
del df[name]
 gets translated to 
df.__delitem__(name)
 under the covers by Python.

","I'm sorry, I couldn't find relevant information in the provided context.
"
How do I get the number of elements in a list (length of a list) in Python?,"The 
len()
 function can be used with several different types in Python - both built-in types and library types. For example:


>>> len([1, 2, 3])
3


","The provided text mentions `PyList_Size()` as a function to get the length of a list in Python's C API.  However, it does not describe how to obtain the length of a list within standard Python code.
"
How do I pad a string with zeros?,"To pad strings:


>>> n = '4'
>>> print(n.zfill(3))
004



To pad numbers:


>>> n = 4
>>> print(f'{n:03}') # Preferred method, python >= 3.6
004
>>> print('%03d' % n)
004
>>> print(format(n, '03')) # python >= 2.6
004
>>> print('{0:03d}'.format(n))  # python >= 2.6 + python 3
004
>>> print('{foo:03d}'.format(foo=n))  # python >= 2.6 + python 3
004
>>> print('{:03d}'.format(n))  # python >= 2.7 + python3
004



String formatting documentation
.

","The `str.zfill()` method pads a numeric string on the left with zeros.  It handles plus and minus signs.  For example, `'12'.zfill(5)` returns `'00012'` and `'-3.14'.zfill(7)` returns `'-003.14'`.
"
Delete an element from a dictionary,"The 
del
 statement
 removes an element:


del d[key]



Note that this mutates the existing dictionary, so the contents of the dictionary changes for anybody else who has a reference to the same instance. To return a 
new
 dictionary, make a copy of the dictionary:


def removekey(d, key):
    r = dict(d)
    del r[key]
    return r



The 
dict()
 constructor makes a 
shallow copy
. To make a deep copy, see the 
copy
 module
.




Note that making a copy for every dict 
del
/assignment/etc. means you're going from constant time to linear time, and also using linear space. For small dicts, this is not a problem. But if you're planning to make lots of copies of large dicts, you probably want a different data structure, like a HAMT (as described in 
this answer
).

","Use the `del` keyword.  For example: `del my_dictionary[key_to_delete]`.
"
"What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc?","This is my personal recommendation for beginners:
 start by learning 
virtualenv
 and 
pip
, tools which work with both Python 2 and 3 and in a variety of situations, and pick up other tools once you start needing them.


Now on to answer the question: what is the difference between these similarly named things: venv, virtualenv, etc?


PyPI packages not in the standard library:




virtualenv
 is a very popular tool that creates isolated Python environments for Python libraries. If you're not familiar with this tool, I highly recommend learning it, as it is a very useful tool.


It works by installing a bunch of files in a directory (eg: 
env/
), and then modifying the 
PATH
 environment variable to prefix it with a custom 
bin
 directory (eg: 
env/bin/
). An exact copy of the 
python
 or 
python3
 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using 
pip
.




pyenv
 is used to isolate Python versions. For example, you may want to test your code against Python 2.7, 3.6, 3.7 and 3.8, so you'll need a way to switch between them. Once activated, it prefixes the 
PATH
 environment variable with 
~/.pyenv/shims
, where there are special files matching the Python commands (
python
, 
pip
). These are not copies of the Python-shipped commands; they are special scripts that decide on the fly which version of Python to run based on the 
PYENV_VERSION
 environment variable, or the 
.python-version
 file, or the 
~/.pyenv/version
 file. 
pyenv
 also makes the process of downloading and installing multiple Python versions easier, using the command 
pyenv install
.




pyenv-virtualenv
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to allow you to use 
pyenv
 and 
virtualenv
 at the same time conveniently. However, if you're using Python 3.3 or later, 
pyenv-virtualenv
 will try to run 
python -m venv
 if it is available, instead of 
virtualenv
. You can use 
virtualenv
 and 
pyenv
 together without 
pyenv-virtualenv
, if you don't want the convenience features.




virtualenvwrapper
 is a set of extensions to 
virtualenv
 (see 
docs
). It gives you commands like 
mkvirtualenv
, 
lssitepackages
, and especially 
workon
 for switching between different 
virtualenv
 directories. This tool is especially useful if you want multiple 
virtualenv
 directories.




pyenv-virtualenvwrapper
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to conveniently integrate 
virtualenvwrapper
 into 
pyenv
.




pipenv
 aims to combine 
Pipfile
, 
pip
 and 
virtualenv
 into one command on the command-line. The 
virtualenv
 directory typically gets placed in 
~/.local/share/virtualenvs/XXX
, with 
XXX
 being a hash of the path of the project directory. This is different from 
virtualenv
, where the directory is typically in the current working directory. 
pipenv
 is meant to be used when developing Python applications (as opposed to libraries). There are alternatives to 
pipenv
, such as 
poetry
, which I won't list here since this question is only about the packages that are similarly named.






Standard library:




pyvenv
 (not to be confused with 
pyenv
 in the previous section) is a script shipped with Python 3.3 to 3.7. It was 
removed from Python 3.8
 as it had problems (not to mention the confusing name). Running 
python3 -m venv
 has exactly the same effect as 
pyvenv
.




venv
 is a package shipped with Python 3, which you can run using 
python3 -m venv
 (although for some reason some distros separate it out into a separate distro package, such as 
python3-venv
 on Ubuntu/Debian). It serves the same purpose as 
virtualenv
, but only has a subset of its features (
see a comparison here
). 
virtualenv
 continues to be more popular than 
venv
, especially since the former supports both Python 2 and 3.





","`venv` is the standard Python tool (since Python 3.3) for creating virtual environments; since Python 3.4, it automatically installs `pip`.  `virtualenv` is a third-party alternative that predates `venv` and supports older Python versions which may lack `venv` or its automatic `pip` installation.
"
Determine the type of an object?,"There are two built-in functions that help you identify the type of an object. You can use 
type()
  if you need the exact type of an object, and 
isinstance()
 to 
check
 an object’s type against something. Usually, you want to use 
isinstance()
 most of the times since it is very robust and also supports type inheritance.




To get the actual type of an object, you use the built-in 
type()
 function. Passing an object as the only parameter will return the type object of that object:


>>> type([]) is list
True
>>> type({}) is dict
True
>>> type('') is str
True
>>> type(0) is int
True



This of course also works for custom types:


>>> class Test1 (object):
        pass
>>> class Test2 (Test1):
        pass
>>> a = Test1()
>>> b = Test2()
>>> type(a) is Test1
True
>>> type(b) is Test2
True



Note that 
type()
 will only return the immediate type of the object, but won’t be able to tell you about type inheritance.


>>> type(b) is Test1
False



To cover that, you should use the 
isinstance
 function. This of course also works for built-in types:


>>> isinstance(b, Test1)
True
>>> isinstance(b, Test2)
True
>>> isinstance(a, Test1)
True
>>> isinstance(a, Test2)
False
>>> isinstance([], list)
True
>>> isinstance({}, dict)
True



isinstance()
 is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using 
isinstance()
 is preferred over 
type()
.


The second parameter of 
isinstance()
 also accepts a tuple of types, so it’s possible to check for multiple types at once. 
isinstance
 will then return true, if the object is of any of those types:


>>> isinstance([], (tuple, list, set))
True


","The `type()` function returns an object's type, which is itself an object.  This type is unchangeable.
"
How do I count the occurrences of a list item?,"If you only want a single item's count, use the 
count
 method:


>>> [1, 2, 3, 4, 1, 4, 1].count(1)
3





Important: this is very slow if you are counting 
multiple
 different items


Each 
count
 call goes over the entire list of 
n
 elements. Calling 
count
 in a loop 
n
 times means 
n * n
 total checks, which can be catastrophic for performance.


If you want to count multiple items, use 
Counter
, which only does 
n
 total checks.

","Use the `list.count(x)` method.  It returns the number of times `x` appears in the list.
"
How to check if the string is empty in Python?,"Empty strings are ""falsy"" (
python 2
 or 
python 3
 reference), which means they are considered false in a Boolean context, so you can just do this:


if not myString:



This is the preferred way if you know that your variable is a string.  If your variable could also be some other type then you should use:


if myString == """":



See the documentation on 
Truth Value Testing
 for other values that are false in Boolean contexts.

","The provided text shows that `"""".splitlines()` returns an empty list `[]` for an empty string.  This can be used to check for emptiness.
"
Why is reading lines from stdin much slower in C++ than Python?,"tl;dr: Because of different default settings in C++ requiring more system calls.


By default, 
cin
 is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:


std::ios_base::sync_with_stdio(false);



Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the 
FILE*
 based 
stdio
 and 
iostreams
 often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:


int myvalue1;
cin >> myvalue1;
int myvalue2;
scanf(""%d"",&myvalue2);



If more input was read by 
cin
 than it actually needed, then the second integer value wouldn't be available for the 
scanf
 function, which has its own independent buffer.  This would lead to unexpected results.


To avoid this, by default, streams are synchronized with 
stdio
.  One common way to achieve this is to have 
cin
 read each character one at a time as needed using 
stdio
 functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.


Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the 
sync_with_stdio
 method. From this link (emphasis added):




If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, 
which may be considerably faster in some cases
.



","I'm sorry, I couldn't find relevant information in the provided context.
"
Why is it string.join(list) instead of list.join(string)?,"It's because any iterable can be joined (e.g, list, tuple, dict, set), but its contents and the ""joiner"" 
must be
 strings.


For example:


'_'.join(['welcome', 'to', 'stack', 'overflow'])
'_'.join(('welcome', 'to', 'stack', 'overflow'))



'welcome_to_stack_overflow'



Using something other than strings will raise the following error:




TypeError: sequence item 0: expected str instance, int found



","Strings are immutable.  `string.join(list)` is more efficient because it avoids creating many intermediate string objects during concatenation, unlike the inefficient approach of repeatedly concatenating strings directly.
"
How do I append to a file?,"Set the mode in 
open()
 to 
""a""
 (append) instead of 
""w""
 (write):


with open(""test.txt"", ""a"") as myfile:
    myfile.write(""appended text"")



The 
documentation
 lists all the available modes.

","To append to an existing file, open the file using the 'a' mode.  Any data written will be added to the end of the file.
"
Is there a way to run Python on Android?,"One way is to use 
Kivy
:




Open source Python library for rapid development of applications
  that make use of innovative user interfaces, such as multi-touch apps.








Kivy runs on Linux, Windows, OS X, Android and iOS. You can run the same [python] code on all supported platforms.




Kivy Showcase app
 

","Yes, but only in embedded mode.  This involves writing a native Android application, embedding a Python interpreter using libpython, and invoking Python code using the Python embedding API.  There's no way to run a Python executable or interact with a Python REPL directly on Android.
"
