question,expected,generated,BLEU,ROUGE-L,METEOR,BERTScore_F1,Cosine_Similarity
"What does the ""yield"" keyword do in Python?","To understand what 
yield
 does, you must understand what 
generators
 are. And before you can understand generators, you must understand 
iterables
.


Iterables


When you create a list, you can read its items one by one. Reading its items one by one is called iteration:


>>> mylist = [1, 2, 3]
>>> for i in mylist:
...    print(i)
1
2
3



mylist
 is an 
iterable
. When you use a list comprehension, you create a list, and so an iterable:


>>> mylist = [x*x for x in range(3)]
>>> for i in mylist:
...    print(i)
0
1
4



Everything you can use ""
for... in...
"" on is an iterable; 
lists
, 
strings
, files...


These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.


Generators


Generators are 
iterators
, a kind of iterable 
you can only iterate over once
. Generators do not store all the values in memory, 
they generate the values on the fly
:


>>> mygenerator = (x*x for x in range(3))
>>> for i in mygenerator:
...    print(i)
0
1
4



It is just the same except you used 
()
 instead of 
[]
. BUT, you 
cannot
 perform 
for i in mygenerator
 a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end after calculating 4, one by one.


Yield


yield
 is a keyword that is used like 
return
, except the function will return a generator.


>>> def create_generator():
...    mylist = range(3)
...    for i in mylist:
...        yield i*i
...
>>> mygenerator = create_generator() # create a generator
>>> print(mygenerator) # mygenerator is an object!


>>> for i in mygenerator:
...     print(i)
0
1
4



Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.


To master 
yield
, you must understand that 
when you call the function, the code you have written in the function body does not run.
 The function only returns the generator object, this is a bit tricky.


Then, your code will continue from where it left off each time 
for
 uses the generator.


Now the hard part:


The first time the 
for
 calls the generator object created from your function, it will run the code in your function from the beginning until it hits 
yield
, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting 
yield
. That can be because the loop has come to an end, or because you no longer satisfy an 
""if/else""
.




Your code explained


Generator:


# Here you create the method of the node object that will return the generator
def _get_child_candidates(self, distance, min_dist, max_dist):

    # Here is the code that will be called each time you use the generator object:

    # If there is still a child of the node object on its left
    # AND if the distance is ok, return the next child
    if self._leftchild and distance - max_dist < self._median:
        yield self._leftchild

    # If there is still a child of the node object on its right
    # AND if the distance is ok, return the next child
    if self._rightchild and distance + max_dist >= self._median:
        yield self._rightchild

    # If the function arrives here, the generator will be considered empty
    # There are no more than two values: the left and the right children



Caller:


# Create an empty list and a list with the current object reference
result, candidates = list(), [self]

# Loop on candidates (they contain only one element at the beginning)
while candidates:

    # Get the last candidate and remove it from the list
    node = candidates.pop()

    # Get the distance between obj and the candidate
    distance = node._get_dist(obj)

    # If the distance is ok, then you can fill in the result
    if distance <= max_dist and distance >= min_dist:
        result.extend(node._values)

    # Add the children of the candidate to the candidate's list
    # so the loop will keep running until it has looked
    # at all the children of the children of the children, etc. of the candidate
    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))

return result



This code contains several smart parts:




The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, 
candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
 exhausts all the values of the generator, but 
while
 keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.




The 
extend()
 method is a list object method that expects an iterable and adds its values to the list.






Usually, we pass a list to it:


>>> a = [1, 2]
>>> b = [3, 4]
>>> a.extend(b)
>>> print(a)
[1, 2, 3, 4]



But in your code, it gets a generator, which is good because:




You don't need to read the values twice.


You may have a lot of children and you don't want them all stored in memory.




And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...


You can stop here, or read a little bit to see an advanced use of a generator:


Controlling a generator exhaustion


>>> class Bank(): # Let's create a bank, building ATMs
...    crisis = False
...    def create_atm(self):
...        while not self.crisis:
...            yield ""$100""
>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want
>>> corner_street_atm = hsbc.create_atm()
>>> print(corner_street_atm.next())
$100
>>> print(corner_street_atm.next())
$100
>>> print([corner_street_atm.next() for cash in range(5)])
['$100', '$100', '$100', '$100', '$100']
>>> hsbc.crisis = True # Crisis is coming, no more money!
>>> print(corner_street_atm.next())


>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs
>>> print(wall_street_atm.next())


>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty
>>> print(corner_street_atm.next())


>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business
>>> for cash in brand_new_atm:
...    print cash
$100
$100
$100
$100
$100
$100
$100
$100
$100
...



Note:
 For Python 3, use
print(corner_street_atm.__next__())
 or 
print(next(corner_street_atm))


It can be useful for various things like controlling access to a resource.


Itertools, your best friend


The 
itertools
 module contains special functions to manipulate iterables. Ever wish to duplicate a generator?
Chain two generators? Group values in a nested list with a one-liner? 
Map / Zip
 without creating another list?


Then just 
import itertools
.


An example? Let's see the possible orders of arrival for a four-horse race:


>>> horses = [1, 2, 3, 4]
>>> races = itertools.permutations(horses)
>>> print(races)


>>> print(list(itertools.permutations(horses)))
[(1, 2, 3, 4),
 (1, 2, 4, 3),
 (1, 3, 2, 4),
 (1, 3, 4, 2),
 (1, 4, 2, 3),
 (1, 4, 3, 2),
 (2, 1, 3, 4),
 (2, 1, 4, 3),
 (2, 3, 1, 4),
 (2, 3, 4, 1),
 (2, 4, 1, 3),
 (2, 4, 3, 1),
 (3, 1, 2, 4),
 (3, 1, 4, 2),
 (3, 2, 1, 4),
 (3, 2, 4, 1),
 (3, 4, 1, 2),
 (3, 4, 2, 1),
 (4, 1, 2, 3),
 (4, 1, 3, 2),
 (4, 2, 1, 3),
 (4, 2, 3, 1),
 (4, 3, 1, 2),
 (4, 3, 2, 1)]



Understanding the inner mechanisms of iteration


Iteration is a process implying iterables (implementing the 
__iter__()
 method) and iterators (implementing the 
__next__()
 method).
Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.


There is more about it in this article about 
how 
for
 loops work
.

","Answer: The `yield` keyword is used in generator functions to return an iterator that produces a stream of values. When a `yield` expression is executed, the generator outputs a value, similar to a `return` statement, but the generator's state of execution is suspended and local variables are preserved. Execution resumes on the next call to the generator's `__next__()` method. Any function containing a `yield` keyword is considered a generator function, as detected by Python's bytecode compiler.

References: [1]
",4.876931248250324e-162,0.055744391570360305,0.024812327499192675,0.5100706815719604,0.6723107
"What does if __name__ == ""__main__"": do?","Short Answer


It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:




If you import the guardless script in another script (e.g. 
import my_script_without_a_name_eq_main_guard
), then the latter script will trigger the former to run 
at import time
 and 
using the second script's command line arguments
. This is almost always a mistake.




If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.






Long Answer


To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.


Whenever the Python interpreter reads a source file, it does two things:




it sets a few special variables like 
__name__
, and then




it executes all of the code found in the file.






Let's see how this works and how it relates to your question about the 
__name__
 checks we always see in Python scripts.


Code Sample


Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called 
foo.py
.


# Suppose this is foo.py.

print(""before import"")
import math

print(""before function_a"")
def function_a():
    print(""Function A"")

print(""before function_b"")
def function_b():
    print(""Function B {}"".format(math.sqrt(100)))

print(""before __name__ guard"")
if __name__ == '__main__':
    function_a()
    function_b()
print(""after __name__ guard"")



Special Variables


When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the 
__name__
 variable.


When Your Module Is the Main Program


If you are running your module (the source file) as the main program, e.g.


python foo.py



the interpreter will assign the hard-coded string 
""__main__""
 to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when run as the main program.
__name__ = ""__main__"" 



When Your Module Is Imported By Another


On the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:


# Suppose this is in some other main program.
import foo



The interpreter will search for your 
foo.py
 file (along with searching for a few other variants), and prior to executing that module, it will assign the name 
""foo""
 from the import statement to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when it's imported from another module.
__name__ = ""foo""



Executing the Module's Code


After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.


Always




It prints the string 
""before import""
 (without quotes).




It loads the 
math
 module and assigns it to a variable called 
math
. This is equivalent to replacing 
import math
 with the following (note that 
__import__
 is a low-level function in Python that takes a string and triggers the actual import):






# Find and load a module given its string name, ""math"",
# then assign it to a local variable called math.
math = __import__(""math"")





It prints the string 
""before function_a""
.




It executes the 
def
 block, creating a function object, then assigning that function object to a variable called 
function_a
.




It prints the string 
""before function_b""
.




It executes the second 
def
 block, creating another function object, then assigning it to a variable called 
function_b
.




It prints the string 
""before __name__ guard""
.






Only When Your Module Is the Main Program




If your module is the main program, then it will see that 
__name__
 was indeed set to 
""__main__""
 and it calls the two functions, printing the strings 
""Function A""
 and 
""Function B 10.0""
.




Only When Your Module Is Imported by Another




(
instead
) If your module is not the main program but was imported by another one, then 
__name__
 will be 
""foo""
, not 
""__main__""
, and it'll skip the body of the 
if
 statement.




Always




It will print the string 
""after __name__ guard""
 in both situations.




Summary


In summary, here's what'd be printed in the two cases:


# What gets printed if foo is the main program
before import
before function_a
before function_b
before __name__ guard
Function A
Function B 10.0
after __name__ guard



# What gets printed if foo is imported as a regular module
before import
before function_a
before function_b
before __name__ guard
after __name__ guard



Why Does It Work This Way?


You might naturally wonder why anybody would want this.  Well, sometimes you want to write a 
.py
 file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:




Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.




Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing 
.py
 files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.




Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.






Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. ""Running"" the script is a side effect of importing the script's module.


Food for Thought




Question: Can I have multiple 
__name__
 checking blocks?  Answer: it's strange to do so, but the language won't stop you.




Suppose the following is in 
foo2.py
.  What happens if you say 
python foo2.py
 on the command-line? Why?






# Suppose this is foo2.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo2 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
if __name__ == ""__main__"":
    print(""m1"")
    function_a()
    print(""m2"")
print(""t2"")
      





Now, figure out what will happen in 
foo3.py
 (having removed the 
__name__
 check):




# Suppose this is foo3.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo3 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
print(""m1"")
function_a()
print(""m2"")
print(""t2"")





What will this do when used as a script?  When imported as a module?




# Suppose this is in foo4.py
__name__ = ""__main__""

def bar():
    print(""bar"")
    
print(""before __name__ guard"")
if __name__ == ""__main__"":
    bar()
print(""after __name__ guard"")


","Answer: It is a conditional statement that checks if the module is running in the top-level environment. If the condition is true, the code inside the block will execute. This is useful for code intended for script use only, such as parsing command-line arguments, to prevent it from running when the module is imported into another module.

References: [3]
",1.0477643319046775e-162,0.05192761605035405,0.020800832033281327,0.5189509987831116,0.5283151
Does Python have a ternary conditional operator?,"Yes, it was 
added
 in version 2.5. The expression syntax is:


a if condition else b



First 
condition
 is evaluated, then exactly one of either 
a
 or 
b
 is evaluated and returned based on the 
Boolean
 value of 
condition
. If 
condition
 evaluates to 
True
, then 
a
 is evaluated and returned but 
b
 is ignored, or else when 
b
 is evaluated and returned but 
a
 is ignored.


This allows short-circuiting because when 
condition
 is true only 
a
 is evaluated and 
b
 is not evaluated at all, but when 
condition
 is false only 
b
 is evaluated and 
a
 is not evaluated at all.


For example:


>>> 'true' if True else 'false'
'true'
>>> 'true' if False else 'false'
'false'



Note that conditionals are an 
expression
, not a 
statement
. This means you can't use 
statements
 such as 
pass
, or assignments with 
=
 (or ""augmented"" assignments like 
+=
), within a conditional 
expression
:


>>> pass if False else pass
  File ""
"", line 1
    pass if False else pass
         ^
SyntaxError: invalid syntax

>>> # Python parses this as `x = (1 if False else y) = 2`
>>> # The `(1 if False else x)` part is actually valid, but
>>> # it can't be on the left-hand side of `=`.
>>> x = 1 if False else y = 2
  File ""
"", line 1
SyntaxError: cannot assign to conditional expression

>>> # If we parenthesize it instead...
>>> (x = 1) if False else (y = 2)
  File ""
"", line 1
    (x = 1) if False else (y = 2)
       ^
SyntaxError: invalid syntax



(In 3.8 and above, the 
:=
 ""walrus"" operator allows simple assignment of values 
as an expression
, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)


Similarly, because it is an expression, the 
else
 part is 
mandatory
:


# Invalid syntax: we didn't specify what the value should be if the 
# condition isn't met. It doesn't matter if we can verify that
# ahead of time.
a if True



You can, however, use conditional expressions to assign a variable like so:


x = a if True else b



Or for example to return a value:


# Of course we should just use the standard library `max`;
# this is just for demonstration purposes.
def my_max(a, b):
    return a if a > b else b



Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will 
do the same thing
 with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to 
do something different
 depending on the condition, then use a normal 
if
 
statement
 instead.




Keep in mind that it's frowned upon by some Pythonistas for several reasons:




The order of the arguments is different from those of the classic 
condition ? a : b
 ternary operator from many other languages (such as 
C
, 
C++
, 
Go
, 
Perl
, 
Ruby
, 
Java
, 
JavaScript
, etc.), which may lead to bugs when people unfamiliar with Python's ""surprising"" behaviour use it (they may reverse the argument order).


Some find it ""unwieldy"", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects).


Stylistic reasons. (Although the 'inline 
if
' can be 
really
 useful, and make your script more concise, it really does complicate your code)




If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, 
x = 4 if b > 8 else 9
 is read aloud as 
x will be 4 if b is greater than 8 otherwise 9
.


Official documentation:




Conditional expressions


Is there an equivalent of C’s ”?:” ternary operator?



","Answer: Yes, Python has a ternary conditional operator. Its syntax is `[on_true] if [expression] else [on_false]`. For example: `x, y = 50, 25` followed by `small = x if x < y else y`.

References: [2, 3]
",2.9847777492861003e-162,0.06163328197226502,0.03407661022247341,0.5397446751594543,0.63329285
What are metaclasses in Python?,"A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.


While in Python you can use arbitrary callables for metaclasses (like 
Jerub
 shows), the better approach is to make it an actual class itself. 
type
 is the usual metaclass in Python. 
type
 is itself a class, and it is its own type. You won't be able to recreate something like 
type
 purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass 
type
.


A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal 
__init__
 and 
__new__
 methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.


When the 
class
 statement is executed, Python first executes the body of the 
class
 statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the 
__metaclass__
 attribute of the class-to-be (if any) or the 
__metaclass__
 global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.


However, metaclasses actually define the 
type
 of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. 
type.__subclasses__()
 is an example of a method on the 
type
 metaclass. You can also define the normal 'magic' methods, like 
__add__
, 
__iter__
 and 
__getattr__
, to implement or change how the class behaves.


Here's an aggregated example of the bits and pieces:


def make_hook(f):
    """"""Decorator to turn 'foo' method into '__foo__'""""""
    f.is_hook = 1
    return f

class MyType(type):
    def __new__(mcls, name, bases, attrs):

        if name.startswith('None'):
            return None

        # Go over attributes and see if they should be renamed.
        newattrs = {}
        for attrname, attrvalue in attrs.iteritems():
            if getattr(attrvalue, 'is_hook', 0):
                newattrs['__%s__' % attrname] = attrvalue
            else:
                newattrs[attrname] = attrvalue

        return super(MyType, mcls).__new__(mcls, name, bases, newattrs)

    def __init__(self, name, bases, attrs):
        super(MyType, self).__init__(name, bases, attrs)

        # classregistry.register(self, self.interfaces)
        print ""Would register class %s now."" % self

    def __add__(self, other):
        class AutoClass(self, other):
            pass
        return AutoClass
        # Alternatively, to autogenerate the classname as well as the class:
        # return type(self.__name__ + other.__name__, (self, other), {})

    def unregister(self):
        # classregistry.unregister(self)
        print ""Would unregister class %s now."" % self

class MyObject:
    __metaclass__ = MyType


class NoneSample(MyObject):
    pass

# Will print ""NoneType None""
print type(NoneSample), repr(NoneSample)

class Example(MyObject):
    def __init__(self, value):
        self.value = value
    @make_hook
    def add(self, other):
        return self.__class__(self.value + other.value)

# Will unregister the class
Example.unregister()

inst = Example(10)
# Will fail with an AttributeError
#inst.unregister()

print inst + inst
class Sibling(MyObject):
    pass

ExampleSibling = Example + Sibling
# ExampleSibling is now a subclass of both Example and Sibling (with no
# content of its own) although it will believe it's called 'AutoClass'
print ExampleSibling
print ExampleSibling.__mro__


","Answer: By default, classes are constructed using `type()`. You can customize the class creation process by passing the `metaclass` keyword argument in the class definition line or by inheriting from an existing class that included such an argument.

References: [2, 3]
",1.1473684710659542e-160,0.05198776758409786,0.03057707442186009,0.5422725081443787,0.5938442
How do I merge two dictionaries in a single expression in Python?,"How can I merge two Python dictionaries in a single expression?


For dictionaries 
x
 and 
y
, their shallowly-merged dictionary 
z
 takes values from 
y
, replacing those from 
x
.




In Python 3.9.0 or greater (released 17 October 2020, 
PEP-584
, 
discussed here
):


z = x | y





In Python 3.5 or greater:


z = {**x, **y}





In Python 2, (or 3.4 or lower) write a function:


def merge_two_dicts(x, y):
    z = x.copy()   # start with keys and values of x
    z.update(y)    # modifies z with keys and values of y
    return z



and now:


z = merge_two_dicts(x, y)







Explanation


Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:


x = {'a': 1, 'b': 2}
y = {'b': 3, 'c': 4}



The desired result is to get a new dictionary (
z
) with the values merged, and the second dictionary's values overwriting those from the first.


>>> z
{'a': 1, 'b': 3, 'c': 4}



A new syntax for this, proposed in 
PEP 448
 and 
available as of Python 3.5
, is


z = {**x, **y}



And it is indeed a single expression.


Note that we can merge in with literal notation as well:


z = {**x, 'foo': 1, 'bar': 2, **y}



and now:


>>> z
{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}



It is now showing as implemented in the 
release schedule for 3.5, PEP 478
, and it has now made its way into the 
What's New in Python 3.5
 document.


However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:


z = x.copy()
z.update(y) # which returns None since it mutates z



In both approaches, 
y
 will come second and its values will replace 
x
's values, thus 
b
 will point to 
3
 in our final result.


Not yet on Python 3.5, but want a 
single expression


If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a 
single expression
, the most performant while the correct approach is to put it in a function:


def merge_two_dicts(x, y):
    """"""Given two dictionaries, merge them into a new dict as a shallow copy.""""""
    z = x.copy()
    z.update(y)
    return z



and then you have a single expression:


z = merge_two_dicts(x, y)



You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:


def merge_dicts(*dict_args):
    """"""
    Given any number of dictionaries, shallow copy and merge into a new dict,
    precedence goes to key-value pairs in latter dictionaries.
    """"""
    result = {}
    for dictionary in dict_args:
        result.update(dictionary)
    return result



This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries 
a
 to 
g
:


z = merge_dicts(a, b, c, d, e, f, g) 



and key-value pairs in 
g
 will take precedence over dictionaries 
a
 to 
f
, and so on.


Critiques of Other Answers


Don't use what you see in the formerly accepted answer:


z = dict(x.items() + y.items())



In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. 
In Python 3, this will fail
 because you're adding two 
dict_items
 objects together, not two lists -


>>> c = dict(a.items() + b.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'



and you would have to explicitly create them as lists, e.g. 
z = dict(list(x.items()) + list(y.items()))
. This is a waste of resources and computation power.


Similarly, taking the union of 
items()
 in Python 3 (
viewitems()
 in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, 
since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:


>>> c = dict(a.items() | b.items())



This example demonstrates what happens when values are unhashable:


>>> x = {'a': []}
>>> y = {'b': []}
>>> dict(x.items() | y.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unhashable type: 'list'



Here's an example where 
y
 should have precedence, but instead the value from 
x
 is retained due to the arbitrary order of sets:


>>> x = {'a': 2}
>>> y = {'a': 1}
>>> dict(x.items() | y.items())
{'a': 2}



Another hack you should not use:


z = dict(x, **y)



This uses the 
dict
 constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.


Here's an example of the usage being 
remediated in django
.


Dictionaries are intended to take hashable keys (e.g. 
frozenset
s or tuples), but 
this method fails in Python 3 when keys are not strings.


>>> c = dict(a, **b)
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: keyword arguments must be strings



From the 
mailing list
, Guido van Rossum, the creator of the language, wrote:




I am fine with
declaring dict({}, **{1:3}) illegal, since after all it is abuse of
the ** mechanism.




and




Apparently dict(x, **y) is going around as ""cool hack"" for ""call
x.update(y) and return x"". Personally, I find it more despicable than
cool.




It is my understanding (as well as the understanding of the 
creator of the language
) that the intended usage for 
dict(**y)
 is for creating dictionaries for readability purposes, e.g.:


dict(a=1, b=10, c=11)



instead of


{'a': 1, 'b': 10, 'c': 11}



Response to comments




Despite what Guido says, 
dict(x, **y)
 is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.




Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. 
dict
 broke this consistency in Python 2:


>>> foo(**{('a', 'b'): None})
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: foo() keywords must be strings
>>> dict(**{('a', 'b'): None})
{('a', 'b'): None}



This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.


I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.


More comments:




dict(x.items() + y.items())
 is still the most readable solution for Python 2. Readability counts.




My response: 
merge_two_dicts(x, y)
 actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.




{**x, **y}
 does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word ""merging"" these answers describe ""updating one dict with another"", and not merging.




Yes. I must refer you back to the question, which is asking for a 
shallow
 merge of 
two
 dictionaries, with the first's values being overwritten by the second's - in a single expression.


Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:


from copy import deepcopy

def dict_of_dicts_merge(x, y):
    z = {}
    overlapping_keys = x.keys() & y.keys()
    for key in overlapping_keys:
        z[key] = dict_of_dicts_merge(x[key], y[key])
    for key in x.keys() - overlapping_keys:
        z[key] = deepcopy(x[key])
    for key in y.keys() - overlapping_keys:
        z[key] = deepcopy(y[key])
    return z



Usage:


>>> x = {'a':{1:{}}, 'b': {2:{}}}
>>> y = {'b':{10:{}}, 'c': {11:{}}}
>>> dict_of_dicts_merge(x, y)
{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}



Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at 
my answer to the canonical question on a ""Dictionaries of dictionaries merge""
.


Less Performant But Correct Ad-hocs


These approaches are less performant, but they will provide correct behavior.
They will be 
much less
 performant than 
copy
 and 
update
 or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they 
do
 respect the order of precedence (latter dictionaries have precedence)


You can also chain the dictionaries manually inside a 
dict comprehension
:


{k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7



or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):


dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2



itertools.chain
 will chain the iterators over the key-value pairs in the correct order:


from itertools import chain
z = dict(chain(x.items(), y.items())) # iteritems in Python 2



Performance Analysis


I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)


from timeit import repeat
from itertools import chain

x = dict.fromkeys('abcdefg')
y = dict.fromkeys('efghijk')

def merge_two_dicts(x, y):
    z = x.copy()
    z.update(y)
    return z

min(repeat(lambda: {**x, **y}))
min(repeat(lambda: merge_two_dicts(x, y)))
min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
min(repeat(lambda: dict(chain(x.items(), y.items()))))
min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))



In Python 3.8.1, NixOS:


>>> min(repeat(lambda: {**x, **y}))
1.0804965235292912
>>> min(repeat(lambda: merge_two_dicts(x, y)))
1.636518670246005
>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
3.1779992282390594
>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))
2.740647904574871
>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))
4.266070580109954



$ uname -a
Linux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux



Resources on Dictionaries




My explanation of Python's 
dictionary implementation
, updated for 3.6.


Answer on how to add new keys to a dictionary


Mapping two lists into a dictionary


The official Python docs on dictionaries


The Dictionary Even Mightier
 - talk by Brandon Rhodes at Pycon 2017


Modern Python Dictionaries, A Confluence of Great Ideas
 - talk by Raymond Hettinger at Pycon 2017



","I'm sorry, I couldn't find relevant information in the provided context.",2.9431563497382985e-227,0.006113092205807438,0.0022184575669570833,0.3045409917831421,0.020144407
How do I execute a program or call a system command?,"Use 
subprocess.run
:


import subprocess

subprocess.run([""ls"", ""-l""]) 



Another common way is 
os.system
 but you shouldn't use it because it is unsafe if any parts of the command come from outside your program or can contain spaces or other special characters, also 
subprocess.run
 is generally more flexible (you can get the 
stdout
, 
stderr
, the 
""real"" status code
, better 
error handling
, etc.). Even the 
documentation for 
os.system
 recommends using 
subprocess
 instead.


On Python 3.4 and earlier, use 
subprocess.call
 instead of 
.run
:


subprocess.call([""ls"", ""-l""])


","I'm sorry, I couldn't find relevant information in the provided context.
",1.094111069641906e-234,0.038461538461538464,0.023809523809523808,0.34677866101264954,-0.08101575
"How do I create a directory, and any missing parent directories?","On Python ≥ 3.5, use 
pathlib.Path.mkdir
:


from pathlib import Path
Path(""/my/directory"").mkdir(parents=True, exist_ok=True)



For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:


Try 
os.path.exists
, and consider 
os.makedirs
 for the creation.


import os
if not os.path.exists(directory):
    os.makedirs(directory)



As noted in comments and elsewhere, there's a race condition – if the directory is created between the 
os.path.exists
 and the 
os.makedirs
 calls, the 
os.makedirs
 will fail with an 
OSError
. Unfortunately, blanket-catching 
OSError
 and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.


One option would be to trap the 
OSError
 and examine the embedded error code (see 
Is there a cross-platform way of getting information from Python’s OSError
):


import os, errno

try:
    os.makedirs(directory)
except OSError as e:
    if e.errno != errno.EEXIST:
        raise



Alternatively, there could be a second 
os.path.exists
, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled. 


Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.


Modern versions of Python improve this code quite a bit, both by exposing 
FileExistsError
 (in 3.3+)...


try:
    os.makedirs(""path/to/directory"")
except FileExistsError:
    # directory already exists
    pass



...and by allowing 
a keyword argument to 
os.makedirs
 called 
exist_ok
 (in 3.2+).


os.makedirs(""path/to/directory"", exist_ok=True)  # succeeds even if directory exists.


","Answer: To create a directory and any necessary parent directories, you can use the `Path.mkdir()` method with the `parents` parameter set to `True`.

References: [3]
",6.155556904217695e-236,0.06528189910979229,0.029959003468937245,0.5015262365341187,0.65553766
How to access the index value in a 'for' loop?,"Use the built-in function 
enumerate()
:


for idx, x in enumerate(xs):
    print(idx, x)



It is 
non-pythonic
 to manually index via 
for i in range(len(xs)): x = xs[i]
 or manually manage an additional state variable.


Check out 
PEP 279
 for more.

","I'm sorry, I couldn't find relevant information in the provided context.
",8.52038995356238e-233,0.06896551724137931,0.05154639175257732,0.360601007938385,-0.019040432
How do I make a flat list out of a list of lists?,"A list of lists named 
xss
 can be flattened using a nested 
list comprehension
:


flat_list = [
    x
    for xs in xss
    for x in xs
]



The above is equivalent to:


flat_list = []

for xs in xss:
    for x in xs:
        flat_list.append(x)



Here is the corresponding function:


def flatten(xss):
    return [x for xs in xss for x in xs]



This is the fastest method.
As evidence, using the 
timeit
 module in the standard library, we see:


$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' '[x for xs in xss for x in xs]'
10000 loops, best of 3: 143 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'sum(xss, [])'
1000 loops, best of 3: 969 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'reduce(lambda xs, ys: xs + ys, xss)'
1000 loops, best of 3: 1.1 msec per loop



Explanation: the methods based on 
+
 (including the implied use in 
sum
) are, of necessity, 
O(L**2)
 when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of M items each: the first M items are copied back and forth 
L-1
 times, the second M items 
L-2
 times, and so on; total number of copies is M times the sum of x for x from 1 to L excluded, i.e., 
M * (L**2)/2
.


The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.

","Answer: You can flatten a list of lists using a list comprehension with two 'for' clauses. For example: `[num for elem in vec for num in elem]` where `vec = [[1,2,3], [4,5,6], [7,8,9]]` would result in `[1, 2, 3, 4, 5, 6, 7, 8, 9]`.

References: [2]
",1.1355584258496767e-80,0.18181818181818185,0.07437804565273146,0.60737144947052,0.595888
What is the difference between @staticmethod and @classmethod in Python?,"Maybe a bit of example code will help: Notice the difference in the call signatures of 
foo
, 
class_foo
 and 
static_foo
:


class A(object):
    def foo(self, x):
        print(f""executing foo({self}, {x})"")

    @classmethod
    def class_foo(cls, x):
        print(f""executing class_foo({cls}, {x})"")

    @staticmethod
    def static_foo(x):
        print(f""executing static_foo({x})"")

a = A()



Below is the usual way an object instance calls a method. The object instance, 
a
, is implicitly passed as the first argument.


a.foo(1)
# executing foo(<__main__.A object at 0xb7dbef0c>, 1)





With classmethods
, the class of the object instance is implicitly passed as the first argument instead of 
self
.


a.class_foo(1)
# executing class_foo(
, 1)



You can also call 
class_foo
 using the class. In fact, if you define something to be
a classmethod, it is probably because you intend to call it from the class rather than from a class instance. 
A.foo(1)
 would have raised a TypeError, but 
A.class_foo(1)
 works just fine:


A.class_foo(1)
# executing class_foo(
, 1)



One use people have found for class methods is to create 
inheritable alternative constructors
.




With staticmethods
, neither 
self
 (the object instance) nor  
cls
 (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:


a.static_foo(1)
# executing static_foo(1)

A.static_foo('hi')
# executing static_foo(hi)



Staticmethods are used to group functions which have some logical connection with a class to the class.




foo
 is just a function, but when you call 
a.foo
 you don't just get the function,
you get a ""partially applied"" version of the function with the object instance 
a
 bound as the first argument to the function. 
foo
 expects 2 arguments, while 
a.foo
 only expects 1 argument.


a
 is bound to 
foo
. That is what is meant by the term ""bound"" below:


print(a.foo)
# 
>



With 
a.class_foo
, 
a
 is not bound to 
class_foo
, rather the class 
A
 is bound to 
class_foo
.


print(a.class_foo)
# 
>



Here, with a staticmethod, even though it is a method, 
a.static_foo
 just returns
a good 'ole function with no arguments bound. 
static_foo
 expects 1 argument, and

a.static_foo
 expects 1 argument too.


print(a.static_foo)
# 




And of course the same thing happens when you call 
static_foo
 with the class 
A
 instead.


print(A.static_foo)
# 



","Answer: A static method doesn't receive an implicit first argument, and can be called either on the class or on an instance.

References: [1]
",3.5815075624216056e-161,0.058823529411764705,0.02546905468706128,0.4934704303741455,0.5906938
How slicing in Python works,"The syntax is:


a[start:stop]  # items start through stop-1
a[start:]      # items start through the rest of the array
a[:stop]       # items from the beginning through stop-1
a[:]           # a copy of the whole array



There is also the 
step
 value, which can be used with any of the above:


a[start:stop:step] # start through not past stop, by step



The key point to remember is that the 
:stop
 value represents the first value that is 
not
 in the selected slice. So, the difference between 
stop
 and 
start
 is the number of elements selected (if 
step
 is 1, the default).


The other feature is that 
start
 or 
stop
 may be a 
negative
 number, which means it counts from the end of the array instead of the beginning. So:


a[-1]    # last item in the array
a[-2:]   # last two items in the array
a[:-2]   # everything except the last two items



Similarly, 
step
 may be a negative number:


a[::-1]    # all items in the array, reversed
a[1::-1]   # the first two items, reversed
a[:-3:-1]  # the last two items, reversed
a[-3::-1]  # everything except the last two items, reversed



Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for 
a[:-2]
 and 
a
 only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.


Relationship with the 
slice
 object


A 
slice
 object
 can represent a slicing operation, i.e.:


a[start:stop:step]



is equivalent to:


a[slice(start, stop, step)]



Slice objects also behave slightly differently depending on the number of arguments, similar to 
range()
, i.e. both 
slice(stop)
 and 
slice(start, stop[, step])
 are supported.
To skip specifying a given argument, one might use 
None
, so that e.g. 
a[start:]
 is equivalent to 
a[slice(start, None)]
 or 
a[::-1]
 is equivalent to 
a[slice(None, None, -1)]
.


While the 
:
-based notation is very helpful for simple slicing, the explicit use of 
slice()
 objects simplifies the programmatic generation of slicing.

","Answer: Slicing allows you to obtain substrings. When slicing, the start index is included, and the end index is excluded. Omitted first indices default to zero, and omitted second indices default to the size of the string being sliced.

References: [2, 3]
",5.6455823848589845e-158,0.07481296758104738,0.040659588886379036,0.5054771304130554,0.39859498
How to find the index for a given item in a list?,">>> [""foo"", ""bar"", ""baz""].index(""bar"")
1



See 
the documentation
 for the built-in 
.index()
 method of the list:




list.index(x[, start[, end]])



Return zero-based index in the list of the first item whose value is equal to 
x
. Raises a 
ValueError
 if there is no such item.


The optional arguments 
start
 and 
end
 are interpreted as in the 
slice notation
 and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.




Caveats


Linear time-complexity in list length


An 
index
 call checks every element of the list in order, until it finds a match. If the list is long, and if there is no guarantee that the value will be near the beginning, this can slow down the code.


This problem can only be completely avoided by using a different data structure. However, if the element is known to be within a certain part of the list, the 
start
 and 
end
 parameters can be used to narrow the search.


For example:


>>> import timeit
>>> timeit.timeit('l.index(999_999)', setup='l = list(range(0, 1_000_000))', number=1000)
9.356267921015387
>>> timeit.timeit('l.index(999_999, 999_990, 1_000_000)', setup='l = list(range(0, 1_000_000))', number=1000)
0.0004404920036904514



The second call is orders of magnitude faster, because it only has to search through 10 elements, rather than all 1 million.


Only the index of the 
first match
 is returned


A call to 
index
 searches through the list in order until it finds a match, and 
stops there.
 If there could be more than one occurrence of the value, and all indices are needed, 
index
 cannot solve the problem:


>>> [1, 1].index(1) # the `1` index is not found.
0



Instead, use a 
list comprehension or generator expression to do the search
, with 
enumerate
 to get indices
:


>>> # A list comprehension gives a list of indices directly:
>>> [i for i, e in enumerate([1, 2, 1]) if e == 1]
[0, 2]
>>> # A generator comprehension gives us an iterable object...
>>> g = (i for i, e in enumerate([1, 2, 1]) if e == 1)
>>> # which can be used in a `for` loop, or manually iterated with `next`:
>>> next(g)
0
>>> next(g)
2



The list comprehension and generator expression techniques still work if there is only one match, and are more generalizable.


Raises an exception if there is no match


As noted in the documentation above, using 
.index
 will raise an exception if the searched-for value is not in the list:


>>> [1, 1].index(2)
Traceback (most recent call last):
  File ""
"", line 1, in 

ValueError: 2 is not in list



If this is a concern, either 
explicitly check first
 using 
item in my_list
, or handle the exception with 
try
/
except
 as appropriate.


The explicit check is simple and readable, but it must iterate the list a second time. See 
What is the EAFP principle in Python?
 for more guidance on this choice.

","Answer: To find the index of an item in a list, use the `list.index(x)` method, where `x` is the item you are looking for. This returns the zero-based index of the first occurrence of the item. You can also specify optional `start` and `end` arguments to limit the search to a subsequence of the list. If the item is not found, a ValueError is raised.

References: [1]
",0.0003863595879615598,0.13126079447322972,0.07044166797993956,0.6072283387184143,0.7834866
Iterating over dictionaries using 'for' loops,"key
 is just a variable name.  


for key in d:



will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:


For Python 3.x:


for key, value in d.items():



For Python 2.x:


for key, value in d.iteritems():



To test for yourself, change the word 
key
 to 
poop
.


In Python 3.x, 
iteritems()
 was replaced with simply 
items()
, which returns a set-like view backed by the dict, like 
iteritems()
 but even better. 
This is also available in 2.7 as 
viewitems()
. 


The operation 
items()
 will work for both 2 and 3, but in 2 it will return a list of the dictionary's 
(key, value)
 pairs, which will not reflect changes to the dict that happen after the 
items()
 call. If you want the 2.x behavior in 3.x, you can call 
list(d.items())
.

","Answer: When you loop through dictionaries, you can get the key and its corresponding value at the same time using the items() method.

References: [3]
",5.27271183814656e-157,0.13259668508287295,0.080901146345574,0.5334550738334656,0.7231802
How can I iterate over rows in a Pandas DataFrame?,"DataFrame.iterrows
 is a generator which yields both the index and row (as a Series):


import pandas as pd

df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})
df = df.reset_index()  # make sure indexes pair with number of rows

for index, row in df.iterrows():
    print(row['c1'], row['c2'])



10 100
11 110
12 120





Obligatory disclaimer from the 
documentation




Iterating through pandas objects is generally 
slow
. In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches:




Look for a 
vectorized
 solution: many operations can be performed using built-in methods or NumPy functions, (boolean) indexing, …


When you have a function that cannot work on the full DataFrame/Series at once, it is better to use 
apply()
 instead of iterating over the values. See the docs on 
function application
.


If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop with cython or numba. See the 
enhancing performance
 section for some examples of this approach.






Other answers in this thread delve into greater depth on alternatives to iter* functions if you are interested to learn more.

","I'm sorry, I couldn't find relevant information in the provided context.",7.08494894434863e-239,0.01886792452830189,0.013245033112582781,0.3445732295513153,-0.061013475
How can I use a global variable in a function?,"You can use a global variable within other functions by declaring it as 
global
 
within each function that assigns a value to it
:


globvar = 0

def set_globvar_to_one():
    global globvar    # Needed to modify global copy of globvar
    globvar = 1

def print_globvar():
    print(globvar)     # No need for global declaration to read value of globvar

set_globvar_to_one()
print_globvar()       # Prints 1



Since it's unclear whether 
globvar = 1
 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the 
global
 keyword.


See other answers if you want to share a global variable across modules.

","Answer: To access a global variable within a function, you need to declare it using the `global` keyword inside the function before using it. This tells Python that you are referring to the variable in the outer scope, not creating a new local variable.

References: [1]
",0.019887093947788734,0.2012578616352201,0.1490066225165563,0.5622058510780334,0.7159242
How do I get the current time in Python?,"Use 
datetime
:


>>> import datetime
>>> now = datetime.datetime.now()
>>> now
datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)
>>> print(now)
2009-01-06 15:08:24.789150



For just the clock time without the date:


>>> now.time()
datetime.time(15, 8, 24, 78915)
>>> print(now.time())
15:08:24.789150





To save typing, you can import the 
datetime
 object from the 
datetime
 module:


>>> from datetime import datetime



Then remove the prefix 
datetime.
 from all of the above.

","Answer: You can get the current local date and time by using the `datetime.now()` method. If you want the current UTC date and time, you can use `datetime.now(timezone.utc)`.

References: [1, 2, 3]
",1.3505193719544285e-155,0.1592920353982301,0.11087086631430765,0.5751866698265076,0.5384042
"How to catch multiple exceptions in one line? (in the ""except"" block)","From 
Python Documentation
:




An except clause may name multiple exceptions as a parenthesized tuple, for example




except (IDontLikeYouException, YouAreBeingMeanException) as e:
    pass



Or, for Python 2 only:


except (IDontLikeYouException, YouAreBeingMeanException), e:
    pass



Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using 
as
.

","Answer: You can name multiple exceptions in a single except clause by using a parenthesized tuple. For example: `except (RuntimeError, TypeError, NameError):`.

References: [2, 3]
",5.0745183255699413e-79,0.23655913978494625,0.23978157916080414,0.5946263670921326,0.73450136
How do I copy a file?,"shutil
 has many methods you can use. One of which is:


import shutil

shutil.copyfile(src, dst)

# 2nd option
shutil.copy(src, dst)  # dst can be a folder; use shutil.copy2() to preserve timestamp





Copy the contents of the file named 
src
 to a file named 
dst
. Both 
src
 and 
dst
 need to be the entire filename of the files, including path.


The destination location must be writable; otherwise, an 
IOError
 exception will be raised.


If 
dst
 already exists, it will be replaced.


Special files such as character or block devices and pipes cannot be copied with this function.


With 
copy
, 
src
 and 
dst
 are path names given as 
str
s.




Another 
shutil
 method to look at is 
shutil.copy2()
. It's similar but preserves more metadata (e.g. time stamps).


If you use 
os.path
 operations, use 
copy
 rather than 
copyfile
. 
copyfile
 will only accept strings.

","Answer: The context mentions how to copy a file in section 4.4.2

References: [1]
",5.631996742961866e-159,0.049079754601226995,0.03665728922058699,0.4013616144657135,0.44735715
What is __init__.py for?,"It used to be a required part of a package (
old, pre-3.3 ""regular package""
, not 
newer 3.3+ ""namespace package""
).


Here's the documentation.




Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an 
__init__.py
 file. When a regular package is imported, this 
__init__.py
 file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The 
__init__.py
 file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.




But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without 
__init__.py
.

","I'm sorry, I couldn't find relevant information in the provided context.
",4.420706784645626e-160,0.025157232704402514,0.016869095816464237,0.3559444844722748,0.073415324
Convert bytes to a string in Python 3,"Decode the 
bytes
 object
 to produce a string:


>>> b""abcde"".decode(""utf-8"")
'abcde'



The above example 
assumes
 that the 
bytes
 object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!

","I'm sorry, I couldn't find relevant information in the provided context.
",9.331270692956627e-233,0.07142857142857142,0.038535645472061654,0.3758108913898468,0.018337017
What is the difference between __str__ and __repr__?,"

Alex Martelli summarized well
 but, surprisingly, was too succinct.


First, let me reiterate the main points in 
Alex
’s post:




The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)


__repr__
 goal is to be unambiguous


__str__
 goal is to be readable


Container’s 
__str__
 uses contained objects’ 
__repr__




Default implementation is useless


This is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default for 
__repr__
 which would act like:


return ""%s(%r)"" % (self.__class__, self.__dict__)



Or in new f-string formatting:


return f""{self.__class__!s}({self.__dict__!r})""



would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if 
__repr__
 is defined, and 
__str__
 is not, the object will behave as though 
__str__=__repr__
.


This means, in simple terms: almost every object you implement should have a functional 
__repr__
 that’s usable for understanding the object. Implementing 
__str__
 is optional: do that if you need a “pretty print” functionality (for example, used by a report generator).


The goal of 
__repr__
 is to be unambiguous


Let me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a


log(INFO, ""I am in the weird function and a is"", a, ""and b is"", b, ""but I got a null C — using default"", default_c)



But you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work. This is why the “eval” thing comes up: if you have enough information so 
eval(repr(c))==c
, that means you know everything there is to know about 
c
. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about 
c
 anyway. I usually use an eval-like format: 
""MyClass(this=%r,that=%r)"" % (self.this,self.that)
. It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.


Note: I used 
%r
 above, not 
%s
. You always want to use 
repr()
 [or 
%r
 formatting character, equivalently] inside 
__repr__
 implementation, or you’re defeating the goal of repr. You want to be able to differentiate 
MyClass(3)
 and 
MyClass(""3"")
.


The goal of 
__str__
 is to be readable


Specifically, it is not intended to be unambiguous — notice that 
str(3)==str(""3"")
. Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be ""2010/4/12 15:35:22"", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement.


Container’s 
__str__
 uses contained objects’ 
__repr__


This seems surprising, doesn’t it? It is a little, but how readable would it be if it used their 
__str__
?


[moshe is, 3, hello
world, this is a list, oh I don't know, containing just 4 elements]



Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you’re printing a list, just


print(""["" + "", "".join(lst) + ""]"")



(you can probably also figure out what to do about dictionaries).


Summary


Implement 
__repr__
 for any class you implement. This should be second nature. Implement 
__str__
 if you think it would be useful to have a string version which errs on the side of readability.

","Answer: `__repr__` is used to compute the “official” string representation of an object, and if at all possible, should look like a valid Python expression that could be used to recreate an object with the same value. `__str__` is used to compute the “informal” or nicely printable string representation of an object. There is no expectation that `__str__` return a valid Python expression: a more convenient or concise representation can be used.

References: [2]
",9.750309142686711e-159,0.07852760736196318,0.04350467344247757,0.5451562404632568,0.6643071
How do I select rows from a DataFrame based on column values?,"To select rows whose column value equals a scalar, 
some_value
, use 
==
:


df.loc[df['column_name'] == some_value]



To select rows whose column value is in an iterable, 
some_values
, use 
isin
:


df.loc[df['column_name'].isin(some_values)]



Combine multiple conditions with 
&
:


df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]



Note the parentheses. Due to Python's 
operator precedence rules
, 
&
 binds more tightly than 
<=
 and 
>=
. Thus, the parentheses in the last example are necessary. Without the parentheses


df['column_name'] >= A & df['column_name'] <= B



is parsed as


df['column_name'] >= (A & df['column_name']) <= B



which results in a 
Truth value of a Series is ambiguous error
.




To select rows whose column value 
does not equal
 
some_value
, use 
!=
:


df.loc[df['column_name'] != some_value]



The 
isin
 returns a boolean Series, so to select rows whose value is 
not
 in 
some_values
, negate the boolean Series using 
~
:


df = df.loc[~df['column_name'].isin(some_values)] # .loc is not in-place replacement





For example,


import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
#      A      B  C   D
# 0  foo    one  0   0
# 1  bar    one  1   2
# 2  foo    two  2   4
# 3  bar  three  3   6
# 4  foo    two  4   8
# 5  bar    two  5  10
# 6  foo    one  6  12
# 7  foo  three  7  14

print(df.loc[df['A'] == 'foo'])



yields


     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14





If you have multiple values you want to include, put them in a
list (or more generally, any iterable) and use 
isin
:


print(df.loc[df['B'].isin(['one','three'])])



yields


     A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14





Note, however, that if you wish to do this many times, it is more efficient to
make an index first, and then use 
df.loc
:


df = df.set_index(['B'])
print(df.loc['one'])



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
one  foo  6  12



or, to include multiple values from the index use 
df.index.isin
:


df.loc[df.index.isin(['one','two'])]



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
two  foo  2   4
two  foo  4   8
two  bar  5  10
one  foo  6  12


","I'm sorry, I couldn't find relevant information in the provided context.
",3.558293467298744e-171,0.008602150537634409,0.006378713322398395,0.2706823945045471,0.018170033
How can I add new keys to a dictionary?,"You create a new key/value pair on a dictionary by assigning a value to that key


d = {'key': 'value'}
print(d)  # {'key': 'value'}

d['mynewkey'] = 'mynewvalue'

print(d)  # {'key': 'value', 'mynewkey': 'mynewvalue'}



If the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.

","Answer: To add new keys to a dictionary, you can use the assignment operator with the syntax `d[key] = value`.

References: [3]
",2.8071012967838865e-232,0.2,0.11614401858304296,0.5491893291473389,0.77516985
Does Python have a string 'contains' substring method?,"Use the 
in
 operator
:


if ""blah"" not in somestring: 
    continue



Note: This is case-sensitive.

","I'm sorry, I couldn't find relevant information in the provided context.
",8.269750081803823e-232,0.07142857142857144,0.07692307692307691,0.3905266523361206,-0.005423583
How can I delete a file or folder in Python?,"Use one of these methods:




pathlib.Path.unlink()
 removes a file or symbolic link.




pathlib.Path.rmdir()
 removes an empty directory.




shutil.rmtree()
 deletes a directory and all its contents.








On Python 3.3 and below, you can use these methods instead of the 
pathlib
 ones:




os.remove()
 removes a file.




os.unlink()
 removes a symbolic link.




os.rmdir()
 removes an empty directory.





","Answer: To delete a file, use `Path.unlink()`. To delete a directory, use `Path.rmdir()`, but note that the directory must be empty. To remove directories recursively, you can use `os.removedirs()`. There is also an example implementation of `shutil.rmtree()` that walks the tree bottom-up and uses `Path.unlink()` to delete files and `Path.rmdir()` to delete directories.

References: [1, 2, 3]
",1.292216806096361e-78,0.25196850393700787,0.398575487012987,0.6553160548210144,0.82571495
"""Least Astonishment"" and the Mutable Default Argument","Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are 
first-class objects
, and not only a piece of code.


As soon as you think of it this way, then it completely makes sense: a function is an 
object
 being evaluated on its definition; default parameters are kind of 
""member data""
 and therefore their state may change from one call to the other - exactly as in any other object.


In any case, the Effbot (
Fredrik Lundh
) has a very nice explanation of the reasons for this behavior in 
Default Parameter Values in Python
. I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.8333210793296512e-236,0.027972027972027975,0.022421524663677125,0.41124412417411804,-0.031156603
What does ** (double star/asterisk) and * (star/asterisk) do for parameters?,"The 
*args
 and 
**kwargs
 are common idioms to allow an arbitrary number of arguments to functions, as described in the section 
more on defining functions
 in the Python tutorial.


The 
*args
 will give you all positional arguments 
as a tuple
:


def foo(*args):
    for a in args:
        print(a)        

foo(1)
# 1

foo(1, 2, 3)
# 1
# 2
# 3



The 
**kwargs
 will give you all
keyword arguments as a dictionary:


def bar(**kwargs):
    for a in kwargs:
        print(a, kwargs[a])  

bar(name='one', age=27)
# name one
# age 27



Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:


def foo(kind, *args, bar=None, **kwargs):
    print(kind, args, bar, kwargs)

foo(123, 'a', 'b', apple='red')
# 123 ('a', 'b') None {'apple': 'red'}



It is also possible to use this the other way around:


def foo(a, b, c):
    print(a, b, c)

obj = {'b':10, 'c':'lee'}

foo(100, **obj)
# 100 10 lee



Another usage of the 
*l
 idiom is to 
unpack argument lists
 when calling a function.


def foo(bar, lee):
    print(bar, lee)

baz = [1, 2]

foo(*baz)
# 1 2



In Python 3 it is possible to use 
*l
 on the left side of an assignment (
Extended Iterable Unpacking
), though it gives a list instead of a tuple in this context:


first, *rest = [1, 2, 3, 4]
# first = 1
# rest = [2, 3, 4]



Also Python 3 adds a new semantic (refer 
PEP 3102
):


def func(arg1, arg2, arg3, *, kwarg1, kwarg2):
    pass



Such function accepts only 3 positional arguments, and everything after 
*
 can only be passed as keyword arguments.


Note:


A Python 
dict
, semantically used for keyword argument passing, is arbitrarily ordered. However, in Python 3.6+, keyword arguments are guaranteed to remember insertion order.
""The order of elements in 
**kwargs
 now corresponds to the order in which keyword arguments were passed to the function."" - 
What’s New In Python 3.6
.
In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, and this becomes standard in Python 3.7.

","Answer: Based on the context, * precedes an iterable to pass elements as positional arguments, while ** precedes a dictionary to pass values as keyword arguments.

References: [1]",3.734110910130644e-83,0.06970509383378015,0.03804368471035138,0.49157172441482544,0.4696763
How can I access environment variables in Python?,"Environment variables are accessed through 
os.environ
:


import os
print(os.environ['HOME'])



To see a list of all environment variables:


print(os.environ)





If a key is not present, attempting to access it will raise a 
KeyError
. To avoid this:


# Returns `None` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST'))

# Returns `default_value` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST', default_value))

# Returns `default_value` if the key doesn't exist
print(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))


","I'm sorry, I couldn't find relevant information in the provided context.
",6.74043217109484e-234,0.037383177570093455,0.024654832347140037,0.31025832891464233,0.03430532
How do I sort a dictionary by value?,"Python 3.7+ or CPython 3.6


Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but 
it's an implementation detail
.


>>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



or


>>> dict(sorted(x.items(), key=lambda item: item[1]))
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



Older Python


It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.


For instance,


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(1))



sorted_x
 will be a list of tuples sorted by the second element in each tuple. 
dict(sorted_x) == x
.


And for those wishing to sort on keys instead of values:


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(0))



In Python3 since 
unpacking is not allowed
 we can use


x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=lambda kv: kv[1])



If you want the output as a dict, you can use 
collections.OrderedDict
:


import collections

sorted_dict = collections.OrderedDict(sorted_x)


","Answer: Both `list.sort()` and `sorted()` accept a `key` parameter. You can pass a function to this parameter that will be called on each list element before comparisons are made. This function takes a single argument and returns a key to be used for sorting.

References: [1, 2, 3]
",8.105878929938094e-157,0.10793650793650794,0.06828090932682068,0.5365753173828125,0.54369605
How do I clone a list so that it doesn't change unexpectedly after assignment?,"new_list = my_list
 doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both 
new_list
 and 
my_list
 refer to the same list after the assignment.


To actually copy the list, you have several options:




You can use the built-in 
list.copy()
 method (available since Python 3.3):


new_list = old_list.copy()





You can slice it:


new_list = old_list[:]



Alex Martelli
's opinion (at least 
back in 2007
) about this is, that 
it is a weird syntax and it does not make sense to use it ever
. ;) (In his opinion, the next one is more readable).




You can use the built-in 
list()
 constructor:


new_list = list(old_list)





You can use generic 
copy.copy()
:


import copy
new_list = copy.copy(old_list)



This is a little slower than 
list()
 because it has to find out the datatype of 
old_list
 first.




If you need to copy the elements of the list as well, use generic 
copy.deepcopy()
:


import copy
new_list = copy.deepcopy(old_list)



Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).






Example:


import copy

class Foo(object):
    def __init__(self, val):
         self.val = val

    def __repr__(self):
        return f'Foo({self.val!r})'

foo = Foo(1)

a = ['foo', foo]
b = a.copy()
c = a[:]
d = list(a)
e = copy.copy(a)
f = copy.deepcopy(a)

# edit orignal list and instance 
a.append('baz')
foo.val = 5

print(f'original: {a}\nlist.copy(): {b}\nslice: {c}\nlist(): {d}\ncopy: {e}\ndeepcopy: {f}')



Result:


original: ['foo', Foo(5), 'baz']
list.copy(): ['foo', Foo(5)]
slice: ['foo', Foo(5)]
list(): ['foo', Foo(5)]
copy: ['foo', Foo(5)]
deepcopy: ['foo', Foo(1)]


","Answer: To create a copy of a list, use `L[:]`. Replicating a list with `*` only creates references to the existing objects.

References: [1]
",2.9661959272516347e-159,0.0729483282674772,0.036639201557981574,0.5076051950454712,0.64631486
How do I pass a variable by reference?,"Arguments are 
passed by assignment
. The rationale behind this is twofold:




the parameter passed in is actually a 
reference
 to an object (but the reference is passed by value)


some data types are mutable, but others aren't




So:




If you pass a 
mutable
 object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object. 


If you pass an 
immutable
 object to a method, you still can't rebind the outer reference, and you can't even mutate the object.




To make it even more clear, let's have some examples. 


List - a mutable type


Let's try to modify the list that was passed to a method:


def try_to_change_list_contents(the_list):
    print('got', the_list)
    the_list.append('four')
    print('changed to', the_list)

outer_list = ['one', 'two', 'three']

print('before, outer_list =', outer_list)
try_to_change_list_contents(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['one', 'two', 'three']
got ['one', 'two', 'three']
changed to ['one', 'two', 'three', 'four']
after, outer_list = ['one', 'two', 'three', 'four']



Since the parameter passed in is a reference to 
outer_list
, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.


Now let's see what happens when we try to change the reference that was passed in as a parameter:


def try_to_change_list_reference(the_list):
    print('got', the_list)
    the_list = ['and', 'we', 'can', 'not', 'lie']
    print('set to', the_list)

outer_list = ['we', 'like', 'proper', 'English']

print('before, outer_list =', outer_list)
try_to_change_list_reference(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['we', 'like', 'proper', 'English']
got ['we', 'like', 'proper', 'English']
set to ['and', 'we', 'can', 'not', 'lie']
after, outer_list = ['we', 'like', 'proper', 'English']



Since the 
the_list
 parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The 
the_list
 was a copy of the 
outer_list
 reference, and we had 
the_list
 point to a new list, but there was no way to change where 
outer_list
 pointed.


String - an immutable type


It's immutable, so there's nothing we can do to change the contents of the string


Now, let's try to change the reference


def try_to_change_string_reference(the_string):
    print('got', the_string)
    the_string = 'In a kingdom by the sea'
    print('set to', the_string)

outer_string = 'It was many and many a year ago'

print('before, outer_string =', outer_string)
try_to_change_string_reference(outer_string)
print('after, outer_string =', outer_string)



Output:


before, outer_string = It was many and many a year ago
got It was many and many a year ago
set to In a kingdom by the sea
after, outer_string = It was many and many a year ago



Again, since the 
the_string
 parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The 
the_string
 was a copy of the 
outer_string
 reference, and we had 
the_string
 point to a new string, but there was no way to change where 
outer_string
 pointed.


I hope this clears things up a little.


EDIT:
 It's been noted that this doesn't answer the question that @David originally asked, ""Is there something I can do to pass the variable by actual reference?"". Let's work on that.


How do we get around this?


As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:


def return_a_whole_new_string(the_string):
    new_string = something_to_do_with_the_old_string(the_string)
    return new_string

# then you could call it like
my_string = return_a_whole_new_string(my_string)



If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:


def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):
    new_string = something_to_do_with_the_old_string(stuff_to_change[0])
    stuff_to_change[0] = new_string

# then you could call it like
wrapper = [my_string]
use_a_wrapper_to_simulate_pass_by_reference(wrapper)

do_something_with(wrapper[0])



Although this seems a little cumbersome.

","Answer: The documentation contains information on how to write a function with output parameters (call by reference).

References: [1, 2]
",1.6057297934698341e-245,0.0267639902676399,0.013801035077630823,0.46074479818344116,0.33712116
Manually raising (throwing) an exception in Python,"

How do I manually throw/raise an exception in Python?




Use the most specific Exception constructor that semantically fits your issue
.


Be specific in your message, e.g.:


raise ValueError('A very specific bad thing happened.')



Don't raise generic exceptions


Avoid raising a generic 
Exception
. To catch it, you'll have to catch all other more specific exceptions that subclass it.


Problem 1: Hiding bugs


raise Exception('I know Python!') # Don't! If you catch, likely to hide bugs.



For example:


def demo_bad_catch():
    try:
        raise ValueError('Represents a hidden bug, do not catch this')
        raise Exception('This is the exception you expect to handle')
    except Exception as error:
        print('Caught this error: ' + repr(error))

>>> demo_bad_catch()
Caught this error: ValueError('Represents a hidden bug, do not catch this',)



Problem 2: Won't catch


And more specific catches won't catch the general exception:


def demo_no_catch():
    try:
        raise Exception('general exceptions not caught by specific handling')
    except ValueError as e:
        print('we will not catch exception: Exception')
 

>>> demo_no_catch()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in demo_no_catch
Exception: general exceptions not caught by specific handling



Best Practices: 
raise
 statement


Instead, use the most specific Exception constructor that semantically fits your issue
.


raise ValueError('A very specific bad thing happened')



which also handily allows an arbitrary number of arguments to be passed to the constructor:


raise ValueError('A very specific bad thing happened', 'foo', 'bar', 'baz') 



These arguments are accessed by the 
args
 attribute on the 
Exception
 object. For example:


try:
    some_code_that_may_raise_our_value_error()
except ValueError as err:
    print(err.args)



prints


('message', 'foo', 'bar', 'baz')    



In Python 2.5, an actual 
message
 attribute was added to 
BaseException
 in favor of encouraging users to subclass Exceptions and stop using 
args
, but 
the introduction of 
message
 and the original deprecation of args has been retracted
.


Best Practices: 
except
 clause


When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:


logger = logging.getLogger(__name__)

try:
    do_something_in_app_that_breaks_easily()
except AppError as error:
    logger.error(error)
    raise                 # just this!
    # raise AppError      # Don't do this, you'll lose the stack trace!



Don't modify your errors... but if you insist.


You can preserve the stacktrace (and error value) with 
sys.exc_info()
, but 
this is way more error prone
 and 
has compatibility problems between Python 2 and 3
, prefer to use a bare 
raise
 to re-raise.


To explain - the 
sys.exc_info()
 returns the type, value, and traceback.


type, value, traceback = sys.exc_info()



This is the syntax in Python 2 - note this is not compatible with Python 3:


raise AppError, error, sys.exc_info()[2] # avoid this.
# Equivalently, as error *is* the second object:
raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]



If you want to, you can modify what happens with your new raise - e.g. setting new 
args
 for the instance:


def error():
    raise ValueError('oops!')

def catch_error_modify_message():
    try:
        error()
    except ValueError:
        error_type, error_instance, traceback = sys.exc_info()
        error_instance.args = (error_instance.args[0] + ' 
',)
        raise error_type, error_instance, traceback



And we have preserved the whole traceback while modifying the args. Note that this is 
not a best practice
 and it is 
invalid syntax
 in Python 3 (making keeping compatibility much harder to work around).


>>> catch_error_modify_message()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in catch_error_modify_message
  File ""
"", line 2, in error
ValueError: oops! 




In 
Python 3
:


raise error.with_traceback(sys.exc_info()[2])



Again: avoid manually manipulating tracebacks. It's 
less efficient
 and more error prone. And if you're using threading and 
sys.exc_info
 you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)


Python 3, Exception chaining


In Python 3, you can chain Exceptions, which preserve tracebacks:


raise RuntimeError('specific message') from error



Be aware:




this 
does
 allow changing the error type raised, and


this is 
not
 compatible with Python 2.




Deprecated Methods:


These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, 
but not the one intended!


Valid in Python 2, but not in Python 3
 is the following:


raise ValueError, 'message' # Don't do this, it's deprecated!



Only 
valid in much older versions of Python
 (2.4 and lower), you may still see people raising strings:


raise 'message' # really really wrong. don't do this.



In all modern versions, this will actually raise a 
TypeError
, because you're not raising a 
BaseException
 type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.


Example Usage


I raise Exceptions to warn consumers of my API if they're using it incorrectly:


def api_func(foo):
    '''foo should be either 'baz' or 'bar'. returns something very useful.'''
    if foo not in _ALLOWED_ARGS:
        raise ValueError('{foo} wrong, use ""baz"" or ""bar""'.format(foo=repr(foo)))



Create your own error types when apropos




""I want to make an error on purpose, so that it would go into the except""




You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:


class MyAppLookupError(LookupError):
    '''raise this when there's a lookup error for my app'''



and usage:


if important_key not in resource_dict and not ok_to_be_missing:
    raise MyAppLookupError('resource is missing, and that is not ok.')


","Answer: You can force a specified exception to occur using the `raise` statement. The argument to `raise` indicates the exception to be raised and can be an exception instance or an exception class (a class that derives from `BaseException`, such as `Exception` or one of its subclasses). If you pass an exception class, it will be implicitly instantiated by calling its constructor with no arguments. For example: `raise NameError('HiThere')` or `raise ValueError`.

References: [1]
",9.466365295154711e-160,0.06384976525821597,0.03789499913576554,0.5705543160438538,0.7442769
Understanding Python super() with __init__() methods,"super()
 lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of 
fun stuff
 can happen. See the 
standard docs on super
 if you haven't already.


Note that 
the syntax changed in Python 3.0
: you can just say 
super().__init__()
 instead of 
super(ChildB, self).__init__()
 which IMO is quite a bit nicer. The standard docs also refer to a 
guide to using 
super()
 which is quite explanatory.

","Answer: The `super()` function returns a proxy object that delegates method calls to a parent or sibling class. This is helpful for accessing inherited methods that have been overridden in a class. When called within a class method, `super()` will use the enclosing class as the type and self as the object.

References: [1]
",2.294817901548723e-155,0.14492753623188406,0.18439895703070516,0.5319742560386658,0.741344
How do I concatenate two lists in Python?,"Use the 
+
 operator to combine the lists:


listone = [1, 2, 3]
listtwo = [4, 5, 6]

joinedlist = listone + listtwo



Output:


>>> joinedlist
[1, 2, 3, 4, 5, 6]



NOTE: This will create a new list with a shallow copy of the items in the first list, followed by a shallow copy of the items in the second list. Use 
copy.deepcopy()
 to get deep copies of lists.

","I'm sorry, I couldn't find relevant information in the provided context.",2.565569994436291e-157,0.05128205128205129,0.05512549847525216,0.3456485867500305,-0.05173756
How do I check if a list is empty?,"if not a:
    print(""List is empty"")



Using the 
implicit booleanness
 of the empty 
list
 is quite Pythonic.

","I'm sorry, I couldn't find relevant information in the provided context.
",5.797920459331518e-232,0.06451612903225808,0.04329004329004329,0.3730942904949188,-0.01036823
How do I make function decorators and chain them together?,"Check out 
the documentation
 to see how decorators work. Here is what you asked for:


from functools import wraps

def makebold(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

def makeitalic(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

@makebold
@makeitalic
def hello():
    return ""hello world""

@makebold
@makeitalic
def log(s):
    return s

print hello()        # returns ""
hello world
""
print hello.__name__ # with functools.wraps() this returns ""hello""
print log('hello')   # returns ""
hello
""


","Answer: You can apply multiple decorators to a function in a nested fashion by listing them one after another above the function definition. For example:

```
@f1(arg)
@f2
def func(): pass
```

This is roughly equivalent to:

```
def func(): pass
func = f1(arg)(f2(func))
```

References: [1]",4.455831202780549e-232,0.09375,0.13808871668403444,0.5578359961509705,0.67755866
How do I split a list into equally-sized chunks?,"Here's a generator that yields evenly-sized chunks:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]



import pprint
pprint.pprint(list(chunks(range(10, 75), 10)))
[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]



For Python 2, using 
xrange
 instead of 
range
:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in xrange(0, len(lst), n):
        yield lst[i:i + n]





Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:


[lst[i:i + n] for i in range(0, len(lst), n)]



For Python 2:


[lst[i:i + n] for i in xrange(0, len(lst), n)]


","Answer: You can use the `grouper` function to collect data into non-overlapping fixed-length chunks. Alternatively, `zip` can be used to split the list into equally sized chunks if the length of the list is divisible by the number of chunks.

References: [1]",5.202531417248969e-233,0.05084745762711864,0.032417412781722756,0.41869428753852844,0.59891844
What is the difference between Python's list methods append and extend?,".append()
 appends a 
single object
 at the end of the list:


>>> x = [1, 2, 3]
>>> x.append([4, 5])
>>> print(x)
[1, 2, 3, [4, 5]]



.extend()
 appends 
multiple objects
 that are taken from inside the specified iterable:


>>> x = [1, 2, 3]
>>> x.extend([4, 5])
>>> print(x)
[1, 2, 3, 4, 5]


","Answer: The `append()` method adds an item to the end of a list. The `extend()` method extends a list by appending all the items from an iterable.

References: [2, 3]
",8.218389637904296e-79,0.26506024096385544,0.1293365083811925,0.6264334917068481,0.8339048
Find the current directory and file's directory,"To get the full path to the directory a Python file is contained in, write this in that file:


import os 
dir_path = os.path.dirname(os.path.realpath(__file__))



(Note that the incantation above won't work if you've already used 
os.chdir()
 to change your current working directory, since the value of the 
__file__
 constant is relative to the current working directory and is not changed by an 
os.chdir()
 call.)




To get the current working directory use 


import os
cwd = os.getcwd()





Documentation references for the modules, constants and functions used above:




The 
os
 and 
os.path
 modules.


The 
__file__
 constant


os.path.realpath(path)
 (returns 
""the canonical path of the specified filename, eliminating any symbolic links encountered in the path""
)


os.path.dirname(path)
 (returns 
""the directory name of pathname 
path
""
)


os.getcwd()
 (returns 
""a string representing the current working directory""
)


os.chdir(path)
 (
""change the current working directory to 
path
""
)



","I'm sorry, I couldn't find relevant information in the provided context.
",3.365485784624206e-160,0.03550295857988166,0.0176678445229682,0.3483196794986725,-0.08213649
"Why is ""1000000000000000 in range(1000000000000001)"" so fast in Python 3?","The Python 3 
range()
 object doesn't produce numbers immediately; it is a smart 
sequence object
 that produces numbers 
on demand
. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.


The object also implements the 
object.__contains__
 hook
, and 
calculates
 if your number is part of its range. Calculating is a (near) constant time operation 
*
. There is never a need to scan through all possible integers in the range.


From the 
range()
 object documentation
:




The advantage of the 
range
 type over a regular 
list
 or 
tuple
 is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the 
start
, 
stop
 and 
step
 values, calculating individual items and subranges as needed).




So at a minimum, your 
range()
 object would do:


class my_range:
    def __init__(self, start, stop=None, step=1, /):
        if stop is None:
            start, stop = 0, start
        self.start, self.stop, self.step = start, stop, step
        if step < 0:
            lo, hi, step = stop, start, -step
        else:
            lo, hi = start, stop
        self.length = 0 if lo > hi else ((hi - lo - 1) // step) + 1

    def __iter__(self):
        current = self.start
        if self.step < 0:
            while current > self.stop:
                yield current
                current += self.step
        else:
            while current < self.stop:
                yield current
                current += self.step

    def __len__(self):
        return self.length

    def __getitem__(self, i):
        if i < 0:
            i += self.length
        if 0 <= i < self.length:
            return self.start + i * self.step
        raise IndexError('my_range object index out of range')

    def __contains__(self, num):
        if self.step < 0:
            if not (self.stop < num <= self.start):
                return False
        else:
            if not (self.start <= num < self.stop):
                return False
        return (num - self.start) % self.step == 0



This is still missing several things that a real 
range()
 supports (such as the 
.index()
 or 
.count()
 methods, hashing, equality testing, or slicing), but should give you an idea.


I also simplified the 
__contains__
 implementation to only focus on integer tests; if you give a real 
range()
 object a non-integer value (including subclasses of 
int
), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original 
Python issue
 that implemented the containment test.




* 
Near
 constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it’s all executed in optimised C code and Python stores integer values in 30-bit chunks, you’d run out of memory before you saw any performance impact due to the size of the integers involved here.

","I'm sorry, I couldn't find relevant information in the provided context.
",6.195710317274865e-174,0.015873015873015872,0.0071723148646225575,0.29339680075645447,-0.056736194
Renaming column names in Pandas,"Just assign it to the 
.columns
 attribute:


>>> df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})
>>> df
   $a  $b
0   1  10
1   2  20

>>> df.columns = ['a', 'b']
>>> df
   a   b
0  1  10
1  2  20


","I'm sorry, I couldn't find relevant information in the provided context.
",8.593391654994864e-233,0.0392156862745098,0.028985507246376815,0.27284303307533264,-0.029637652
"Convert string ""Jun 1 2005 1:33PM"" into datetime","datetime.strptime
 parses an input string in the user-specified format into a 
timezone-naive
 
datetime
 object:


>>> from datetime import datetime
>>> datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')
datetime.datetime(2005, 6, 1, 13, 33)



To obtain a 
date
 object using an existing 
datetime
 object, convert it using 
.date()
:


>>> datetime.strptime('Jun 1 2005', '%b %d %Y').date()
date(2005, 6, 1)





Links:




strptime
 docs: 
Python 2
, 
Python 3




strptime
/
strftime
 format string docs: 
Python 2
, 
Python 3




strftime.org
 format string cheatsheet






Notes:




strptime
 = ""string parse time""


strftime
 = ""string format time""



","I'm sorry, I couldn't find relevant information in the provided context.
",3.4721214186039027e-158,0.036036036036036036,0.03103267022480996,0.28436216711997986,0.043053076
How can I remove a key from a Python dictionary?,"To delete a key regardless of whether it is in the dictionary, use the two-argument form of 
dict.pop()
:


my_dict.pop('key', None)



This will return 
my_dict[key]
 if 
key
 exists in the dictionary, and 
None
 otherwise. If the second parameter is not specified (i.e. 
my_dict.pop('key')
) and 
key
 does not exist, a 
KeyError
 is raised.


To delete a key that is guaranteed to exist, you can also use


del my_dict['key']



This will raise a 
KeyError
 if the key is not in the dictionary.

","Answer: To remove a key from a dictionary, use `del d[key]`. This will remove `d[key]` from the dictionary `d`. If the key is not in the dictionary, it will raise a `KeyError`. Another method is `pop(key[, default])`. If key is in the dictionary, remove it and return its value, else return default. If default is not given and key is not in the dictionary, a KeyError is raised.

References: [1]
",0.17749433206121892,0.32727272727272727,0.37883728646780856,0.6893410086631775,0.8779596
How to upgrade all Python packages with pip,"There isn't a built-in flag yet. Starting with pip version 22.3, the 
--outdated
 and 
--format=freeze
 have become 
mutually exclusive
. Use Python, to parse the JSON output:


pip --disable-pip-version-check list --outdated --format=json | python -c ""import json, sys; print('\n'.join([x['name'] for x in json.load(sys.stdin)]))"" | xargs -n1 pip install -U



If you are using 
pip<22.3
 you can use:


pip list --outdated --format=freeze | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U



For older versions of 
pip
:


pip freeze --local | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U







The 
grep
 is to skip editable (""-e"") package definitions, as suggested by 
@jawache
. (Yes, you could replace 
grep
+
cut
 with 
sed
 or 
awk
 or 
perl
 or...).




The 
-n1
 flag for 
xargs
 prevents stopping everything if updating one package fails (thanks 
@andsens
).








Note:
 there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!

","Answer: To upgrade a Python package using pip, you need to run the following command: python -m pip install --upgrade SomePackage.

References: [1]
",8.74187585401394e-158,0.08080808080808081,0.0599462451285893,0.5173834562301636,0.5244062
How to sort a list of dictionaries by a value of the dictionary in Python?,"The 
sorted()
 function takes a 
key=
 parameter


newlist = sorted(list_to_be_sorted, key=lambda d: d['name'])



Alternatively, you can use 
operator.itemgetter
 instead of defining the function yourself


from operator import itemgetter
newlist = sorted(list_to_be_sorted, key=itemgetter('name'))



For completeness, add 
reverse=True
 to sort in descending order


newlist = sorted(list_to_be_sorted, key=itemgetter('name'), reverse=True)


","Answer: To sort a list of dictionaries by a value, you can use the `sorted()` function with a `key` parameter. The `key` parameter should be a function that takes a single dictionary as an argument and returns the value you want to sort by. A lambda function is commonly used for this purpose.

References: [2]
",1.646564940793981e-78,0.18487394957983194,0.18192764490175692,0.5208635330200195,0.66841704
How do I get the last element of a list?,"some_list[-1]
 is the shortest and most Pythonic.


In fact, you can do much more with this syntax. The 
some_list[-n]
 syntax gets the nth-to-last element. So 
some_list[-1]
 gets the last element, 
some_list[-2]
 gets the second to last, etc, all the way down to 
some_list[-len(some_list)]
, which gives you the first element.


You can also set list elements in this way. For instance:


>>> some_list = [1, 2, 3]
>>> some_list[-1] = 5 # Set the last element
>>> some_list[-2] = 3 # Set the second to last element
>>> some_list
[1, 3, 5]



Note that getting a list item by index will raise an 
IndexError
 if the expected item doesn't exist. This means that 
some_list[-1]
 will raise an exception if 
some_list
 is empty, because an empty list can't have a last element.

","I'm sorry, I couldn't find relevant information in the provided context.
",2.1760038868888633e-236,0.025157232704402514,0.02331002331002331,0.3398226797580719,-0.06758008
How to leave/exit/deactivate a Python virtualenv,"Usually, activating a virtualenv gives you a shell function named:


$ deactivate



which puts things back to normal.


I have just looked specifically again at the code for 
virtualenvwrapper
, and, yes, it too supports 
deactivate
 as the way to escape from all virtualenvs.


If you are trying to leave an 
Anaconda
 environment, the command depends upon your version of 
conda
. Recent versions (like 4.6) install a 
conda
 function directly in your shell, in which case you run:


conda deactivate



Older conda versions instead implement deactivation using a stand-alone script:


source deactivate


","Answer: You can deactivate a Python virtual environment by typing `deactivate` in your shell.

References: [1]
",4.356043509282008e-157,0.11111111111111109,0.08672942317422837,0.549150824546814,0.60606354
How do I install pip on Windows?,"Python 3.4+ and 2.7.9+


Good news! 
Python 3.4
 (released March 2014) and 
Python 2.7.9
 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins 
Ruby
, 
Node.js
, 
Haskell
, 
Perl
, 
Go
—almost every other contemporary language with a majority open-source community. Thank you, Python.


If you do find that pip is not available, simply run 
ensurepip
.




On Windows:


py -3 -m ensurepip





Otherwise:


python3 -m ensurepip







Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this 
in the Stack Overflow question 
Does Python have a package/module management system?
.


Python 3 ≤ 3.3 and 2 ≤ 2.7.8


Flying in the face of its 
'batteries included'
 motto, Python ships without a package manager. To make matters worse, Pip was—until recently—ironically difficult to install.


Official instructions


Per 
https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip
:


Download 
get-pip.py
, being careful to save it as a 
.py
 file rather than 
.txt
. Then, run it from the command prompt:


python get-pip.py



You possibly need an administrator command prompt to do this. Follow 
Start a Command Prompt as an Administrator
 (Microsoft TechNet).


This installs the pip package, which (in Windows) contains ...\Scripts\pip.exe that path must be in PATH environment variable to use pip from the command line (see the second part of 'Alternative Instructions' for adding it to your PATH,


Alternative instructions


The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced and prohibitively difficult for newbies.


For our sake, Christoph Gohlke prepares Windows installers (
.msi
) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to:




Install setuptools


Install pip




For me, this installed Pip at 
C:\Python27\Scripts\pip.exe
. Find 
pip.exe
 on your computer, then add its folder (for example, 
C:\Python27\Scripts
) to your path (Start / Edit environment variables). Now you should be able to run 
pip
 from the command line. Try installing a package:


pip install httpie



There you go (hopefully)! Solutions for common problems are given below:


Proxy problems


If you work in an office, you might be behind an HTTP proxy. If so, set the environment variables 
http_proxy
 and 
https_proxy
. Most Python applications (and other free software) respect these. Example syntax:


http://proxy_url:port
http://username:password@proxy_url:port



If you're really unlucky, your proxy might be a Microsoft 
NTLM
 proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. 
http://cntlm.sourceforge.net/


Unable to find vcvarsall.bat


Python modules can be partly written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.




Error: Unable to find vcvarsall.bat




You can fix that by 
installing a C++ compiler
 such as 
MinGW
 or 
Visual C++
. Microsoft actually ships one specifically for use with Python. Or try 
Microsoft Visual C++ Compiler for Python 2.7
.


Often though it's easier to check 
Christoph's site
 for your package.

","Answer: To install pip in versions of Python prior to Python 3.4, see section 3.1.

References: [2]
",8.07523037848779e-245,0.03322259136212625,0.015466575012888813,0.48039087653160095,0.6625333
How do I parse a string to a float or int?,">>> a = ""545.2222""
>>> float(a)
545.22220000000004
>>> int(float(a))
545


","Answer: To convert a string to an integer, use the `int()` constructor, for example `int('144') == 144`. To convert a string to a floating-point number, use the `float()` constructor, for example `float('144') == 144.0`. The `int()` constructor can also take a second optional argument specifying the base to convert from. For example, `int('0x144', 16) == 324`.

References: [3]
",6.60163220855285e-232,0.11267605633802817,0.17391304347826086,0.5081360936164856,0.6192486
How do I get a substring of a string in Python?,">>> x = ""Hello World!""
>>> x[2:]
'llo World!'
>>> x[:2]
'He'
>>> x[:-2]
'Hello Worl'
>>> x[-2:]
'd!'
>>> x[2:-2]
'llo Worl'



Python calls this concept ""slicing"" and it works on more than just strings. Take a look 
here
 for a comprehensive introduction.

","I'm sorry, I couldn't find relevant information in the provided context.",0.0,0.0,0.0060606060606060615,0.27861306071281433,-0.031356603
How do I escape curly-brace ({}) characters characters in a string while using .format?,"You need to double the 
{{
 and 
}}
:


>>> x = "" {{ Hello }} {0} ""
>>> print(x.format(42))
' { Hello } 42 '



Here's the relevant part of the 
Python documentation for format string syntax
:




Format strings contain “replacement fields” surrounded by curly braces 
{}
. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: 
{{
 and 
}}
.



","Answer: To include a literal curly brace character in a string when using `.format()`, you can escape it by doubling the brace: `{{` for an opening brace and `}}` for a closing brace.

References: [1, 2]
",4.9060858995599e-79,0.20370370370370372,0.20390856244307834,0.6151357293128967,0.6748719
Check if a given key already exists in a dictionary,"in
 tests for the existence of a key in a 
dict
:


d = {""key1"": 10, ""key2"": 23}

if ""key1"" in d:
    print(""this will execute"")

if ""nonexistent key"" in d:
    print(""this will not"")





Use 
dict.get()
 to provide a default value when the key does not exist:


d = {}

for i in range(100):
    key = i % 10
    d[key] = d.get(key, 0) + 1





To provide a default value for 
every
 key, either use 
dict.setdefault()
 on each assignment:


d = {}

for i in range(100):
    d[i % 10] = d.setdefault(i % 10, 0) + 1    



...or better, use 
defaultdict
 from the 
collections
 module:


from collections import defaultdict

d = defaultdict(int)

for i in range(100):
    d[i % 10] += 1


","Answer: To check if a key exists in a dictionary `d`, you can use the expression `key in d`, which returns `True` if the key is in the dictionary, and `False` otherwise.

References: [1, 2, 3]
",6.354799409666299e-156,0.18300653594771243,0.08304696449026346,0.5184638500213623,0.6446339
Class (static) variables and methods,"Variables declared inside the class definition, but not inside a method are class or static variables:


>>> class MyClass:
...     i = 3
...
>>> MyClass.i
3 



As @
millerdev
 points out, this creates a class-level 
i
 variable, but this is distinct from any instance-level 
i
 variable, so you could have


>>> m = MyClass()
>>> m.i = 4
>>> MyClass.i, m.i
>>> (3, 4)



This is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.


See 
what the Python tutorial has to say on the subject of classes and class objects
.


@Steve Johnson has already answered regarding 
static methods
, also documented under 
""Built-in Functions"" in the Python Library Reference
.


class C:
    @staticmethod
    def f(arg1, arg2, ...): ...



@beidy recommends 
classmethod
s over staticmethod, as the method then receives the class type as the first argument.

","Answer: Static class methods and static class data creation are possible.

References: [3]
",2.9250650775883015e-236,0.07547169811320754,0.036292573981016193,0.4726293981075287,0.37797058
How do I lowercase a string in Python?,"Use 
str.lower()
:


""Kilometer"".lower()


","Answer: To lowercase a string in Python, you can use the `casefold()` method, which is more aggressive than `lower()` in removing case distinctions.

References: [1, 2, 3]
",0.0,0.125,0.35742035742035744,0.47890961170196533,0.3705194
How to check if an object has an attribute?,"Try 
hasattr()
:


if hasattr(a, 'property'):
    a.property



See 
zweiterlinde's answer
 below, who offers good advice about asking forgiveness! A very pythonic approach!


The general practice in python is that, if the property is likely to be there most of the time, simply call it and either let the exception propagate, or trap it with a try/except block. This will likely be faster than 
hasattr
. If the property is likely to not be there most of the time, or you're not sure, using 
hasattr
 will probably be faster than repeatedly falling into an exception block.

","I'm sorry, I couldn't find relevant information in the provided context.
",5.740993591864357e-235,0.036036036036036036,0.023809523809523808,0.38461634516716003,-0.082973115
How to print without a newline or space,"In Python 3, you can use the 
sep=
 and 
end=
 parameters of the 
print
 function:


To not add a newline to the end of the string:


print('.', end='')



To not add a space between all the function arguments you want to print:


print('a', 'b', 'c', sep='')



You can pass any string to either parameter, and you can use both parameters at the same time.


If you are having trouble with buffering, you can flush the output by adding 
flush=True
 keyword argument:


print('.', end='', flush=True)



Python 2.6 and 2.7


From Python 2.6 you can either import the 
print
 function from Python 3 using the 
__future__
 module
:


from __future__ import print_function



which allows you to use the Python 3 solution above.


However, note that the 
flush
 keyword is not available in the version of the 
print
 function imported from 
__future__
 in Python 2; it only works in Python 3, more specifically 3.3 and later. In earlier versions you'll still need to flush manually with a call to 
sys.stdout.flush()
. You'll also have to rewrite all other print statements in the file where you do this import.


Or you can use 
sys.stdout.write()


import sys
sys.stdout.write('.')



You may also need to call


sys.stdout.flush()



to ensure 
stdout
 is flushed immediately.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.0957836564844083e-162,0.01702127659574468,0.013300674252001685,0.3336082398891449,-0.12981473
Calling a function of a module by using its name (a string),"Given a module 
foo
 with method 
bar
:


import foo
bar = getattr(foo, 'bar')
result = bar()



getattr
 can similarly be used on class instance bound methods, module-level methods, class methods... the list goes on.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.128778049395171e-232,0.0425531914893617,0.03496503496503497,0.3096638023853302,0.030860066
How can I randomly select (choose) an item from a list (get a random element)?,"Use 
random.choice()
:


import random

foo = ['a', 'b', 'c', 'd', 'e']
print(random.choice(foo))



For 
cryptographically secure
 random choices (e.g., for generating a passphrase from a wordlist), use 
secrets.choice()
:


import secrets

foo = ['battery', 'correct', 'horse', 'staple']
print(secrets.choice(foo))



secrets
 is new in Python 3.6. On older versions of Python you can use the 
random.SystemRandom
 class:


import random

secure_random = random.SystemRandom()
print(secure_random.choice(foo))


","I'm sorry, I couldn't find relevant information in the provided context.
",1.262850162188788e-233,0.04651162790697674,0.01904761904761905,0.30833953619003296,-0.015626127
How to remove an element from a list by index,"Use 
del
 and specify the index of the element you want to delete:


>>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> del a[-1]
>>> a
[0, 1, 2, 3, 4, 5, 6, 7, 8]



Also supports slices:


>>> del a[2:4]
>>> a
[0, 1, 4, 5, 6, 7, 8, 9]



Here
 is the section from the tutorial.

","Answer: To remove an item from a list given its index, you can use the `del` statement. For example, `del a[0]` will remove the item at index 0 from list `a`. Alternatively, you can use `list.pop([i])` which removes the item at the given position in the list, and returns it.

References: [1]
",9.510385657467775e-232,0.1565217391304348,0.1731040133394664,0.49904733896255493,0.63054836
Delete a column from a Pandas DataFrame,"As you've guessed, the right syntax is 


del df['column_name']



It's difficult to make 
del df.column_name
 work simply as the result of syntactic limitations in Python. 
del df[name]
 gets translated to 
df.__delitem__(name)
 under the covers by Python.

","Answer: You can remove an item from a list using the `del` statement if you know its index. The `del` statement can also remove slices from a list or clear the entire list. You can also use `del` to delete entire variables.

References: [3]",9.309480961664223e-232,0.15730337078651688,0.16472868217054262,0.4609202444553375,0.35338986
How do I get the number of elements in a list (length of a list) in Python?,"The 
len()
 function can be used with several different types in Python - both built-in types and library types. For example:


>>> len([1, 2, 3])
3


","I'm sorry, I couldn't find relevant information in the provided context.",2.558234810691267e-232,0.05128205128205129,0.06830601092896174,0.3324240446090698,-0.028169263
How do I pad a string with zeros?,"To pad strings:


>>> n = '4'
>>> print(n.zfill(3))
004



To pad numbers:


>>> n = 4
>>> print(f'{n:03}') # Preferred method, python >= 3.6
004
>>> print('%03d' % n)
004
>>> print(format(n, '03')) # python >= 2.6
004
>>> print('{0:03d}'.format(n))  # python >= 2.6 + python 3
004
>>> print('{foo:03d}'.format(foo=n))  # python >= 2.6 + python 3
004
>>> print('{:03d}'.format(n))  # python >= 2.7 + python3
004



String formatting documentation
.

","Answer: To pad a string with zeros on the left, use the `zfill(width)` method. This returns a copy of the string left filled with ASCII '0' digits to make the string of the specified `width`. If the string already has a leading sign ('+'/'-'), the padding is inserted after the sign character. If `width` is less than or equal to the length of the original string, the original string is returned.

References: [1, 2, 3]
",2.055211251400735e-155,0.10884353741496597,0.06561679790026247,0.47569283843040466,0.5955467
Delete an element from a dictionary,"The 
del
 statement
 removes an element:


del d[key]



Note that this mutates the existing dictionary, so the contents of the dictionary changes for anybody else who has a reference to the same instance. To return a 
new
 dictionary, make a copy of the dictionary:


def removekey(d, key):
    r = dict(d)
    del r[key]
    return r



The 
dict()
 constructor makes a 
shallow copy
. To make a deep copy, see the 
copy
 module
.




Note that making a copy for every dict 
del
/assignment/etc. means you're going from constant time to linear time, and also using linear space. For small dicts, this is not a problem. But if you're planning to make lots of copies of large dicts, you probably want a different data structure, like a HAMT (as described in 
this answer
).

","Answer: To remove an element from a dictionary, use `del d[key]`. This will remove the item `d[key]` from the dictionary `d`. If the key is not in the map, it raises a KeyError.

References: [3]
",3.6556015065169454e-156,0.17441860465116277,0.15355432766704166,0.5814303755760193,0.68988764
"What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc?","This is my personal recommendation for beginners:
 start by learning 
virtualenv
 and 
pip
, tools which work with both Python 2 and 3 and in a variety of situations, and pick up other tools once you start needing them.


Now on to answer the question: what is the difference between these similarly named things: venv, virtualenv, etc?


PyPI packages not in the standard library:




virtualenv
 is a very popular tool that creates isolated Python environments for Python libraries. If you're not familiar with this tool, I highly recommend learning it, as it is a very useful tool.


It works by installing a bunch of files in a directory (eg: 
env/
), and then modifying the 
PATH
 environment variable to prefix it with a custom 
bin
 directory (eg: 
env/bin/
). An exact copy of the 
python
 or 
python3
 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using 
pip
.




pyenv
 is used to isolate Python versions. For example, you may want to test your code against Python 2.7, 3.6, 3.7 and 3.8, so you'll need a way to switch between them. Once activated, it prefixes the 
PATH
 environment variable with 
~/.pyenv/shims
, where there are special files matching the Python commands (
python
, 
pip
). These are not copies of the Python-shipped commands; they are special scripts that decide on the fly which version of Python to run based on the 
PYENV_VERSION
 environment variable, or the 
.python-version
 file, or the 
~/.pyenv/version
 file. 
pyenv
 also makes the process of downloading and installing multiple Python versions easier, using the command 
pyenv install
.




pyenv-virtualenv
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to allow you to use 
pyenv
 and 
virtualenv
 at the same time conveniently. However, if you're using Python 3.3 or later, 
pyenv-virtualenv
 will try to run 
python -m venv
 if it is available, instead of 
virtualenv
. You can use 
virtualenv
 and 
pyenv
 together without 
pyenv-virtualenv
, if you don't want the convenience features.




virtualenvwrapper
 is a set of extensions to 
virtualenv
 (see 
docs
). It gives you commands like 
mkvirtualenv
, 
lssitepackages
, and especially 
workon
 for switching between different 
virtualenv
 directories. This tool is especially useful if you want multiple 
virtualenv
 directories.




pyenv-virtualenvwrapper
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to conveniently integrate 
virtualenvwrapper
 into 
pyenv
.




pipenv
 aims to combine 
Pipfile
, 
pip
 and 
virtualenv
 into one command on the command-line. The 
virtualenv
 directory typically gets placed in 
~/.local/share/virtualenvs/XXX
, with 
XXX
 being a hash of the path of the project directory. This is different from 
virtualenv
, where the directory is typically in the current working directory. 
pipenv
 is meant to be used when developing Python applications (as opposed to libraries). There are alternatives to 
pipenv
, such as 
poetry
, which I won't list here since this question is only about the packages that are similarly named.






Standard library:




pyvenv
 (not to be confused with 
pyenv
 in the previous section) is a script shipped with Python 3.3 to 3.7. It was 
removed from Python 3.8
 as it had problems (not to mention the confusing name). Running 
python3 -m venv
 has exactly the same effect as 
pyvenv
.




venv
 is a package shipped with Python 3, which you can run using 
python3 -m venv
 (although for some reason some distros separate it out into a separate distro package, such as 
python3-venv
 on Ubuntu/Debian). It serves the same purpose as 
virtualenv
, but only has a subset of its features (
see a comparison here
). 
virtualenv
 continues to be more popular than 
venv
, especially since the former supports both Python 2 and 3.





","I'm sorry, I couldn't find relevant information in the provided context.",3.922151885297028e-180,0.018018018018018018,0.006107802717972209,0.3582908511161804,-0.057207055
How do I count the occurrences of a list item?,"If you only want a single item's count, use the 
count
 method:


>>> [1, 2, 3, 4, 1, 4, 1].count(1)
3





Important: this is very slow if you are counting 
multiple
 different items


Each 
count
 call goes over the entire list of 
n
 elements. Calling 
count
 in a loop 
n
 times means 
n * n
 total checks, which can be catastrophic for performance.


If you want to count multiple items, use 
Counter
, which only does 
n
 total checks.

","Answer: You can count the number of times an item appears in a list using the `list.count(x)` method.

References: [1]
",3.0627970653373017e-156,0.13861386138613863,0.1311482198277365,0.5594303607940674,0.67297703
Determine the type of an object?,"There are two built-in functions that help you identify the type of an object. You can use 
type()
  if you need the exact type of an object, and 
isinstance()
 to 
check
 an object’s type against something. Usually, you want to use 
isinstance()
 most of the times since it is very robust and also supports type inheritance.




To get the actual type of an object, you use the built-in 
type()
 function. Passing an object as the only parameter will return the type object of that object:


>>> type([]) is list
True
>>> type({}) is dict
True
>>> type('') is str
True
>>> type(0) is int
True



This of course also works for custom types:


>>> class Test1 (object):
        pass
>>> class Test2 (Test1):
        pass
>>> a = Test1()
>>> b = Test2()
>>> type(a) is Test1
True
>>> type(b) is Test2
True



Note that 
type()
 will only return the immediate type of the object, but won’t be able to tell you about type inheritance.


>>> type(b) is Test1
False



To cover that, you should use the 
isinstance
 function. This of course also works for built-in types:


>>> isinstance(b, Test1)
True
>>> isinstance(b, Test2)
True
>>> isinstance(a, Test1)
True
>>> isinstance(a, Test2)
False
>>> isinstance([], list)
True
>>> isinstance({}, dict)
True



isinstance()
 is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using 
isinstance()
 is preferred over 
type()
.


The second parameter of 
isinstance()
 also accepts a tuple of types, so it’s possible to check for multiple types at once. 
isinstance
 will then return true, if the object is of any of those types:


>>> isinstance([], (tuple, list, set))
True


","Answer: To determine the type of an object o, you can use `PyObject_Type(PyObject *o)`. This is equivalent to the Python expression `type(o)`. Alternatively, `PyObject_TypeCheck(PyObject *o, PyTypeObject *type)` can be used to check if the object o is of type type or a subtype of type.

References: [1]
",0.0008492267155441748,0.15015015015015015,0.06966011734080772,0.5376914143562317,0.66293067
How to check if the string is empty in Python?,"Empty strings are ""falsy"" (
python 2
 or 
python 3
 reference), which means they are considered false in a Boolean context, so you can just do this:


if not myString:



This is the preferred way if you know that your variable is a string.  If your variable could also be some other type then you should use:


if myString == """":



See the documentation on 
Truth Value Testing
 for other values that are false in Boolean contexts.

","I'm sorry, I couldn't find relevant information in the provided context.",2.948836949920929e-234,0.06896551724137932,0.0428921568627451,0.3852955996990204,-0.07886311
Why is reading lines from stdin much slower in C++ than Python?,"tl;dr: Because of different default settings in C++ requiring more system calls.


By default, 
cin
 is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:


std::ios_base::sync_with_stdio(false);



Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the 
FILE*
 based 
stdio
 and 
iostreams
 often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:


int myvalue1;
cin >> myvalue1;
int myvalue2;
scanf(""%d"",&myvalue2);



If more input was read by 
cin
 than it actually needed, then the second integer value wouldn't be available for the 
scanf
 function, which has its own independent buffer.  This would lead to unexpected results.


To avoid this, by default, streams are synchronized with 
stdio
.  One common way to achieve this is to have 
cin
 read each character one at a time as needed using 
stdio
 functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.


Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the 
sync_with_stdio
 method. From this link (emphasis added):




If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, 
which may be considerably faster in some cases
.



","I'm sorry, I couldn't find relevant information in the provided context.",4.143909548047049e-242,0.01993355481727575,0.016165535079211122,0.36697468161582947,-0.054651983
Why is it string.join(list) instead of list.join(string)?,"It's because any iterable can be joined (e.g, list, tuple, dict, set), but its contents and the ""joiner"" 
must be
 strings.


For example:


'_'.join(['welcome', 'to', 'stack', 'overflow'])
'_'.join(('welcome', 'to', 'stack', 'overflow'))



'welcome_to_stack_overflow'



Using something other than strings will raise the following error:




TypeError: sequence item 0: expected str instance, int found



","Answer: To efficiently concatenate many strings, the recommended approach is to place the strings into a list and then call str.join() at the end.

References: [1, 2]
",4.6466808094980825e-232,0.09302325581395349,0.0963718820861678,0.5106296539306641,0.5102183
How do I append to a file?,"Set the mode in 
open()
 to 
""a""
 (append) instead of 
""w""
 (write):


with open(""test.txt"", ""a"") as myfile:
    myfile.write(""appended text"")



The 
documentation
 lists all the available modes.

","I'm sorry, I couldn't find relevant information in the provided context.
",3.042271038721479e-232,0.09302325581395349,0.041407867494824016,0.37676310539245605,-0.06934745
Is there a way to run Python on Android?,"One way is to use 
Kivy
:




Open source Python library for rapid development of applications
  that make use of innovative user interfaces, such as multi-touch apps.








Kivy runs on Linux, Windows, OS X, Android and iOS. You can run the same [python] code on all supported platforms.




Kivy Showcase app
 

","Answer: The only way to use Python on Android is in embedded mode by writing a native Android application, embedding a Python interpreter using libpython, and invoking Python code using the Python embedding API. Tools such as Briefcase, Buildozer, Chaquopy, pyqtdeploy, and Termux can simplify the process.

References: [3]
",4.643333934838175e-155,0.21999999999999997,0.2319600665557405,0.5460861921310425,0.5481561
Static methods in Python?,"Yep, using the 
staticmethod
 decorator:


class MyClass(object):
    @staticmethod
    def the_static_method(x):
        print(x)

MyClass.the_static_method(2)  # outputs 2



Note that some code might use the old method of defining a static method, using 
staticmethod
 as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3):


class MyClass(object):
    def the_static_method(x):
        print(x)
    the_static_method = staticmethod(the_static_method)

MyClass.the_static_method(2)  # outputs 2



This is entirely identical to the first example (using 
@staticmethod
), just not using the nice decorator syntax.


Finally, use 
staticmethod
 sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate ""top-level"" function would have been clearer.




The following is verbatim from the documentation:
:




A static method does not receive an implicit first argument. To declare a static method, use this idiom:


class C:
    @staticmethod
    def f(arg1, arg2, ...): ...



The @staticmethod form is a function 
decorator
 – see the description of function definitions in 
Function definitions
 for details.


It can be called either on the class (such as 
C.f()
) or on an instance (such as 
C().f()
). The instance is ignored except for its class.


Static methods in Python are similar to those found in Java or C++. For a more advanced concept, see 
classmethod()
.


For more information on static methods, consult the documentation on the standard type hierarchy in 
The standard type hierarchy
.


New in version 2.2.


Changed in version 2.4: Function decorator syntax added.



","Answer: To find out how to create static class data and static class methods, see section 2.6.8.

References: [1, 2, 3]
",2.7079223424111162e-236,0.06802721088435373,0.03139458030403172,0.4845791757106781,0.42054105
Installing specific package version with pip,"TL;DR
:


Update as of 2022-12-28
:


pip install --force-reinstall -v


For example: 
pip install --force-reinstall -v ""MySQL_python==1.2.2""


What these options mean:




--force-reinstall
 is an option to reinstall all packages even if they are already up-to-date.


-v
 is for verbose. You can combine for even more verbosity (i.e. 
-vv
) up to 3 times (e.g. 
--force-reinstall -vvv
).




Thanks to 
@Peter
 for highlighting this (and it seems that the context of the question has broadened given the time when the question was first asked!), 
the documentation for Python
 discusses a caveat with using 
-I
, in that it can break your installation if it was installed with a different package manager or if if your package is/was a different version.




Original answer:




pip install -Iv
 (i.e. 
pip install -Iv MySQL_python==1.2.2
)






What these options mean:




-I
 stands for 
--ignore-installed
 which will ignore the installed packages, overwriting them.


-v
 is for verbose. You can combine for even more verbosity (i.e. 
-vv
) up to 3 times (e.g. 
-Ivvv
).




For more information, see 
pip install --help


First, I see two issues with what you're trying to do. Since you already have an installed version, you should either uninstall the current existing driver or use 
pip install -I MySQL_python==1.2.2


However, you'll soon find out that this doesn't work. If you look at pip's installation log, or if you do a 
pip install -Iv MySQL_python==1.2.2
 you'll find that the PyPI URL link does not work for MySQL_python v1.2.2. You can verify this here: 
http://pypi.python.org/pypi/MySQL-python/1.2.2


The download link 404s and the fallback URL links are re-directing infinitely due to sourceforge.net's recent upgrade and PyPI's stale URL.


So to properly install the driver, you can follow these steps:


pip uninstall MySQL_python
pip install -Iv http://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.2/MySQL-python-1.2.2.tar.gz/download


","Answer: To install a specific version of a package using pip, you can use the following command: `python -m pip install SomePackage==1.0.4`. For a minimum version, you can use: `python -m pip install ""SomePackage>=1.0.4""`. Remember to enclose the package name and version within double quotes when using comparator operators.

References: [2]
",6.058733061458912e-157,0.0970873786407767,0.08213264601907014,0.5423287749290466,0.5752154
How do I split the definition of a long string over multiple lines?,"Are you talking about multi-line strings? Easy, use triple quotes to start and end them.


s = """""" this is a very
        long string if I had the
        energy to type more and more ...""""""



You can use single quotes too (3 of them of course at start and end) and treat the resulting string 
s
 just like any other string.


NOTE
: Just as with any string, anything between the starting and ending quotes becomes part of the string, so this example has a leading blank (as pointed out by @root45). This string will also contain both blanks and newlines.


I.e.,:


' this is a very\n        long string if I had the\n        energy to type more and more ...'



Finally, one can also construct long lines in Python like this:


 s = (""this is a very""
      ""long string too""
      ""for sure ...""
     )



which will 
not
 include any extra blanks or newlines (this is a deliberate example showing what the effect of skipping blanks will result in):


'this is a verylong string toofor sure ...'



No commas required, simply place the strings to be joined together into a pair of parenthesis and be sure to account for any needed blanks and newlines.

","I'm sorry, I couldn't find relevant information in the provided context.
",3.4596143585827833e-239,0.03809523809523809,0.013850415512465374,0.3724672198295593,-0.027419247
How to prettyprint a JSON file?,"Use the 
indent=
 parameter of 
json.dump()
 or 
json.dumps()
 to specify how many spaces to indent by:


>>> import json
>>> your_json = '[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]'
>>> parsed = json.loads(your_json)
>>> print(json.dumps(parsed, indent=4))
[
    ""foo"",
    {
        ""bar"": [
            ""baz"",
            null,
            1.0,
            2
        ]
    }
]



To parse a file, use 
json.load()
:


with open('filename.txt', 'r') as handle:
    parsed = json.load(handle)


","Answer:
You can pretty-print a JSON file using the `json.tool` module from the shell, or by using the `json.dumps()` method with the `indent` parameter.

References: [1, 3]
",3.0917762158729885e-232,0.18947368421052632,0.0831255195344971,0.6006975173950195,0.7718277
Getting the class name of an instance,"Have you tried the 
__name__
 attribute
 of the class? ie 
type(x).__name__
 will give you the name of the class, which I think is what you want.


>>> import itertools
>>> x = itertools.count(0)
>>> type(x).__name__
'count'



If you're still using Python 2, note that the above method works with 
new-style classes
 only (in Python 3+ all classes are ""new-style"" classes). Your code might use some old-style classes. The following works for both:


x.__class__.__name__


","Answer: Each value in Python is an object and has a class (also called its type). It is stored as `object.__class__`.

References: [1]
",1.1251629539246562e-232,0.07619047619047618,0.09439718934911241,0.5316277146339417,0.5979254
How do I check if a string represents a number (float or int)?,"

Which, not only is ugly and slow




I'd dispute both.


A regex or other string parsing method would be uglier and slower.  


I'm not sure that anything much could be faster than the above.  It calls the function and returns.  Try/Catch doesn't introduce much overhead because the most common exception is caught without an extensive search of stack frames.


The issue is that any numeric conversion function has two kinds of results




A number, if the number is valid


A status code (e.g., via errno) or exception to show that no valid number could be parsed.




C (as an example) hacks around this a number of ways.  Python lays it out clearly and explicitly.


I think your code for doing this is perfect.

","Answer: You can use the built-in `int()` or `float()` type constructors to convert a string to a number. For example, `int('144') == 144` and `float('144') == 144.0`. If the string cannot be converted, a ValueError will be raised.

References: [3]
",1.5754074799209398e-232,0.09411764705882353,0.11086891925445613,0.47345787286758423,0.52130497
How do I get the row count of a Pandas DataFrame?,"For a dataframe 
df
, one can use any of the following:




len(df.index)


df.shape[0]


df[df.columns[0]].count()
 (== 
number of non-NaN values
 in first column)








Code to reproduce the plot:


import numpy as np
import pandas as pd
import perfplot

perfplot.save(
    ""out.png"",
    setup=lambda n: pd.DataFrame(np.arange(n * 3).reshape(n, 3)),
    n_range=[2**k for k in range(25)],
    kernels=[
        lambda df: len(df.index),
        lambda df: df.shape[0],
        lambda df: df[df.columns[0]].count(),
    ],
    labels=[""len(df.index)"", ""df.shape[0]"", ""df[df.columns[0]].count()""],
    xlabel=""Number of rows"",
)


","I'm sorry, I couldn't find relevant information in the provided context.
",6.102408721542616e-234,0.03418803418803419,0.013020833333333332,0.30796125531196594,0.022759702
Meaning of @classmethod and @staticmethod for beginner,"Though 
classmethod
 and 
staticmethod
 are quite similar, there's a slight difference in usage for both entities: 
classmethod
 must have a reference to a class object as the first parameter, whereas 
staticmethod
 can have no parameters at all.


Example


class Date(object):
    
    def __init__(self, day=0, month=0, year=0):
        self.day = day
        self.month = month
        self.year = year

    @classmethod
    def from_string(cls, date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        date1 = cls(day, month, year)
        return date1

    @staticmethod
    def is_date_valid(date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        return day <= 31 and month <= 12 and year <= 3999

date2 = Date.from_string('11-09-2012')
is_date = Date.is_date_valid('11-09-2012')



Explanation


Let's assume an example of a class, dealing with date information (this will be our boilerplate):


class Date(object):
    
    def __init__(self, day=0, month=0, year=0):
        self.day = day
        self.month = month
        self.year = year



This class obviously could be used to store information about certain dates (without timezone information; let's assume all dates are presented in UTC).


Here we have 
__init__
, a typical initializer of Python class instances, which receives arguments as a typical instance method, having the first non-optional argument (
self
) that holds a reference to a newly created instance.


Class Method


We have some tasks that can be nicely done using 
classmethod
s.


Let's assume that we want to create a lot of 
Date
 class instances having date information coming from an outer source encoded as a string with format 'dd-mm-yyyy'. Suppose we have to do this in different places in the source code of our project.


So what we must do here is:




Parse a string to receive day, month and year as three integer variables or a 3-item tuple consisting of that variable.


Instantiate 
Date
 by passing those values to the initialization call.




This will look like:


day, month, year = map(int, string_date.split('-'))
date1 = Date(day, month, year)



For this purpose, C++ can implement such a feature with overloading, but Python lacks this overloading. Instead, we can use 
classmethod
. Let's create another 
constructor
.


    @classmethod
    def from_string(cls, date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        date1 = cls(day, month, year)
        return date1

date2 = Date.from_string('11-09-2012')



Let's look more carefully at the above implementation, and review what advantages we have here:




We've implemented date string parsing in one place and it's reusable now.


Encapsulation works fine here (if you think that you could implement string parsing as a single function elsewhere, this solution fits the OOP paradigm far better).


cls
 is the 
class itself
, not an instance of the class. It's pretty cool because if we inherit our 
Date
 class, all children will have 
from_string
 defined also.




Static method


What about 
staticmethod
? It's pretty similar to 
classmethod
 but doesn't take any obligatory parameters (like a class method or instance method does).


Let's look at the next use case.


We have a date string that we want to validate somehow. This task is also logically bound to the 
Date
 class we've used so far, but doesn't require instantiation of it.


Here is where 
staticmethod
 can be useful. Let's look at the next piece of code:


    @staticmethod
    def is_date_valid(date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        return day <= 31 and month <= 12 and year <= 3999

# usage:
is_date = Date.is_date_valid('11-09-2012')



So, as we can see from usage of 
staticmethod
, we don't have any access to what the class is---it's basically just a function,  called syntactically like a method, but without access to the object and its internals (fields and other methods), which 
classmethod
 does have.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.8978152503904693e-177,0.009036144578313253,0.006355932203389829,0.3204173743724823,-0.010863442
What's the canonical way to check for type in Python?,"Use 
isinstance
 to check if 
o
 is an instance of 
str
 or any subclass of 
str
:


if isinstance(o, str):



To check if the type of 
o
 is exactly 
str
, 
excluding subclasses of 
str
:


if type(o) is str:



See 
Built-in Functions
 in the Python Library Reference for relevant information.




Checking for strings in Python 2


For Python 2, this is a better way to check if 
o
 is a string:


if isinstance(o, basestring):



because this will also catch Unicode strings. 
unicode
 is not a subclass of 
str
; both 
str
 and 
unicode
 are subclasses of 
basestring
. In Python 3, 
basestring
 no longer exists since there's 
a strict separation
 of strings (
str
) and binary data (
bytes
).


Alternatively, 
isinstance
 accepts a tuple of classes. This will return 
True
 if 
o
 is an instance of any subclass of any of 
(str, unicode)
:


if isinstance(o, (str, unicode)):


","Answer: Type predicate functions are user-defined functions that return whether their argument is an instance of a particular type. TypeGuard is a special typing construct for marking these functions. Using `-> TypeGuard` tells the static type checker that for a given function: (1) The return value is a boolean, and (2) If the return value is True, the type of its argument is the type inside TypeGuard.

References: [2, 3]
",0.021034693014401806,0.1566820276497696,0.1447155845710704,0.5290777087211609,0.1746645
Proper way to declare custom exceptions in modern Python?,"Maybe I missed the question, but why not:


class MyException(Exception):
    pass



To override something (or pass extra args), do this:


class ValidationError(Exception):
    def __init__(self, message, errors):            
        # Call the base class constructor with the parameters it needs
        super().__init__(message)
            
        # Now for your custom code...
        self.errors = errors



That way you could pass dict of error messages to the second param, and get to it later with 
e.errors
.


In Python 2, you have to use this slightly more complex form of 
super()
:


super(ValidationError, self).__init__(message)


","Answer: To declare custom exceptions in Python, you create a new class that inherits from the base `Exception` class or one of its subclasses. These classes are usually kept simple and often only offer attributes to provide error information to exception handlers. It's common to name custom exceptions with names ending in ""Error"".

References: [1, 3]
",2.307618680326606e-155,0.1496598639455782,0.15139126974172196,0.5099554657936096,0.64350665
How can I install packages using pip according to the requirements.txt file from a local directory?,"This works for me:


$ pip install -r requirements.txt --no-index --find-links file:///tmp/packages



--no-index
 - Ignore package index (only look at 
--find-links
 URLs instead).


-f, --find-links 
 - If 
 is a URL or a path to an HTML file, then parse for links to archives. If 
 is a local path or a 
file://
 URL that's a directory, then look for archives in the directory listing.

","Answer: I'm sorry, I couldn't find relevant information in the provided context.
",7.465083738624576e-157,0.07228915662650602,0.04927152317880794,0.38796594738960266,-0.019629188
Generate random integers between 0 and 9,"Try 
random.randrange
:


from random import randrange
print(randrange(10))


","Answer: You can use `random.randint(a, b)` which returns a random integer N such that a <= N <= b. As an alias for `randrange(a, b+1)`. Or you can use `random.randrange(stop)` or `random.randrange(start, stop[, step])` which returns a randomly selected element from `range(start, stop, step)`.

References: [1]
",8.319100378795605e-232,0.15873015873015875,0.21028037383177575,0.5471927523612976,0.6956247
fatal error: Python.h: No such file or directory,"I managed to solve this issue and generate the .so file in one command 


gcc -shared -o UtilcS.so
-fPIC -I/usr/include/python2.7 -lpython2.7  utilsmodule.c


","I'm sorry, I couldn't find relevant information in the provided context.
",4.84335144972907e-232,0.09523809523809525,0.09389671361502347,0.3604260981082916,-0.043076172
What is the meaning of single and double underscore before an object name?,"Single Underscore


In a class, names with a leading underscore indicate to other programmers that the attribute or method is intended to be be used inside that class. However, privacy is not 
enforced
 in any way.
Using leading underscores for functions in a module indicates it should not be imported from somewhere else.


From the 
PEP-8
 style guide:




_single_leading_underscore
: weak ""internal use"" indicator. E.g. 
from M import *
 does not import objects whose name starts with an underscore.




Double Underscore (Name Mangling)


From 
the Python docs
:




Any identifier of the form 
__spam
 (at least two leading underscores, at most one trailing underscore) is textually replaced with 
_classname__spam
, where 
classname
 is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, so it can be used to define class-private instance and class variables, methods, variables stored in globals, and even variables stored in instances. private to this class on instances of other classes.




And a warning from the same page:




Name mangling is intended to give classes an easy way to define “private” instance variables and methods, without having to worry about instance variables defined by derived classes, or mucking with instance variables by code outside the class. Note that the mangling rules are designed mostly to avoid accidents; 
it still is possible for a determined soul to access or modify a variable that is considered private.




Example


>>> class MyClass():
...     def __init__(self):
...             self.__superprivate = ""Hello""
...             self._semiprivate = "", world!""
...
>>> mc = MyClass()
>>> print mc.__superprivate
Traceback (most recent call last):
  File ""
"", line 1, in 

AttributeError: myClass instance has no attribute '__superprivate'
>>> print mc._semiprivate
, world!
>>> print mc.__dict__
{'_MyClass__superprivate': 'Hello', '_semiprivate': ', world!'}


","Answer:
Identifiers with a single underscore `_*` are not imported by `from module import *`. The single underscore `_` by itself is used as a soft keyword denoting a wildcard in a case pattern within a match statement. It can also store the result of the last evaluation in the interactive interpreter. It is also commonly used for unused variables or with internationalization. Identifiers with double underscores both leading and trailing `__*__` are system-defined names, also known as ""dunder"" names, defined by the interpreter and its implementation. Identifiers with leading double underscores `__*` are class-private names, which are rewritten to use a mangled form within a class definition to avoid name clashes.

References: [3]
",1.1727378414962402e-155,0.14035087719298248,0.12598803249879323,0.5801823735237122,0.78847885
Relative imports for the billionth time,"Script vs. Module


Here's an explanation.  The short version is that there is a big difference between directly running a Python file, and importing that file from somewhere else.  
Just knowing what directory a file is in does not determine what package Python thinks it is in.
  That depends, additionally, on how you load the file into Python (by running or by importing).


There are two ways to load a Python file: as the top-level script, or as a
module.  A file is loaded as the top-level script if you execute it directly, for instance by typing 
python myfile.py
 on the command line.  It is loaded as a module when an 
import
 statement is encountered inside some other file.  There can only be one top-level script at a time; the top-level script is the Python file you ran to start things off.


Naming


When a file is loaded, it is given a name (which is stored in its 
__name__
 attribute).  If it was loaded as the top-level script, its name is 
__main__
.  If it was loaded as a module, its name is the filename, preceded by the names of any packages/subpackages of which it is a part, separated by dots.


So for instance in your example:


package/
    __init__.py
    subpackage1/
        __init__.py
        moduleX.py
    moduleA.py



if you imported 
moduleX
 (note: 
imported
, not directly executed), its name would be 
package.subpackage1.moduleX
.  If you imported 
moduleA
, its name would be 
package.moduleA
.  However, if you 
directly run
 
moduleX
 from the command line, its name will instead be 
__main__
, and if you directly run 
moduleA
 from the command line, its name will be 
__main__
.  When a module is run as the top-level script, it loses its normal name and its name is instead 
__main__
.


Accessing a module NOT through its containing package


There is an additional wrinkle: the module's name depends on whether it was imported ""directly"" from the directory it is in or imported via a package.  This only makes a difference if you run Python in a directory, and try to import a file in that same directory (or a subdirectory of it).  For instance, if you start the Python interpreter in the directory 
package/subpackage1
 and then do 
import moduleX
, the name of 
moduleX
 will just be 
moduleX
, and not 
package.subpackage1.moduleX
.  This is because Python adds the current directory to its search path when the interpreter is entered interactively; if it finds the to-be-imported module in the current directory, it will not know that that directory is part of a package, and the package information will not become part of the module's name.


A special case is if you run the interpreter interactively (e.g., just type 
python
 and start entering Python code on the fly).  In this case, the name of that interactive session is 
__main__
.


Now here is the crucial thing for your error message: 
if a module's name has no dots, it is not considered to be part of a package
.  It doesn't matter where the file actually is on disk.  All that matters is what its name is, and its name depends on how you loaded it.


Now look at the quote you included in your question:




Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top-level module, regardless of where the module is actually located on the file system.




Relative imports...


Relative imports use the module's 
name
 to determine where it is in a package.  When you use a relative import like 
from .. import foo
, the dots indicate to step up some number of levels in the package hierarchy.  For instance, if your current module's name is 
package.subpackage1.moduleX
, then 
..moduleA
 would mean 
package.moduleA
.  For a 
from .. import
 to work, the module's name must have at least as many dots as there are in the 
import
 statement.


... are only relative in a package


However, if your module's name is 
__main__
, it is not considered to be in a package.  Its name has no dots, and therefore you cannot use 
from .. import
 statements inside it.  If you try to do so, you will get the ""relative-import in non-package"" error.


Scripts can't import relative


What you probably did is you tried to run 
moduleX
 or the like from the command line.  When you did this, its name was set to 
__main__
, which means that relative imports within it will fail, because its name does not reveal that it is in a package. Note that this will also happen if you run Python from the same directory where a module is, and then try to import that module, because, as described above, Python will find the module in the current directory ""too early"" without realizing it is part of a package.


Also remember that when you run the interactive interpreter, the ""name"" of that interactive session is always 
__main__
.  Thus 
you cannot do relative imports directly from an interactive session
.  Relative imports are only for use within module files.


Two solutions:




If you really do want to run 
moduleX
 directly, but you still want it to be considered part of a package, you can do 
python -m package.subpackage1.moduleX
.  The 
-m
 tells Python to load it as a module, not as the top-level script.




Or perhaps you don't actually want to 
run
 
moduleX
, you just want to run some other script, say 
myfile.py
, that 
uses
 functions inside 
moduleX
.  If that is the case, put 
myfile.py
 
somewhere else
 – 
not
 inside the 
package
 directory – and run it.  If inside 
myfile.py
 you do things like 
from package.moduleA import spam
, it will work fine.






Notes




For either of these solutions, the package directory (
package
 in your example) must be accessible from the Python module search path (
sys.path
).  If it is not, you will not be able to use anything in the package reliably at all.




Since Python 2.6, the module's ""name"" for package-resolution purposes is determined not just by its 
__name__
 attributes but also by the 
__package__
 attribute.  That's why I'm avoiding using the explicit symbol 
__name__
 to refer to the module's ""name"".  Since Python 2.6 a module's ""name"" is effectively 
__package__ + '.' + __name__
, or just 
__name__
 if 
__package__
 is 
None
.)





","I'm sorry, I couldn't find relevant information in the provided context.",3.577474400469471e-197,0.007181328545780969,0.004528985507246377,0.32525399327278137,0.00956016
Extracting extension from filename,"Use 
os.path.splitext
:


>>> import os
>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')
>>> filename
'/path/to/somefile'
>>> file_extension
'.ext'



Unlike most manual string-splitting attempts, 
os.path.splitext
 will correctly treat 
/a/b.c/d
 as having no extension instead of having extension 
.c/d
, and it will treat 
.bashrc
 as having no extension instead of having extension 
.bashrc
:


>>> os.path.splitext('/a/b.c/d')
('/a/b.c/d', '')
>>> os.path.splitext('.bashrc')
('.bashrc', '')


","I'm sorry, I couldn't find relevant information in the provided context.
",0.0,0.0,0.005688282138794084,0.2765221893787384,-0.07274007
How do I write JSON data to a file?,"data
 is a Python dictionary. It needs to be encoded as JSON before writing.


Use this for maximum compatibility (Python 2 and 3):


import json
with open('data.json', 'w') as f:
    json.dump(data, f)



On a modern system (i.e. Python 3 and UTF-8 support), you can write a nicer file using:


import json
with open('data.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)



See 
json
 documentation.

","Answer: To write JSON data to a file, you can use the `json.dump(x, f)` function where `x` is the object you want to serialize and `f` is a text file object opened for writing. Remember to open the JSON file with `encoding=""utf-8""` when opening it as a text file for writing.

References: [3]
",3.978811059106402e-155,0.23529411764705882,0.1991998472011419,0.6269053816795349,0.7407919
How can I import a module dynamically given the full path?,"Let's have 
MyClass
 in 
module.name
 module defined at 
/path/to/file.py
. Below is how we import 
MyClass
 from this module


For Python 3.5+ use (
docs
):


import importlib.util
import sys
spec = importlib.util.spec_from_file_location(""module.name"", ""/path/to/file.py"")
foo = importlib.util.module_from_spec(spec)
sys.modules[""module.name""] = foo
spec.loader.exec_module(foo)
foo.MyClass()



For Python 3.3 and 3.4 use:


from importlib.machinery import SourceFileLoader

foo = SourceFileLoader(""module.name"", ""/path/to/file.py"").load_module()
foo.MyClass()



(Although this has been deprecated in Python 3.4.)


For Python 2 use:


import imp

foo = imp.load_source('module.name', '/path/to/file.py')
foo.MyClass()



There are equivalent convenience functions for compiled Python files and DLLs.


See also 
http://bugs.python.org/issue21436
.

","Answer: You can import a source file directly by using `importlib.util.spec_from_file_location()` along with `importlib.util.module_from_spec()` and `spec.loader.exec_module()`.

References: [1]
",1.8223940859830378e-233,0.20481927710843373,0.07880642871817861,0.6242576241493225,0.6888669
Relative imports in Python 3,"

unfortunately, this module needs to be inside the package, and it also
needs to be runnable as a script, sometimes. Any idea how I could
achieve that?




It's quite common to have a layout like this...


main.py
mypackage/
    __init__.py
    mymodule.py
    myothermodule.py



...with a 
mymodule.py
 like this...


#!/usr/bin/env python3

# Exported function
def as_int(a):
    return int(a)

# Test function for module  
def _test():
    assert as_int('1') == 1

if __name__ == '__main__':
    _test()



...a 
myothermodule.py
 like this...


#!/usr/bin/env python3

from .mymodule import as_int

# Exported function
def add(a, b):
    return as_int(a) + as_int(b)

# Test function for module  
def _test():
    assert add('1', '1') == 2

if __name__ == '__main__':
    _test()



...and a 
main.py
 like this...


#!/usr/bin/env python3

from mypackage.myothermodule import add

def main():
    print(add('1', '1'))

if __name__ == '__main__':
    main()



...which works fine when you run 
main.py
 or 
mypackage/mymodule.py
, but fails with 
mypackage/myothermodule.py
, due to the relative import...


from .mymodule import as_int



The way you're supposed to run it is by using the -m option and giving the path in the Python module system (rather than in the filesystem)...


python3 -m mypackage.myothermodule



...but it's somewhat verbose, and doesn't mix well with a shebang line like 
#!/usr/bin/env python3
.


An alternative is to avoid using relative imports, and just use...


from mypackage.mymodule import as_int



Either way, you'll need to run from the parent of 
mypackage
, or add that directory to 
PYTHONPATH
 (either one will ensure that 
mypackage
 is in the sys.path 
module search path
). Or, if you want it to work ""out of the box"", you can frob the 
PYTHONPATH
 in code first with this...


import sys
import os

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(SCRIPT_DIR))

from mypackage.mymodule import as_int



It's kind of a pain, but there's a clue as to why in 
an email
 written by a certain Guido van Rossum...




I'm -1 on this and on any other proposed twiddlings of the 
__main__

machinery. The only use case seems to be running scripts that happen
to be living inside a module's directory, which I've always seen as an
antipattern. To make me change my mind you'd have to convince me that
it isn't.




Whether running scripts inside a package is an antipattern or not is subjective, but personally I find it really useful in a package I have which contains some custom wxPython widgets, so I can run the script for any of the source files to display a 
wx.Frame
 containing only that widget for testing purposes.

","Answer: Relative imports in Python 3 use leading dots. A single dot indicates a relative import starting from the current package. Two or more dots indicate a relative import to the parent(s) of the current package, increasing one level per dot after the first.

References: [2]
",2.3734537797540774e-158,0.07100591715976332,0.03457392719137685,0.40879368782043457,0.32989913
Use different Python version with virtualenv,"NOTE:
 For 
Python 3.3+
, see The Aelfinn's 
answer
 below.




Use the 
--python
 (or short 
-p
) option when creating a virtualenv instance to specify the Python executable you want to use, e.g.:


virtualenv --python=""/usr/bin/python2.6"" ""/path/to/new/virtualenv/""


","I'm sorry, I couldn't find relevant information in the provided context.",1.0306880454264251e-232,0.03508771929824561,0.04301075268817204,0.347640722990036,-0.12901407
How do I get time of a Python program's execution?,"The simplest way in Python:


import time
start_time = time.time()
main()
print(""--- %s seconds ---"" % (time.time() - start_time))



This assumes that your program takes at least a tenth of second to run.


Prints:


--- 0.764891862869 seconds ---


","Answer: You can use the `timeit` module, which provides both a Command-Line Interface and a callable one, to measure the execution time of small bits of Python code. The `timeit.timeit()` function can be used from the Python Interface. Also, the `timeit.default_timer()` function returns the time in float seconds, using `time.perf_counter()` as the default timer.

References: [2, 3]
",1.0377133938315695e-231,0.1,0.16286644951140064,0.5167343616485596,0.69951904
Random string generation with upper case letters and digits,"Answer in one line:


''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))



or even shorter starting with Python 3.6 using 
random.choices()
:


''.join(random.choices(string.ascii_uppercase + string.digits, k=N))



A cryptographically more secure version:
 
see this post


''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))



In details, with a clean function for further reuse:


>>> import string
>>> import random
>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):
...    return ''.join(random.choice(chars) for _ in range(size))
...
>>> id_generator()
'G5G74W'
>>> id_generator(3, ""6793YUIO"")
'Y3U'



How does it work ?


We import 
string
, a module that contains sequences of common ASCII characters, and 
random
, a module that deals with random generation.


string.ascii_uppercase + string.digits
 just concatenates the list of characters representing uppercase ASCII chars and digits:


>>> string.ascii_uppercase
'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
>>> string.digits
'0123456789'
>>> string.ascii_uppercase + string.digits
'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'



Then we use a list comprehension to create a list of 'n' elements:


>>> range(4) # range create a list of 'n' numbers
[0, 1, 2, 3]
>>> ['elem' for _ in range(4)] # we use range to create 4 times 'elem'
['elem', 'elem', 'elem', 'elem']



In the example above, we use 
[
 to create the list, but we don't in the 
id_generator
 function so Python doesn't create the list in memory, but generates the elements on the fly, one by one (more about this 
here
).


Instead of asking to create 'n' times the string 
elem
, we will ask Python to create 'n' times a random character, picked from a sequence of characters:


>>> random.choice(""abcde"")
'a'
>>> random.choice(""abcde"")
'd'
>>> random.choice(""abcde"")
'b'



Therefore 
random.choice(chars) for _ in range(size)
 really is creating a sequence of 
size
 characters. Characters that are randomly picked from 
chars
:


>>> [random.choice('abcde') for _ in range(3)]
['a', 'b', 'b']
>>> [random.choice('abcde') for _ in range(3)]
['e', 'b', 'e']
>>> [random.choice('abcde') for _ in range(3)]
['d', 'a', 'c']



Then we just join them with an empty string so the sequence becomes a string:


>>> ''.join(['a', 'b', 'b'])
'abb'
>>> [random.choice('abcde') for _ in range(3)]
['d', 'c', 'b']
>>> ''.join(random.choice('abcde') for _ in range(3))
'dac'


","I'm sorry, I couldn't find relevant information in the provided context.
",6.147658283376849e-168,0.015665796344647518,0.007230657989877079,0.2902485430240631,0.008299043
How do I print to stderr in Python?,"I found this to be the only one short, flexible, portable and readable:


import sys

def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)



The optional function 
eprint
 saves some repetition. It can be used in the same way as the standard 
print
 function:


>>> print(""Test"")
Test
>>> eprint(""Test"")
Test
>>> eprint(""foo"", ""bar"", ""baz"", sep=""---"")
foo---bar---baz


","Answer: To print to stderr in Python, you can define an object with a `write()` method and assign it to `sys.stderr`. For example, you can use `io.StringIO` and then call `sys.stderr.write(sys.stdout.getvalue())`.

References: [2, 3]
",6.451892463478741e-232,0.12,0.09541984732824428,0.5366269946098328,0.5433308
Save plot to image file instead of displaying it,"When using 
matplotlib.pyplot.savefig
, the file format can be specified by the extension:


from matplotlib import pyplot as plt

plt.savefig('foo.png')
plt.savefig('foo.pdf')



That gives a rasterized or vectorized output respectively.
In addition, there is sometimes undesirable whitespace around the image, which can be removed with:


plt.savefig('foo.png', bbox_inches='tight')



Note that if showing the plot, 
plt.show()
 should follow 
plt.savefig()
; otherwise, the file image will be blank.

","I'm sorry, I couldn't find relevant information in the provided context.
",8.084448072045063e-234,0.04444444444444445,0.024242424242424246,0.3291880786418915,-0.012632374
Selecting multiple columns in a Pandas dataframe,"The column names (which are strings) cannot be sliced in the manner you tried.


Here you have a couple of options. If you know from context which variables you want to slice out, you can just return a view of only those columns by passing a list into the 
__getitem__
 syntax
 (the []'s).


df1 = df[['a', 'b']]



Alternatively, if it matters to index them numerically and not by their name (say your code should automatically do this without knowing the names of the first two columns) then you can do this instead:


df1 = df.iloc[:, 0:2] # Remember that Python does not slice inclusive of the ending index.



Additionally, you should familiarize yourself with the idea of a view into a Pandas object vs. a copy of that object. The first of the above methods will return a new copy in memory of the desired sub-object (the desired slices).


Sometimes, however, there are indexing conventions in Pandas that don't do this and instead give you a new variable that just refers to the same chunk of memory as the sub-object or slice in the original object. This will happen with the second way of indexing, so you can modify it with the 
.copy()
 method to get a regular copy. When this happens, changing what you think is the sliced object can sometimes alter the original object. Always good to be on the look out for this.


df1 = df.iloc[0, 0:2].copy() # To avoid the case where changing df1 also changes df



To use 
iloc
, you need to know the column positions (or indices). As the column positions may change, instead of hard-coding indices, you can use 
iloc
 along with 
get_loc
 function of 
columns
 method of dataframe object to obtain column indices.


{df.columns.get_loc(c): c for idx, c in enumerate(df.columns)}



Now you can use this dictionary to access columns through names and using 
iloc
.

","I'm sorry, I couldn't find relevant information in the provided context.",5.9668158228604825e-167,0.01775147928994083,0.010109763142692086,0.3521602153778076,-0.0011213459
Make a dictionary (dict) from separate lists of keys and values,"Like this:


keys = ['a', 'b', 'c']
values = [1, 2, 3]
dictionary = dict(zip(keys, values))
print(dictionary) # {'a': 1, 'b': 2, 'c': 3}



Voila :-)  The pairwise 
dict
 constructor and 
zip
 function are awesomely useful.

","Answer: You can use the `dict()` constructor to build dictionaries from sequences of key-value pairs. Also, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions.

References: [1]
",8.896400634860552e-232,0.17910447761194032,0.1358695652173913,0.5390495657920837,0.6702429
What does __all__ mean in Python?,"It's a list of public objects of that module, as interpreted by 
import *
. It overrides the default of hiding everything that begins with an underscore.

","I'm sorry, I couldn't find relevant information in the provided context.",2.3359260380604138e-232,0.05128205128205129,0.052631578947368425,0.4216881990432739,0.1824598
What is the best way of implementing a singleton in Python?,"You just need a decorator, different depending on the python version.


Notice how 
foo
 gets printed only once.




Python 3.2+


Implementation
:


from functools import lru_cache

@lru_cache(maxsize=None)
class CustomClass(object):

    def __init__(self, arg):
        print(f""CustomClass initialised with {arg}"")
        self.arg = arg



Usage


c1 = CustomClass(""foo"")
c2 = CustomClass(""foo"")
c3 = CustomClass(""bar"")

print(c1 == c2)
print(c1 == c3)



Output


>>> CustomClass initialised with foo
>>> CustomClass initialised with bar
>>> True
>>> False





Python 3.9+


Implementation
:


from functools import cache

@cache
class CustomClass(object):
    ...


","Answer: A singleton means only one instance of that object can exist.

References: [2, 3]
",1.0632535048187678e-233,0.0792079207920792,0.0273224043715847,0.4195283055305481,0.22915837
How do I get the filename without the extension from a path in Python?,"Python 3.4+


Use 
pathlib.Path.stem


>>> from pathlib import Path
>>> Path(""/path/to/file.txt"").stem
'file'
>>> Path(""/path/to/file.tar.gz"").stem
'file.tar'



Python < 3.4


Use 
os.path.splitext
 in combination with 
os.path.basename
:


>>> os.path.splitext(os.path.basename(""/path/to/file.txt""))[0]
'file'
>>> os.path.splitext(os.path.basename(""/path/to/file.tar.gz""))[0]
'file.tar'


","Answer: You can use the `stem` attribute of a `PurePath` object to get the filename without the extension.

References: [1]
",0.0,0.06976744186046512,0.027027027027027025,0.4379482567310333,0.4128051
How do I profile a Python script?,"Python includes a profiler called 
cProfile
.
 It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.


You can call it from within your code, or from the interpreter, like this:


import cProfile
cProfile.run('foo()')



Even more usefully, you can invoke cProfile when running a script:


python -m cProfile myscript.py



Or when running a module:


python -m cProfile -m mymodule



To make it even easier, I made a little batch file called 'profile.bat':


python -m cProfile %1



So all I have to do is run:


profile euler048.py



And I get this:


1007 function calls in 0.061 CPU seconds

Ordered by: standard name
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    1    0.000    0.000    0.061    0.061 
:1(
)
 1000    0.051    0.000    0.051    0.000 euler048.py:2(
)
    1    0.005    0.005    0.061    0.061 euler048.py:2(
)
    1    0.000    0.000    0.061    0.061 {execfile}
    1    0.002    0.002    0.053    0.053 {map}
    1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}
    1    0.000    0.000    0.000    0.000 {range}
    1    0.003    0.003    0.003    0.003 {sum}



For more information, check out this tutorial from PyCon 2013 titled

Python Profiling


Also via YouTube
.

","Answer: To profile a Python script, you can use the Linux perf profiler, which is a tool that provides performance information about your application. In Python 3.12 and later, the interpreter can run in a special mode that allows Python functions to appear in the output of the perf profiler. To collect the data, you can run perf to sample CPU stack traces, and then use perf report to analyze the data.

References: [1, 2, 3]
",6.91081693159719e-156,0.10625000000000001,0.11488802083333335,0.5094842314720154,0.6722393
if/else in a list comprehension,"You can totally do that. It's just an ordering issue:


[f(x) if x is not None else '' for x in xs]



In general,


[f(x) if condition else g(x) for x in sequence]



And, for list comprehensions with 
if
 conditions only,


[f(x) for x in sequence if condition]



Note that this actually uses a different language construct, a 
conditional expression
, which itself is not part of the 
comprehension syntax
, while the 
if
 after the 
for…in
 is part of list comprehensions and used to 
filter
 elements from the source iterable.




Conditional expressions can be used in all kinds of situations where you want to choose between two expression values based on some condition. This does the same as the 
ternary operator 
?:
 that exists in other languages
. For example:


value = 123
print(value, 'is', 'even' if value % 2 == 0 else 'odd')


","I'm sorry, I couldn't find relevant information in the provided context.
",6.094263601362811e-237,0.025477707006369428,0.012099213551119177,0.36513084173202515,-0.031867474
Replacements for switch statement in Python?,"Python 3.10 (2021) introduced the 
match
-
case
 statement, which provides a first-class implementation of a ""switch"" for Python. For example:


def f(x):
    match x:
        case 'a':
            return 1
        case 'b':
            return 2
        case _:
            return 0   # 0 is the default case if x is not found



The 
match
-
case
 statement is considerably more powerful than this simple example.


Documentation:




match
 statements
 (under the ""More Control Flow Tools"" page)


The 
match
 statement
 (under ""Compound statements"" page)


PEP 634 – Structural Pattern Matching: Specification


PEP 636 – Structural Pattern Matching: Tutorial






If you need to support Python ≤ 3.9, use a dictionary instead:


def f(x):
    return {
        'a': 1,
        'b': 2,
    }.get(x, 0)  # default case


","Answer: In Python, the functions of switch or case statements can be achieved using a sequence of `if... elif... elif... else` statements, or the `match ... case` statement (available since Python 3.10). Alternatively, for a large number of possibilities, a dictionary can map case values to functions.

References: [1, 3]
",1.0738857951699072e-155,0.19512195121951217,0.1080737444373808,0.5372087359428406,0.76607215
How to check for NaN values,"Use 
math.isnan
:


>>> import math
>>> x = float('nan')
>>> math.isnan(x)
True


","Answer: You can check for NaN values using `math.isnan`. To count the number of NaN values in a dataset, you can use `sum(map(isnan, data))`. To remove NaN values, you can use `itertools.filterfalse`.

References: [2, 3]
",0.0,0.196078431372549,0.11986301369863012,0.5292813777923584,0.6154231
Why do Python classes inherit object?,"

Is there any reason for a class declaration to inherit from 
object
?




In Python 3, apart from compatibility between Python 2 and 3, 
no reason
. In Python 2, 
many reasons
. 




Python 2.x story:


In Python 2.x (from 2.2 onwards) there's two styles of classes depending on the presence or absence of 
object
 as a base-class:




""classic"" style
 classes: they don't have 
object
 as a base class:


>>> class ClassicSpam:      # no base class
...     pass
>>> ClassicSpam.__bases__
()



""new"" style
 classes: they have, directly 
or indirectly
 (e.g inherit from a 
built-in type
), 
object
 as a base class:


>>> class NewSpam(object):           # directly inherit from object
...    pass
>>> NewSpam.__bases__
(
,)
>>> class IntSpam(int):              # indirectly inherit from object...
...    pass
>>> IntSpam.__bases__
(
,) 
>>> IntSpam.__bases__[0].__bases__   # ... because int inherits from object  
(
,)





Without a doubt, when writing a class you'll 
always
 want to go for new-style classes. The perks of doing so are numerous, to list some of them:




Support for descriptors
. Specifically, the following constructs are made possible with descriptors: 




classmethod
: A method that receives the class as an implicit argument instead of the instance.


staticmethod
: A method that does not receive the implicit argument 
self
 as a first argument.


properties with 
property
: Create functions for managing the getting, setting and deleting of an attribute. 


__slots__
: Saves memory consumptions of a class and also results in faster attribute access. Of course, it does 
impose limitations
.




The 
__new__
 static method: lets you customize how new class instances are created. 


Method resolution order (MRO)
: in what order the base classes of a class will be searched when trying to resolve which method to call. 


Related to MRO, 
super
 calls
. Also see, 
super()
 considered super.




If you don't inherit from 
object
, forget these. A more exhaustive description of the previous bullet points along with other perks of ""new"" style classes can be found 
here
.


One of the downsides of new-style classes is that the class itself is more memory demanding. Unless you're creating many class objects, though, I doubt this would be an issue and it's a negative sinking in a sea of positives.




Python 3.x story:


In Python 3, things are simplified. Only new-style classes exist (referred to plainly as classes) so, the only difference in adding 
object
 is requiring you to type in 8 more characters. This:


class ClassicSpam:
    pass



is completely equivalent (apart from their name :-) to this:


class NewSpam(object):
     pass



and to this:


class Spam():
    pass



All have 
object
 in their 
__bases__
.


>>> [object in cls.__bases__ for cls in {Spam, NewSpam, ClassicSpam}]
[True, True, True]





So, what should you do?


In Python 2:
 
always inherit from 
object
 explicitly
. Get the perks.


In Python 3:
 inherit from 
object
 if you are writing code that tries to be Python agnostic, that is, it needs to work both in Python 2 and in Python 3. Otherwise don't, it really makes no difference since Python inserts it for you behind the scenes.

","Answer: All classes inherit from object; thus, any case of multiple inheritance provides more than one path to reach object.

References: [1]
",1.2025477369152146e-164,0.038461538461538464,0.02234535807268919,0.45103004574775696,0.42727742
How to put the legend outside the plot,"

You can make the legend text smaller by specifying 
set_size
 of 
FontProperties
.


Resources:



Legend guide


matplotlib.legend


matplotlib.pyplot.legend


matplotlib.font_manager




set_size(self, size)


Valid font size are 
xx-small
, 
x-small
, 
small
, 
medium
, 
large
, 
x-large
, 
xx-large
, 
larger
, 
smaller
, and 
None
.






Real Python: Python Plotting With Matplotlib (Guide)








import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

fontP = FontProperties()
fontP.set_size('xx-small')

p1, = plt.plot([1, 2, 3], label='Line 1')
p2, = plt.plot([3, 2, 1], label='Line 2')
plt.legend(handles=[p1, p2], title='title', bbox_to_anchor=(1.05, 1), loc='upper left', prop=fontP)







fontsize='xx-small'
 also works, without importing 
FontProperties
.




plt.legend(handles=[p1, p2], title='title', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='xx-small')


","I'm sorry, I couldn't find relevant information in the provided context.
",2.5548202360647446e-235,0.013513513513513514,0.01590330788804071,0.2699666917324066,-0.00015867036
How do I reverse a string in Python?,"Using 
slicing
:


>>> 'hello world'[::-1]
'dlrow olleh'





Slice notation takes the form 
[start:stop:step]
. In this case, we omit the 
start
 and 
stop
 positions since we want the whole string. We also use 
step = -1
, which means, ""repeatedly step from right to left by 1 character"".

","Answer: To iterate over a sequence in reverse order, you can use the `reversed()` built-in function. This builds a new copy with the reversed order to iterate over, without modifying the original sequence.

References: [2]
",7.507857495251065e-232,0.14457831325301204,0.12724550898203593,0.4995693564414978,0.39315772
How do I check if a directory exists in Python?,"Use 
os.path.isdir
 for directories only:


>>> import os
>>> os.path.isdir('new_folder')
True



Use 
os.path.exists
 for both files and directories:


>>> import os
>>> os.path.exists(os.path.join(os.getcwd(), 'new_folder', 'file.txt'))
False



Alternatively, you can use 
pathlib
:


 >>> from pathlib import Path
 >>> Path('new_folder').is_dir()
 True
 >>> (Path.cwd() / 'new_folder' / 'file.txt').exists()
 False


","Answer: You can use `os.path.isdir(path)` to check if a directory exists. It returns `True` if the path is an existing directory, and it accepts path-like objects. Alternatively, `os.path.exists(path)` will return `True` if the `path` refers to an existing path or an open file descriptor.

References: [1, 3]
",3.0936650509380603e-155,0.27586206896551724,0.1520458043912015,0.5727114677429199,0.68851805
"What is the Python 3 equivalent of ""python -m SimpleHTTPServer""","From 
the docs
:




The 
SimpleHTTPServer
 module has been merged into 
http.server
 in Python 3.0. The 2to3 tool will automatically adapt imports when converting your sources to 3.0.




So, your command is 
python -m http.server
, or depending on your installation, it can be:


python3 -m http.server


","I'm sorry, I couldn't find relevant information in the provided context.
",4.509104038208206e-233,0.0634920634920635,0.041407867494824016,0.35872340202331543,-0.023890857
What is setup.py?,"setup.py
 is a Python file, the presence of which is an indication that the module/package you are about to install has likely been packaged and distributed with 
Distutils
, which is the standard for distributing Python Modules.


This allows you to easily 
install Python packages
. Often it's enough to write:


$ pip install . 



pip
 will use 
setup.py
 to install your module. Avoid calling 
setup.py
 directly.

","I'm sorry, I couldn't find relevant information in the provided context.
",6.154693443478704e-234,0.024691358024691357,0.022321428571428565,0.36772653460502625,0.02855327
How can I flush the output of the print function?,"In Python 3, 
print
 can take an optional 
flush
 argument:


print(""Hello, World!"", flush=True)



In Python 2, after calling 
print
, do:


import sys
sys.stdout.flush()



By default, 
print
 prints to 
sys.stdout
 (see the documentation for more about 
file objects
).

","I'm sorry, I couldn't find relevant information in the provided context.
",7.846632075469826e-233,0.07272727272727272,0.048169556840077066,0.3163043260574341,-0.12907362
Create a dictionary with comprehension,"Use a 
dict comprehension
 (Python 2.7 and later):


{key: value for key, value in zip(keys, values)}





Alternatively, use the 
dict
 constructor:


pairs = [('a', 1), ('b', 2)]
dict(pairs)                          # → {'a': 1, 'b': 2}
dict((k, v + 10) for k, v in pairs)  # → {'a': 11, 'b': 12}



Given separate lists of keys and values, use the 
dict
 constructor with 
zip
:


keys = ['a', 'b']
values = [1, 2]
dict(zip(keys, values))              # → {'a': 1, 'b': 2}


","Answer: Dict comprehensions can be used to create dictionaries from arbitrary key and value expressions using the syntax `{x: x**2 for x in (2, 4, 6)}` as an example.

References: [2]
",2.4544513550351436e-232,0.20754716981132076,0.09706349016987974,0.5795232653617859,0.6251718
Convert integer to string in Python,">>> str(42)
'42'

>>> int('42')
42



Links to the documentation:




int()


str()




str(x)
 converts any object 
x
 to a string by calling 
x.
__str__()
, or 
repr(x)
 if 
x
 doesn't have a 
__str__()
 method.

","Answer: To convert a number to a string, you can use the built-in type constructor `str()`. If you want a hexadecimal or octal representation, use the built-in functions `hex()` or `oct()`. For specialized formatting, you can use f-strings and format strings.

References: [1]
",3.421647610625111e-155,0.1951219512195122,0.23213728549141965,0.546568751335144,0.60465074
Use of *args and **kwargs,"The syntax is the 
*
 and 
**
.  The names 
*args
 and 
**kwargs
 are only by convention but there's no hard requirement to use them.


You would use 
*args
 when you're not sure how many arguments might be passed to your function, i.e. it allows you pass an arbitrary number of arguments to your function.  For example:


>>> def print_everything(*args):
        for count, thing in enumerate(args):
...         print( '{0}. {1}'.format(count, thing))
...
>>> print_everything('apple', 'banana', 'cabbage')
0. apple
1. banana
2. cabbage



Similarly, 
**kwargs
 allows you to handle named arguments that you have not defined in advance:


>>> def table_things(**kwargs):
...     for name, value in kwargs.items():
...         print( '{0} = {1}'.format(name, value))
...
>>> table_things(apple = 'fruit', cabbage = 'vegetable')
cabbage = vegetable
apple = fruit



You can use these along with named arguments too.  The explicit arguments get values first and then everything else is passed to 
*args
 and 
**kwargs
.  The named arguments come first in the list.  For example:


def table_things(titlestring, **kwargs)



You can also use both in the same function definition but 
*args
 must occur before 
**kwargs
.


You can also use the 
*
 and 
**
 syntax when calling a function.  For example:


>>> def print_three_things(a, b, c):
...     print( 'a = {0}, b = {1}, c = {2}'.format(a,b,c))
...
>>> mylist = ['aardvark', 'baboon', 'cat']
>>> print_three_things(*mylist)
a = aardvark, b = baboon, c = cat



As you can see in this case it takes the list (or tuple) of items and unpacks it. By this it matches them to the arguments in the function.  Of course, you could have a 
*
 both in the function definition and in the function call.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.8881333408285256e-165,0.02112676056338028,0.013790338258164852,0.30247846245765686,-0.0071874764
Change column type in pandas,"You have four main options for converting types in pandas:




to_numeric()
 - provides functionality to safely convert non-numeric types (e.g. strings) to a suitable numeric type. (See also 
to_datetime()
 and 
to_timedelta()
.)




astype()
 - convert (almost) any type to (almost) any other type (even if it's not necessarily sensible to do so). Also allows you to convert to 
categorial
 types (very useful).




infer_objects()
 - a utility method to convert object columns holding Python objects to a pandas type if possible.




convert_dtypes()
 - convert DataFrame columns to the ""best possible""  dtype that supports 
pd.NA
 (pandas' object to indicate a missing value).






Read on for more detailed explanations and usage of each of these methods.




1. 
to_numeric()


The best way to convert one or more columns of a DataFrame to numeric values is to use 
pandas.to_numeric()
.


This function will try to change non-numeric objects (such as strings) into integers or floating-point numbers as appropriate.


Basic usage


The input to 
to_numeric()
 is a Series or a single column of a DataFrame.


>>> s = pd.Series([""8"", 6, ""7.5"", 3, ""0.9""]) # mixed string and numeric values
>>> s
0      8
1      6
2    7.5
3      3
4    0.9
dtype: object

>>> pd.to_numeric(s) # convert everything to float values
0    8.0
1    6.0
2    7.5
3    3.0
4    0.9
dtype: float64



As you can see, a new Series is returned. Remember to assign this output to a variable or column name to continue using it:


# convert Series
my_series = pd.to_numeric(my_series)

# convert column ""a"" of a DataFrame
df[""a""] = pd.to_numeric(df[""a""])



You can also use it to convert multiple columns of a DataFrame via the 
apply()
 method:


# convert all columns of DataFrame
df = df.apply(pd.to_numeric) # convert all columns of DataFrame

# convert just columns ""a"" and ""b""
df[[""a"", ""b""]] = df[[""a"", ""b""]].apply(pd.to_numeric)



As long as your values can all be converted, that's probably all you need.


Error handling


But what if some values can't be converted to a numeric type?


to_numeric()
 also takes an 
errors
 keyword argument that allows you to force non-numeric values to be 
NaN
, or simply ignore columns containing these values.


Here's an example using a Series of strings 
s
 which has the object dtype:


>>> s = pd.Series(['1', '2', '4.7', 'pandas', '10'])
>>> s
0         1
1         2
2       4.7
3    pandas
4        10
dtype: object



The default behaviour is to raise if it can't convert a value. In this case, it can't cope with the string 'pandas':


>>> pd.to_numeric(s) # or pd.to_numeric(s, errors='raise')
ValueError: Unable to parse string



Rather than fail, we might want 'pandas' to be considered a missing/bad numeric value. We can coerce invalid values to 
NaN
 as follows using the 
errors
 keyword argument:


>>> pd.to_numeric(s, errors='coerce')
0     1.0
1     2.0
2     4.7
3     NaN
4    10.0
dtype: float64



The third option for 
errors
 is just to ignore the operation if an invalid value is encountered:


>>> pd.to_numeric(s, errors='ignore')
# the original Series is returned untouched



This last option is particularly useful for converting your entire DataFrame, but don't know which of our columns can be converted reliably to a numeric type. In that case, just write:


df.apply(pd.to_numeric, errors='ignore')



The function will be applied to each column of the DataFrame. Columns that can be converted to a numeric type will be converted, while columns that cannot (e.g. they contain non-digit strings or dates) will be left alone.


Downcasting


By default, conversion with 
to_numeric()
 will give you either an 
int64
 or 
float64
 dtype (or whatever integer width is native to your platform).


That's usually what you want, but what if you wanted to save some memory and use a more compact dtype, like 
float32
, or 
int8
?


to_numeric()
 gives you the option to downcast to either 
'integer'
, 
'signed'
, 
'unsigned'
, 
'float'
. Here's an example for a simple series 
s
 of integer type:


>>> s = pd.Series([1, 2, -7])
>>> s
0    1
1    2
2   -7
dtype: int64



Downcasting to 
'integer'
 uses the smallest possible integer that can hold the values:


>>> pd.to_numeric(s, downcast='integer')
0    1
1    2
2   -7
dtype: int8



Downcasting to 
'float'
 similarly picks a smaller than normal floating type:


>>> pd.to_numeric(s, downcast='float')
0    1.0
1    2.0
2   -7.0
dtype: float32





2. 
astype()


The 
astype()
 method enables you to be explicit about the dtype you want your DataFrame or Series to have. It's very versatile in that you can try and go from one type to any other.


Basic usage


Just pick a type: you can use a NumPy dtype (e.g. 
np.int16
), some Python types (e.g. bool), or pandas-specific types (like the categorical dtype).


Call the method on the object you want to convert and 
astype()
 will try and convert it for you:


# convert all DataFrame columns to the int64 dtype
df = df.astype(int)

# convert column ""a"" to int64 dtype and ""b"" to complex type
df = df.astype({""a"": int, ""b"": complex})

# convert Series to float16 type
s = s.astype(np.float16)

# convert Series to Python strings
s = s.astype(str)

# convert Series to categorical type - see docs for more details
s = s.astype('category')



Notice I said ""try"" - if 
astype()
 does not know how to convert a value in the Series or DataFrame, it will raise an error. For example, if you have a 
NaN
 or 
inf
 value you'll get an error trying to convert it to an integer.


As of pandas 0.20.0, this error can be suppressed by passing 
errors='ignore'
. Your original object will be returned untouched.


Be careful


astype()
 is powerful, but it will sometimes convert values ""incorrectly"". For example:


>>> s = pd.Series([1, 2, -7])
>>> s
0    1
1    2
2   -7
dtype: int64



These are small integers, so how about converting to an unsigned 8-bit type to save memory?


>>> s.astype(np.uint8)
0      1
1      2
2    249
dtype: uint8



The conversion worked, but the -7 was wrapped round to become 249 (i.e. 2
8
 - 7)!


Trying to downcast using 
pd.to_numeric(s, downcast='unsigned')
 instead could help prevent this error.




3. 
infer_objects()


Version 0.21.0 of pandas introduced the method 
infer_objects()
 for converting columns of a DataFrame that have an object datatype to a more specific type (soft conversions).


For example, here's a DataFrame with two columns of object type. One holds actual integers and the other holds strings representing integers:


>>> df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')
>>> df.dtypes
a    object
b    object
dtype: object



Using 
infer_objects()
, you can change the type of column 'a' to int64:


>>> df = df.infer_objects()
>>> df.dtypes
a     int64
b    object
dtype: object



Column 'b' has been left alone since its values were strings, not integers. If you wanted to force both columns to an integer type, you could use 
df.astype(int)
 instead.




4. 
convert_dtypes()


Version 1.0 and above includes a method 
convert_dtypes()
 to convert Series and DataFrame columns to the best possible dtype that supports the 
pd.NA
 missing value.


Here ""best possible"" means the type most suited to hold the values. For example, this a pandas integer type, if all of the values are integers (or missing values): an object column of Python integer objects are converted to 
Int64
, a column of NumPy 
int32
 values, will become the pandas dtype 
Int32
.


With our 
object
 DataFrame 
df
, we get the following result:


>>> df.convert_dtypes().dtypes                                             
a     Int64
b    string
dtype: object



Since column 'a' held integer values, it was converted to the 
Int64
 type (which is capable of holding missing values, unlike 
int64
).


Column 'b' contained string objects, so was changed to pandas' 
string
 dtype.


By default, this method will infer the type from object values in each column. We can change this by passing 
infer_objects=False
:


>>> df.convert_dtypes(infer_objects=False).dtypes                          
a    object
b    string
dtype: object



Now column 'a' remained an object column: pandas knows it can be described as an 'integer' column (internally it ran 
infer_dtype
) but didn't infer exactly what dtype of integer it should have so did not convert it. Column 'b' was again converted to 'string' dtype as it was recognised as holding 'string' values.

","I'm sorry, I couldn't find relevant information in the provided context.",1.8726359837419607e-207,0.004140786749482402,0.0030413625304136255,0.29150909185409546,-0.06092784
Catch and print full Python exception traceback without halting/exiting the program,"Some other answer have already pointed out the 
traceback
 module.


Please notice that with 
print_exc
, in some corner cases, you will not obtain what you would expect. In Python 2.x:


import traceback

try:
    raise TypeError(""Oups!"")
except Exception, err:
    try:
        raise TypeError(""Again !?!"")
    except:
        pass

    traceback.print_exc()



...will display the traceback of the 
last
 exception:


Traceback (most recent call last):
  File ""e.py"", line 7, in 

    raise TypeError(""Again !?!"")
TypeError: Again !?!



If you really need to access the original 
traceback
 one solution is to cache the 
exception infos
 as returned from 
exc_info
 in a local variable and display it using 
print_exception
:


import traceback
import sys

try:
    raise TypeError(""Oups!"")
except Exception, err:
    try:
        exc_info = sys.exc_info()

        # do you usefull stuff here
        # (potentially raising an exception)
        try:
            raise TypeError(""Again !?!"")
        except:
            pass
        # end of useful stuff


    finally:
        # Display the *original* exception
        traceback.print_exception(*exc_info)
        del exc_info



Producing:


Traceback (most recent call last):
  File ""t.py"", line 6, in 

    raise TypeError(""Oups!"")
TypeError: Oups!



Few pitfalls with this though:




From the doc of 
sys_info
:




Assigning the traceback return value to a local variable in a function that is handling an exception will cause a 
circular reference
. This will prevent anything referenced by a local variable in the same function or by the traceback from being garbage collected. [...] 
If you do need the traceback, make sure to delete it after use
 (best done with a try ... finally statement)




but, from the same doc:




Beginning with Python 2.2, such cycles are automatically reclaimed
 when garbage collection is enabled and they become unreachable, but it remains more efficient to avoid creating cycles.








On the other hand, by allowing you to access the traceback 
associated with
 an exception, Python 3 produce a less surprising result:


import traceback

try:
    raise TypeError(""Oups!"")
except Exception as err:
    try:
        raise TypeError(""Again !?!"")
    except:
        pass

    traceback.print_tb(err.__traceback__)



... will display:


  File ""e3.py"", line 4, in 

    raise TypeError(""Oups!"")


","Answer: To catch and print the full traceback of a Python exception without halting the program, you can use `traceback.print_exc()`. This is a shorthand for `traceback.print_exception(sys.exception())`.

References: [1]
",1.7158432626273507e-159,0.09809264305177112,0.03880669415474169,0.5715380311012268,0.7872084
What are the differences between type() and isinstance()?,"To summarize the contents of other (already good!) answers, 
isinstance
 caters for inheritance (an instance of a derived class 
is an
 instance of a base class, too), while checking for equality of 
type
 does not (it demands identity of types and rejects instances of subtypes, AKA subclasses).


Normally, in Python, you want your code to support inheritance, of course (since inheritance is so handy, it would be bad to stop code using yours from using it!), so 
isinstance
 is less bad than checking identity of 
type
s because it seamlessly supports inheritance.


It's not that 
isinstance
 is 
good
, mind you—it's just 
less bad
 than checking equality of types.  The normal, Pythonic, preferred solution is almost invariably ""duck typing"": try using the argument 
as if
 it was of a certain desired type, do it in a 
try
/
except
 statement catching all exceptions that could arise if the argument was not in fact of that type (or any other type nicely duck-mimicking it;-), and in the 
except
 clause, try something else (using the argument ""as if"" it was of some other type).


basestring
 
is
, however, quite a special case—a builtin type that exists 
only
 to let you use 
isinstance
 (both 
str
 and 
unicode
 subclass 
basestring
). Strings are sequences (you could loop over them, index them, slice them, ...), but you generally want to treat them as ""scalar"" types—it's somewhat incovenient (but a reasonably frequent use case) to treat all kinds of strings (and maybe other scalar types, i.e., ones you can't loop on) one way, all containers (lists, sets, dicts, ...) in another way, and 
basestring
 plus 
isinstance
 helps you do that—the overall structure of this idiom is something like:


if isinstance(x, basestring)
  return treatasscalar(x)
try:
  return treatasiter(iter(x))
except TypeError:
  return treatasscalar(x)



You could say that 
basestring
 is an 
Abstract Base Class
 (""ABC"")—it offers no concrete functionality to subclasses, but rather exists as a ""marker"", mainly for use with 
isinstance
. The concept is obviously a growing one in Python, since 
PEP 3119
, which introduces a generalization of it, was accepted and has been implemented starting with Python 2.6 and 3.0.


The PEP makes it clear that, while ABCs can often substitute for duck typing, there is generally no big pressure to do that (see 
here
). ABCs as implemented in recent Python versions do however offer extra goodies: 
isinstance
 (and 
issubclass
) can now mean more than just ""[an instance of] a derived class"" (in particular, any class can be ""registered"" with an ABC so that it will show as a subclass, and its instances as instances of the ABC); and ABCs can also offer extra convenience to actual subclasses in a very natural way via Template Method design pattern applications (see 
here
 and 
here
 [[part II]] for more on the TM DP, in general and specifically in Python, independent of ABCs).


For the underlying mechanics of ABC support as offered in Python 2.6, see 
here
; for their 3.1 version, very similar, see 
here
.  In both versions, standard library module 
collections
 (that's the 3.1 version—for the very similar 2.6 version, see 
here
) offers several useful ABCs.


For the purpose of this answer, the key thing to retain about ABCs (beyond an arguably more natural placement for TM DP functionality, compared to the classic Python alternative of mixin classes such as 
UserDict.DictMixin
) is that they make 
isinstance
 (and 
issubclass
) much more attractive and pervasive (in Python 2.6 and going forward) than they used to be (in 2.5 and before), and therefore, by contrast, make checking type equality an even worse practice in recent Python versions than it already used to be.

","Answer: The built-in function `type()` is used to access an object's type. The built-in function `isinstance(obj, cls)` checks if an object is an instance of a given class or a subclass of it.

References: [2]
",1.0706815547891185e-08,0.06969696969696969,0.03142892443988871,0.5219110250473022,0.5512811
How do I sort a dictionary by key?,"

Note:
 for Python 3.7+, see 
this answer




Standard Python dictionaries are unordered (until Python 3.7). Even if you sorted the (key,value) pairs, you wouldn't be able to store them in a 
dict
 in a way that would preserve the ordering.


The easiest way is to use 
OrderedDict
, which remembers the order in which the elements have been inserted:


In [1]: import collections

In [2]: d = {2:3, 1:89, 4:5, 3:0}

In [3]: od = collections.OrderedDict(sorted(d.items()))

In [4]: od
Out[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])



Never mind the way 
od
 is printed out; it'll work as expected:


In [11]: od[1]
Out[11]: 89

In [12]: od[3]
Out[12]: 0

In [13]: for k, v in od.iteritems(): print k, v
   ....: 
1 89
2 3
3 0
4 5



Python 3


For Python 3 users, one needs to use the 
.items()
 instead of 
.iteritems()
:


In [13]: for k, v in od.items(): print(k, v)
   ....: 
1 89
2 3
3 0
4 5


","Answer: To sort a dictionary by its keys, you can use the `sorted()` function, which accepts any iterable. The `sorted()` function returns a new sorted list.

References: [1, 3]
",4.627172447873223e-157,0.10576923076923077,0.06948094459096336,0.5393916368484497,0.6906065
Is there a built-in function to print all the current properties and values of an object?,"You are really mixing together two different things.


Use 
dir()
, 
vars()
 or the 
inspect
 module to get what you are interested in (I use 
__builtins__
 as an example; you can use any object instead).


>>> l = dir(__builtins__)
>>> d = __builtins__.__dict__



Print that dictionary however fancy you like:


>>> print l
['ArithmeticError', 'AssertionError', 'AttributeError',...



or


>>> from pprint import pprint
>>> pprint(l)
['ArithmeticError',
 'AssertionError',
 'AttributeError',
 'BaseException',
 'DeprecationWarning',
...

>>> pprint(d, indent=2)
{ 'ArithmeticError': 
,
  'AssertionError': 
,
  'AttributeError': 
,
...
  '_': [ 'ArithmeticError',
         'AssertionError',
         'AttributeError',
         'BaseException',
         'DeprecationWarning',
...



Pretty printing is also available in the interactive debugger as a command:


(Pdb) pp vars()
{'__builtins__': {'ArithmeticError': 
,
                  'AssertionError': 
,
                  'AttributeError': 
,
                  'BaseException': 
,
                  'BufferError': 
,
                  ...
                  'zip': 
},
 '__file__': 'pass.py',
 '__name__': '__main__'}


","Answer: I'm sorry, I couldn't find relevant information in the provided context.

References: None
",2.1559572748969345e-158,0.05042016806722689,0.026364283944499498,0.3160811960697174,0.059005596
How to convert string to bytes in Python 3,"If you look at the docs for 
bytes
, it points you to 
bytearray
:




bytearray([source[, encoding[, errors]]])


Return a new array of bytes. The bytearray type is a mutable sequence of integers in the range 0 <= x < 256. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as most methods that the bytes type has, see Bytes and Byte Array Methods.


The optional source parameter can be used to initialize the array in a few different ways:


If it is a string, you must also give the encoding (and optionally, errors) parameters; bytearray() then converts the string to bytes using str.encode().


If it is an integer, the array will have that size and will be initialized with null bytes.


If it is an object conforming to the buffer interface, a read-only buffer of the object will be used to initialize the bytes array.


If it is an iterable, it must be an iterable of integers in the range 0 <= x < 256, which are used as the initial contents of the array.


Without an argument, an array of size 0 is created.




So 
bytes
 can do much more than just encode a string. It's Pythonic that it would allow you to call the constructor with any type of source parameter that makes sense.


For  encoding a string, I think that 
some_string.encode(encoding)
 is more Pythonic than using the constructor, because it is the most self documenting -- ""take this string and encode it with this encoding"" is clearer than 
bytes(some_string, encoding)
 -- there is no explicit verb when you use the constructor.


I checked the Python source. If you pass a unicode string to 
bytes
 using CPython, it calls 
PyUnicode_AsEncodedString
, which is the implementation of 
encode
; so you're just skipping a level of indirection if you call 
encode
 yourself.


Also, see Serdalis' comment -- 
unicode_string.encode(encoding)
 is also more Pythonic because its inverse is 
byte_string.decode(encoding)
 and symmetry is nice.

","I'm sorry, I couldn't find relevant information in the provided context.",1.4079364949263955e-167,0.017142857142857144,0.009730330831248262,0.3549763858318329,-0.033127625
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128),"Read the Python 
Unicode HOWTO
. This error is the 
very first example
.


Do not use 
str()
 to convert from unicode to encoded text / bytes.


Instead, use 
.encode()
 to encode the string:


p.agent_info = u' '.join((agent_contact, agent_telno)).encode('utf-8').strip()



or work entirely in unicode.

","Answer: A `UnicodeEncodeError` occurs when a string object contains code points that cannot be encoded with the specified codec, such as 'ascii'. The 'ascii' codec can only map code points 0-127.

References: [2]
",6.476979316768562e-232,0.048192771084337345,0.09259259259259257,0.49158307909965515,0.61173266
How do I move a file in Python?,"os.rename()
, 
os.replace()
, or 
shutil.move()


All employ the same syntax:


import os
import shutil

os.rename(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")
os.replace(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")
shutil.move(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")





The filename (
""file.foo""
) must be included in both the source and destination arguments. If it differs between the two, the file will be renamed as well as moved.


The directory within which the new file is being created must already exist.


On Windows, a file with that name must not exist or an exception will be raised, but 
os.replace()
 will silently replace a file even in that occurrence.


shutil.move
 simply calls 
os.rename
 in most cases. However, if the destination is on a different disk than the source, it will instead copy and then delete the source file.



","Answer: You can move a file or directory in Python using `shutil.move(src, dst, copy_function=copy2)`. This function recursively moves a file or directory (src) to another location (dst) and returns the destination. If the destination is on the current filesystem, `os.rename()` is used. Otherwise, the file is copied to the destination using `copy_function` and then removed.

References: [1, 2, 3]
",0.027093175109327503,0.17857142857142858,0.17624273072060687,0.5715636014938354,0.8047438
How do I get the full path of the current file's directory?,"The special variable 
__file__
 contains the path to the current file. From that we can get the directory using either 
pathlib
 or the 
os.path
 module.


Python 3


For the directory of the script being run:


import pathlib
pathlib.Path(__file__).parent.resolve()



For the current working directory:


import pathlib
pathlib.Path().resolve()



Python 2 and 3


For the directory of the script being run:


import os
os.path.dirname(os.path.abspath(__file__))



If you mean the current working directory:


import os
os.path.abspath(os.getcwd())



Note that before and after 
file
 is two underscores, not just one.


Also note that if you are running interactively or have loaded code from something other than a file (eg: a database or online resource), 
__file__
 may not be set since there is no notion of ""current file"". The above answer assumes the most common scenario of running a python script that is in a file.


References




pathlib
 in the python documentation.


os.path - Python 2.7
, 
os.path - Python 3


os.getcwd - Python 2.7
, 
os.getcwd - Python 3


what does the __file__ variable mean/do?



","I'm sorry, I couldn't find relevant information in the provided context.
",3.4674870442897756e-161,0.020100502512562818,0.01589825119236884,0.318839967250824,-0.01616276
Null object in Python,"In Python, the 'null' object is the singleton 
None
.


To check if something is 
None
, use the 
is
 identity operator:


if foo is None:
    ...


","Answer: The Python None object denotes a lack of value. It is a singleton, meaning that object identity tests (using == in C) are sufficient for comparison. There is no `PyNone_Check()` function for this reason. It has no methods and is immortal.

References: [1, 2, 3]
",1.0948551819675659e-231,0.2,0.23391812865497078,0.5456498861312866,0.68399036
Why can't Python parse this JSON data?,"Your data is not valid 
JSON
 format. You have 
[]
 when you should have 
{}
 for the 
""masks""
 and 
""parameters""
 elements:




[]
 are for JSON arrays, which are called 
list
 in Python


{}
 are for JSON objects, which are called 
dict
 in Python




Here's how your JSON file should look:


{
    ""maps"": [
        {
            ""id"": ""blabla"",
            ""iscategorical"": ""0""
        },
        {
            ""id"": ""blabla"",
            ""iscategorical"": ""0""
        }
    ],
    ""masks"": {
        ""id"": ""valore""
    },
    ""om_points"": ""value"",
    ""parameters"": {
        ""id"": ""valore""
    }
}



Then you can use your code:


import json
from pprint import pprint

with open('data.json') as f:
    data = json.load(f)

pprint(data)



With data, you can now also find values like so:


data[""maps""][0][""id""]
data[""masks""][""id""]
data[""om_points""]



Try those out and see if it starts to make sense.

","Answer: If the data being deserialized is not a valid JSON document, a JSONDecodeError will be raised.

References: [2, 3]
",3.6467420618210286e-157,0.07142857142857142,0.04003532743569531,0.48608729243278503,0.39708528
"What is the use of ""assert"" in Python?","The 
assert
 statement exists in almost every programming language. It has two main uses:




It helps detect problems early in your program, where the cause is clear, rather than later when some other operation fails. A type error in Python, for example, can go through several layers of code before actually raising an 
Exception
 if not caught early on.




It works as documentation for other developers reading the code, who see the 
assert
 and can confidently say that its condition holds from now on.






When you do...


assert condition



... you're telling the program to test that condition, and immediately trigger an error if the condition is false.


In Python, it's roughly equivalent to this:


if not condition:
    raise AssertionError()



Try it in the Python shell:


>>> assert True # nothing happens
>>> assert False
Traceback (most recent call last):
  File ""
"", line 1, in 

AssertionError



Assertions can include an optional message, and you can disable them when running the interpreter.


To print a message if the assertion fails:


assert False, ""Oh no! This assertion failed!""



Do 
not
 use parenthesis to call 
assert
 like a function. It is a statement. If you do 
assert(condition, message)
 you'll be running the 
assert
 with a 
(condition, message)
 tuple as first parameter.


As for disabling them, when running 
python
 in optimized mode, where 
__debug__
 is 
False
, assert statements will be ignored. Just pass the 
-O
 flag:


python -O script.py



See 
here
 for the relevant documentation.

","Answer: The TestCase class provides several assert methods to check for and report failures.

References: [3]
",9.827955434769169e-238,0.038910505836575876,0.02041573867854491,0.4719598591327667,0.53878814
Removing duplicates in lists,"The common approach to get a unique collection of items is to use a 
set
. Sets are 
unordered
 collections of 
distinct
 objects. To create a set from any iterable, you can simply pass it to the built-in 
set()
 function. If you later need a real list again, you can similarly pass the set to the 
list()
 function.


The following example should cover whatever you are trying to do:


>>> t = [1, 2, 3, 1, 2, 3, 5, 6, 7, 8]
>>> list(set(t))
[1, 2, 3, 5, 6, 7, 8]
>>> s = [1, 2, 3]
>>> list(set(t) - set(s))
[8, 5, 6, 7]



As you can see from the example result, 
the original order is not maintained
. As mentioned above, sets themselves are unordered collections, so the order is lost. When converting a set back to a list, an arbitrary order is created.


Maintaining order


If order is important to you, then you will have to use a different mechanism. A very common solution for this is to rely on 
OrderedDict
 to keep the order of keys during insertion:


>>> from collections import OrderedDict
>>> list(OrderedDict.fromkeys(t))
[1, 2, 3, 5, 6, 7, 8]



Starting with Python 3.7
, the built-in dictionary is guaranteed to maintain the insertion order as well, so you can also use that directly if you are on Python 3.7 or later (or CPython 3.6):


>>> list(dict.fromkeys(t))
[1, 2, 3, 5, 6, 7, 8]



Note that this may have some overhead of creating a dictionary first, and then creating a list from it. If you don’t actually need to preserve the order, you’re often better off using a set, especially because it gives you a lot more operations to work with. Check out 
this question
 for more details and alternative ways to preserve the order when removing duplicates.




Finally note that both the 
set
 as well as the 
OrderedDict
/
dict
 solutions require your items to be 
hashable
. This usually means that they have to be immutable. If you have to deal with items that are not hashable (e.g. list objects), then you will have to use a slow approach in which you will basically have to compare every item with every other item in a nested loop.

","Answer: To remove duplicates from a list, you can convert the list into a set, which removes duplicates, and then back into a list. This method is fast if all elements of the list can be used as set keys.
Alternatively, you can sort the list and then scan it from the end, deleting duplicates as you go. Here’s the code:
```python
if mylist:
    mylist.sort()
    last = mylist[-1]
    for i in range(len(mylist)-2, -1, -1):
        if last == mylist[i]:
            del mylist[i]
        else:
            last = mylist[i]
```
For a long discussion of other ways to remove duplicates, refer to the Python Cookbook.

References: [1]
",4.5330127294131194e-156,0.1316872427983539,0.12529819018547245,0.589928925037384,0.5777742
How do I print an exception in Python?,"For Python 2.6 and later and Python 3.x:


except Exception as e: print(e)



For Python 2.5 and earlier, use:


except Exception,e: print str(e)


","Answer: To print an exception, you can use a `try...except` block. In the `except` block, you can print the exception using the `print()` function. For example, `except Exception as err: print(f""Unexpected {err=}, {type(err)=}"") raise`. This will print the exception and its type.

References: [1]
",3.3820843419568566e-155,0.18181818181818185,0.29963859603748794,0.5047622919082642,0.65013313
How do I check which version of Python is running my script?,"This information is available in the 
sys.version
 string in the 
sys
 module:


>>> import sys



Human readable:


>>> print(sys.version)  # parentheses necessary in python 3.       
2.5.2 (r252:60911, Jul 31 2008, 17:28:52) 
[GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]



For further processing, use 
sys.version_info
 or 
sys.hexversion
:


>>> sys.version_info
(2, 5, 2, 'final', 0)
# or
>>> sys.hexversion
34014192



To ensure a script runs with a minimal version requirement of the Python interpreter add this to your code:


assert sys.version_info >= (2, 5)



This compares major and minor version information. Add micro (=
0
, 
1
, etc) and even releaselevel (=
'alpha'
,
'final'
, etc) to the tuple as you like. Note however, that it is almost always better to ""duck"" check if a certain feature is there, and if not, workaround (or bail out). Sometimes features go away in newer releases, being replaced by others.

","Answer: You can find the Python version using `sys.hexversion` or `sys.version_info`. Also, the `platform` module can be used with `platform.python_version()` which returns the version as a string, or `platform.python_version_tuple()` which returns the version as a tuple of strings.

References: [1, 3]
",3.740688887782184e-156,0.15999999999999998,0.10342950462710941,0.5721400380134583,0.78394586
How to make a class JSON serializable,"Do you have an idea about the expected output? For example, will this do?


>>> f  = FileItem(""/foo/bar"")
>>> magic(f)
'{""fname"": ""/foo/bar""}'



In that case you can merely call 
json.dumps(f.__dict__)
. 


If you want more customized output then you will have to subclass 
JSONEncoder
 and implement your own custom serialization. 


For a trivial example, see below.


>>> from json import JSONEncoder
>>> class MyEncoder(JSONEncoder):
        def default(self, o):
            return o.__dict__    

>>> MyEncoder().encode(f)
'{""fname"": ""/foo/bar""}'



Then you pass this class into the 
json.dumps()
 method as 
cls
 kwarg:


json.dumps(cls=MyEncoder)



If you also want to decode then you'll have to supply a custom 
object_hook
 to the 
JSONDecoder
 class. For example:


>>> def from_json(json_object):
        if 'fname' in json_object:
            return FileItem(json_object['fname'])
>>> f = JSONDecoder(object_hook = from_json).decode('{""fname"": ""/foo/bar""}')
>>> f
<__main__.FileItem object at 0x9337fac>
>>> 


","Answer: Enumerations can be pickled and unpickled, with some restrictions. Picklable enums must be defined in the top level of a module to be importable for unpickling. Pickle protocol version 4 makes it easier to pickle enums nested in other classes. You can modify how enum members are pickled/unpickled by defining __reduce_ex__() in the enumeration class, with the default method being by-value.

References: [1, 2]
",4.262525165746913e-232,0.08294930875576038,0.07688828584350972,0.49147263169288635,0.22481222
How to deal with SettingWithCopyWarning in Pandas,"The 
SettingWithCopyWarning
 was created to flag potentially confusing ""chained"" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a 
copy
.  [see 
GH5390
 and 
GH5597
 for background discussion.]


df[df['A'] > 2]['B'] = new_val  # new_val not set in df



The warning offers a suggestion to rewrite as follows:


df.loc[df['A'] > 2, 'B'] = new_val



However, this doesn't fit your usage, which is equivalent to:


df = df[df['A'] > 2]
df['B'] = new_val



While it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the 
docs on indexing
, if you'd like to read further.  You can safely disable this new warning with the following assignment.


import pandas as pd
pd.options.mode.chained_assignment = None  # default='warn'





Other Resources




pandas User Guide: Indexing and selecting data


Python Data Science Handbook: Data Indexing and Selection


Real Python: SettingWithCopyWarning in Pandas: Views vs Copies


Dataquest: SettingwithCopyWarning: How to Fix This Warning in Pandas


Towards Data Science: Explaining the SettingWithCopyWarning in pandas



","I'm sorry, I couldn't find relevant information in the provided context.
",1.43935780886542e-162,0.02654867256637168,0.012091898428053204,0.34237635135650635,0.091211766
How to drop rows of Pandas DataFrame whose value in a certain column is NaN,"Don't drop, just take the rows where EPS is not NA:


df = df[df['EPS'].notna()]


","I'm sorry, I couldn't find relevant information in the provided context.
",7.61581178815304e-232,0.13333333333333333,0.05813953488372093,0.38160401582717896,0.022832211
Running shell command and capturing the output,"In all officially maintained versions of Python, the simplest approach is to use the 
subprocess.check_output
 function:


>>> subprocess.check_output(['ls', '-l'])
b'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



check_output
 runs a single program that takes only arguments as input.
1
 It returns the result exactly as printed to 
stdout
. If you need to write input to 
stdin
, skip ahead to the 
run
 or 
Popen
 sections. If you want to execute complex shell commands, see the note on 
shell=True
 at the end of this answer.


The 
check_output
 function works in all officially maintained versions of Python. But for more recent versions, a more flexible approach is available.


Modern versions of Python (3.5 or higher): 
run


If you're using 
Python 3.5+
, and 
do not need backwards compatibility
, the new 
run
 function is recommended by the official documentation for most tasks. It provides a very general, high-level API for the 
subprocess
 module. To capture the output of a program, pass the 
subprocess.PIPE
 flag to the 
stdout
 keyword argument. Then access the 
stdout
 attribute of the returned 
CompletedProcess
 object:


>>> import subprocess
>>> result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)
>>> result.stdout
b'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



The return value is a 
bytes
 object, so if you want a proper string, you'll need to 
decode
 it. Assuming the called process returns a UTF-8-encoded string:


>>> result.stdout.decode('utf-8')
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



This can all be compressed to a one-liner if desired:


>>> subprocess.run(['ls', '-l'], stdout=subprocess.PIPE).stdout.decode('utf-8')
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



If you want to pass input to the process's 
stdin
, you can pass a 
bytes
 object to the 
input
 keyword argument:


>>> cmd = ['awk', 'length($0) > 5']
>>> ip = 'foo\nfoofoo\n'.encode('utf-8')
>>> result = subprocess.run(cmd, stdout=subprocess.PIPE, input=ip)
>>> result.stdout.decode('utf-8')
'foofoo\n'



You can capture errors by passing 
stderr=subprocess.PIPE
 (capture to 
result.stderr
) or 
stderr=subprocess.STDOUT
 (capture to 
result.stdout
 along with regular output). If you want 
run
 to throw an exception when the process returns a nonzero exit code, you can pass 
check=True
. (Or you can check the 
returncode
 attribute of 
result
 above.) When security is not a concern, you can also run more complex shell commands by passing 
shell=True
 as described at the end of this answer.


Later versions of Python streamline the above further. In Python 3.7+, the above one-liner can be spelled like this:


>>> subprocess.run(['ls', '-l'], capture_output=True, text=True).stdout
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



Using 
run
 this way adds just a bit of complexity, compared to the old way of doing things. But now you can do almost anything you need to do with the 
run
 function alone.


Older versions of Python (3-3.4): more about 
check_output


If you are using an older version of Python, or need modest backwards compatibility, you can use the 
check_output
 function as briefly described above. It has been available since Python 2.7.


subprocess.check_output(*popenargs, **kwargs)  



It takes takes the same arguments as 
Popen
 (see below), and returns a string containing the program's output. The beginning of this answer has a more detailed usage example. In Python 3.5+, 
check_output
 is equivalent to executing 
run
 with 
check=True
 and 
stdout=PIPE
, and returning just the 
stdout
 attribute.


You can pass 
stderr=subprocess.STDOUT
 to ensure that error messages are included in the returned output. When security is not a concern, you can also run more complex shell commands by passing 
shell=True
 as described at the end of this answer.


If you need to pipe from 
stderr
 or pass input to the process, 
check_output
 won't be up to the task. See the 
Popen
 examples below in that case.


Complex applications and legacy versions of Python (2.6 and below): 
Popen


If you need deep backwards compatibility, or if you need more sophisticated functionality than 
check_output
 or 
run
 provide, you'll have to work directly with 
Popen
 objects, which encapsulate the low-level API for subprocesses.


The 
Popen
 constructor accepts either 
a single command
 without arguments, or 
a list
 containing a command as its first item, followed by any number of arguments, each as a separate item in the list. 
shlex.split
 can help parse strings into appropriately formatted lists. 
Popen
 objects also accept a 
host of different arguments
 for process IO management and low-level configuration.


To send input and capture output, 
communicate
 is almost always the preferred method. As in:


output = subprocess.Popen([""mycmd"", ""myarg""], 
                          stdout=subprocess.PIPE).communicate()[0]



Or


>>> import subprocess
>>> p = subprocess.Popen(['ls', '-a'], stdout=subprocess.PIPE, 
...                                    stderr=subprocess.PIPE)
>>> out, err = p.communicate()
>>> print out
.
..
foo



If you set 
stdin=PIPE
, 
communicate
 also allows you to pass data to the process via 
stdin
:


>>> cmd = ['awk', 'length($0) > 5']
>>> p = subprocess.Popen(cmd, stdout=subprocess.PIPE,
...                           stderr=subprocess.PIPE,
...                           stdin=subprocess.PIPE)
>>> out, err = p.communicate('foo\nfoofoo\n')
>>> print out
foofoo



Note 
Aaron Hall's answer
, which indicates that on some systems, you may need to set 
stdout
, 
stderr
, and 
stdin
 all to 
PIPE
 (or 
DEVNULL
) to get 
communicate
 to work at all.


In some rare cases, you may need complex, real-time output capturing. 
Vartec
's answer suggests a way forward, but methods other than 
communicate
 are prone to deadlocks if not used carefully.


As with all the above functions, when security is not a concern, you can run more complex shell commands by passing 
shell=True
.


Notes


1. Running shell commands: the 
shell=True
 argument


Normally, each call to 
run
, 
check_output
, or the 
Popen
 constructor executes a 
single program
. That means no fancy bash-style pipes. If you want to run complex shell commands, you can pass 
shell=True
, which all three functions support. For example:


>>> subprocess.check_output('cat books/* | wc', shell=True, text=True)
' 1299377 17005208 101299376\n'



However, doing this raises 
security concerns
. If you're doing anything more than light scripting, you might be better off calling each process separately, and passing the output from each as an input to the next, via


run(cmd, [stdout=etc...], input=other_output)



Or


Popen(cmd, [stdout=etc...]).communicate(other_output)



The temptation to directly connect pipes is strong; resist it. Otherwise, you'll likely see deadlocks or have to do hacky things like 
this
.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.257012917085511e-194,0.005253940455341506,0.00373785198106155,0.3034309446811676,-0.11598268
Automatically create file 'requirements.txt',"Use 
Pipenv or other tools
 is recommended for improving your development flow.


pip3 freeze > requirements.txt  # Python3
pip freeze > requirements.txt  # Python2



If you do not use a virtual environment, 
pigar
 will be a good choice for you.

","I'm sorry, I couldn't find relevant information in the provided context.
",0.0,0.0,0.024875621890547265,0.37134334444999695,-0.041244574
"How can I overcome ""datetime.datetime not JSON serializable""?","Updated for 2018


The original answer accommodated the way MongoDB ""date"" fields were represented as:


{""$date"": 1506816000000}


If you want a generic Python solution for serializing 
datetime
 to json, check out 
@jjmontes' answer
 for a quick solution which requires no dependencies.




As you are using mongoengine (per comments) and pymongo is a dependency, pymongo has built-in utilities to help with json serialization:


http://api.mongodb.org/python/1.10.1/api/bson/json_util.html


Example usage (serialization):


from bson import json_util
import json

json.dumps(anObject, default=json_util.default)



Example usage (deserialization):


json.loads(aJsonString, object_hook=json_util.object_hook)





Django


Django provides a native 
DjangoJSONEncoder
 serializer that deals with this kind of properly.


See 
https://docs.djangoproject.com/en/dev/topics/serialization/#djangojsonencoder


from django.core.serializers.json import DjangoJSONEncoder

return json.dumps(
  item,
  sort_keys=True,
  indent=1,
  cls=DjangoJSONEncoder
)



One difference I've noticed between 
DjangoJSONEncoder
 and using a custom 
default
 like this:


import datetime
import json

def default(o):
    if isinstance(o, (datetime.date, datetime.datetime)):
        return o.isoformat()

return json.dumps(
  item,
  sort_keys=True,
  indent=1,
  default=default
)



Is that Django strips a bit of the data:


 ""last_login"": ""2018-08-03T10:51:42.990"", # DjangoJSONEncoder 
 ""last_login"": ""2018-08-03T10:51:42.990239"", # default



So, you may need to be careful about that in some cases.

","Answer: To get an aware datetime object, you can use `datetime.fromtimestamp(timestamp, timezone.utc)`.

References: [2, 3]
",4.374135756515443e-236,0.04065040650406503,0.02922661870503597,0.4970305263996124,0.46997696
String formatting: % vs. .format vs. f-string literal,"To answer your first question... 
.format
 just seems more sophisticated in many ways. An annoying thing about 
%
 is also how it can either take a variable or a tuple. You'd think the following would always work:


""Hello %s"" % name



yet, if 
name
 happens to be 
(1, 2, 3)
, it will throw a 
TypeError
. To guarantee that it always prints, you'd need to do


""Hello %s"" % (name,)   # supply the single argument as a single-item tuple



which is just ugly. 
.format
 doesn't have those issues. Also in the second example you gave, the 
.format
 example is much cleaner looking.


Only use it for backwards compatibility with Python 2.5.




To answer your second question, string formatting happens at the same time as any other operation - when the string formatting expression is evaluated. And Python, not being a lazy language, evaluates expressions before calling functions, so the expression 
log.debug(""some debug info: %s"" % some_info)
 will first evaluate the string to, e.g. 
""some debug info: roflcopters are active""
, then that string will be passed to 
log.debug()
.

","Answer: Python offers several ways to format output: Formatted string literals (f-strings), the `str.format()` method, and manual string formatting using string slicing and concatenation. F-strings allow you to include the value of Python expressions inside a string by prefixing the string with `f` or `F` and writing expressions as `{expression}`. The `str.format()` method requires more manual effort, using `{}` to mark where a variable will be substituted and requires you to provide the information to be formatted. You can also format strings manually using string slicing and concatenation, along with functions like `str()` and `repr()` for converting values to strings.

References: [2, 3]
",2.3998170077711022e-155,0.13286713286713286,0.16503837563999543,0.5414336919784546,0.6015531
How do I create multiline comments in Python?,"You can use triple-quoted strings. When they're not a docstring (the first thing in a class/function/module), they are ignored.


'''
This is a multiline
comment.
'''



(Make sure to indent the leading 
'''
 appropriately to avoid an 
IndentationError
.)


Guido van Rossum
 (creator of Python) 
tweeted this
 as a ""pro tip"".


However, Python's style guide, PEP8, 
favors using consecutive single-line comments
, like this:


# This is a multiline
# comment.



...and this is also what you'll find in many projects. Text editors usually have a shortcut to do this easily.

","Answer: In Python, comments start with the hash character, `#`, and extend to the end of the line. Multiline comments can be created by using a `#` at the beginning of each line.

References: [1]
",2.459770855197576e-232,0.14516129032258063,0.10989010989010989,0.51591956615448,0.8099179
Display number with leading zeros,"In Python 2 (and Python 3) you can do:


number = 1
print(""%02d"" % (number,))



Basically 
%
 is like 
printf
 or 
sprintf
 (see 
docs
).




For Python 3.+, the same behavior can also be achieved with 
format
:


number = 1
print(""{:02d}"".format(number))





For Python 3.6+ the same behavior can be achieved with 
f-strings
:


number = 1
print(f""{number:02d}"")


","Answer: To display a number with leading zeros, precede the width field by a zero ('0') character when no explicit alignment is given. This enables sign-aware zero-padding for numeric types, excluding complex types and is equivalent to using a fill character of '0' with an alignment type of '='.

References: [1, 2, 3]
",9.187781949963966e-232,0.10619469026548672,0.10579064587973275,0.500969409942627,0.5613953
Python: how to determine if an object is iterable?,"

Checking for 
__iter__
 works on sequence types, but it would fail on e.g. strings 
in Python 2
. I would like to know the right answer too, until then, here is one possibility (which would work on strings, too):


try:
    some_object_iterator = iter(some_object)
except TypeError as te:
    print(some_object, 'is not iterable')



The 
iter
 built-in checks for the 
__iter__
 method or in the case of strings the 
__getitem__
 method.




Another general pythonic approach is to assume an iterable, then fail gracefully if it does not work on the given object. The Python glossary:




Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object (""If it looks like a 
duck
 and quacks like a 
duck
, it must be a 
duck
."") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). 
Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming.


...


try:
   _ = (e for e in my_object)
except TypeError:
   print(my_object, 'is not iterable')







The 
collections
 module provides some abstract base classes, which allow to ask classes or instances if they provide particular functionality, for example:


from collections.abc import Iterable

if isinstance(e, Iterable):
    # e is iterable



However, this does not check for classes that are iterable through 
__getitem__
.





","Answer: An object is iterable if you can get an iterator for it. The built-in `iter()` function attempts to return an iterator for an object. If the object does not support iteration, a TypeError is raised.

References: [2, 3]
",3.967924321678593e-157,0.13523131672597863,0.08016814304506954,0.5687012076377869,0.71582806
How do I find the location of my Python site-packages directory?,"There are two types of site-packages directories, 
global
 and 
per user
.




Global
 site-packages (""
dist-packages
"") directories are listed in 
sys.path
 when you run:


 python -m site



For a more concise list run 
getsitepackages
 from the 
site module
 in Python code:


 python -c 'import site; print(site.getsitepackages())'



Caution:
 In virtual environments 
getsitepackages is not available
 with 
older versions of 
virtualenv
, 
sys.path
 from above will list the virtualenv's site-packages directory correctly, though. In Python 3, you may use the 
sysconfig module
 instead:


 python3 -c 'import sysconfig; print(sysconfig.get_paths()[""purelib""])'





The 
per user
 site-packages directory (
PEP 370
) is where Python installs your local packages:


 python -m site --user-site



If this points to a non-existing directory check the exit status of Python and see 
python -m site --help
 for explanations.


Hint:
 Running 
pip list --user
 or 
pip freeze --user
 gives you a list of all installed 
per user
 site-packages.








Practical Tips




.__path__
 lets you identify the location(s) of a specific package: (
details
)


  $ python -c ""import setuptools as _; print(_.__path__)""
  ['/usr/lib/python2.7/dist-packages/setuptools']





.__file__
 lets you identify the location of a specific module: (
difference
)


  $ python3 -c ""import os as _; print(_.__file__)""
  /usr/lib/python3.6/os.py





Run 
pip show 
 to show Debian-style package information:


  $ pip show pytest
  Name: pytest
  Version: 3.8.2
  Summary: pytest: simple powerful testing with Python
  Home-page: https://docs.pytest.org/en/latest/
  Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin and others
  Author-email: None
  License: MIT license
  Location: /home/peter/.local/lib/python3.4/site-packages
  Requires: more-itertools, atomicwrites, setuptools, attrs, pathlib2, six, py, pluggy






","Answer: You can find the user site-packages directory by running `python -m site --user-site` in the command line. The global site-packages directories can be listed by calling `site.getsitepackages()`. The path to the user-specific site-packages directory, `USER_SITE`, can be found by calling `site.getusersitepackages()`.

References: [1]
",1.814204914531489e-80,0.14328358208955222,0.06863741713371457,0.5787264108657837,0.7857743
Getting key with maximum value in dictionary?,"You can use 
operator.itemgetter
 for that:


import operator
stats = {'a': 1000, 'b': 3000, 'c': 100}
max(stats.iteritems(), key=operator.itemgetter(1))[0]



And instead of building a new list in memory use 
stats.iteritems()
. The 
key
 parameter to the 
max()
 function is a function that computes a key that is used to determine how to rank items.


Please note that if you were to have another key-value pair 'd': 3000 that this method will only return 
one
 of the 
two
 even though they both have the maximum value.


>>> import operator
>>> stats = {'a': 1000, 'b': 3000, 'c': 100, 'd': 3000}
>>> max(stats.iteritems(), key=operator.itemgetter(1))[0]
'b' 



If using Python3:


>>> max(stats.items(), key=operator.itemgetter(1))[0]
'b'


","I'm sorry, I couldn't find relevant information in the provided context.
",1.6078614791712954e-235,0.029411764705882356,0.016863406408094434,0.3154182434082031,-0.04210677
What does the 'b' character do in front of a string literal?,"To quote 
the Python 2.x documentation
:




A prefix of 'b' or 'B' is ignored in
  Python 2; it indicates that the
  literal should become a bytes literal
  in Python 3 (e.g. when code is
  automatically converted with 2to3). A
  'u' or 'b' prefix may be followed by
  an 'r' prefix.




The 
Python 3 documentation
 states:




Bytes literals are always prefixed with 'b' or 'B'; they produce an instance of the bytes type instead of the str type. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with escapes.



","Answer: The 'b' character in front of a string literal indicates that it is a bytes literal, producing an instance of the bytes type instead of the string type. Bytes literals can only contain ASCII characters, and bytes with a numeric value of 128 or greater must be expressed with escapes.

References: [3]
",0.20262014314052848,0.5,0.4184025210553468,0.7082664370536804,0.67917275
How do I create a constant in Python?,"You cannot declare a variable or value as constant in Python.




To 
indicate
 to programmers that a variable is a constant, one usually writes it in upper case:


CONST_NAME = ""Name""





To raise exceptions when constants are changed, see 
Constants in Python
 by Alex Martelli. Note that this is not commonly used in practice.




As of Python 3.8, there's a 
typing.Final
 variable annotation that will tell static type checkers (like mypy) that your variable shouldn't be reassigned. This is the closest equivalent to Java's 
final
. However, it 
does not actually prevent reassignment
:


from typing import Final

a: Final[int] = 1

# Executes fine, but mypy will report an error if you run mypy on this:
a = 2


","I'm sorry, I couldn't find relevant information in the provided context.
",5.914991824386249e-236,0.029850746268656716,0.030721966205837174,0.36483311653137207,-0.09687778
How do I terminate a script?,"import sys
sys.exit()



details from the 
sys
 module documentation
:




sys.
exit
([
arg
])


Exit from Python. This is implemented by raising the

SystemExit
 exception, so cleanup actions specified by finally clauses
of 
try
 statements are honored, and it is possible to intercept the
exit attempt at an outer level.


The optional argument 
arg
 can be an integer giving the exit status
(defaulting to zero), or another type of object. If it is an integer,
zero is considered “successful termination” and any nonzero value is
considered “abnormal termination” by shells and the like. Most systems
require it to be in the range 0-127, and produce undefined results
otherwise. Some systems have a convention for assigning specific
meanings to specific exit codes, but these are generally
underdeveloped; Unix programs generally use 2 for command line syntax
errors and 1 for all other kind of errors. If another type of object
is passed, None is equivalent to passing zero, and any other object is
printed to 
stderr
 and results in an exit code of 1. In particular,

sys.exit(""some error message"")
 is a quick way to exit a program when
an error occurs.


Since 
exit()
 ultimately “only” raises an exception, it will only exit
the process when called from the main thread, and the exception is not
intercepted.




Note that this is the 'nice' way to exit.  @
glyphtwistedmatrix
 below points out that if you want a 'hard exit', you can use 
os._exit(*errorcode*)
, though it's likely os-specific to some extent (it might not take an errorcode under windows, for example), and it definitely is less friendly since it doesn't let the interpreter do any cleanup before the process dies.  On the other hand, it 
does
 kill the entire process, including all running threads, while 
sys.exit()
 (as it says in the docs) only exits if called from the main thread, with no other threads running.

","I'm sorry, I couldn't find relevant information in the provided context.
",6.534674342557416e-167,0.018126888217522657,0.010215995329830705,0.36104390025138855,-0.060484495
What is the difference between null=True and blank=True in Django?,"null=True
 sets 
NULL
 (versus 
NOT NULL
) on the column in your DB. Blank values for Django field types such as 
DateTimeField
 or 
ForeignKey
 will be stored as 
NULL
 in the DB.


blank
 determines whether the field will be required in forms. This includes the admin and your custom forms. If 
blank=True
 then the field will not be required, whereas if it's 
False
 the field cannot be blank.


The combo of the two is so frequent because typically if you're going to allow a field to be blank in your form, you're going to also need your database to allow 
NULL
 values for that field. The exception is 
CharField
s and 
TextField
s, which in Django are 
never
 saved as 
NULL
. Blank values are stored in the DB as an empty string (
''
).


A few examples:


models.DateTimeField(blank=True) # raises IntegrityError if blank

models.DateTimeField(null=True) # NULL allowed, but must be filled out in a form



Obviously, Those two options don't make logical sense to use (though there might be a use case for 
null=True, blank=False
 if you want a field to always be required in forms, optional when dealing with an object through something like the shell.)


models.CharField(blank=True) # No problem, blank is stored as ''

models.CharField(null=True) # NULL allowed, but will never be set as NULL



CHAR
 and 
TEXT
 types are never saved as 
NULL
 by Django, so 
null=True
 is unnecessary. However, you can manually set one of these fields to 
None
 to force set it as 
NULL
. If you have a scenario where that might be necessary, you should still include 
null=True
.

","I'm sorry, I couldn't find relevant information in the provided context.",3.90735790489072e-165,0.02061855670103093,0.0106951871657754,0.3570529520511627,-0.013717528
Create a Pandas Dataframe by appending one row at a time,"You can use 
df.loc[i]
, where the row with index 
i
 will be what you specify it to be in the dataframe.


>>> import pandas as pd
>>> from numpy.random import randint

>>> df = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])
>>> for i in range(5):
>>>     df.loc[i] = ['name' + str(i)] + list(randint(10, size=2))

>>> df
     lib qty1 qty2
0  name0    3    3
1  name1    2    4
2  name2    2    8
3  name3    2    1
4  name4    9    6


","I'm sorry, I couldn't find relevant information in the provided context.
",1.3577338696078945e-157,0.08695652173913043,0.02652519893899204,0.310613214969635,0.016426535
How do I check if a variable exists?,"To check the existence of a local variable:


if 'myVar' in locals():
  # myVar exists.



To check the existence of a global variable:


if 'myVar' in globals():
  # myVar exists.



To check if an object has an attribute:


if hasattr(obj, 'attr_name'):
  # obj.attr_name exists.


","I'm sorry, I couldn't find relevant information in the provided context.
",5.922897343809692e-233,0.06896551724137931,0.0338409475465313,0.34728217124938965,-0.03576309
How does the @property decorator work in Python?,"The 
property()
 function returns a special 
descriptor object
:


>>> property()





It is this object that has 
extra
 methods:


>>> property().getter


>>> property().setter


>>> property().deleter





These act as decorators 
too
. They return a new property object:


>>> property().getter(None)





that is a copy of the old object, but with one of the functions replaced.


Remember, that the 
@decorator
 syntax is just syntactic sugar; the syntax:


@property
def foo(self): return self._foo



really means the same thing as


def foo(self): return self._foo
foo = property(foo)



so 
foo
 the function is replaced by 
property(foo)
, which we saw above is a special object. Then when you use 
@foo.setter()
, what you are doing is call that 
property().setter
 method I showed you above, which returns a new copy of the property, but this time with the setter function replaced with the decorated method.


The following sequence also creates a full-on property, by using those decorator methods.


First we create some functions:


>>> def getter(self): print('Get!')
... 
>>> def setter(self, value): print('Set to {!r}!'.format(value))
... 
>>> def deleter(self): print('Delete!')
... 



Then, we create a 
property
 object with only a getter:


>>> prop = property(getter)
>>> prop.fget is getter
True
>>> prop.fset is None
True
>>> prop.fdel is None
True



Next we use the 
.setter()
 method to add a setter:


>>> prop = prop.setter(setter)
>>> prop.fget is getter
True
>>> prop.fset is setter
True
>>> prop.fdel is None
True



Last we add a deleter with the 
.deleter()
 method:


>>> prop = prop.deleter(deleter)
>>> prop.fget is getter
True
>>> prop.fset is setter
True
>>> prop.fdel is deleter
True



Last but not least, the 
property
 object acts as a 
descriptor object
, so it has 
.__get__()
, 
.__set__()
 and 
.__delete__()
 methods to hook into instance attribute getting, setting and deleting:


>>> class Foo: pass
... 
>>> prop.__get__(Foo(), Foo)
Get!
>>> prop.__set__(Foo(), 'bar')
Set to 'bar'!
>>> prop.__delete__(Foo())
Delete!



The Descriptor Howto includes a 
pure Python sample implementation
 of the 
property()
 type:




class Property:
    ""Emulate PyProperty_Type() in Objects/descrobject.c""

    def __init__(self, fget=None, fset=None, fdel=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdel = fdel
        if doc is None and fget is not None:
            doc = fget.__doc__
        self.__doc__ = doc

    def __get__(self, obj, objtype=None):
        if obj is None:
            return self
        if self.fget is None:
            raise AttributeError(""unreadable attribute"")
        return self.fget(obj)

    def __set__(self, obj, value):
        if self.fset is None:
            raise AttributeError(""can't set attribute"")
        self.fset(obj, value)

    def __delete__(self, obj):
        if self.fdel is None:
            raise AttributeError(""can't delete attribute"")
        self.fdel(obj)

    def getter(self, fget):
        return type(self)(fget, self.fset, self.fdel, self.__doc__)

    def setter(self, fset):
        return type(self)(self.fget, fset, self.fdel, self.__doc__)

    def deleter(self, fdel):
        return type(self)(self.fget, self.fset, fdel, self.__doc__)




","Answer: The `@property` decorator in Python is a succinct way to create a data descriptor that triggers a function call upon attribute access. It's used to manage attribute access and can wrap access to an attribute, so improvements to the program do not affect existing client code that directly accesses the attribute.

References: [1, 2, 3]
",6.868922947928381e-158,0.0675422138836773,0.030497102775236356,0.46523571014404297,0.7316849
How can I do a line break (line continuation) in Python (split up a long line of source code)?,"What is the line?  You can just have arguments on the next line without any problems:


a = dostuff(blahblah1, blahblah2, blahblah3, blahblah4, blahblah5, 
            blahblah6, blahblah7)



Otherwise you can do something like this:


if (a == True and
    b == False):



or with explicit line break:


if a == True and \
   b == False:



Check the 
style guide
 for more information.


Using parentheses, your example can be written over multiple lines:


a = ('1' + '2' + '3' +
    '4' + '5')



The same effect can be obtained using explicit line break:


a = '1' + '2' + '3' + \
    '4' + '5'



Note that the style guide says that using the implicit continuation with parentheses is preferred, but in this particular case just adding parentheses around your expression is probably the wrong way to go.

","Answer: You can break a long line of code into multiple physical lines in Python using either explicit or implicit line joining. For explicit line joining, you can use a backslash (\) at the end of a physical line to join it with the next line. For implicit line joining, you can split expressions within parentheses, square brackets, or curly braces across multiple lines without using backslashes.

References: [2, 3]
",2.1941277319758502e-155,0.15789473684210525,0.15371777003484324,0.5315208435058594,0.4134586
How can I read a text file into a string variable and strip newlines?,"You could use:


with open('data.txt', 'r') as file:
    data = file.read().replace('\n', '')



Or if the file content is guaranteed to be one line:


with open('data.txt', 'r') as file:
    data = file.read().rstrip()


","Answer: To read a text file into a string and remove trailing newlines, you can use the `rstrip()` method on the string. For example, `S.rstrip(""\r\n"")` removes line terminators from the end of the string `S`.

References: [1]
",8.784466509829401e-232,0.12987012987012989,0.15273057021103895,0.5624709725379944,0.71819675
How do I reverse a list or loop over it backwards?,"To get a 
new
 reversed list, apply the 
reversed
 function and collect the items into a 
list
:


>>> xs = [0, 10, 20, 40]
>>> list(reversed(xs))
[40, 20, 10, 0]



To iterate backwards through a list:


>>> xs = [0, 10, 20, 40]
>>> for x in reversed(xs):
...     print(x)
40
20
10
0


","Answer: You can reverse a list in place using `list.reverse()`.

References: [1]
",1.6091152585935656e-156,0.15625000000000003,0.08004392301912962,0.49363458156585693,0.6738817
What is a mixin and why is it useful?,"A mixin is a special kind of multiple inheritance.  There are two main situations where mixins are used:




You want to provide a lot of optional features for a class.


You want to use one particular feature in a lot of different classes.




For an example of number one, consider 
werkzeug's request and response system
.  I can make a plain old request object by saying:


from werkzeug import BaseRequest

class Request(BaseRequest):
    pass



If I want to add accept header support, I would make that


from werkzeug import BaseRequest, AcceptMixin

class Request(AcceptMixin, BaseRequest):
    pass



If I wanted to make a request object that supports accept headers, etags, authentication, and user agent support, I could do this:


from werkzeug import BaseRequest, AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin

class Request(AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin, BaseRequest):
    pass



The difference is subtle, but in the above examples, the mixin classes weren't made to stand on their own.  In more traditional multiple inheritance, the 
AuthenticationMixin
 (for example) would probably be something more like 
Authenticator
.  That is, the class would probably be designed to stand on its own.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.2890265524293978e-161,0.051020408163265314,0.028751876774197473,0.35398808121681213,0.07201693
Putting a simple if-then-else statement on one line,"That's more specifically a 
ternary operator
 expression than an if-then, here's the python syntax


value_when_true if condition else value_when_false



Better Example:
 (thanks 
Mr. Burns
)


'Yes' if fruit == 'Apple' else 'No'



Now with assignment and contrast with if syntax


fruit = 'Apple'
isApple = True if fruit == 'Apple' else False



vs


fruit = 'Apple'
isApple = False
if fruit == 'Apple' : isApple = True


","I'm sorry, I couldn't find relevant information in the provided context.
",6.154693443478704e-234,0.025974025974025976,0.013774104683195593,0.3151806890964508,0.037634585
Correct way to write line to file?,"This should be as simple as:


with open('somefile.txt', 'a') as the_file:
    the_file.write('Hello\n')



From The Documentation:




Do not use 
os.linesep
 as a line terminator when writing files opened in text mode (the default); use a single 
'\n'
 instead, on all platforms.




Some useful reading:




The 
with
 statement


open()




'a'
 is for append, or use


'w'
 to write with truncation






os
 (particularly 
os.linesep
)



","I'm sorry, I couldn't find relevant information in the provided context.
",9.696455504718338e-234,0.048192771084337345,0.023980815347721823,0.35732728242874146,-0.09374394
Use a list of values to select rows from a Pandas dataframe,"You can use the 
isin
 method:


In [1]: df = pd.DataFrame({'A': [5,6,3,4], 'B': [1,2,3,5]})

In [2]: df
Out[2]:
   A  B
0  5  1
1  6  2
2  3  3
3  4  5

In [3]: df[df['A'].isin([3, 6])]
Out[3]:
   A  B
1  6  2
2  3  3



And to get the opposite use 
~
:


In [4]: df[~df['A'].isin([3, 6])]
Out[4]:
   A  B
0  5  1
3  4  5


","I'm sorry, I couldn't find relevant information in the provided context.
",6.74043217109484e-234,0.04210526315789474,0.024038461538461536,0.26229676604270935,0.04568197
"Extract file name from path, no matter what the os/path format","Using 
os.path.split
 or 
os.path.basename
 as others suggest won't work in all cases: if you're running the script on Linux and attempt to process a classic windows-style path, it will fail.


Windows paths can use either backslash or forward slash as path separator. Therefore, the 
ntpath
 module (which is equivalent to os.path when running on windows) will work for all
(1)
 paths on all platforms.


import ntpath
ntpath.basename(""a/b/c"")



Of course, if the file ends with a slash, the basename will be empty, so make your own function to deal with it:


def path_leaf(path):
    head, tail = ntpath.split(path)
    return tail or ntpath.basename(head)



Verification:


>>> paths = ['a/b/c/', 'a/b/c', '\\a\\b\\c', '\\a\\b\\c\\', 'a\\b\\c', 
...     'a/b/../../a/b/c/', 'a/b/../../a/b/c']
>>> [path_leaf(path) for path in paths]
['c', 'c', 'c', 'c', 'c', 'c', 'c']





(1) There's one caveat: Linux filenames 
may contain backslashes
. So on linux, 
r'a/b\c'
 always refers to the file 
b\c
 in the 
a
 folder, while on Windows, it always refers to the 
c
 file in the 
b
 subfolder of the 
a
 folder. So when both forward and backward slashes are used in a path, you 
need
 to know the associated platform to be able to interpret it correctly. In practice it's usually safe to assume it's a windows path since backslashes are seldom used in Linux filenames, but keep this in mind when you code so you don't create accidental security holes.

","I'm sorry, I couldn't find relevant information in the provided context.
",1.6241164733740684e-163,0.021428571428571425,0.01148293963254593,0.3219565451145172,-0.07791729
Get a list from Pandas DataFrame column headers,"You can get the values as a list by doing:


list(my_dataframe.columns.values)



Also you can simply use (as shown in 
Ed Chum's answer
):


list(my_dataframe)


","I'm sorry, I couldn't find relevant information in the provided context.
",3.648888025177688e-232,0.046511627906976744,0.04672897196261683,0.38367220759391785,-0.029435754
How do I trim whitespace from a string?,"To remove all whitespace surrounding a string, use 
.strip()
. Examples:


>>> ' Hello '.strip()
'Hello'
>>> ' Hello'.strip()
'Hello'
>>> 'Bob has a cat'.strip()
'Bob has a cat'
>>> '   Hello   '.strip()  # ALL consecutive spaces at both ends removed
'Hello'



Note that 
str.strip()
 removes all whitespace characters, including tabs and newlines. To remove only spaces, specify the specific character to remove as an argument to 
strip
:


>>> ""  Hello\n  "".strip("" "")
'Hello\n'





To remove only one space at most:


def strip_one_space(s):
    if s.endswith("" ""): s = s[:-1]
    if s.startswith("" ""): s = s[1:]
    return s

>>> strip_one_space(""   Hello "")
'  Hello'


","Answer: You can use the `strip()`, `lstrip()`, or `rstrip()` methods to remove whitespace from a string. The `strip()` method removes both leading and trailing whitespace. The `lstrip()` method removes leading whitespace, and the `rstrip()` method removes trailing whitespace. If you want to remove specific characters instead of whitespace, you can pass a string of those characters as an argument to these methods.

References: [1, 2]
",0.029074979077181914,0.2331288343558282,0.19889018691588783,0.5550775527954102,0.73861146
How do I remove all packages installed by pip?,"I've found this snippet as an alternative solution. It's a more graceful removal of libraries than remaking the virtualenv:


pip freeze | xargs pip uninstall -y





In case you have packages installed via VCS, you need to exclude those lines and remove the packages manually (elevated from the comments below):


pip freeze --exclude-editable | xargs pip uninstall -y





If you have packages installed directly from github/gitlab, those will have 
@
.
Like:


django @ git+https://github.com/django.git@


You can add 
cut -d ""@"" -f1
 to get just the package name that is required to uninstall it.


pip freeze | cut -d ""@"" -f1 | xargs pip uninstall -y


","Answer: To remove packages installed with pip, use the command `python -m pip uninstall` followed by one or more package names.

References: [1]
",1.385710436556109e-156,0.12403100775193798,0.10128879217128028,0.5265937447547913,0.6166142
How does Python's super() work with multiple inheritance?,"This is detailed with a reasonable amount of detail by Guido himself in his blog post 
Method Resolution Order
 (including two earlier attempts).


In your example, 
Third()
 will call 
First.__init__
. Python looks for each attribute in the class's parents as they are listed left to right. In this case, we are looking for 
__init__
. So, if you define


class Third(First, Second):
    ...



Python will start by looking at 
First
, and, if 
First
 doesn't have the attribute, then it will look at 
Second
.


This situation becomes more complex when inheritance starts crossing paths (for example if 
First
 inherited from 
Second
). Read the link above for more details, but, in a nutshell, Python will try to maintain the order in which each class appears on the inheritance list, starting with the child class itself.


So, for instance, if you had:


class First(object):
    def __init__(self):
        print ""first""

class Second(First):
    def __init__(self):
        print ""second""

class Third(First):
    def __init__(self):
        print ""third""

class Fourth(Second, Third):
    def __init__(self):
        super(Fourth, self).__init__()
        print ""that's it""



the MRO would be 
[Fourth, Second, Third, First].


By the way: if Python cannot find a coherent method resolution order, it'll raise an exception, instead of falling back to behavior which might surprise the user.


Example of an ambiguous MRO:


class First(object):
    def __init__(self):
        print ""first""
        
class Second(First):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        print ""third""



Should 
Third
's MRO be 
[First, Second]
 or 
[Second, First]
? There's no obvious expectation, and Python will raise an error:


TypeError: Error when calling the metaclass bases
    Cannot create a consistent method resolution order (MRO) for bases Second, First



Why do the examples above lack 
super()
 calls? The point of the examples is to show how the MRO is constructed. They are 
not
 intended to print 
""first\nsecond\third""
 or whatever. You can – and should, of course, play around with the example, add 
super()
 calls, see what happens, and gain a deeper understanding of Python's inheritance model. But my goal here is to keep it simple and show how the MRO is built. And it is built as I explained:


>>> Fourth.__mro__
(
,
 
, 
,
 
,
 
)


","I'm sorry, I couldn't find relevant information in the provided context.
",1.2996374100860296e-168,0.015665796344647518,0.007556131260794473,0.32391390204429626,0.010965578
How do I return dictionary keys as a list in Python?,"This will convert the 
dict_keys
 object to a 
list
:


list(newdict.keys())





On the other hand, you should ask yourself whether or not it matters. It is Pythonic to assume 
duck typing
 -- 
if it looks like a duck and it quacks like a duck, it is a duck
. The 
dict_keys
 object can be 
iterated
 over just like a 
list
. For instance:


for key in newdict.keys():
    print(key)



Note that 
dict_keys
 doesn't support insertion 
newdict[k] = v
, though you may not need it.

","Answer: You can return a list of dictionary keys using `list(d)` or `list(d.keys())`.

References: [1, 2]
",7.64509444688707e-157,0.11320754716981131,0.10309278350515465,0.5268665552139282,0.66137457
