question,expected,generated,BLEU,ROUGE-L,METEOR,BERTScore_F1,Cosine_Similarity
"What does the ""yield"" keyword do in Python?","To understand what 
yield
 does, you must understand what 
generators
 are. And before you can understand generators, you must understand 
iterables
.


Iterables


When you create a list, you can read its items one by one. Reading its items one by one is called iteration:


>>> mylist = [1, 2, 3]
>>> for i in mylist:
...    print(i)
1
2
3



mylist
 is an 
iterable
. When you use a list comprehension, you create a list, and so an iterable:


>>> mylist = [x*x for x in range(3)]
>>> for i in mylist:
...    print(i)
0
1
4



Everything you can use ""
for... in...
"" on is an iterable; 
lists
, 
strings
, files...


These iterables are handy because you can read them as much as you wish, but you store all the values in memory and this is not always what you want when you have a lot of values.


Generators


Generators are 
iterators
, a kind of iterable 
you can only iterate over once
. Generators do not store all the values in memory, 
they generate the values on the fly
:


>>> mygenerator = (x*x for x in range(3))
>>> for i in mygenerator:
...    print(i)
0
1
4



It is just the same except you used 
()
 instead of 
[]
. BUT, you 
cannot
 perform 
for i in mygenerator
 a second time since generators can only be used once: they calculate 0, then forget about it and calculate 1, and end after calculating 4, one by one.


Yield


yield
 is a keyword that is used like 
return
, except the function will return a generator.


>>> def create_generator():
...    mylist = range(3)
...    for i in mylist:
...        yield i*i
...
>>> mygenerator = create_generator() # create a generator
>>> print(mygenerator) # mygenerator is an object!


>>> for i in mygenerator:
...     print(i)
0
1
4



Here it's a useless example, but it's handy when you know your function will return a huge set of values that you will only need to read once.


To master 
yield
, you must understand that 
when you call the function, the code you have written in the function body does not run.
 The function only returns the generator object, this is a bit tricky.


Then, your code will continue from where it left off each time 
for
 uses the generator.


Now the hard part:


The first time the 
for
 calls the generator object created from your function, it will run the code in your function from the beginning until it hits 
yield
, then it'll return the first value of the loop. Then, each subsequent call will run another iteration of the loop you have written in the function and return the next value. This will continue until the generator is considered empty, which happens when the function runs without hitting 
yield
. That can be because the loop has come to an end, or because you no longer satisfy an 
""if/else""
.




Your code explained


Generator:


# Here you create the method of the node object that will return the generator
def _get_child_candidates(self, distance, min_dist, max_dist):

    # Here is the code that will be called each time you use the generator object:

    # If there is still a child of the node object on its left
    # AND if the distance is ok, return the next child
    if self._leftchild and distance - max_dist < self._median:
        yield self._leftchild

    # If there is still a child of the node object on its right
    # AND if the distance is ok, return the next child
    if self._rightchild and distance + max_dist >= self._median:
        yield self._rightchild

    # If the function arrives here, the generator will be considered empty
    # There are no more than two values: the left and the right children



Caller:


# Create an empty list and a list with the current object reference
result, candidates = list(), [self]

# Loop on candidates (they contain only one element at the beginning)
while candidates:

    # Get the last candidate and remove it from the list
    node = candidates.pop()

    # Get the distance between obj and the candidate
    distance = node._get_dist(obj)

    # If the distance is ok, then you can fill in the result
    if distance <= max_dist and distance >= min_dist:
        result.extend(node._values)

    # Add the children of the candidate to the candidate's list
    # so the loop will keep running until it has looked
    # at all the children of the children of the children, etc. of the candidate
    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))

return result



This code contains several smart parts:




The loop iterates on a list, but the list expands while the loop is being iterated. It's a concise way to go through all these nested data even if it's a bit dangerous since you can end up with an infinite loop. In this case, 
candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
 exhausts all the values of the generator, but 
while
 keeps creating new generator objects which will produce different values from the previous ones since it's not applied on the same node.




The 
extend()
 method is a list object method that expects an iterable and adds its values to the list.






Usually, we pass a list to it:


>>> a = [1, 2]
>>> b = [3, 4]
>>> a.extend(b)
>>> print(a)
[1, 2, 3, 4]



But in your code, it gets a generator, which is good because:




You don't need to read the values twice.


You may have a lot of children and you don't want them all stored in memory.




And it works because Python does not care if the argument of a method is a list or not. Python expects iterables so it will work with strings, lists, tuples, and generators! This is called duck typing and is one of the reasons why Python is so cool. But this is another story, for another question...


You can stop here, or read a little bit to see an advanced use of a generator:


Controlling a generator exhaustion


>>> class Bank(): # Let's create a bank, building ATMs
...    crisis = False
...    def create_atm(self):
...        while not self.crisis:
...            yield ""$100""
>>> hsbc = Bank() # When everything's ok the ATM gives you as much as you want
>>> corner_street_atm = hsbc.create_atm()
>>> print(corner_street_atm.next())
$100
>>> print(corner_street_atm.next())
$100
>>> print([corner_street_atm.next() for cash in range(5)])
['$100', '$100', '$100', '$100', '$100']
>>> hsbc.crisis = True # Crisis is coming, no more money!
>>> print(corner_street_atm.next())


>>> wall_street_atm = hsbc.create_atm() # It's even true for new ATMs
>>> print(wall_street_atm.next())


>>> hsbc.crisis = False # The trouble is, even post-crisis the ATM remains empty
>>> print(corner_street_atm.next())


>>> brand_new_atm = hsbc.create_atm() # Build a new one to get back in business
>>> for cash in brand_new_atm:
...    print cash
$100
$100
$100
$100
$100
$100
$100
$100
$100
...



Note:
 For Python 3, use
print(corner_street_atm.__next__())
 or 
print(next(corner_street_atm))


It can be useful for various things like controlling access to a resource.


Itertools, your best friend


The 
itertools
 module contains special functions to manipulate iterables. Ever wish to duplicate a generator?
Chain two generators? Group values in a nested list with a one-liner? 
Map / Zip
 without creating another list?


Then just 
import itertools
.


An example? Let's see the possible orders of arrival for a four-horse race:


>>> horses = [1, 2, 3, 4]
>>> races = itertools.permutations(horses)
>>> print(races)


>>> print(list(itertools.permutations(horses)))
[(1, 2, 3, 4),
 (1, 2, 4, 3),
 (1, 3, 2, 4),
 (1, 3, 4, 2),
 (1, 4, 2, 3),
 (1, 4, 3, 2),
 (2, 1, 3, 4),
 (2, 1, 4, 3),
 (2, 3, 1, 4),
 (2, 3, 4, 1),
 (2, 4, 1, 3),
 (2, 4, 3, 1),
 (3, 1, 2, 4),
 (3, 1, 4, 2),
 (3, 2, 1, 4),
 (3, 2, 4, 1),
 (3, 4, 1, 2),
 (3, 4, 2, 1),
 (4, 1, 2, 3),
 (4, 1, 3, 2),
 (4, 2, 1, 3),
 (4, 2, 3, 1),
 (4, 3, 1, 2),
 (4, 3, 2, 1)]



Understanding the inner mechanisms of iteration


Iteration is a process implying iterables (implementing the 
__iter__()
 method) and iterators (implementing the 
__next__()
 method).
Iterables are any objects you can get an iterator from. Iterators are objects that let you iterate on iterables.


There is more about it in this article about 
how 
for
 loops work
.

","(""Answer: The `yield` keyword is used in generator functions to return a value, similar to a `return` statement. However, when a `yield` statement is reached, the generator's state of execution is suspended, and local variables are preserved. The function can then be resumed on the next call to the generator's `__next__()` method. Any function containing a `yield` keyword is considered a generator function, which is detected by Python's bytecode compiler.\n\nReferences: [1, 2, 3]\n"", '[1] This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing. Here’s a sample usage of the generate_ints() generator:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile ""stdin"", line 1, in <module>\nFile ""stdin"", line 2, in generate_ints\nStopIteration\nYou could equally write for i in generate_ints(5), or a, b, c = generate_ints(3). Inside a generator function, return value causes StopIteration(value) to be raised from the __next__()\nmethod. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator\ncannot yield any further values. You could achieve the effect of generators manually by writing your own class and storing all the local variables of the\ngenerator as instance variables. For example, returning a list of integers could be done by setting self.count to 0,\nand having the __next__() method increment self.count and return it. However, for a moderately complicated\ngenerator, writing a corresponding class can be much messier. The test suite included with Python’s library, Lib/test/test_generators.py, contains a number of more interesting ex-\namples. Here’s one generator that implements an in-order traversal of a tree using generators recursively. # A recursive generator that generates Tree leaves in in-order. def inorder(t):\nif t:\nfor x in inorder(t.left):\nyield x\nyield t.label\nfor x in inorder(t.right):\nyield x\nTwo other examples in test_generators.py produce solutions for the N-Queens problem (placing N queens on\nan NxN chess board so that no queen threatens another) and the Knight’s Tour (finding a route that takes a knight to\nevery square of an NxN chessboard without visiting any square twice). 4.1 Passing values into a generator\nIn Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator,\nthere was no way to pass any new information into the function when its execution is resumed. You could hack\ntogether this ability by making the generator look at a global variable or by passing in some mutable object that\ncallers then modify, but these approaches are messy. In Python 2.5 there’s a simple way to pass values into a generator. yield became an expression, returning a value\nthat can be assigned to a variable or otherwise operated on:\n8\n\nval = (yield i)\nI recommend that you always put parentheses around a yield expression when you’re doing something with the\nreturned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them\ninstead of having to remember when they’re needed. (PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it\noccurs at the top-level expression on the right-hand side of an assignment. This means you can write val = yield\ni but have to use parentheses when there’s an operation, as in val = (yield i) + 12.) Values are sent into a generator by calling its send(value) method. This method resumes the generator’s code and\nthe yield expression returns the specified value. If the regular __next__() method is called, the yield returns\nNone. Here’s a simple counter that increments by 1 and allows changing the value of the internal counter. def counter(maximum):\ni = 0\nwhile i < maximum:\nval = (yield i)\n# If value provided, change counter\nif val is not None:\ni = val\nelse:\ni += 1\nAnd here’s an example of changing the counter:\n>>> it = counter(10)\n>>> next(it)\n0\n>>> next(it)\n1\n>>> it.send(8)\n8\n>>> next(it)\n9\n>>> next(it)\nTraceback (most recent call last):\nFile ""t.py"", line 15, in <module>\nit.next()\nStopIteration\nBecause yield will often be returning None, you should always check for this case. Don’t just use its value in\nexpressions unless you’re sure that the send() method will be the only method used to resume your generator\nfunction. In addition to send(), there are two other methods on generators:\n• throw(value) is used to raise an exception inside the generator; the exception is raised by the yield ex-\npression where the generator’s execution is paused. • close() raises a GeneratorExit exception inside the generator to terminate the iteration. On receiving\nthis exception, the generator’s code must either raise GeneratorExit or StopIteration; catching the\nexception and doing anything else is illegal and will trigger a RuntimeError. close() will also be called by\nPython’s garbage collector when the generator is garbage-collected. If you need to run cleanup code when a GeneratorExit occurs, I suggest using a try: ... finally:\nsuite instead of catching GeneratorExit. The cumulative effect of these changes is to turn generators from one-way producers of information into both pro-\nducers and consumers. 9\n\nGenerators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point\nand exited at another point (the top of the function, and a return statement), but coroutines can be entered, exited,\nand resumed at many different points (the yield statements). 5 Built-in functions\nLet’s look in more detail at built-in functions often used with iterators. Two of Python’s built-in functions, map() and filter() duplicate the features of generator expressions:\nmap(f, iterA, iterB, ...) returns an iterator over the sequence\nf(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2], iterB[2]), ....\n>>> def upper(s):\n...\nreturn s.upper()\n>>> list(map(upper, [\'sentence\', \'fragment\']))\n[\'SENTENCE\', \'FRAGMENT\']\n>>> [upper(s) for s in [\'sentence\', \'fragment\']]\n[\'SENTENCE\', \'FRAGMENT\']\nYou can of course achieve the same effect with a list comprehension. filter(predicate, iter) returns an iterator over all the sequence elements that meet a certain condition, and is\nsimilarly duplicated by list comprehensions. A predicate is a function that returns the truth value of some condition;\nfor use with filter(), the predicate must take a single value.\n\n[2] sequence3 is then looped over for each resulting pair of elements from sequence1\nand sequence2. To put it another way, a list comprehension or generator expression is equivalent to the following Python code:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue\n# Skip this element\nfor expr2 in sequence2:\nif not (condition2):\ncontinue\n# Skip this element\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue\n# Skip this element\n# Output the value of\n# the expression. This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing. Here’s a sample usage of the generate_ints() generator:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile ""stdin"", line 1, in <module>\nFile ""stdin"", line 2, in generate_ints\nStopIteration\nYou could equally write for i in generate_ints(5), or a, b, c = generate_ints(3). Inside a generator function, return value causes StopIteration(value) to be raised from the __next__()\nmethod. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator\ncannot yield any further values. You could achieve the effect of generators manually by writing your own class and storing all the local variables of the\ngenerator as instance variables. For example, returning a list of integers could be done by setting self.count to 0,\nand having the __next__() method increment self.count and return it. However, for a moderately complicated\ngenerator, writing a corresponding class can be much messier. The test suite included with Python’s library, Lib/test/test_generators.py, contains a number of more interesting ex-\namples. Here’s one generator that implements an in-order traversal of a tree using generators recursively. # A recursive generator that generates Tree leaves in in-order. def inorder(t):\nif t:\nfor x in inorder(t.left):\nyield x\nyield t.label\nfor x in inorder(t.right):\nyield x\nTwo other examples in test_generators.py produce solutions for the N-Queens problem (placing N queens on\nan NxN chess board so that no queen threatens another) and the Knight’s Tour (finding a route that takes a knight to\nevery square of an NxN chessboard without visiting any square twice). 4.1 Passing values into a generator\nIn Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator,\nthere was no way to pass any new information into the function when its execution is resumed. You could hack\ntogether this ability by making the generator look at a global variable or by passing in some mutable object that\ncallers then modify, but these approaches are messy. In Python 2.5 there’s a simple way to pass values into a generator. yield became an expression, returning a value\nthat can be assigned to a variable or otherwise operated on:\n8\n\nval = (yield i)\nI recommend that you always put parentheses around a yield expression when you’re doing something with the\nreturned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them\ninstead of having to remember when they’re needed. (PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it\noccurs at the top-level expression on the right-hand side of an assignment. This means you can write val = yield\ni but have to use parentheses when there’s an operation, as in val = (yield i) + 12.) Values are sent into a generator by calling its send(value) method. This method resumes the generator’s code and\nthe yield expression returns the specified value. If the regular __next__() method is called, the yield returns\nNone. Here’s a simple counter that increments by 1 and allows changing the value of the internal counter. def counter(maximum):\ni = 0\nwhile i < maximum:\nval = (yield i)\n# If value provided, change counter\nif val is not None:\ni = val\nelse:\ni += 1\nAnd here’s an example of changing the counter:\n>>> it = counter(10)\n>>> next(it)\n0\n>>> next(it)\n1\n>>> it.send(8)\n8\n>>> next(it)\n9\n>>> next(it)\nTraceback (most recent call last):\nFile ""t.py"", line 15, in <module>\nit.next()\nStopIteration\nBecause yield will often be returning None, you should always check for this case. Don’t just use its value in\nexpressions unless you’re sure that the send() method will be the only method used to resume your generator\nfunction. In addition to send(), there are two other methods on generators:\n• throw(value) is used to raise an exception inside the generator; the exception is raised by the yield ex-\npression where the generator’s execution is paused. • close() raises a GeneratorExit exception inside the generator to terminate the iteration. On receiving\nthis exception, the generator’s code must either raise GeneratorExit or StopIteration; catching the\nexception and doing anything else is illegal and will trigger a RuntimeError. close() will also be called by\nPython’s garbage collector when the generator is garbage-collected. If you need to run cleanup code when a GeneratorExit occurs, I suggest using a try: ... finally:\nsuite instead of catching GeneratorExit. The cumulative effect of these changes is to turn generators from one-way producers of information into both pro-\nducers and consumers. 9\n\nGenerators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point\nand exited at another point (the top of the function, and a return statement), but coroutines can be entered, exited,\nand resumed at many different points (the yield statements). 5 Built-in functions\nLet’s look in more detail at built-in functions often used with iterators. Two of Python’s built-in functions, map() and filter() duplicate the features of generator expressions:\nmap(f, iterA, iterB, ...) returns an iterator over the sequence\nf(iterA[0], iterB[0]), f(iterA[1], iterB[1]), f(iterA[2], iterB[2]), ....\n>>> def upper(s):\n...\nreturn s.upper()\n>>> list(map(upper, [\'sentence\', \'fragment\']))\n[\'SENTENCE\', \'FRAGMENT\']\n>>> [upper(s) for s in [\'sentence\', \'fragment\']]\n[\'SENTENCE\', \'FRAGMENT\']\nYou can of course achieve the same effect with a list comprehension.\n\n[3] For each element in sequence1, sequence2 is\n6\n\nlooped over from the beginning. sequence3 is then looped over for each resulting pair of elements from sequence1\nand sequence2. To put it another way, a list comprehension or generator expression is equivalent to the following Python code:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue\n# Skip this element\nfor expr2 in sequence2:\nif not (condition2):\ncontinue\n# Skip this element\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue\n# Skip this element\n# Output the value of\n# the expression. This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing. Here’s a sample usage of the generate_ints() generator:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile ""stdin"", line 1, in <module>\nFile ""stdin"", line 2, in generate_ints\nStopIteration\nYou could equally write for i in generate_ints(5), or a, b, c = generate_ints(3). Inside a generator function, return value causes StopIteration(value) to be raised from the __next__()\nmethod. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator\ncannot yield any further values. You could achieve the effect of generators manually by writing your own class and storing all the local variables of the\ngenerator as instance variables. For example, returning a list of integers could be done by setting self.count to 0,\nand having the __next__() method increment self.count and return it. However, for a moderately complicated\ngenerator, writing a corresponding class can be much messier. The test suite included with Python’s library, Lib/test/test_generators.py, contains a number of more interesting ex-\namples. Here’s one generator that implements an in-order traversal of a tree using generators recursively. # A recursive generator that generates Tree leaves in in-order. def inorder(t):\nif t:\nfor x in inorder(t.left):\nyield x\nyield t.label\nfor x in inorder(t.right):\nyield x\nTwo other examples in test_generators.py produce solutions for the N-Queens problem (placing N queens on\nan NxN chess board so that no queen threatens another) and the Knight’s Tour (finding a route that takes a knight to\nevery square of an NxN chessboard without visiting any square twice). 4.1 Passing values into a generator\nIn Python 2.4 and earlier, generators only produced output. Once a generator’s code was invoked to create an iterator,\nthere was no way to pass any new information into the function when its execution is resumed. You could hack\ntogether this ability by making the generator look at a global variable or by passing in some mutable object that\ncallers then modify, but these approaches are messy. In Python 2.5 there’s a simple way to pass values into a generator. yield became an expression, returning a value\nthat can be assigned to a variable or otherwise operated on:\n8\n\nval = (yield i)\nI recommend that you always put parentheses around a yield expression when you’re doing something with the\nreturned value, as in the above example. The parentheses aren’t always necessary, but it’s easier to always add them\ninstead of having to remember when they’re needed. (PEP 342 explains the exact rules, which are that a yield-expression must always be parenthesized except when it\noccurs at the top-level expression on the right-hand side of an assignment. This means you can write val = yield\ni but have to use parentheses when there’s an operation, as in val = (yield i) + 12.) Values are sent into a generator by calling its send(value) method. This method resumes the generator’s code and\nthe yield expression returns the specified value. If the regular __next__() method is called, the yield returns\nNone. Here’s a simple counter that increments by 1 and allows changing the value of the internal counter. def counter(maximum):\ni = 0\nwhile i < maximum:\nval = (yield i)\n# If value provided, change counter\nif val is not None:\ni = val\nelse:\ni += 1\nAnd here’s an example of changing the counter:\n>>> it = counter(10)\n>>> next(it)\n0\n>>> next(it)\n1\n>>> it.send(8)\n8\n>>> next(it)\n9\n>>> next(it)\nTraceback (most recent call last):\nFile ""t.py"", line 15, in <module>\nit.next()\nStopIteration\nBecause yield will often be returning None, you should always check for this case. Don’t just use its value in\nexpressions unless you’re sure that the send() method will be the only method used to resume your generator\nfunction. In addition to send(), there are two other methods on generators:\n• throw(value) is used to raise an exception inside the generator; the exception is raised by the yield ex-\npression where the generator’s execution is paused. • close() raises a GeneratorExit exception inside the generator to terminate the iteration. On receiving\nthis exception, the generator’s code must either raise GeneratorExit or StopIteration; catching the\nexception and doing anything else is illegal and will trigger a RuntimeError. close() will also be called by\nPython’s garbage collector when the generator is garbage-collected. If you need to run cleanup code when a GeneratorExit occurs, I suggest using a try: ... finally:\nsuite instead of catching GeneratorExit. The cumulative effect of these changes is to turn generators from one-way producers of information into both pro-\nducers and consumers. 9\n\nGenerators also become coroutines, a more generalized form of subroutines. Subroutines are entered at one point\nand exited at another point (the top of the function, and a return statement), but coroutines can be entered, exited,\nand resumed at many different points (the yield statements). 5 Built-in functions\nLet’s look in more detail at built-in functions often used with iterators.')",7.746814328207469e-79,0.11480466072652502,0.36843216692620717,0.597188413143158,0.65110344
"What does if __name__ == ""__main__"": do?","Short Answer


It's boilerplate code that protects users from accidentally invoking the script when they didn't intend to. Here are some common problems when the guard is omitted from a script:




If you import the guardless script in another script (e.g. 
import my_script_without_a_name_eq_main_guard
), then the latter script will trigger the former to run 
at import time
 and 
using the second script's command line arguments
. This is almost always a mistake.




If you have a custom class in the guardless script and save it to a pickle file, then unpickling it in another script will trigger an import of the guardless script, with the same problems outlined in the previous bullet.






Long Answer


To better understand why and how this matters, we need to take a step back to understand how Python initializes scripts and how this interacts with its module import mechanism.


Whenever the Python interpreter reads a source file, it does two things:




it sets a few special variables like 
__name__
, and then




it executes all of the code found in the file.






Let's see how this works and how it relates to your question about the 
__name__
 checks we always see in Python scripts.


Code Sample


Let's use a slightly different code sample to explore how imports and scripts work.  Suppose the following is in a file called 
foo.py
.


# Suppose this is foo.py.

print(""before import"")
import math

print(""before function_a"")
def function_a():
    print(""Function A"")

print(""before function_b"")
def function_b():
    print(""Function B {}"".format(math.sqrt(100)))

print(""before __name__ guard"")
if __name__ == '__main__':
    function_a()
    function_b()
print(""after __name__ guard"")



Special Variables


When the Python interpreter reads a source file, it first defines a few special variables. In this case, we care about the 
__name__
 variable.


When Your Module Is the Main Program


If you are running your module (the source file) as the main program, e.g.


python foo.py



the interpreter will assign the hard-coded string 
""__main__""
 to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when run as the main program.
__name__ = ""__main__"" 



When Your Module Is Imported By Another


On the other hand, suppose some other module is the main program and it imports your module. This means there's a statement like this in the main program, or in some other module the main program imports:


# Suppose this is in some other main program.
import foo



The interpreter will search for your 
foo.py
 file (along with searching for a few other variants), and prior to executing that module, it will assign the name 
""foo""
 from the import statement to the 
__name__
 variable, i.e.


# It's as if the interpreter inserts this at the top
# of your module when it's imported from another module.
__name__ = ""foo""



Executing the Module's Code


After the special variables are set up, the interpreter executes all the code in the module, one statement at a time. You may want to open another window on the side with the code sample so you can follow along with this explanation.


Always




It prints the string 
""before import""
 (without quotes).




It loads the 
math
 module and assigns it to a variable called 
math
. This is equivalent to replacing 
import math
 with the following (note that 
__import__
 is a low-level function in Python that takes a string and triggers the actual import):






# Find and load a module given its string name, ""math"",
# then assign it to a local variable called math.
math = __import__(""math"")





It prints the string 
""before function_a""
.




It executes the 
def
 block, creating a function object, then assigning that function object to a variable called 
function_a
.




It prints the string 
""before function_b""
.




It executes the second 
def
 block, creating another function object, then assigning it to a variable called 
function_b
.




It prints the string 
""before __name__ guard""
.






Only When Your Module Is the Main Program




If your module is the main program, then it will see that 
__name__
 was indeed set to 
""__main__""
 and it calls the two functions, printing the strings 
""Function A""
 and 
""Function B 10.0""
.




Only When Your Module Is Imported by Another




(
instead
) If your module is not the main program but was imported by another one, then 
__name__
 will be 
""foo""
, not 
""__main__""
, and it'll skip the body of the 
if
 statement.




Always




It will print the string 
""after __name__ guard""
 in both situations.




Summary


In summary, here's what'd be printed in the two cases:


# What gets printed if foo is the main program
before import
before function_a
before function_b
before __name__ guard
Function A
Function B 10.0
after __name__ guard



# What gets printed if foo is imported as a regular module
before import
before function_a
before function_b
before __name__ guard
after __name__ guard



Why Does It Work This Way?


You might naturally wonder why anybody would want this.  Well, sometimes you want to write a 
.py
 file that can be both used by other programs and/or modules as a module, and can also be run as the main program itself.  Examples:




Your module is a library, but you want to have a script mode where it runs some unit tests or a demo.




Your module is only used as a main program, but it has some unit tests, and the testing framework works by importing 
.py
 files like your script and running special test functions. You don't want it to try running the script just because it's importing the module.




Your module is mostly used as a main program, but it also provides a programmer-friendly API for advanced users.






Beyond those examples, it's elegant that running a script in Python is just setting up a few magic variables and importing the script. ""Running"" the script is a side effect of importing the script's module.


Food for Thought




Question: Can I have multiple 
__name__
 checking blocks?  Answer: it's strange to do so, but the language won't stop you.




Suppose the following is in 
foo2.py
.  What happens if you say 
python foo2.py
 on the command-line? Why?






# Suppose this is foo2.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo2 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
if __name__ == ""__main__"":
    print(""m1"")
    function_a()
    print(""m2"")
print(""t2"")
      





Now, figure out what will happen in 
foo3.py
 (having removed the 
__name__
 check):




# Suppose this is foo3.py.
import os, sys; sys.path.insert(0, os.path.dirname(__file__)) # needed for some interpreters

def function_a():
    print(""a1"")
    from foo3 import function_b
    print(""a2"")
    function_b()
    print(""a3"")

def function_b():
    print(""b"")

print(""t1"")
print(""m1"")
function_a()
print(""m2"")
print(""t2"")





What will this do when used as a script?  When imported as a module?




# Suppose this is in foo4.py
__name__ = ""__main__""

def bar():
    print(""bar"")
    
print(""before __name__ guard"")
if __name__ == ""__main__"":
    bar()
print(""after __name__ guard"")


","('Answer: The `if __name__ == ""__main__"":` statement allows code to be conditionally executed when the module is run as the main program, preventing it from running when the module is imported into another program.\n\nReferences: [1, 3]\n', '[1] ... In each of these situations, the top-level module’s __name__ is set to \'__main__\'. As a result, a module can discover whether or not it is running in the top-level environment by checking its own\n__name__, which allows a common idiom for conditionally executing code when the module is not initialized from\nan import statement:\nif __name__ == \'__main__\':\n# Execute when the module is not initialized from an import statement. ...\nµ See also\nFor a more detailed look at how __name__ is set in all situations, see the tutorial section tut-modules. Idiomatic Usage\nSome modules contain code that is intended for script use only, like parsing command-line arguments or fetching\ndata from standard input. If a module like this was imported from a different module, for example to unit test it, the\nscript code would unintentionally execute as well. This is where using the if __name__ == \'__main__\' code block comes in handy. Code within this block won’t\nrun unless the module is executed in the top-level environment. Putting as few statements as possible in the block below if __name__ == \'__main__\' can improve code clarity\nand correctness. Most often, a function named main encapsulates the program’s primary behavior:\n# echo.py\nimport shlex\nimport sys\ndef echo(phrase: str) -> None:\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1943\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n""""""A dummy wrapper around print."""""" # for demonstration purposes, you can imagine that there is some\n# valuable and reusable logic inside this function\nprint(phrase)\ndef main() -> int:\n""""""Echo the input arguments to standard output""""""\nphrase = shlex.join(sys.argv)\necho(phrase)\nreturn 0\nif __name__ == \'__main__\':\nsys.exit(main())\n# next section explains the use of sys.exit\nNote that if the module didn’t encapsulate code inside the main function but instead put it directly within the if\n__name__ == \'__main__\' block, the phrase variable would be global to the entire module. This is error-prone\nas other functions within the module could be unintentionally using the global variable instead of a local name. A\nmain function solves this problem. Using a main function has the added benefit of the echo function itself being isolated and importable elsewhere. When echo.py is imported, the echo and main functions will be defined, but neither of them will be called, because\n__name__ != \'__main__\'. Packaging Considerations\nmain functions are often used to create command-line tools by specifying them as entry points for console scripts. When this is done, pip inserts the function call into a template script, where the return value of main is passed into\nsys.exit(). For example:\nsys.exit(main())\nSince the call to main is wrapped in sys.exit(), the expectation is that your function will return some value\nacceptable as an input to sys.exit(); typically, an integer or None (which is implicitly returned if your function\ndoes not have a return statement). By proactively following this convention ourselves, our module will have the same behavior when run directly (i.e. python echo.py) as it will have if we later package it as a console script entry-point in a pip-installable package. In particular, be careful about returning strings from your main function. sys.exit() will interpret a string argu-\nment as a failure message, so your program will have an exit code of 1, indicating failure, and the string will be written\nto sys.stderr. The echo.py example from earlier exemplifies using the sys.exit(main()) convention. µ See also\nPython Packaging User Guide contains a collection of tutorials and references on how to distribute and install\nPython packages with modern tools. 30.5.2 __main__.py in Python Packages\nIf you are not familiar with Python packages, see section tut-packages of the tutorial. Most commonly, the\n__main__.py file is used to provide a command-line interface for a package. Consider the following hypotheti-\ncal package, “bandclass”:\nbandclass\n├──__init__.py\n├──__main__.py\n└──student.py\n1944\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n__main__.py will be executed when the package itself is invoked directly from the command line using the -m flag. For example:\n$ python -m bandclass\nThis command will cause __main__.py to run. How you utilize this mechanism will depend on the nature of the\npackage you are writing, but in this hypothetical case, it might make sense to allow the teacher to search for students:\n# bandclass/__main__.py\nimport sys\nfrom .student import search_students\nstudent_name = sys.argv[1] if len(sys.argv) >= 2 else \'\'\nprint(f\'Found student: {search_students(student_name)}\')\nNote that from .student import search_students is an example of a relative import. This import style\ncan be used when referencing modules within a package. For more details, see intra-package-references in the tut-\nmodules section of the tutorial. Idiomatic Usage\nThe content of __main__.py typically isn’t fenced with an if __name__ == \'__main__\' block. Instead, those\nfiles are kept short and import functions to execute from other modules. Those other modules can then be easily\nunit-tested and are properly reusable. If used, an if __name__ == \'__main__\' block will still work as expected for a __main__.py file within a\npackage, because its __name__ attribute will include the package’s path if imported:\n>>> import asyncio.__main__\n>>> asyncio.__main__.__name__\n\'asyncio.__main__\'\nThis won’t work for __main__.py files in the root directory of a .zip file though. Hence, for consistency, a minimal\n__main__.py without a __name__ check is preferred. µ See also\nSee venv for an example of a package with a minimal __main__.py in the standard library. It doesn’t contain\na if __name__ == \'__main__\' block. You can invoke it with python -m venv [directory]. See runpy for more details on the -m flag to the interpreter executable. See zipapp for how to run applications packaged as .zip files. In this case Python looks for a __main__.py file\nin the root directory of the archive. 30.5.3 import __main__\nRegardless of which module a Python program was started with, other modules running within that same program\ncan import the top-level environment’s scope (namespace) by importing the __main__ module. This doesn’t import\na __main__.py file but rather whichever module that received the special name \'__main__\'. Here is an example module that consumes the __main__ namespace:\n# namely.py\nimport __main__\ndef did_user_define_their_name():\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1945\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nreturn \'my_name\' in dir(__main__)\ndef print_user_name():\nif not did_user_define_their_name():\nraise ValueError(\'Define the variable `my_name`!\') if \'__file__\' in dir(__main__):\nprint(__main__.my_name, ""found in file"", __main__.__file__)\nelse:\nprint(__main__.my_name)\nExample usage of this module could be as follows:\n# start.py\nimport sys\nfrom namely import print_user_name\n# my_name = ""Dinsdale""\ndef main():\ntry:\nprint_user_name()\nexcept ValueError as ve:\nreturn str(ve)\nif __name__ == ""__main__"":\nsys.exit(main())\nNow, if we started our program, the result would look like this:\n$ python start.py\nDefine the variable `my_name`! The exit code of the program would be 1, indicating an error. Uncommenting the line with my_name =\n""Dinsdale"" fixes the program and now it exits with status code 0, indicating success:\n$ python start.py\nDinsdale found in file /path/to/start.py\nNote that importing __main__ doesn’t cause any issues with unintentionally running top-level code meant for script\nuse which is put in the if __name__ == ""__main__"" block of the start module.\n\n[2] ...\nµ See also\nFor a more detailed look at how __name__ is set in all situations, see the tutorial section tut-modules. Idiomatic Usage\nSome modules contain code that is intended for script use only, like parsing command-line arguments or fetching\ndata from standard input. If a module like this was imported from a different module, for example to unit test it, the\nscript code would unintentionally execute as well. This is where using the if __name__ == \'__main__\' code block comes in handy. Code within this block won’t\nrun unless the module is executed in the top-level environment. Putting as few statements as possible in the block below if __name__ == \'__main__\' can improve code clarity\nand correctness. Most often, a function named main encapsulates the program’s primary behavior:\n# echo.py\nimport shlex\nimport sys\ndef echo(phrase: str) -> None:\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1943\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n""""""A dummy wrapper around print."""""" # for demonstration purposes, you can imagine that there is some\n# valuable and reusable logic inside this function\nprint(phrase)\ndef main() -> int:\n""""""Echo the input arguments to standard output""""""\nphrase = shlex.join(sys.argv)\necho(phrase)\nreturn 0\nif __name__ == \'__main__\':\nsys.exit(main())\n# next section explains the use of sys.exit\nNote that if the module didn’t encapsulate code inside the main function but instead put it directly within the if\n__name__ == \'__main__\' block, the phrase variable would be global to the entire module. This is error-prone\nas other functions within the module could be unintentionally using the global variable instead of a local name. A\nmain function solves this problem. Using a main function has the added benefit of the echo function itself being isolated and importable elsewhere. When echo.py is imported, the echo and main functions will be defined, but neither of them will be called, because\n__name__ != \'__main__\'. Packaging Considerations\nmain functions are often used to create command-line tools by specifying them as entry points for console scripts. When this is done, pip inserts the function call into a template script, where the return value of main is passed into\nsys.exit(). For example:\nsys.exit(main())\nSince the call to main is wrapped in sys.exit(), the expectation is that your function will return some value\nacceptable as an input to sys.exit(); typically, an integer or None (which is implicitly returned if your function\ndoes not have a return statement). By proactively following this convention ourselves, our module will have the same behavior when run directly (i.e. python echo.py) as it will have if we later package it as a console script entry-point in a pip-installable package. In particular, be careful about returning strings from your main function. sys.exit() will interpret a string argu-\nment as a failure message, so your program will have an exit code of 1, indicating failure, and the string will be written\nto sys.stderr. The echo.py example from earlier exemplifies using the sys.exit(main()) convention. µ See also\nPython Packaging User Guide contains a collection of tutorials and references on how to distribute and install\nPython packages with modern tools. 30.5.2 __main__.py in Python Packages\nIf you are not familiar with Python packages, see section tut-packages of the tutorial. Most commonly, the\n__main__.py file is used to provide a command-line interface for a package. Consider the following hypotheti-\ncal package, “bandclass”:\nbandclass\n├──__init__.py\n├──__main__.py\n└──student.py\n1944\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n__main__.py will be executed when the package itself is invoked directly from the command line using the -m flag. For example:\n$ python -m bandclass\nThis command will cause __main__.py to run. How you utilize this mechanism will depend on the nature of the\npackage you are writing, but in this hypothetical case, it might make sense to allow the teacher to search for students:\n# bandclass/__main__.py\nimport sys\nfrom .student import search_students\nstudent_name = sys.argv[1] if len(sys.argv) >= 2 else \'\'\nprint(f\'Found student: {search_students(student_name)}\')\nNote that from .student import search_students is an example of a relative import. This import style\ncan be used when referencing modules within a package. For more details, see intra-package-references in the tut-\nmodules section of the tutorial. Idiomatic Usage\nThe content of __main__.py typically isn’t fenced with an if __name__ == \'__main__\' block. Instead, those\nfiles are kept short and import functions to execute from other modules. Those other modules can then be easily\nunit-tested and are properly reusable. If used, an if __name__ == \'__main__\' block will still work as expected for a __main__.py file within a\npackage, because its __name__ attribute will include the package’s path if imported:\n>>> import asyncio.__main__\n>>> asyncio.__main__.__name__\n\'asyncio.__main__\'\nThis won’t work for __main__.py files in the root directory of a .zip file though. Hence, for consistency, a minimal\n__main__.py without a __name__ check is preferred. µ See also\nSee venv for an example of a package with a minimal __main__.py in the standard library. It doesn’t contain\na if __name__ == \'__main__\' block. You can invoke it with python -m venv [directory]. See runpy for more details on the -m flag to the interpreter executable. See zipapp for how to run applications packaged as .zip files. In this case Python looks for a __main__.py file\nin the root directory of the archive. 30.5.3 import __main__\nRegardless of which module a Python program was started with, other modules running within that same program\ncan import the top-level environment’s scope (namespace) by importing the __main__ module. This doesn’t import\na __main__.py file but rather whichever module that received the special name \'__main__\'. Here is an example module that consumes the __main__ namespace:\n# namely.py\nimport __main__\ndef did_user_define_their_name():\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1945\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nreturn \'my_name\' in dir(__main__)\ndef print_user_name():\nif not did_user_define_their_name():\nraise ValueError(\'Define the variable `my_name`!\') if \'__file__\' in dir(__main__):\nprint(__main__.my_name, ""found in file"", __main__.__file__)\nelse:\nprint(__main__.my_name)\nExample usage of this module could be as follows:\n# start.py\nimport sys\nfrom namely import print_user_name\n# my_name = ""Dinsdale""\ndef main():\ntry:\nprint_user_name()\nexcept ValueError as ve:\nreturn str(ve)\nif __name__ == ""__main__"":\nsys.exit(main())\nNow, if we started our program, the result would look like this:\n$ python start.py\nDefine the variable `my_name`! The exit code of the program would be 1, indicating an error. Uncommenting the line with my_name =\n""Dinsdale"" fixes the program and now it exits with status code 0, indicating success:\n$ python start.py\nDinsdale found in file /path/to/start.py\nNote that importing __main__ doesn’t cause any issues with unintentionally running top-level code meant for script\nuse which is put in the if __name__ == ""__main__"" block of the start module. Why does this work? Python inserts an empty __main__ module in sys.modules at interpreter startup, and populates it by running top-\nlevel code. In our example this is the start module which runs line by line and imports namely.\n\n[3] As a result, a module can discover whether or not it is running in the top-level environment by checking its own\n__name__, which allows a common idiom for conditionally executing code when the module is not initialized from\nan import statement:\nif __name__ == \'__main__\':\n# Execute when the module is not initialized from an import statement. ...\nµ See also\nFor a more detailed look at how __name__ is set in all situations, see the tutorial section tut-modules. Idiomatic Usage\nSome modules contain code that is intended for script use only, like parsing command-line arguments or fetching\ndata from standard input. If a module like this was imported from a different module, for example to unit test it, the\nscript code would unintentionally execute as well. This is where using the if __name__ == \'__main__\' code block comes in handy. Code within this block won’t\nrun unless the module is executed in the top-level environment. Putting as few statements as possible in the block below if __name__ == \'__main__\' can improve code clarity\nand correctness. Most often, a function named main encapsulates the program’s primary behavior:\n# echo.py\nimport shlex\nimport sys\ndef echo(phrase: str) -> None:\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1943\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n""""""A dummy wrapper around print."""""" # for demonstration purposes, you can imagine that there is some\n# valuable and reusable logic inside this function\nprint(phrase)\ndef main() -> int:\n""""""Echo the input arguments to standard output""""""\nphrase = shlex.join(sys.argv)\necho(phrase)\nreturn 0\nif __name__ == \'__main__\':\nsys.exit(main())\n# next section explains the use of sys.exit\nNote that if the module didn’t encapsulate code inside the main function but instead put it directly within the if\n__name__ == \'__main__\' block, the phrase variable would be global to the entire module. This is error-prone\nas other functions within the module could be unintentionally using the global variable instead of a local name. A\nmain function solves this problem. Using a main function has the added benefit of the echo function itself being isolated and importable elsewhere. When echo.py is imported, the echo and main functions will be defined, but neither of them will be called, because\n__name__ != \'__main__\'. Packaging Considerations\nmain functions are often used to create command-line tools by specifying them as entry points for console scripts. When this is done, pip inserts the function call into a template script, where the return value of main is passed into\nsys.exit(). For example:\nsys.exit(main())\nSince the call to main is wrapped in sys.exit(), the expectation is that your function will return some value\nacceptable as an input to sys.exit(); typically, an integer or None (which is implicitly returned if your function\ndoes not have a return statement). By proactively following this convention ourselves, our module will have the same behavior when run directly (i.e. python echo.py) as it will have if we later package it as a console script entry-point in a pip-installable package. In particular, be careful about returning strings from your main function. sys.exit() will interpret a string argu-\nment as a failure message, so your program will have an exit code of 1, indicating failure, and the string will be written\nto sys.stderr. The echo.py example from earlier exemplifies using the sys.exit(main()) convention. µ See also\nPython Packaging User Guide contains a collection of tutorials and references on how to distribute and install\nPython packages with modern tools. 30.5.2 __main__.py in Python Packages\nIf you are not familiar with Python packages, see section tut-packages of the tutorial. Most commonly, the\n__main__.py file is used to provide a command-line interface for a package. Consider the following hypotheti-\ncal package, “bandclass”:\nbandclass\n├──__init__.py\n├──__main__.py\n└──student.py\n1944\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n__main__.py will be executed when the package itself is invoked directly from the command line using the -m flag. For example:\n$ python -m bandclass\nThis command will cause __main__.py to run. How you utilize this mechanism will depend on the nature of the\npackage you are writing, but in this hypothetical case, it might make sense to allow the teacher to search for students:\n# bandclass/__main__.py\nimport sys\nfrom .student import search_students\nstudent_name = sys.argv[1] if len(sys.argv) >= 2 else \'\'\nprint(f\'Found student: {search_students(student_name)}\')\nNote that from .student import search_students is an example of a relative import. This import style\ncan be used when referencing modules within a package. For more details, see intra-package-references in the tut-\nmodules section of the tutorial. Idiomatic Usage\nThe content of __main__.py typically isn’t fenced with an if __name__ == \'__main__\' block. Instead, those\nfiles are kept short and import functions to execute from other modules. Those other modules can then be easily\nunit-tested and are properly reusable. If used, an if __name__ == \'__main__\' block will still work as expected for a __main__.py file within a\npackage, because its __name__ attribute will include the package’s path if imported:\n>>> import asyncio.__main__\n>>> asyncio.__main__.__name__\n\'asyncio.__main__\'\nThis won’t work for __main__.py files in the root directory of a .zip file though. Hence, for consistency, a minimal\n__main__.py without a __name__ check is preferred. µ See also\nSee venv for an example of a package with a minimal __main__.py in the standard library. It doesn’t contain\na if __name__ == \'__main__\' block. You can invoke it with python -m venv [directory]. See runpy for more details on the -m flag to the interpreter executable. See zipapp for how to run applications packaged as .zip files. In this case Python looks for a __main__.py file\nin the root directory of the archive. 30.5.3 import __main__\nRegardless of which module a Python program was started with, other modules running within that same program\ncan import the top-level environment’s scope (namespace) by importing the __main__ module. This doesn’t import\na __main__.py file but rather whichever module that received the special name \'__main__\'. Here is an example module that consumes the __main__ namespace:\n# namely.py\nimport __main__\ndef did_user_define_their_name():\n(continues on next page)\n30.5. __main__ — Top-level code environment\n1945\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nreturn \'my_name\' in dir(__main__)\ndef print_user_name():\nif not did_user_define_their_name():\nraise ValueError(\'Define the variable `my_name`!\') if \'__file__\' in dir(__main__):\nprint(__main__.my_name, ""found in file"", __main__.__file__)\nelse:\nprint(__main__.my_name)\nExample usage of this module could be as follows:\n# start.py\nimport sys\nfrom namely import print_user_name\n# my_name = ""Dinsdale""\ndef main():\ntry:\nprint_user_name()\nexcept ValueError as ve:\nreturn str(ve)\nif __name__ == ""__main__"":\nsys.exit(main())\nNow, if we started our program, the result would look like this:\n$ python start.py\nDefine the variable `my_name`! The exit code of the program would be 1, indicating an error. Uncommenting the line with my_name =\n""Dinsdale"" fixes the program and now it exits with status code 0, indicating success:\n$ python start.py\nDinsdale found in file /path/to/start.py\nNote that importing __main__ doesn’t cause any issues with unintentionally running top-level code meant for script\nuse which is put in the if __name__ == ""__main__"" block of the start module. Why does this work? Python inserts an empty __main__ module in sys.modules at interpreter startup, and populates it by running top-\nlevel code.')",0.009438977792560034,0.12437427801309203,0.31778880449645414,0.6085971593856812,0.5817651
Does Python have a ternary conditional operator?,"Yes, it was 
added
 in version 2.5. The expression syntax is:


a if condition else b



First 
condition
 is evaluated, then exactly one of either 
a
 or 
b
 is evaluated and returned based on the 
Boolean
 value of 
condition
. If 
condition
 evaluates to 
True
, then 
a
 is evaluated and returned but 
b
 is ignored, or else when 
b
 is evaluated and returned but 
a
 is ignored.


This allows short-circuiting because when 
condition
 is true only 
a
 is evaluated and 
b
 is not evaluated at all, but when 
condition
 is false only 
b
 is evaluated and 
a
 is not evaluated at all.


For example:


>>> 'true' if True else 'false'
'true'
>>> 'true' if False else 'false'
'false'



Note that conditionals are an 
expression
, not a 
statement
. This means you can't use 
statements
 such as 
pass
, or assignments with 
=
 (or ""augmented"" assignments like 
+=
), within a conditional 
expression
:


>>> pass if False else pass
  File ""
"", line 1
    pass if False else pass
         ^
SyntaxError: invalid syntax

>>> # Python parses this as `x = (1 if False else y) = 2`
>>> # The `(1 if False else x)` part is actually valid, but
>>> # it can't be on the left-hand side of `=`.
>>> x = 1 if False else y = 2
  File ""
"", line 1
SyntaxError: cannot assign to conditional expression

>>> # If we parenthesize it instead...
>>> (x = 1) if False else (y = 2)
  File ""
"", line 1
    (x = 1) if False else (y = 2)
       ^
SyntaxError: invalid syntax



(In 3.8 and above, the 
:=
 ""walrus"" operator allows simple assignment of values 
as an expression
, which is then compatible with this syntax. But please don't write code like that; it will quickly become very difficult to understand.)


Similarly, because it is an expression, the 
else
 part is 
mandatory
:


# Invalid syntax: we didn't specify what the value should be if the 
# condition isn't met. It doesn't matter if we can verify that
# ahead of time.
a if True



You can, however, use conditional expressions to assign a variable like so:


x = a if True else b



Or for example to return a value:


# Of course we should just use the standard library `max`;
# this is just for demonstration purposes.
def my_max(a, b):
    return a if a > b else b



Think of the conditional expression as switching between two values. We can use it when we are in a 'one value or another' situation, where we will 
do the same thing
 with the result, regardless of whether the condition is met. We use the expression to compute the value, and then do something with it. If you need to 
do something different
 depending on the condition, then use a normal 
if
 
statement
 instead.




Keep in mind that it's frowned upon by some Pythonistas for several reasons:




The order of the arguments is different from those of the classic 
condition ? a : b
 ternary operator from many other languages (such as 
C
, 
C++
, 
Go
, 
Perl
, 
Ruby
, 
Java
, 
JavaScript
, etc.), which may lead to bugs when people unfamiliar with Python's ""surprising"" behaviour use it (they may reverse the argument order).


Some find it ""unwieldy"", since it goes contrary to the normal flow of thought (thinking of the condition first and then the effects).


Stylistic reasons. (Although the 'inline 
if
' can be 
really
 useful, and make your script more concise, it really does complicate your code)




If you're having trouble remembering the order, then remember that when read aloud, you (almost) say what you mean. For example, 
x = 4 if b > 8 else 9
 is read aloud as 
x will be 4 if b is greater than 8 otherwise 9
.


Official documentation:




Conditional expressions


Is there an equivalent of C’s ”?:” ternary operator?



","('Answer: Yes, Python has a ternary conditional operator. The syntax is `[on_true] if [expression] else [on_false]`.\n\nReferences: [2, 3]\n', '[1] :” ternary operator? Yes, there is. The syntax is as follows:\n[on_true] if [expression] else [on_false]\nx, y = 50, 25\nsmall = x if x < y else y\nBefore this syntax was introduced in Python 2.5, a common idiom was to use logical operators:\n16\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n[expression] and [on_true] or [on_false]\nHowever, this idiom is unsafe, as it can give wrong results when on_true has a false boolean value. Therefore, it is\nalways better to use the ... if ... else ... form. 2.2.17 Is it possible to write obfuscated one-liners in Python? Yes. Usually this is done by nesting lambda within lambda. See the following three examples, slightly adapted from\nUlf Bartelt:\nfrom functools import reduce\n# Primes < 1000\nprint(list(filter(None,map(lambda y:y*reduce(lambda x,y:x*y!=0,\nmap(lambda x,y=y:y%x,range(2,int(pow(y,0.5)+1))),1),range(2,1000)))))\n# First 10 Fibonacci numbers\nprint(list(map(lambda x,f=lambda x,f:(f(x-1,f)+f(x-2,f)) if x>1 else 1:\nf(x,f), range(10))))\n# Mandelbrot set\nprint((lambda Ru,Ro,Iu,Io,IM,Sx,Sy:reduce(lambda x,y:x+\'\\n\'+y,map(lambda y,\nIu=Iu,Io=Io,Ru=Ru,Ro=Ro,Sy=Sy,L=lambda yc,Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,i=IM,\nSx=Sx,Sy=Sy:reduce(lambda x,y:x+y,map(lambda x,xc=Ru,yc=yc,Ru=Ru,Ro=Ro,\ni=i,Sx=Sx,F=lambda xc,yc,x,y,k,f=lambda xc,yc,x,y,k,f:(k<=0)or (x*x+y*y\n>=4.0) or 1+f(xc,yc,x*x-y*y+xc,2.0*x*y+yc,k-1,f):f(xc,yc,x,y,k,f):chr(\n64+F(Ru+x*(Ro-Ru)/Sx,yc,0,0,i)),range(Sx))):L(Iu+y*(Io-Iu)/Sy),range(Sy\n))))(-2.1, 0.7, -1.2, 1.2, 30, 80, 24))\n#\n\\___ ___/\n\\___ ___/\n|\n|\n|__ lines on screen\n#\nV\nV\n|\n|______ columns on screen\n#\n|\n|\n|__________ maximum of ""iterations""\n#\n|\n|_________________ range on y axis\n#\n|____________________________ range on x axis\nDon’t try this at home, kids! 2.2.18 What does the slash(/) in the parameter list of a function mean? A slash in the argument list of a function denotes that the parameters prior to it are positional-only. Positional-\nonly parameters are the ones without an externally usable name. Upon calling a function that accepts positional-only\nparameters, arguments are mapped to parameters based solely on their position. For example, divmod() is a function\nthat accepts positional-only parameters. Its documentation looks like this:\n>>> help(divmod)\nHelp on built-in function divmod in module builtins:\ndivmod(x, y, /)\nReturn the tuple (x//y, x%y). Invariant: div*y + mod == x. The slash at the end of the parameter list means that both parameters are positional-only. Thus, calling divmod()\nwith keyword arguments would lead to an error:\n>>> divmod(x=3, y=4)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: divmod() takes no keyword arguments\n2.2. Core Language\n17\n\nPython Frequently Asked Questions, Release 3.13.2\n2.3 Numbers and strings\n2.3.1 How do I specify hexadecimal and octal integers? To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set\nthe variable “a” to the octal value “10” (8 in decimal), type:\n>>> a = 0o10\n>>> a\n8\nHexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g.\n\n[2] 2.2.16 Is there an equivalent of C’s “? :” ternary operator? Yes, there is. The syntax is as follows:\n[on_true] if [expression] else [on_false]\nx, y = 50, 25\nsmall = x if x < y else y\nBefore this syntax was introduced in Python 2.5, a common idiom was to use logical operators:\n16\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n[expression] and [on_true] or [on_false]\nHowever, this idiom is unsafe, as it can give wrong results when on_true has a false boolean value. Therefore, it is\nalways better to use the ... if ... else ... form. 2.2.17 Is it possible to write obfuscated one-liners in Python? Yes. Usually this is done by nesting lambda within lambda. See the following three examples, slightly adapted from\nUlf Bartelt:\nfrom functools import reduce\n# Primes < 1000\nprint(list(filter(None,map(lambda y:y*reduce(lambda x,y:x*y!=0,\nmap(lambda x,y=y:y%x,range(2,int(pow(y,0.5)+1))),1),range(2,1000)))))\n# First 10 Fibonacci numbers\nprint(list(map(lambda x,f=lambda x,f:(f(x-1,f)+f(x-2,f)) if x>1 else 1:\nf(x,f), range(10))))\n# Mandelbrot set\nprint((lambda Ru,Ro,Iu,Io,IM,Sx,Sy:reduce(lambda x,y:x+\'\\n\'+y,map(lambda y,\nIu=Iu,Io=Io,Ru=Ru,Ro=Ro,Sy=Sy,L=lambda yc,Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,i=IM,\nSx=Sx,Sy=Sy:reduce(lambda x,y:x+y,map(lambda x,xc=Ru,yc=yc,Ru=Ru,Ro=Ro,\ni=i,Sx=Sx,F=lambda xc,yc,x,y,k,f=lambda xc,yc,x,y,k,f:(k<=0)or (x*x+y*y\n>=4.0) or 1+f(xc,yc,x*x-y*y+xc,2.0*x*y+yc,k-1,f):f(xc,yc,x,y,k,f):chr(\n64+F(Ru+x*(Ro-Ru)/Sx,yc,0,0,i)),range(Sx))):L(Iu+y*(Io-Iu)/Sy),range(Sy\n))))(-2.1, 0.7, -1.2, 1.2, 30, 80, 24))\n#\n\\___ ___/\n\\___ ___/\n|\n|\n|__ lines on screen\n#\nV\nV\n|\n|______ columns on screen\n#\n|\n|\n|__________ maximum of ""iterations""\n#\n|\n|_________________ range on y axis\n#\n|____________________________ range on x axis\nDon’t try this at home, kids! 2.2.18 What does the slash(/) in the parameter list of a function mean? A slash in the argument list of a function denotes that the parameters prior to it are positional-only. Positional-\nonly parameters are the ones without an externally usable name. Upon calling a function that accepts positional-only\nparameters, arguments are mapped to parameters based solely on their position. For example, divmod() is a function\nthat accepts positional-only parameters. Its documentation looks like this:\n>>> help(divmod)\nHelp on built-in function divmod in module builtins:\ndivmod(x, y, /)\nReturn the tuple (x//y, x%y). Invariant: div*y + mod == x. The slash at the end of the parameter list means that both parameters are positional-only. Thus, calling divmod()\nwith keyword arguments would lead to an error:\n>>> divmod(x=3, y=4)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: divmod() takes no keyword arguments\n2.2. Core Language\n17\n\nPython Frequently Asked Questions, Release 3.13.2\n2.3 Numbers and strings\n2.3.1 How do I specify hexadecimal and octal integers? To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set\nthe variable “a” to the octal value “10” (8 in decimal), type:\n>>> a = 0o10\n>>> a\n8\nHexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct().\n\n[3] They are not truly operators but syntactic delimiters\nin assignment statements. 2.2.16 Is there an equivalent of C’s “? :” ternary operator? Yes, there is. The syntax is as follows:\n[on_true] if [expression] else [on_false]\nx, y = 50, 25\nsmall = x if x < y else y\nBefore this syntax was introduced in Python 2.5, a common idiom was to use logical operators:\n16\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n[expression] and [on_true] or [on_false]\nHowever, this idiom is unsafe, as it can give wrong results when on_true has a false boolean value. Therefore, it is\nalways better to use the ... if ... else ... form. 2.2.17 Is it possible to write obfuscated one-liners in Python? Yes. Usually this is done by nesting lambda within lambda. See the following three examples, slightly adapted from\nUlf Bartelt:\nfrom functools import reduce\n# Primes < 1000\nprint(list(filter(None,map(lambda y:y*reduce(lambda x,y:x*y!=0,\nmap(lambda x,y=y:y%x,range(2,int(pow(y,0.5)+1))),1),range(2,1000)))))\n# First 10 Fibonacci numbers\nprint(list(map(lambda x,f=lambda x,f:(f(x-1,f)+f(x-2,f)) if x>1 else 1:\nf(x,f), range(10))))\n# Mandelbrot set\nprint((lambda Ru,Ro,Iu,Io,IM,Sx,Sy:reduce(lambda x,y:x+\'\\n\'+y,map(lambda y,\nIu=Iu,Io=Io,Ru=Ru,Ro=Ro,Sy=Sy,L=lambda yc,Iu=Iu,Io=Io,Ru=Ru,Ro=Ro,i=IM,\nSx=Sx,Sy=Sy:reduce(lambda x,y:x+y,map(lambda x,xc=Ru,yc=yc,Ru=Ru,Ro=Ro,\ni=i,Sx=Sx,F=lambda xc,yc,x,y,k,f=lambda xc,yc,x,y,k,f:(k<=0)or (x*x+y*y\n>=4.0) or 1+f(xc,yc,x*x-y*y+xc,2.0*x*y+yc,k-1,f):f(xc,yc,x,y,k,f):chr(\n64+F(Ru+x*(Ro-Ru)/Sx,yc,0,0,i)),range(Sx))):L(Iu+y*(Io-Iu)/Sy),range(Sy\n))))(-2.1, 0.7, -1.2, 1.2, 30, 80, 24))\n#\n\\___ ___/\n\\___ ___/\n|\n|\n|__ lines on screen\n#\nV\nV\n|\n|______ columns on screen\n#\n|\n|\n|__________ maximum of ""iterations""\n#\n|\n|_________________ range on y axis\n#\n|____________________________ range on x axis\nDon’t try this at home, kids! 2.2.18 What does the slash(/) in the parameter list of a function mean? A slash in the argument list of a function denotes that the parameters prior to it are positional-only. Positional-\nonly parameters are the ones without an externally usable name. Upon calling a function that accepts positional-only\nparameters, arguments are mapped to parameters based solely on their position. For example, divmod() is a function\nthat accepts positional-only parameters. Its documentation looks like this:\n>>> help(divmod)\nHelp on built-in function divmod in module builtins:\ndivmod(x, y, /)\nReturn the tuple (x//y, x%y). Invariant: div*y + mod == x. The slash at the end of the parameter list means that both parameters are positional-only. Thus, calling divmod()\nwith keyword arguments would lead to an error:\n>>> divmod(x=3, y=4)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: divmod() takes no keyword arguments\n2.2. Core Language\n17\n\nPython Frequently Asked Questions, Release 3.13.2\n2.3 Numbers and strings\n2.3.1 How do I specify hexadecimal and octal integers? To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set\nthe variable “a” to the octal value “10” (8 in decimal), type:\n>>> a = 0o10\n>>> a\n8\nHexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str().')",0.0073085884233680554,0.08307019674520282,0.2741551516595568,0.5717542171478271,0.730845
What are metaclasses in Python?,"A metaclass is the class of a class. A class defines how an instance of the class (i.e. an object) behaves while a metaclass defines how a class behaves. A class is an instance of a metaclass.


While in Python you can use arbitrary callables for metaclasses (like 
Jerub
 shows), the better approach is to make it an actual class itself. 
type
 is the usual metaclass in Python. 
type
 is itself a class, and it is its own type. You won't be able to recreate something like 
type
 purely in Python, but Python cheats a little. To create your own metaclass in Python you really just want to subclass 
type
.


A metaclass is most commonly used as a class-factory. When you create an object by calling the class, Python creates a new class (when it executes the 'class' statement) by calling the metaclass. Combined with the normal 
__init__
 and 
__new__
 methods, metaclasses therefore allow you to do 'extra things' when creating a class, like registering the new class with some registry or replace the class with something else entirely.


When the 
class
 statement is executed, Python first executes the body of the 
class
 statement as a normal block of code. The resulting namespace (a dict) holds the attributes of the class-to-be. The metaclass is determined by looking at the baseclasses of the class-to-be (metaclasses are inherited), at the 
__metaclass__
 attribute of the class-to-be (if any) or the 
__metaclass__
 global variable. The metaclass is then called with the name, bases and attributes of the class to instantiate it.


However, metaclasses actually define the 
type
 of a class, not just a factory for it, so you can do much more with them. You can, for instance, define normal methods on the metaclass. These metaclass-methods are like classmethods in that they can be called on the class without an instance, but they are also not like classmethods in that they cannot be called on an instance of the class. 
type.__subclasses__()
 is an example of a method on the 
type
 metaclass. You can also define the normal 'magic' methods, like 
__add__
, 
__iter__
 and 
__getattr__
, to implement or change how the class behaves.


Here's an aggregated example of the bits and pieces:


def make_hook(f):
    """"""Decorator to turn 'foo' method into '__foo__'""""""
    f.is_hook = 1
    return f

class MyType(type):
    def __new__(mcls, name, bases, attrs):

        if name.startswith('None'):
            return None

        # Go over attributes and see if they should be renamed.
        newattrs = {}
        for attrname, attrvalue in attrs.iteritems():
            if getattr(attrvalue, 'is_hook', 0):
                newattrs['__%s__' % attrname] = attrvalue
            else:
                newattrs[attrname] = attrvalue

        return super(MyType, mcls).__new__(mcls, name, bases, newattrs)

    def __init__(self, name, bases, attrs):
        super(MyType, self).__init__(name, bases, attrs)

        # classregistry.register(self, self.interfaces)
        print ""Would register class %s now."" % self

    def __add__(self, other):
        class AutoClass(self, other):
            pass
        return AutoClass
        # Alternatively, to autogenerate the classname as well as the class:
        # return type(self.__name__ + other.__name__, (self, other), {})

    def unregister(self):
        # classregistry.unregister(self)
        print ""Would unregister class %s now."" % self

class MyObject:
    __metaclass__ = MyType


class NoneSample(MyObject):
    pass

# Will print ""NoneType None""
print type(NoneSample), repr(NoneSample)

class Example(MyObject):
    def __init__(self, value):
        self.value = value
    @make_hook
    def add(self, other):
        return self.__class__(self.value + other.value)

# Will unregister the class
Example.unregister()

inst = Example(10)
# Will fail with an AttributeError
#inst.unregister()

print inst + inst
class Sibling(MyObject):
    pass

ExampleSibling = Example + Sibling
# ExampleSibling is now a subclass of both Example and Sibling (with no
# content of its own) although it will believe it's called 'AutoClass'
print ExampleSibling
print ExampleSibling.__mro__


","('Answer: By default, classes are constructed using type(). The class creation process can be customized by passing the metaclass keyword argument in the class definition line, or by inheriting from an existing class that included such an argument.\n\nReferences: [2, 3]\n', ""[1] ® Note\nThe metaclass hint metaclass is consumed by the rest of the type machinery, and is never passed to\n__init_subclass__ implementations. The actual metaclass (rather than the explicit hint) can be ac-\ncessed as type(cls). Added in version 3.6. When a class is created, type.__new__() scans the class variables and makes callbacks to those with a\n__set_name__() hook. object.__set_name__(self, owner, name)\nAutomatically called at the time the owning class owner is created. The object has been assigned to name in\nthat class:\nclass A:\nx = C()\n# Automatically calls: x.__set_name__(A, 'x')\nIf the class variable is assigned after the class is created, __set_name__() will not be called automatically. If needed, __set_name__() can be called directly:\nclass A:\npass\nc = C()\nA.x = c\n# The hook is not called\nc.__set_name__(A, 'x')\n# Manually invoke the hook\nSee Creating the class object for more details. Added in version 3.6. Metaclasses\nBy default, classes are constructed using type(). The class body is executed in a new namespace and the class name\nis bound locally to the result of type(name, bases, namespace). The class creation process can be customized by passing the metaclass keyword argument in the class definition\nline, or by inheriting from an existing class that included such an argument. In the following example, both MyClass\nand MySubclass are instances of Meta:\nclass Meta(type):\npass\nclass MyClass(metaclass=Meta):\npass\nclass MySubclass(MyClass):\npass\n3.3. Special method names\n43\n\nThe Python Language Reference, Release 3.13.2\nAny other keyword arguments that are specified in the class definition are passed through to all metaclass operations\ndescribed below. When a class definition is executed, the following steps occur:\n• MRO entries are resolved;\n• the appropriate metaclass is determined;\n• the class namespace is prepared;\n• the class body is executed;\n• the class object is created. Resolving MRO entries\nobject.__mro_entries__(self, bases)\nIf a base that appears in a class definition is not an instance of type, then an __mro_entries__() method\nis searched on the base. If an __mro_entries__() method is found, the base is substituted with the result\nof a call to __mro_entries__() when creating the class. The method is called with the original bases tuple\npassed to the bases parameter, and must return a tuple of classes that will be used instead of the base. The\nreturned tuple may be empty: in these cases, the original base is ignored. µ See also\ntypes.resolve_bases()\nDynamically resolve bases that are not instances of type. types.get_original_bases()\nRetrieve a class’s “original bases” prior to modifications by __mro_entries__(). PEP 560\nCore support for typing module and generic types. Determining the appropriate metaclass\nThe appropriate metaclass for a class definition is determined as follows:\n• if no bases and no explicit metaclass are given, then type() is used;\n• if an explicit metaclass is given and it is not an instance of type(), then it is used directly as the metaclass;\n• if an instance of type() is given as the explicit metaclass, or bases are defined, then the most derived metaclass\nis used. The most derived metaclass is selected from the explicitly specified metaclass (if any) and the metaclasses (i.e. type(cls)) of all specified base classes. The most derived metaclass is one which is a subtype of all of these\ncandidate metaclasses. If none of the candidate metaclasses meets that criterion, then the class definition will fail\nwith TypeError. Preparing the class namespace\nOnce the appropriate metaclass has been identified, then the class namespace is prepared. If the metaclass has\na __prepare__ attribute, it is called as namespace = metaclass.__prepare__(name, bases, **kwds)\n(where the additional keyword arguments, if any, come from the class definition). The __prepare__ method should\nbe implemented as a classmethod. The namespace returned by __prepare__ is passed in to __new__, but when\nthe final class object is created the namespace is copied into a new dict. If the metaclass has no __prepare__ attribute, then the class namespace is initialised as an empty ordered mapping. µ See also\n44\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nPEP 3115 - Metaclasses in Python 3000\nIntroduced the __prepare__ namespace hook\nExecuting the class body\nThe class body is executed (approximately) as exec(body, globals(), namespace). The key difference from\na normal call to exec() is that lexical scoping allows the class body (including any methods) to reference names\nfrom the current and outer scopes when the class definition occurs inside a function. However, even when the class definition occurs inside the function, methods defined inside the class still cannot see\nnames defined at the class scope. Class variables must be accessed through the first parameter of instance or class\nmethods, or through the implicit lexically scoped __class__ reference described in the next section. Creating the class object\nOnce the class namespace has been populated by executing the class body, the class object is created by calling\nmetaclass(name, bases, namespace, **kwds) (the additional keywords passed here are the same as those\npassed to __prepare__). This class object is the one that will be referenced by the zero-argument form of super(). __class__ is an implicit\nclosure reference created by the compiler if any methods in a class body refer to either __class__ or super. This\nallows the zero argument form of super() to correctly identify the class being defined based on lexical scoping,\nwhile the class or instance that was used to make the current call is identified based on the first argument passed to\nthe method. CPython implementation detail: In CPython 3.6 and later, the __class__ cell is passed to the metaclass as a\n__classcell__ entry in the class namespace. If present, this must be propagated up to the type.__new__ call\nin order for the class to be initialised correctly. Failing to do so will result in a RuntimeError in Python 3.8. When using the default metaclass type, or any metaclass that ultimately calls type.__new__, the following addi-\ntional customization steps are invoked after creating the class object:\n1) The type.__new__ method collects all of the attributes in the class namespace that define a\n__set_name__() method;\n2) Those __set_name__ methods are called with the class being defined and the assigned name of that particular\nattribute;\n3) The __init_subclass__() hook is called on the immediate parent of the new class in its method resolution\norder. After the class object is created, it is passed to the class decorators included in the class definition (if any) and the\nresulting object is bound in the local namespace as the defined class. When a new class is created by type.__new__, the object provided as the namespace parameter is copied to a new\nordered mapping and the original object is discarded. The new copy is wrapped in a read-only proxy, which becomes\nthe __dict__ attribute of the class object. µ See also\nPEP 3135 - New super\nDescribes the implicit __class__ closure reference\nUses for metaclasses\nThe potential uses for metaclasses are boundless. Some ideas that have been explored include enum, logging, in-\nterface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource\nlocking/synchronization. 3.3. Special method names\n45\n\nThe Python Language Reference, Release 3.13.2\n3.3.4 Customizing instance and subclass checks\nThe following methods are used to override the default behavior of the isinstance() and issubclass() built-in\nfunctions.\n\n[2] Metaclasses\nBy default, classes are constructed using type(). The class body is executed in a new namespace and the class name\nis bound locally to the result of type(name, bases, namespace). The class creation process can be customized by passing the metaclass keyword argument in the class definition\nline, or by inheriting from an existing class that included such an argument. In the following example, both MyClass\nand MySubclass are instances of Meta:\nclass Meta(type):\npass\nclass MyClass(metaclass=Meta):\npass\nclass MySubclass(MyClass):\npass\n3.3. Special method names\n43\n\nThe Python Language Reference, Release 3.13.2\nAny other keyword arguments that are specified in the class definition are passed through to all metaclass operations\ndescribed below. When a class definition is executed, the following steps occur:\n• MRO entries are resolved;\n• the appropriate metaclass is determined;\n• the class namespace is prepared;\n• the class body is executed;\n• the class object is created. Resolving MRO entries\nobject.__mro_entries__(self, bases)\nIf a base that appears in a class definition is not an instance of type, then an __mro_entries__() method\nis searched on the base. If an __mro_entries__() method is found, the base is substituted with the result\nof a call to __mro_entries__() when creating the class. The method is called with the original bases tuple\npassed to the bases parameter, and must return a tuple of classes that will be used instead of the base. The\nreturned tuple may be empty: in these cases, the original base is ignored. µ See also\ntypes.resolve_bases()\nDynamically resolve bases that are not instances of type. types.get_original_bases()\nRetrieve a class’s “original bases” prior to modifications by __mro_entries__(). PEP 560\nCore support for typing module and generic types. Determining the appropriate metaclass\nThe appropriate metaclass for a class definition is determined as follows:\n• if no bases and no explicit metaclass are given, then type() is used;\n• if an explicit metaclass is given and it is not an instance of type(), then it is used directly as the metaclass;\n• if an instance of type() is given as the explicit metaclass, or bases are defined, then the most derived metaclass\nis used. The most derived metaclass is selected from the explicitly specified metaclass (if any) and the metaclasses (i.e. type(cls)) of all specified base classes. The most derived metaclass is one which is a subtype of all of these\ncandidate metaclasses. If none of the candidate metaclasses meets that criterion, then the class definition will fail\nwith TypeError. Preparing the class namespace\nOnce the appropriate metaclass has been identified, then the class namespace is prepared. If the metaclass has\na __prepare__ attribute, it is called as namespace = metaclass.__prepare__(name, bases, **kwds)\n(where the additional keyword arguments, if any, come from the class definition). The __prepare__ method should\nbe implemented as a classmethod. The namespace returned by __prepare__ is passed in to __new__, but when\nthe final class object is created the namespace is copied into a new dict. If the metaclass has no __prepare__ attribute, then the class namespace is initialised as an empty ordered mapping. µ See also\n44\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nPEP 3115 - Metaclasses in Python 3000\nIntroduced the __prepare__ namespace hook\nExecuting the class body\nThe class body is executed (approximately) as exec(body, globals(), namespace). The key difference from\na normal call to exec() is that lexical scoping allows the class body (including any methods) to reference names\nfrom the current and outer scopes when the class definition occurs inside a function. However, even when the class definition occurs inside the function, methods defined inside the class still cannot see\nnames defined at the class scope. Class variables must be accessed through the first parameter of instance or class\nmethods, or through the implicit lexically scoped __class__ reference described in the next section. Creating the class object\nOnce the class namespace has been populated by executing the class body, the class object is created by calling\nmetaclass(name, bases, namespace, **kwds) (the additional keywords passed here are the same as those\npassed to __prepare__). This class object is the one that will be referenced by the zero-argument form of super(). __class__ is an implicit\nclosure reference created by the compiler if any methods in a class body refer to either __class__ or super. This\nallows the zero argument form of super() to correctly identify the class being defined based on lexical scoping,\nwhile the class or instance that was used to make the current call is identified based on the first argument passed to\nthe method. CPython implementation detail: In CPython 3.6 and later, the __class__ cell is passed to the metaclass as a\n__classcell__ entry in the class namespace. If present, this must be propagated up to the type.__new__ call\nin order for the class to be initialised correctly. Failing to do so will result in a RuntimeError in Python 3.8. When using the default metaclass type, or any metaclass that ultimately calls type.__new__, the following addi-\ntional customization steps are invoked after creating the class object:\n1) The type.__new__ method collects all of the attributes in the class namespace that define a\n__set_name__() method;\n2) Those __set_name__ methods are called with the class being defined and the assigned name of that particular\nattribute;\n3) The __init_subclass__() hook is called on the immediate parent of the new class in its method resolution\norder. After the class object is created, it is passed to the class decorators included in the class definition (if any) and the\nresulting object is bound in the local namespace as the defined class. When a new class is created by type.__new__, the object provided as the namespace parameter is copied to a new\nordered mapping and the original object is discarded. The new copy is wrapped in a read-only proxy, which becomes\nthe __dict__ attribute of the class object. µ See also\nPEP 3135 - New super\nDescribes the implicit __class__ closure reference\nUses for metaclasses\nThe potential uses for metaclasses are boundless. Some ideas that have been explored include enum, logging, in-\nterface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource\nlocking/synchronization. 3.3. Special method names\n45\n\nThe Python Language Reference, Release 3.13.2\n3.3.4 Customizing instance and subclass checks\nThe following methods are used to override the default behavior of the isinstance() and issubclass() built-in\nfunctions. In particular, the metaclass abc.ABCMeta implements these methods in order to allow the addition of Abstract Base\nClasses (ABCs) as “virtual base classes” to any class or type (including built-in types), including other ABCs. type.__instancecheck__(self, instance)\nReturn true if instance should be considered a (direct or indirect) instance of class. If defined, called to imple-\nment isinstance(instance, class). type.__subclasscheck__(self, subclass)\nReturn true if subclass should be considered a (direct or indirect) subclass of class. If defined, called to imple-\nment issubclass(subclass, class). Note that these methods are looked up on the type (metaclass) of a class. They cannot be defined as class methods in\nthe actual class. This is consistent with the lookup of special methods that are called on instances, only in this case\nthe instance is itself a class.\n\n[3] The actual metaclass (rather than the explicit hint) can be ac-\ncessed as type(cls). Added in version 3.6. When a class is created, type.__new__() scans the class variables and makes callbacks to those with a\n__set_name__() hook. object.__set_name__(self, owner, name)\nAutomatically called at the time the owning class owner is created. The object has been assigned to name in\nthat class:\nclass A:\nx = C()\n# Automatically calls: x.__set_name__(A, 'x')\nIf the class variable is assigned after the class is created, __set_name__() will not be called automatically. If needed, __set_name__() can be called directly:\nclass A:\npass\nc = C()\nA.x = c\n# The hook is not called\nc.__set_name__(A, 'x')\n# Manually invoke the hook\nSee Creating the class object for more details. Added in version 3.6. Metaclasses\nBy default, classes are constructed using type(). The class body is executed in a new namespace and the class name\nis bound locally to the result of type(name, bases, namespace). The class creation process can be customized by passing the metaclass keyword argument in the class definition\nline, or by inheriting from an existing class that included such an argument. In the following example, both MyClass\nand MySubclass are instances of Meta:\nclass Meta(type):\npass\nclass MyClass(metaclass=Meta):\npass\nclass MySubclass(MyClass):\npass\n3.3. Special method names\n43\n\nThe Python Language Reference, Release 3.13.2\nAny other keyword arguments that are specified in the class definition are passed through to all metaclass operations\ndescribed below. When a class definition is executed, the following steps occur:\n• MRO entries are resolved;\n• the appropriate metaclass is determined;\n• the class namespace is prepared;\n• the class body is executed;\n• the class object is created. Resolving MRO entries\nobject.__mro_entries__(self, bases)\nIf a base that appears in a class definition is not an instance of type, then an __mro_entries__() method\nis searched on the base. If an __mro_entries__() method is found, the base is substituted with the result\nof a call to __mro_entries__() when creating the class. The method is called with the original bases tuple\npassed to the bases parameter, and must return a tuple of classes that will be used instead of the base. The\nreturned tuple may be empty: in these cases, the original base is ignored. µ See also\ntypes.resolve_bases()\nDynamically resolve bases that are not instances of type. types.get_original_bases()\nRetrieve a class’s “original bases” prior to modifications by __mro_entries__(). PEP 560\nCore support for typing module and generic types. Determining the appropriate metaclass\nThe appropriate metaclass for a class definition is determined as follows:\n• if no bases and no explicit metaclass are given, then type() is used;\n• if an explicit metaclass is given and it is not an instance of type(), then it is used directly as the metaclass;\n• if an instance of type() is given as the explicit metaclass, or bases are defined, then the most derived metaclass\nis used. The most derived metaclass is selected from the explicitly specified metaclass (if any) and the metaclasses (i.e. type(cls)) of all specified base classes. The most derived metaclass is one which is a subtype of all of these\ncandidate metaclasses. If none of the candidate metaclasses meets that criterion, then the class definition will fail\nwith TypeError. Preparing the class namespace\nOnce the appropriate metaclass has been identified, then the class namespace is prepared. If the metaclass has\na __prepare__ attribute, it is called as namespace = metaclass.__prepare__(name, bases, **kwds)\n(where the additional keyword arguments, if any, come from the class definition). The __prepare__ method should\nbe implemented as a classmethod. The namespace returned by __prepare__ is passed in to __new__, but when\nthe final class object is created the namespace is copied into a new dict. If the metaclass has no __prepare__ attribute, then the class namespace is initialised as an empty ordered mapping. µ See also\n44\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nPEP 3115 - Metaclasses in Python 3000\nIntroduced the __prepare__ namespace hook\nExecuting the class body\nThe class body is executed (approximately) as exec(body, globals(), namespace). The key difference from\na normal call to exec() is that lexical scoping allows the class body (including any methods) to reference names\nfrom the current and outer scopes when the class definition occurs inside a function. However, even when the class definition occurs inside the function, methods defined inside the class still cannot see\nnames defined at the class scope. Class variables must be accessed through the first parameter of instance or class\nmethods, or through the implicit lexically scoped __class__ reference described in the next section. Creating the class object\nOnce the class namespace has been populated by executing the class body, the class object is created by calling\nmetaclass(name, bases, namespace, **kwds) (the additional keywords passed here are the same as those\npassed to __prepare__). This class object is the one that will be referenced by the zero-argument form of super(). __class__ is an implicit\nclosure reference created by the compiler if any methods in a class body refer to either __class__ or super. This\nallows the zero argument form of super() to correctly identify the class being defined based on lexical scoping,\nwhile the class or instance that was used to make the current call is identified based on the first argument passed to\nthe method. CPython implementation detail: In CPython 3.6 and later, the __class__ cell is passed to the metaclass as a\n__classcell__ entry in the class namespace. If present, this must be propagated up to the type.__new__ call\nin order for the class to be initialised correctly. Failing to do so will result in a RuntimeError in Python 3.8. When using the default metaclass type, or any metaclass that ultimately calls type.__new__, the following addi-\ntional customization steps are invoked after creating the class object:\n1) The type.__new__ method collects all of the attributes in the class namespace that define a\n__set_name__() method;\n2) Those __set_name__ methods are called with the class being defined and the assigned name of that particular\nattribute;\n3) The __init_subclass__() hook is called on the immediate parent of the new class in its method resolution\norder. After the class object is created, it is passed to the class decorators included in the class definition (if any) and the\nresulting object is bound in the local namespace as the defined class. When a new class is created by type.__new__, the object provided as the namespace parameter is copied to a new\nordered mapping and the original object is discarded. The new copy is wrapped in a read-only proxy, which becomes\nthe __dict__ attribute of the class object. µ See also\nPEP 3135 - New super\nDescribes the implicit __class__ closure reference\nUses for metaclasses\nThe potential uses for metaclasses are boundless. Some ideas that have been explored include enum, logging, in-\nterface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource\nlocking/synchronization. 3.3. Special method names\n45\n\nThe Python Language Reference, Release 3.13.2\n3.3.4 Customizing instance and subclass checks\nThe following methods are used to override the default behavior of the isinstance() and issubclass() built-in\nfunctions. In particular, the metaclass abc.ABCMeta implements these methods in order to allow the addition of Abstract Base\nClasses (ABCs) as “virtual base classes” to any class or type (including built-in types), including other ABCs."")",6.800845027520845e-79,0.09811827956989247,0.2516083865720313,0.6014938950538635,0.5999726
How do I merge two dictionaries in a single expression in Python?,"How can I merge two Python dictionaries in a single expression?


For dictionaries 
x
 and 
y
, their shallowly-merged dictionary 
z
 takes values from 
y
, replacing those from 
x
.




In Python 3.9.0 or greater (released 17 October 2020, 
PEP-584
, 
discussed here
):


z = x | y





In Python 3.5 or greater:


z = {**x, **y}





In Python 2, (or 3.4 or lower) write a function:


def merge_two_dicts(x, y):
    z = x.copy()   # start with keys and values of x
    z.update(y)    # modifies z with keys and values of y
    return z



and now:


z = merge_two_dicts(x, y)







Explanation


Say you have two dictionaries and you want to merge them into a new dictionary without altering the original dictionaries:


x = {'a': 1, 'b': 2}
y = {'b': 3, 'c': 4}



The desired result is to get a new dictionary (
z
) with the values merged, and the second dictionary's values overwriting those from the first.


>>> z
{'a': 1, 'b': 3, 'c': 4}



A new syntax for this, proposed in 
PEP 448
 and 
available as of Python 3.5
, is


z = {**x, **y}



And it is indeed a single expression.


Note that we can merge in with literal notation as well:


z = {**x, 'foo': 1, 'bar': 2, **y}



and now:


>>> z
{'a': 1, 'b': 3, 'foo': 1, 'bar': 2, 'c': 4}



It is now showing as implemented in the 
release schedule for 3.5, PEP 478
, and it has now made its way into the 
What's New in Python 3.5
 document.


However, since many organizations are still on Python 2, you may wish to do this in a backward-compatible way. The classically Pythonic way, available in Python 2 and Python 3.0-3.4, is to do this as a two-step process:


z = x.copy()
z.update(y) # which returns None since it mutates z



In both approaches, 
y
 will come second and its values will replace 
x
's values, thus 
b
 will point to 
3
 in our final result.


Not yet on Python 3.5, but want a 
single expression


If you are not yet on Python 3.5 or need to write backward-compatible code, and you want this in a 
single expression
, the most performant while the correct approach is to put it in a function:


def merge_two_dicts(x, y):
    """"""Given two dictionaries, merge them into a new dict as a shallow copy.""""""
    z = x.copy()
    z.update(y)
    return z



and then you have a single expression:


z = merge_two_dicts(x, y)



You can also make a function to merge an arbitrary number of dictionaries, from zero to a very large number:


def merge_dicts(*dict_args):
    """"""
    Given any number of dictionaries, shallow copy and merge into a new dict,
    precedence goes to key-value pairs in latter dictionaries.
    """"""
    result = {}
    for dictionary in dict_args:
        result.update(dictionary)
    return result



This function will work in Python 2 and 3 for all dictionaries. e.g. given dictionaries 
a
 to 
g
:


z = merge_dicts(a, b, c, d, e, f, g) 



and key-value pairs in 
g
 will take precedence over dictionaries 
a
 to 
f
, and so on.


Critiques of Other Answers


Don't use what you see in the formerly accepted answer:


z = dict(x.items() + y.items())



In Python 2, you create two lists in memory for each dict, create a third list in memory with length equal to the length of the first two put together, and then discard all three lists to create the dict. 
In Python 3, this will fail
 because you're adding two 
dict_items
 objects together, not two lists -


>>> c = dict(a.items() + b.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unsupported operand type(s) for +: 'dict_items' and 'dict_items'



and you would have to explicitly create them as lists, e.g. 
z = dict(list(x.items()) + list(y.items()))
. This is a waste of resources and computation power.


Similarly, taking the union of 
items()
 in Python 3 (
viewitems()
 in Python 2.7) will also fail when values are unhashable objects (like lists, for example). Even if your values are hashable, 
since sets are semantically unordered, the behavior is undefined in regards to precedence. So don't do this:


>>> c = dict(a.items() | b.items())



This example demonstrates what happens when values are unhashable:


>>> x = {'a': []}
>>> y = {'b': []}
>>> dict(x.items() | y.items())
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: unhashable type: 'list'



Here's an example where 
y
 should have precedence, but instead the value from 
x
 is retained due to the arbitrary order of sets:


>>> x = {'a': 2}
>>> y = {'a': 1}
>>> dict(x.items() | y.items())
{'a': 2}



Another hack you should not use:


z = dict(x, **y)



This uses the 
dict
 constructor and is very fast and memory-efficient (even slightly more so than our two-step process) but unless you know precisely what is happening here (that is, the second dict is being passed as keyword arguments to the dict constructor), it's difficult to read, it's not the intended usage, and so it is not Pythonic.


Here's an example of the usage being 
remediated in django
.


Dictionaries are intended to take hashable keys (e.g. 
frozenset
s or tuples), but 
this method fails in Python 3 when keys are not strings.


>>> c = dict(a, **b)
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: keyword arguments must be strings



From the 
mailing list
, Guido van Rossum, the creator of the language, wrote:




I am fine with
declaring dict({}, **{1:3}) illegal, since after all it is abuse of
the ** mechanism.




and




Apparently dict(x, **y) is going around as ""cool hack"" for ""call
x.update(y) and return x"". Personally, I find it more despicable than
cool.




It is my understanding (as well as the understanding of the 
creator of the language
) that the intended usage for 
dict(**y)
 is for creating dictionaries for readability purposes, e.g.:


dict(a=1, b=10, c=11)



instead of


{'a': 1, 'b': 10, 'c': 11}



Response to comments




Despite what Guido says, 
dict(x, **y)
 is in line with the dict specification, which btw. works for both Python 2 and 3. The fact that this only works for string keys is a direct consequence of how keyword parameters work and not a short-coming of dict. Nor is using the ** operator in this place an abuse of the mechanism, in fact, ** was designed precisely to pass dictionaries as keywords.




Again, it doesn't work for 3 when keys are not strings. The implicit calling contract is that namespaces take ordinary dictionaries, while users must only pass keyword arguments that are strings. All other callables enforced it. 
dict
 broke this consistency in Python 2:


>>> foo(**{('a', 'b'): None})
Traceback (most recent call last):
  File ""
"", line 1, in 

TypeError: foo() keywords must be strings
>>> dict(**{('a', 'b'): None})
{('a', 'b'): None}



This inconsistency was bad given other implementations of Python (PyPy, Jython, IronPython). Thus it was fixed in Python 3, as this usage could be a breaking change.


I submit to you that it is malicious incompetence to intentionally write code that only works in one version of a language or that only works given certain arbitrary constraints.


More comments:




dict(x.items() + y.items())
 is still the most readable solution for Python 2. Readability counts.




My response: 
merge_two_dicts(x, y)
 actually seems much clearer to me, if we're actually concerned about readability. And it is not forward compatible, as Python 2 is increasingly deprecated.




{**x, **y}
 does not seem to handle nested dictionaries. the contents of nested keys are simply overwritten, not merged [...] I ended up being burnt by these answers that do not merge recursively and I was surprised no one mentioned it. In my interpretation of the word ""merging"" these answers describe ""updating one dict with another"", and not merging.




Yes. I must refer you back to the question, which is asking for a 
shallow
 merge of 
two
 dictionaries, with the first's values being overwritten by the second's - in a single expression.


Assuming two dictionaries of dictionaries, one might recursively merge them in a single function, but you should be careful not to modify the dictionaries from either source, and the surest way to avoid that is to make a copy when assigning values. As keys must be hashable and are usually therefore immutable, it is pointless to copy them:


from copy import deepcopy

def dict_of_dicts_merge(x, y):
    z = {}
    overlapping_keys = x.keys() & y.keys()
    for key in overlapping_keys:
        z[key] = dict_of_dicts_merge(x[key], y[key])
    for key in x.keys() - overlapping_keys:
        z[key] = deepcopy(x[key])
    for key in y.keys() - overlapping_keys:
        z[key] = deepcopy(y[key])
    return z



Usage:


>>> x = {'a':{1:{}}, 'b': {2:{}}}
>>> y = {'b':{10:{}}, 'c': {11:{}}}
>>> dict_of_dicts_merge(x, y)
{'b': {2: {}, 10: {}}, 'a': {1: {}}, 'c': {11: {}}}



Coming up with contingencies for other value types is far beyond the scope of this question, so I will point you at 
my answer to the canonical question on a ""Dictionaries of dictionaries merge""
.


Less Performant But Correct Ad-hocs


These approaches are less performant, but they will provide correct behavior.
They will be 
much less
 performant than 
copy
 and 
update
 or the new unpacking because they iterate through each key-value pair at a higher level of abstraction, but they 
do
 respect the order of precedence (latter dictionaries have precedence)


You can also chain the dictionaries manually inside a 
dict comprehension
:


{k: v for d in dicts for k, v in d.items()} # iteritems in Python 2.7



or in Python 2.6 (and perhaps as early as 2.4 when generator expressions were introduced):


dict((k, v) for d in dicts for k, v in d.items()) # iteritems in Python 2



itertools.chain
 will chain the iterators over the key-value pairs in the correct order:


from itertools import chain
z = dict(chain(x.items(), y.items())) # iteritems in Python 2



Performance Analysis


I'm only going to do the performance analysis of the usages known to behave correctly. (Self-contained so you can copy and paste yourself.)


from timeit import repeat
from itertools import chain

x = dict.fromkeys('abcdefg')
y = dict.fromkeys('efghijk')

def merge_two_dicts(x, y):
    z = x.copy()
    z.update(y)
    return z

min(repeat(lambda: {**x, **y}))
min(repeat(lambda: merge_two_dicts(x, y)))
min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
min(repeat(lambda: dict(chain(x.items(), y.items()))))
min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))



In Python 3.8.1, NixOS:


>>> min(repeat(lambda: {**x, **y}))
1.0804965235292912
>>> min(repeat(lambda: merge_two_dicts(x, y)))
1.636518670246005
>>> min(repeat(lambda: {k: v for d in (x, y) for k, v in d.items()}))
3.1779992282390594
>>> min(repeat(lambda: dict(chain(x.items(), y.items()))))
2.740647904574871
>>> min(repeat(lambda: dict(item for d in (x, y) for item in d.items())))
4.266070580109954



$ uname -a
Linux nixos 4.19.113 #1-NixOS SMP Wed Mar 25 07:06:15 UTC 2020 x86_64 GNU/Linux



Resources on Dictionaries




My explanation of Python's 
dictionary implementation
, updated for 3.6.


Answer on how to add new keys to a dictionary


Mapping two lists into a dictionary


The official Python docs on dictionaries


The Dictionary Even Mightier
 - talk by Brandon Rhodes at Pycon 2017


Modern Python Dictionaries, A Confluence of Great Ideas
 - talk by Raymond Hettinger at Pycon 2017



","(""I'm sorry, I couldn't find relevant information in the provided context."", ""[1] Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for\nstrings uses the Unicode code point number to order individual characters.\n\n[2] Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one.\n\n[3] Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for\nstrings uses the Unicode code point number to order individual characters. Some examples of comparisons between\nsequences of the same type:\n(1, 2, 3)\n< (1, 2, 4)\n[1, 2, 3]\n< [1, 2, 4]\n'ABC' < 'C' < 'Pascal' < 'Python'\n(1, 2, 3, 4)\n< (1, 2, 4)\n(1, 2)\n< (1, 2, -1)\n(1, 2, 3)\n== (1.0, 2.0, 3.0)\n(1, 2, ('aa', 'ab'))\n< (1, 2, ('abc', 'a'), 4)\nNote that comparing objects of different types with < or > is legal provided that the objects have appropriate com-\nparison methods."")",0.009461430845803073,0.10994518402505873,0.32659066174237694,0.5980632901191711,0.28051358
How do I execute a program or call a system command?,"Use 
subprocess.run
:


import subprocess

subprocess.run([""ls"", ""-l""]) 



Another common way is 
os.system
 but you shouldn't use it because it is unsafe if any parts of the command come from outside your program or can contain spaces or other special characters, also 
subprocess.run
 is generally more flexible (you can get the 
stdout
, 
stderr
, the 
""real"" status code
, better 
error handling
, etc.). Even the 
documentation for 
os.system
 recommends using 
subprocess
 instead.


On Python 3.4 and earlier, use 
subprocess.call
 instead of 
.run
:


subprocess.call([""ls"", ""-l""])


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . 62\n6\nUtilities\n63\n6.1\nOperating System Utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n6.2\nSystem Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n6.3\nProcess Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n6.4\nImporting Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901\n29.3.2\nCommand-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901\nxvii\n\n29.3.3\nPython API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1901\n29.3.4\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1902\n29.3.5\nSpecifying the Interpreter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5.17 glob . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5.18 importlib . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5.19 io\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5.20 ipaddress . . . . . . . . . . . . . . . . . . . . . . . . . .')",4.347048958699952e-232,0.05524861878453038,0.05382775119617225,0.4489922821521759,0.034255333
"How do I create a directory, and any missing parent directories?","On Python ≥ 3.5, use 
pathlib.Path.mkdir
:


from pathlib import Path
Path(""/my/directory"").mkdir(parents=True, exist_ok=True)



For older versions of Python, I see two answers with good qualities, each with a small flaw, so I will give my take on it:


Try 
os.path.exists
, and consider 
os.makedirs
 for the creation.


import os
if not os.path.exists(directory):
    os.makedirs(directory)



As noted in comments and elsewhere, there's a race condition – if the directory is created between the 
os.path.exists
 and the 
os.makedirs
 calls, the 
os.makedirs
 will fail with an 
OSError
. Unfortunately, blanket-catching 
OSError
 and continuing is not foolproof, as it will ignore a failure to create the directory due to other factors, such as insufficient permissions, full disk, etc.


One option would be to trap the 
OSError
 and examine the embedded error code (see 
Is there a cross-platform way of getting information from Python’s OSError
):


import os, errno

try:
    os.makedirs(directory)
except OSError as e:
    if e.errno != errno.EEXIST:
        raise



Alternatively, there could be a second 
os.path.exists
, but suppose another created the directory after the first check, then removed it before the second one – we could still be fooled. 


Depending on the application, the danger of concurrent operations may be more or less than the danger posed by other factors such as file permissions. The developer would have to know more about the particular application being developed and its expected environment before choosing an implementation.


Modern versions of Python improve this code quite a bit, both by exposing 
FileExistsError
 (in 3.3+)...


try:
    os.makedirs(""path/to/directory"")
except FileExistsError:
    # directory already exists
    pass



...and by allowing 
a keyword argument to 
os.makedirs
 called 
exist_ok
 (in 3.2+).


os.makedirs(""path/to/directory"", exist_ok=True)  # succeeds even if directory exists.


","('Answer: To create a directory and any missing parent directories, use `Path.mkdir()` with the `parents` parameter set to `True`.\n\nReferences: [3]\n', '[1] Creating files and directories\nPath.touch(mode=0o666, exist_ok=True)\nCreate a file at this given path. If mode is given, it is combined with the process’s umask value to determine\nthe file mode and access flags. If the file already exists, the function succeeds when exist_ok is true (and its\nmodification time is updated to the current time), otherwise FileExistsError is raised. µ See also\nThe open(), write_text() and write_bytes() methods are often used to create files. Path.mkdir(mode=0o777, parents=False, exist_ok=False)\nCreate a new directory at this given path. If mode is given, it is combined with the process’s umask value to\ndetermine the file mode and access flags. If the path already exists, FileExistsError is raised. If parents is true, any missing parents of this path are created as needed; they are created with the default\npermissions without taking mode into account (mimicking the POSIX mkdir -p command). If parents is false (the default), a missing parent raises FileNotFoundError. If exist_ok is false (the default), FileExistsError is raised if the target directory already exists. If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system\nand is not a directory (same behavior as the POSIX mkdir -p command). Changed in version 3.5: The exist_ok parameter was added. Path.symlink_to(target, target_is_directory=False)\nMake this path a symbolic link pointing to target. On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If\nthe target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as\na directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,\ntarget_is_directory is ignored. >>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\n>>> p.stat().st_size\n956\n>>> p.lstat().st_size\n8\n11.1. pathlib — Object-oriented filesystem paths\n459\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThe order of arguments (link, target) is the reverse of os.symlink()’s. Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous\nversions, NotImplementedError was raised. Path.hardlink_to(target)\nMake this path a hard link to the same file as target. ® Note\nThe order of arguments (link, target) is the reverse of os.link()’s. Added in version 3.10. Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-\nsions, NotImplementedError was raised. Renaming and deleting\nPath.rename(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,\nif target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,\nFileExistsError will be raised. target can be either a string or another path object:\n>>> p = Path(\'foo\')\n>>> p.open(\'w\').write(\'some text\')\n9\n>>> target = Path(\'bar\')\n>>> p.rename(target)\nPosixPath(\'bar\')\n>>> target.open().read()\n\'some text\'\nThe target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. It is implemented in terms of os.rename() and gives the same guarantees. Changed in version 3.8: Added return value, return the new Path instance. Path.replace(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. If target\npoints to an existing file or empty directory, it will be unconditionally replaced. The target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. Changed in version 3.8: Added return value, return the new Path instance. Path.unlink(missing_ok=False)\nRemove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead. If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist. If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f\ncommand). Changed in version 3.8: The missing_ok parameter was added. 460\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.rmdir()\nRemove this directory. The directory must be empty. Permissions and ownership\nPath.owner(*, follow_symlinks=True)\nReturn the name of the user owning the file. KeyError is raised if the file’s user identifier (UID) isn’t found\nin the system database. This method normally follows symlinks;\nto get the owner of the symlink,\nadd the argument\nfollow_symlinks=False. Changed in version 3.13: Raises UnsupportedOperation if the pwd module is not available. In earlier\nversions, NotImplementedError was raised. Changed in version 3.13: The follow_symlinks parameter was added.\n\n[2] Walking the tree bottom-up is essential\nas rmdir() doesn’t allow deleting a directory before it is empty:\n# Delete everything reachable from the directory ""top"". # CAUTION:\nThis is dangerous! For example, if top == Path(\'/\'),\n# it could delete all of your files. for root, dirs, files in top.walk(top_down=False):\nfor name in files:\n(root / name).unlink()\nfor name in dirs:\n(root / name).rmdir()\nAdded in version 3.12. Creating files and directories\nPath.touch(mode=0o666, exist_ok=True)\nCreate a file at this given path. If mode is given, it is combined with the process’s umask value to determine\nthe file mode and access flags. If the file already exists, the function succeeds when exist_ok is true (and its\nmodification time is updated to the current time), otherwise FileExistsError is raised. µ See also\nThe open(), write_text() and write_bytes() methods are often used to create files. Path.mkdir(mode=0o777, parents=False, exist_ok=False)\nCreate a new directory at this given path. If mode is given, it is combined with the process’s umask value to\ndetermine the file mode and access flags. If the path already exists, FileExistsError is raised. If parents is true, any missing parents of this path are created as needed; they are created with the default\npermissions without taking mode into account (mimicking the POSIX mkdir -p command). If parents is false (the default), a missing parent raises FileNotFoundError. If exist_ok is false (the default), FileExistsError is raised if the target directory already exists. If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system\nand is not a directory (same behavior as the POSIX mkdir -p command). Changed in version 3.5: The exist_ok parameter was added. Path.symlink_to(target, target_is_directory=False)\nMake this path a symbolic link pointing to target. On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If\nthe target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as\na directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,\ntarget_is_directory is ignored. >>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\n>>> p.stat().st_size\n956\n>>> p.lstat().st_size\n8\n11.1. pathlib — Object-oriented filesystem paths\n459\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThe order of arguments (link, target) is the reverse of os.symlink()’s. Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous\nversions, NotImplementedError was raised. Path.hardlink_to(target)\nMake this path a hard link to the same file as target. ® Note\nThe order of arguments (link, target) is the reverse of os.link()’s. Added in version 3.10. Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-\nsions, NotImplementedError was raised. Renaming and deleting\nPath.rename(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,\nif target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,\nFileExistsError will be raised. target can be either a string or another path object:\n>>> p = Path(\'foo\')\n>>> p.open(\'w\').write(\'some text\')\n9\n>>> target = Path(\'bar\')\n>>> p.rename(target)\nPosixPath(\'bar\')\n>>> target.open().read()\n\'some text\'\nThe target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. It is implemented in terms of os.rename() and gives the same guarantees. Changed in version 3.8: Added return value, return the new Path instance. Path.replace(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. If target\npoints to an existing file or empty directory, it will be unconditionally replaced. The target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. Changed in version 3.8: Added return value, return the new Path instance. Path.unlink(missing_ok=False)\nRemove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead. If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist. If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f\ncommand). Changed in version 3.8: The missing_ok parameter was added. 460\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.rmdir()\nRemove this directory. The directory must be empty. Permissions and ownership\nPath.owner(*, follow_symlinks=True)\nReturn the name of the user owning the file. KeyError is raised if the file’s user identifier (UID) isn’t found\nin the system database.\n\n[3] µ See also\nThe open(), write_text() and write_bytes() methods are often used to create files. Path.mkdir(mode=0o777, parents=False, exist_ok=False)\nCreate a new directory at this given path. If mode is given, it is combined with the process’s umask value to\ndetermine the file mode and access flags. If the path already exists, FileExistsError is raised. If parents is true, any missing parents of this path are created as needed; they are created with the default\npermissions without taking mode into account (mimicking the POSIX mkdir -p command). If parents is false (the default), a missing parent raises FileNotFoundError. If exist_ok is false (the default), FileExistsError is raised if the target directory already exists. If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system\nand is not a directory (same behavior as the POSIX mkdir -p command). Changed in version 3.5: The exist_ok parameter was added. Path.symlink_to(target, target_is_directory=False)\nMake this path a symbolic link pointing to target. On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If\nthe target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as\na directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,\ntarget_is_directory is ignored. >>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\n>>> p.stat().st_size\n956\n>>> p.lstat().st_size\n8\n11.1. pathlib — Object-oriented filesystem paths\n459\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThe order of arguments (link, target) is the reverse of os.symlink()’s. Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous\nversions, NotImplementedError was raised. Path.hardlink_to(target)\nMake this path a hard link to the same file as target. ® Note\nThe order of arguments (link, target) is the reverse of os.link()’s. Added in version 3.10. Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-\nsions, NotImplementedError was raised. Renaming and deleting\nPath.rename(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,\nif target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,\nFileExistsError will be raised. target can be either a string or another path object:\n>>> p = Path(\'foo\')\n>>> p.open(\'w\').write(\'some text\')\n9\n>>> target = Path(\'bar\')\n>>> p.rename(target)\nPosixPath(\'bar\')\n>>> target.open().read()\n\'some text\'\nThe target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. It is implemented in terms of os.rename() and gives the same guarantees. Changed in version 3.8: Added return value, return the new Path instance. Path.replace(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. If target\npoints to an existing file or empty directory, it will be unconditionally replaced. The target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. Changed in version 3.8: Added return value, return the new Path instance. Path.unlink(missing_ok=False)\nRemove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead. If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist. If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f\ncommand). Changed in version 3.8: The missing_ok parameter was added. 460\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.rmdir()\nRemove this directory. The directory must be empty. Permissions and ownership\nPath.owner(*, follow_symlinks=True)\nReturn the name of the user owning the file. KeyError is raised if the file’s user identifier (UID) isn’t found\nin the system database. This method normally follows symlinks;\nto get the owner of the symlink,\nadd the argument\nfollow_symlinks=False. Changed in version 3.13: Raises UnsupportedOperation if the pwd module is not available. In earlier\nversions, NotImplementedError was raised. Changed in version 3.13: The follow_symlinks parameter was added. Path.group(*, follow_symlinks=True)\nReturn the name of the group owning the file. KeyError is raised if the file’s group identifier (GID) isn’t found\nin the system database. This method normally follows symlinks;\nto get the group of the symlink,\nadd the argument\nfollow_symlinks=False.')",1.8260693675155336e-155,0.07654836464857342,0.17692326508935607,0.6023222208023071,0.74098563
How to access the index value in a 'for' loop?,"Use the built-in function 
enumerate()
:


for idx, x in enumerate(xs):
    print(idx, x)



It is 
non-pythonic
 to manually index via 
for i in range(len(xs)): x = xs[i]
 or manually manage an additional state variable.


Check out 
PEP 279
 for more.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.4\nbreak and continue Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.5\nelse Clauses on Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.6\npass Statements . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . 9\n3.1.3\nLists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2\nFirst Steps Towards Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4\nMore Control Flow Tools\n17\n4.1\nif Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function .\n\n[3] . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.1\nHow do I convert between tuples and lists? . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",5.325105075896282e-232,0.05813953488372093,0.12186013986013988,0.3938371241092682,0.20590761
How do I make a flat list out of a list of lists?,"A list of lists named 
xss
 can be flattened using a nested 
list comprehension
:


flat_list = [
    x
    for xs in xss
    for x in xs
]



The above is equivalent to:


flat_list = []

for xs in xss:
    for x in xs:
        flat_list.append(x)



Here is the corresponding function:


def flatten(xss):
    return [x for xs in xss for x in xs]



This is the fastest method.
As evidence, using the 
timeit
 module in the standard library, we see:


$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' '[x for xs in xss for x in xs]'
10000 loops, best of 3: 143 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'sum(xss, [])'
1000 loops, best of 3: 969 usec per loop

$ python -mtimeit -s'xss=[[1,2,3],[4,5,6],[7],[8,9]]*99' 'reduce(lambda xs, ys: xs + ys, xss)'
1000 loops, best of 3: 1.1 msec per loop



Explanation: the methods based on 
+
 (including the implied use in 
sum
) are, of necessity, 
O(L**2)
 when there are L sublists -- as the intermediate result list keeps getting longer, at each step a new intermediate result list object gets allocated, and all the items in the previous intermediate result must be copied over (as well as a few new ones added at the end). So, for simplicity and without actual loss of generality, say you have L sublists of M items each: the first M items are copied back and forth 
L-1
 times, the second M items 
L-2
 times, and so on; total number of copies is M times the sum of x for x from 1 to L excluded, i.e., 
M * (L**2)/2
.


The list comprehension just generates one list, once, and copies each item over (from its original place of residence to the result list) also exactly once.

","(""Answer: You can flatten a list of lists using a list comprehension with two 'for' clauses. For example: `[num for elem in vec for num in elem]` where `vec = [[1,2,3], [4,5,6], [7,8,9]]` would result in `[1, 2, 3, 4, 5, 6, 7, 8, 9]`.\n\nReferences: [2]\n"", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples\nare immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later\nin this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements\nare usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accom-\nmodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed\nby following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example:\n>>> empty = ()\n>>> singleton = \'hello\',\n# <-- note trailing comma\n>>> len(empty)\n0\n>>> len(singleton)\n1\n>>> singleton\n(\'hello\',)\nThe statement t = 12345, 54321, \'hello!\' is an example of tuple packing: the values 12345, 54321 and\n\'hello!\' are packed together in a tuple. The reverse operation is also possible:\n>>> x, y, z = t\nThis is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence\nunpacking requires that there are as many variables on the left side of the equals sign as there are elements in the\nsequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking. 38\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.4 Sets\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses\ninclude membership testing and eliminating duplicate entries.\n\n[3] . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . . 24\n2.5.9\nWhy does a_tuple[i] += [‘item’] raise an exception when the addition works? . . . . . . . 25\n2.5.10\nI want to do a complicated sort: can you do a Schwartzian Transform in Python? . . . . . 26\n2.5.11\nHow can I sort one list by values from another list? . . . . . . . . . . .')",5.631595916579458e-79,0.09739130434782609,0.2238409308156079,0.5750519633293152,0.5754447
What is the difference between @staticmethod and @classmethod in Python?,"Maybe a bit of example code will help: Notice the difference in the call signatures of 
foo
, 
class_foo
 and 
static_foo
:


class A(object):
    def foo(self, x):
        print(f""executing foo({self}, {x})"")

    @classmethod
    def class_foo(cls, x):
        print(f""executing class_foo({cls}, {x})"")

    @staticmethod
    def static_foo(x):
        print(f""executing static_foo({x})"")

a = A()



Below is the usual way an object instance calls a method. The object instance, 
a
, is implicitly passed as the first argument.


a.foo(1)
# executing foo(<__main__.A object at 0xb7dbef0c>, 1)





With classmethods
, the class of the object instance is implicitly passed as the first argument instead of 
self
.


a.class_foo(1)
# executing class_foo(
, 1)



You can also call 
class_foo
 using the class. In fact, if you define something to be
a classmethod, it is probably because you intend to call it from the class rather than from a class instance. 
A.foo(1)
 would have raised a TypeError, but 
A.class_foo(1)
 works just fine:


A.class_foo(1)
# executing class_foo(
, 1)



One use people have found for class methods is to create 
inheritable alternative constructors
.




With staticmethods
, neither 
self
 (the object instance) nor  
cls
 (the class) is implicitly passed as the first argument. They behave like plain functions except that you can call them from an instance or the class:


a.static_foo(1)
# executing static_foo(1)

A.static_foo('hi')
# executing static_foo(hi)



Staticmethods are used to group functions which have some logical connection with a class to the class.




foo
 is just a function, but when you call 
a.foo
 you don't just get the function,
you get a ""partially applied"" version of the function with the object instance 
a
 bound as the first argument to the function. 
foo
 expects 2 arguments, while 
a.foo
 only expects 1 argument.


a
 is bound to 
foo
. That is what is meant by the term ""bound"" below:


print(a.foo)
# 
>



With 
a.class_foo
, 
a
 is not bound to 
class_foo
, rather the class 
A
 is bound to 
class_foo
.


print(a.class_foo)
# 
>



Here, with a staticmethod, even though it is a method, 
a.static_foo
 just returns
a good 'ole function with no arguments bound. 
static_foo
 expects 1 argument, and

a.static_foo
 expects 1 argument too.


print(a.static_foo)
# 




And of course the same thing happens when you call 
static_foo
 with the class 
A
 instead.


print(A.static_foo)
# 



","(""Answer: A static method doesn't receive an implicit first argument, and can be called either on the class or on an instance.\n\nReferences: [1]\n"", ""[1] @staticmethod\nTransform a method into a static method. A static method does not receive an implicit first argument. To declare a static method, use this idiom:\nclass C:\n@staticmethod\ndef f(arg1, arg2, argN): ... The @staticmethod form is a function decorator – see function for details. A static method can be called either on the class (such as C.f()) or on an instance (such as C().f()). Moreover, the static method descriptor is also callable, so it can be used in the class definition (such as f()). Static methods in Python are similar to those found in Java or C++. Also, see classmethod() for a variant\nthat is useful for creating alternate class constructors. Like all decorators, it is also possible to call staticmethod as a regular function and do something with its\nresult. This is needed in some cases where you need a reference to a function from a class body and you want\nto avoid the automatic transformation to instance method. For these cases, use this idiom:\ndef regular_function():\n...\nclass C:\nmethod = staticmethod(regular_function)\nFor more information on static methods, see types. Changed in version 3.10: Static methods now inherit the method attributes (__module__, __name__,\n__qualname__, __doc__ and __annotations__), have a new __wrapped__ attribute, and are now\ncallable as regular functions. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a str version of object. See str() for details. str is the built-in string class. For general information about strings, see Text Sequence Type — str. sum(iterable, /, start=0)\nSums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally\nnumbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of\nstrings is by calling ''.join(sequence). To add floating-point values with extended precision, see math. fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument. Changed in version 3.12: Summation of floats switched to an algorithm that gives higher accuracy and better\ncommutativity on most builds. class super\n29\n\nThe Python Library Reference, Release 3.13.2\nclass super(type, object_or_type=None)\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing\ninherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class\nright after the type. For example, if __mro__ of object_or_type is D -> B -> C -> A -> object and the value of type is B,\nthen super() searches C -> A -> object. The __mro__ attribute of the class corresponding to object_or_type lists the method resolution search order\nused by both getattr() and super(). The attribute is dynamic and can change whenever the inheritance\nhierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object,\nisinstance(obj, type) must be true. If the second argument is a type, issubclass(type2, type)\nmust be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument\nsuper()”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately\nenclosing function (typically self). (This means that zero-argument super() will not work as expected\nwithin nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer\nto parent classes without naming them explicitly, thus making the code more maintainable. This use closely\nparallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This\nuse case is unique to Python and is not found in statically compiled languages or languages that only support\nsingle inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes im-\nplement the same method. Good design dictates that such implementations have the same calling signature in\nevery case (because the order of calls is determined at runtime, because that order adapts to changes in the\nclass hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this:\nclass C(B):\ndef method(self, arg):\nsuper().method(arg)\n# This does the same thing as:\n# super(C, self).method(arg)\nIn addition to method lookups, super() also works for attribute lookups. One possible use case for this is\ncalling descriptors in a parent or sibling class. Note that super() is implemented as part of the binding process for explicit dotted attribute lookups such as\nsuper().__getitem__(name). It does so by implementing its own __getattribute__() method for\nsearching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, super()\nis undefined for implicit lookups using statements or operators such as super()[name]. Also note that, aside from the zero argument form, super() is not limited to use inside methods.\n\n[2] . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . . . . . . . . 29\n2.6.9\nHow can I overload constructors (or methods) in Python? . . . . . . . . . . . . . . . . . 30\n2.6.10\nI try to use __spam and I get an error about _SomeClassName__spam. . . . . . . . . . . 30\n2.6.11\nMy class defines __del__ but it is not called when I delete the object. . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . . . . . . . . 29\n2.6.9\nHow can I overload constructors (or methods) in Python? . . . . . . . . . . . . . . . . ."")",7.759124553270879e-79,0.13315579227696406,0.29438122692014285,0.6016997694969177,0.6916001
How slicing in Python works,"The syntax is:


a[start:stop]  # items start through stop-1
a[start:]      # items start through the rest of the array
a[:stop]       # items from the beginning through stop-1
a[:]           # a copy of the whole array



There is also the 
step
 value, which can be used with any of the above:


a[start:stop:step] # start through not past stop, by step



The key point to remember is that the 
:stop
 value represents the first value that is 
not
 in the selected slice. So, the difference between 
stop
 and 
start
 is the number of elements selected (if 
step
 is 1, the default).


The other feature is that 
start
 or 
stop
 may be a 
negative
 number, which means it counts from the end of the array instead of the beginning. So:


a[-1]    # last item in the array
a[-2:]   # last two items in the array
a[:-2]   # everything except the last two items



Similarly, 
step
 may be a negative number:


a[::-1]    # all items in the array, reversed
a[1::-1]   # the first two items, reversed
a[:-3:-1]  # the last two items, reversed
a[-3::-1]  # everything except the last two items, reversed



Python is kind to the programmer if there are fewer items than you ask for. For example, if you ask for 
a[:-2]
 and 
a
 only contains one element, you get an empty list instead of an error. Sometimes you would prefer the error, so you have to be aware that this may happen.


Relationship with the 
slice
 object


A 
slice
 object
 can represent a slicing operation, i.e.:


a[start:stop:step]



is equivalent to:


a[slice(start, stop, step)]



Slice objects also behave slightly differently depending on the number of arguments, similar to 
range()
, i.e. both 
slice(stop)
 and 
slice(start, stop[, step])
 are supported.
To skip specifying a given argument, one might use 
None
, so that e.g. 
a[start:]
 is equivalent to 
a[slice(start, None)]
 or 
a[::-1]
 is equivalent to 
a[slice(None, None, -1)]
.


While the 
:
-based notation is very helpful for simple slicing, the explicit use of 
slice()
 objects simplifies the programmatic generation of slicing.

","('Answer: Slicing in Python is used to obtain a substring from a sequence (e.g., strings, lists). You specify a range of indices, and the slice includes characters from the start index up to, but not including, the end index. An omitted first index defaults to zero, and an omitted second index defaults to the size of the string being sliced. The start is always included, and the end is always excluded.\n\nReferences: [2, 3]\n', '[1] >>> word[:2]\n# character from the beginning to position 2 (excluded)\n\'Py\'\n>>> word[4:]\n# characters from position 4 (included) to the end\n\'on\'\n>>> word[-2:]\n# characters from the second-last (included) to the end\n\'on\'\nNote how the start is always included, and the end always excluded. This makes sure that s[:i] + s[i:] is always\nequal to s:\n>>> word[:2] + word[2:]\n\'Python\'\n>>> word[:4] + word[4:]\n\'Python\'\nOne way to remember how slices work is to think of the indices as pointing between characters, with the left edge of\nthe first character numbered 0. Then the right edge of the last character of a string of n characters has index n, for\nexample:\n+---+---+---+---+---+---+\n| P | y | t | h | o | n |\n+---+---+---+---+---+---+\n0\n1\n2\n3\n4\n5\n6\n-6\n-5\n-4\n-3\n-2\n-1\nThe first row of numbers gives the position of the indices 0…6 in the string; the second row gives the corresponding\nnegative indices. The slice from i to j consists of all characters between the edges labeled i and j, respectively. For non-negative indices, the length of a slice is the difference of the indices, if both are within bounds. For example,\nthe length of word[1:3] is 2. Attempting to use an index that is too large will result in an error:\n>>> word[42]\n# the word only has 6 characters\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nIndexError: string index out of range\nHowever, out of range slice indexes are handled gracefully when used for slicing:\n3.1. Using Python as a Calculator\n11\n\nPython Tutorial, Release 3.13.2\n>>> word[4:42]\n\'on\'\n>>> word[42:]\n\'\'\nPython strings cannot be changed — they are immutable. Therefore, assigning to an indexed position in the string\nresults in an error:\n>>> word[0] = \'J\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\n>>> word[2:] = \'py\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\nIf you need a different string, you should create a new one:\n>>> \'J\' + word[1:]\n\'Jython\'\n>>> word[:2] + \'py\'\n\'Pypy\'\nThe built-in function len() returns the length of a string:\n>>> s = \'supercalifragilisticexpialidocious\'\n>>> len(s)\n34\nµ See also\ntextseq\nStrings are examples of sequence types, and support the common operations supported by such types. string-methods\nStrings support a large number of methods for basic transformations and searching. f-strings\nString literals that have embedded expressions. formatstrings\nInformation about string formatting with str.format(). old-string-formatting\nThe old formatting operations invoked when strings are the left operand of the % operator are described in\nmore detail here. 3.1.3 Lists\nPython knows a number of compound data types, used to group together other values. The most versatile is the list,\nwhich can be written as a list of comma-separated values (items) between square brackets. Lists might contain items\nof different types, but usually the items all have the same type. >>> squares = [1, 4, 9, 16, 25]\n>>> squares\n[1, 4, 9, 16, 25]\nLike strings (and all other built-in sequence types), lists can be indexed and sliced:\n12\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\n>>> squares[0]\n# indexing returns the item\n1\n>>> squares[-1]\n25\n>>> squares[-3:]\n# slicing returns a new list\n[9, 16, 25]\nLists also support operations like concatenation:\n>>> squares + [36, 49, 64, 81, 100]\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nUnlike strings, which are immutable, lists are a mutable type, i.e. it is possible to change their content:\n>>> cubes = [1, 8, 27, 65, 125]\n# something\'s wrong here\n>>> 4 ** 3\n# the cube of 4 is 64, not 65! 64\n>>> cubes[3] = 64\n# replace the wrong value\n>>> cubes\n[1, 8, 27, 64, 125]\nYou can also add new items at the end of the list, by using the list.append() method (we will see more about\nmethods later):\n>>> cubes.append(216)\n# add the cube of 6\n>>> cubes.append(7 ** 3)\n# and the cube of 7\n>>> cubes\n[1, 8, 27, 64, 125, 216, 343]\nSimple assignment in Python never copies data. When you assign a list to a variable, the variable refers to the existing\nlist. Any changes you make to the list through one variable will be seen through all other variables that refer to it. :\n>>> rgb = [""Red"", ""Green"", ""Blue""]\n>>> rgba = rgb\n>>> id(rgb) == id(rgba)\n# they reference the same object\nTrue\n>>> rgba.append(""Alph"")\n>>> rgb\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAll slice operations return a new list containing the requested elements. This means that the following slice returns a\nshallow copy of the list:\n>>> correct_rgba = rgba[:]\n>>> correct_rgba[-1] = ""Alpha""\n>>> correct_rgba\n[""Red"", ""Green"", ""Blue"", ""Alpha""]\n>>> rgba\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAssignment to slices is also possible, and this can even change the size of the list or clear it entirely:\n>>> letters = [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> letters\n[\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> # replace some values\n>>> letters[2:5] = [\'C\', \'D\', \'E\']\n>>> letters\n(continues on next page)\n3.1. Using Python as a Calculator\n13\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n[\'a\', \'b\', \'C\', \'D\', \'E\', \'f\', \'g\']\n>>> # now remove them\n>>> letters[2:5] = []\n>>> letters\n[\'a\', \'b\', \'f\', \'g\']\n>>> # clear the list by replacing all the elements with an empty list\n>>> letters[:] = []\n>>> letters\n[]\nThe built-in function len() also applies to lists:\n>>> letters = [\'a\', \'b\', \'c\', \'d\']\n>>> len(letters)\n4\nIt is possible to nest lists (create lists containing other lists), for example:\n>>> a = [\'a\', \'b\', \'c\']\n>>> n = [1, 2, 3]\n>>> x = [a, n]\n>>> x\n[[\'a\', \'b\', \'c\'], [1, 2, 3]]\n>>> x[0]\n[\'a\', \'b\', \'c\']\n>>> x[0][1]\n\'b\'\n3.2 First Steps Towards Programming\nOf course, we can use Python for more complicated tasks than adding two and two together. For instance, we can\nwrite an initial sub-sequence of the Fibonacci series as follows:\n>>> # Fibonacci series:\n>>> # the sum of two elements defines the next\n>>> a, b = 0, 1\n>>> while a < 10:\n...\nprint(a)\n...\na, b = b, a+b\n...\n0\n1\n1\n2\n3\n5\n8\nThis example introduces several new features. • The first line contains a multiple assignment: the variables a and b simultaneously get the new values 0 and 1. On the last line this is used again, demonstrating that the expressions on the right-hand side are all evaluated\nfirst before any of the assignments take place. The right-hand side expressions are evaluated from the left to\nthe right. • The while loop executes as long as the condition (here: a < 10) remains true. In Python, like in C, any non-\nzero integer value is true; zero is false. The condition may also be a string or list value, in fact any sequence;\n14\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\nanything with a non-zero length is true, empty sequences are false. The test used in the example is a simple\ncomparison. The standard comparison operators are written the same as in C: < (less than), > (greater than),\n== (equal to), <= (less than or equal to), >= (greater than or equal to) and != (not equal to). • The body of the loop is indented: indentation is Python’s way of grouping statements. At the interactive prompt,\nyou have to type a tab or space(s) for each indented line. In practice you will prepare more complicated input\nfor Python with a text editor; all decent text editors have an auto-indent facility. When a compound statement\nis entered interactively, it must be followed by a blank line to indicate completion (since the parser cannot\nguess when you have typed the last line). Note that each line within a basic block must be indented by the\nsame amount. • The print() function writes the value of the argument(s) it is given. It differs from just writing the expression\nyou want to write (as we did earlier in the calculator examples) in the way it handles multiple arguments,\nfloating-point quantities, and strings. Strings are printed without quotes, and a space is inserted between items,\nso you can format things nicely, like this:\n>>> i = 256*256\n>>> print(\'The value of i is\', i)\nThe value of i is 65536\nThe keyword argument end can be used to avoid the newline after the output, or end the output with a different\nstring:\n>>> a, b = 0, 1\n>>> while a < 1000:\n...\nprint(a, end=\',\')\n...\na, b = b, a+b\n...\n0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,\n3.2. First Steps Towards Programming\n15\n\nPython Tutorial, Release 3.13.2\n16\nChapter 3. An Informal Introduction to Python\n\nCHAPTER\nFOUR\nMORE CONTROL FLOW TOOLS\nAs well as the while statement just introduced, Python uses a few more that we will encounter in this chapter. 4.1 if Statements\nPerhaps the most well-known statement type is the if statement. For example:\n>>> x = int(input(""Please enter an integer: ""))\nPlease enter an integer: 42\n>>> if x < 0:\n...\nx = 0\n...\nprint(\'Negative changed to zero\')\n... elif x == 0:\n...\nprint(\'Zero\')\n... elif x == 1:\n...\nprint(\'Single\')\n... else:\n...\nprint(\'More\')\n...\nMore\nThere can be zero or more elif parts, and the else part is optional. The keyword ‘elif’ is short for ‘else if’, and is\nuseful to avoid excessive indentation. An if … elif … elif … sequence is a substitute for the switch or case\nstatements found in other languages. If you’re comparing the same value to several constants, or checking for specific types or attributes, you may also\nfind the match statement useful. For more details see match Statements.\n\n[2] An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n>>> word[-2]\n# second-last character\n\'o\'\n>>> word[-6]\n\'P\'\nNote that since -0 is the same as 0, negative indices start from -1. In addition to indexing, slicing is also supported. While indexing is used to obtain individual characters, slicing allows\nyou to obtain a substring:\n>>> word[0:2]\n# characters from position 0 (included) to 2 (excluded)\n\'Py\'\n>>> word[2:5]\n# characters from position 2 (included) to 5 (excluded)\n\'tho\'\nSlice indices have useful defaults; an omitted first index defaults to zero, an omitted second index defaults to the size\nof the string being sliced. >>> word[:2]\n# character from the beginning to position 2 (excluded)\n\'Py\'\n>>> word[4:]\n# characters from position 4 (included) to the end\n\'on\'\n>>> word[-2:]\n# characters from the second-last (included) to the end\n\'on\'\nNote how the start is always included, and the end always excluded. This makes sure that s[:i] + s[i:] is always\nequal to s:\n>>> word[:2] + word[2:]\n\'Python\'\n>>> word[:4] + word[4:]\n\'Python\'\nOne way to remember how slices work is to think of the indices as pointing between characters, with the left edge of\nthe first character numbered 0. Then the right edge of the last character of a string of n characters has index n, for\nexample:\n+---+---+---+---+---+---+\n| P | y | t | h | o | n |\n+---+---+---+---+---+---+\n0\n1\n2\n3\n4\n5\n6\n-6\n-5\n-4\n-3\n-2\n-1\nThe first row of numbers gives the position of the indices 0…6 in the string; the second row gives the corresponding\nnegative indices. The slice from i to j consists of all characters between the edges labeled i and j, respectively. For non-negative indices, the length of a slice is the difference of the indices, if both are within bounds. For example,\nthe length of word[1:3] is 2. Attempting to use an index that is too large will result in an error:\n>>> word[42]\n# the word only has 6 characters\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nIndexError: string index out of range\nHowever, out of range slice indexes are handled gracefully when used for slicing:\n3.1. Using Python as a Calculator\n11\n\nPython Tutorial, Release 3.13.2\n>>> word[4:42]\n\'on\'\n>>> word[42:]\n\'\'\nPython strings cannot be changed — they are immutable. Therefore, assigning to an indexed position in the string\nresults in an error:\n>>> word[0] = \'J\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\n>>> word[2:] = \'py\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\nIf you need a different string, you should create a new one:\n>>> \'J\' + word[1:]\n\'Jython\'\n>>> word[:2] + \'py\'\n\'Pypy\'\nThe built-in function len() returns the length of a string:\n>>> s = \'supercalifragilisticexpialidocious\'\n>>> len(s)\n34\nµ See also\ntextseq\nStrings are examples of sequence types, and support the common operations supported by such types. string-methods\nStrings support a large number of methods for basic transformations and searching. f-strings\nString literals that have embedded expressions. formatstrings\nInformation about string formatting with str.format(). old-string-formatting\nThe old formatting operations invoked when strings are the left operand of the % operator are described in\nmore detail here. 3.1.3 Lists\nPython knows a number of compound data types, used to group together other values. The most versatile is the list,\nwhich can be written as a list of comma-separated values (items) between square brackets. Lists might contain items\nof different types, but usually the items all have the same type. >>> squares = [1, 4, 9, 16, 25]\n>>> squares\n[1, 4, 9, 16, 25]\nLike strings (and all other built-in sequence types), lists can be indexed and sliced:\n12\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\n>>> squares[0]\n# indexing returns the item\n1\n>>> squares[-1]\n25\n>>> squares[-3:]\n# slicing returns a new list\n[9, 16, 25]\nLists also support operations like concatenation:\n>>> squares + [36, 49, 64, 81, 100]\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nUnlike strings, which are immutable, lists are a mutable type, i.e. it is possible to change their content:\n>>> cubes = [1, 8, 27, 65, 125]\n# something\'s wrong here\n>>> 4 ** 3\n# the cube of 4 is 64, not 65! 64\n>>> cubes[3] = 64\n# replace the wrong value\n>>> cubes\n[1, 8, 27, 64, 125]\nYou can also add new items at the end of the list, by using the list.append() method (we will see more about\nmethods later):\n>>> cubes.append(216)\n# add the cube of 6\n>>> cubes.append(7 ** 3)\n# and the cube of 7\n>>> cubes\n[1, 8, 27, 64, 125, 216, 343]\nSimple assignment in Python never copies data. When you assign a list to a variable, the variable refers to the existing\nlist. Any changes you make to the list through one variable will be seen through all other variables that refer to it. :\n>>> rgb = [""Red"", ""Green"", ""Blue""]\n>>> rgba = rgb\n>>> id(rgb) == id(rgba)\n# they reference the same object\nTrue\n>>> rgba.append(""Alph"")\n>>> rgb\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAll slice operations return a new list containing the requested elements. This means that the following slice returns a\nshallow copy of the list:\n>>> correct_rgba = rgba[:]\n>>> correct_rgba[-1] = ""Alpha""\n>>> correct_rgba\n[""Red"", ""Green"", ""Blue"", ""Alpha""]\n>>> rgba\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAssignment to slices is also possible, and this can even change the size of the list or clear it entirely:\n>>> letters = [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> letters\n[\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> # replace some values\n>>> letters[2:5] = [\'C\', \'D\', \'E\']\n>>> letters\n(continues on next page)\n3.1. Using Python as a Calculator\n13\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n[\'a\', \'b\', \'C\', \'D\', \'E\', \'f\', \'g\']\n>>> # now remove them\n>>> letters[2:5] = []\n>>> letters\n[\'a\', \'b\', \'f\', \'g\']\n>>> # clear the list by replacing all the elements with an empty list\n>>> letters[:] = []\n>>> letters\n[]\nThe built-in function len() also applies to lists:\n>>> letters = [\'a\', \'b\', \'c\', \'d\']\n>>> len(letters)\n4\nIt is possible to nest lists (create lists containing other lists), for example:\n>>> a = [\'a\', \'b\', \'c\']\n>>> n = [1, 2, 3]\n>>> x = [a, n]\n>>> x\n[[\'a\', \'b\', \'c\'], [1, 2, 3]]\n>>> x[0]\n[\'a\', \'b\', \'c\']\n>>> x[0][1]\n\'b\'\n3.2 First Steps Towards Programming\nOf course, we can use Python for more complicated tasks than adding two and two together. For instance, we can\nwrite an initial sub-sequence of the Fibonacci series as follows:\n>>> # Fibonacci series:\n>>> # the sum of two elements defines the next\n>>> a, b = 0, 1\n>>> while a < 10:\n...\nprint(a)\n...\na, b = b, a+b\n...\n0\n1\n1\n2\n3\n5\n8\nThis example introduces several new features. • The first line contains a multiple assignment: the variables a and b simultaneously get the new values 0 and 1. On the last line this is used again, demonstrating that the expressions on the right-hand side are all evaluated\nfirst before any of the assignments take place. The right-hand side expressions are evaluated from the left to\nthe right. • The while loop executes as long as the condition (here: a < 10) remains true. In Python, like in C, any non-\nzero integer value is true; zero is false. The condition may also be a string or list value, in fact any sequence;\n14\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\nanything with a non-zero length is true, empty sequences are false. The test used in the example is a simple\ncomparison. The standard comparison operators are written the same as in C: < (less than), > (greater than),\n== (equal to), <= (less than or equal to), >= (greater than or equal to) and != (not equal to). • The body of the loop is indented: indentation is Python’s way of grouping statements. At the interactive prompt,\nyou have to type a tab or space(s) for each indented line. In practice you will prepare more complicated input\nfor Python with a text editor; all decent text editors have an auto-indent facility. When a compound statement\nis entered interactively, it must be followed by a blank line to indicate completion (since the parser cannot\nguess when you have typed the last line). Note that each line within a basic block must be indented by the\nsame amount. • The print() function writes the value of the argument(s) it is given. It differs from just writing the expression\nyou want to write (as we did earlier in the calculator examples) in the way it handles multiple arguments,\nfloating-point quantities, and strings. Strings are printed without quotes, and a space is inserted between items,\nso you can format things nicely, like this:\n>>> i = 256*256\n>>> print(\'The value of i is\', i)\nThe value of i is 65536\nThe keyword argument end can be used to avoid the newline after the output, or end the output with a different\nstring:\n>>> a, b = 0, 1\n>>> while a < 1000:\n...\nprint(a, end=\',\')\n...\na, b = b, a+b\n...\n0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,\n3.2. First Steps Towards Programming\n15\n\nPython Tutorial, Release 3.13.2\n16\nChapter 3. An Informal Introduction to Python\n\nCHAPTER\nFOUR\nMORE CONTROL FLOW TOOLS\nAs well as the while statement just introduced, Python uses a few more that we will encounter in this chapter. 4.1 if Statements\nPerhaps the most well-known statement type is the if statement. For example:\n>>> x = int(input(""Please enter an integer: ""))\nPlease enter an integer: 42\n>>> if x < 0:\n...\nx = 0\n...\nprint(\'Negative changed to zero\')\n... elif x == 0:\n...\nprint(\'Zero\')\n... elif x == 1:\n...\nprint(\'Single\')\n... else:\n...\nprint(\'More\')\n...\nMore\nThere can be zero or more elif parts, and the else part is optional. The keyword ‘elif’ is short for ‘else if’, and is\nuseful to avoid excessive indentation.\n\n[3] This makes sure that s[:i] + s[i:] is always\nequal to s:\n>>> word[:2] + word[2:]\n\'Python\'\n>>> word[:4] + word[4:]\n\'Python\'\nOne way to remember how slices work is to think of the indices as pointing between characters, with the left edge of\nthe first character numbered 0. Then the right edge of the last character of a string of n characters has index n, for\nexample:\n+---+---+---+---+---+---+\n| P | y | t | h | o | n |\n+---+---+---+---+---+---+\n0\n1\n2\n3\n4\n5\n6\n-6\n-5\n-4\n-3\n-2\n-1\nThe first row of numbers gives the position of the indices 0…6 in the string; the second row gives the corresponding\nnegative indices. The slice from i to j consists of all characters between the edges labeled i and j, respectively. For non-negative indices, the length of a slice is the difference of the indices, if both are within bounds. For example,\nthe length of word[1:3] is 2. Attempting to use an index that is too large will result in an error:\n>>> word[42]\n# the word only has 6 characters\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nIndexError: string index out of range\nHowever, out of range slice indexes are handled gracefully when used for slicing:\n3.1. Using Python as a Calculator\n11\n\nPython Tutorial, Release 3.13.2\n>>> word[4:42]\n\'on\'\n>>> word[42:]\n\'\'\nPython strings cannot be changed — they are immutable. Therefore, assigning to an indexed position in the string\nresults in an error:\n>>> word[0] = \'J\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\n>>> word[2:] = \'py\'\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'str\' object does not support item assignment\nIf you need a different string, you should create a new one:\n>>> \'J\' + word[1:]\n\'Jython\'\n>>> word[:2] + \'py\'\n\'Pypy\'\nThe built-in function len() returns the length of a string:\n>>> s = \'supercalifragilisticexpialidocious\'\n>>> len(s)\n34\nµ See also\ntextseq\nStrings are examples of sequence types, and support the common operations supported by such types. string-methods\nStrings support a large number of methods for basic transformations and searching. f-strings\nString literals that have embedded expressions. formatstrings\nInformation about string formatting with str.format(). old-string-formatting\nThe old formatting operations invoked when strings are the left operand of the % operator are described in\nmore detail here. 3.1.3 Lists\nPython knows a number of compound data types, used to group together other values. The most versatile is the list,\nwhich can be written as a list of comma-separated values (items) between square brackets. Lists might contain items\nof different types, but usually the items all have the same type. >>> squares = [1, 4, 9, 16, 25]\n>>> squares\n[1, 4, 9, 16, 25]\nLike strings (and all other built-in sequence types), lists can be indexed and sliced:\n12\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\n>>> squares[0]\n# indexing returns the item\n1\n>>> squares[-1]\n25\n>>> squares[-3:]\n# slicing returns a new list\n[9, 16, 25]\nLists also support operations like concatenation:\n>>> squares + [36, 49, 64, 81, 100]\n[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\nUnlike strings, which are immutable, lists are a mutable type, i.e. it is possible to change their content:\n>>> cubes = [1, 8, 27, 65, 125]\n# something\'s wrong here\n>>> 4 ** 3\n# the cube of 4 is 64, not 65! 64\n>>> cubes[3] = 64\n# replace the wrong value\n>>> cubes\n[1, 8, 27, 64, 125]\nYou can also add new items at the end of the list, by using the list.append() method (we will see more about\nmethods later):\n>>> cubes.append(216)\n# add the cube of 6\n>>> cubes.append(7 ** 3)\n# and the cube of 7\n>>> cubes\n[1, 8, 27, 64, 125, 216, 343]\nSimple assignment in Python never copies data. When you assign a list to a variable, the variable refers to the existing\nlist. Any changes you make to the list through one variable will be seen through all other variables that refer to it. :\n>>> rgb = [""Red"", ""Green"", ""Blue""]\n>>> rgba = rgb\n>>> id(rgb) == id(rgba)\n# they reference the same object\nTrue\n>>> rgba.append(""Alph"")\n>>> rgb\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAll slice operations return a new list containing the requested elements. This means that the following slice returns a\nshallow copy of the list:\n>>> correct_rgba = rgba[:]\n>>> correct_rgba[-1] = ""Alpha""\n>>> correct_rgba\n[""Red"", ""Green"", ""Blue"", ""Alpha""]\n>>> rgba\n[""Red"", ""Green"", ""Blue"", ""Alph""]\nAssignment to slices is also possible, and this can even change the size of the list or clear it entirely:\n>>> letters = [\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> letters\n[\'a\', \'b\', \'c\', \'d\', \'e\', \'f\', \'g\']\n>>> # replace some values\n>>> letters[2:5] = [\'C\', \'D\', \'E\']\n>>> letters\n(continues on next page)\n3.1. Using Python as a Calculator\n13\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n[\'a\', \'b\', \'C\', \'D\', \'E\', \'f\', \'g\']\n>>> # now remove them\n>>> letters[2:5] = []\n>>> letters\n[\'a\', \'b\', \'f\', \'g\']\n>>> # clear the list by replacing all the elements with an empty list\n>>> letters[:] = []\n>>> letters\n[]\nThe built-in function len() also applies to lists:\n>>> letters = [\'a\', \'b\', \'c\', \'d\']\n>>> len(letters)\n4\nIt is possible to nest lists (create lists containing other lists), for example:\n>>> a = [\'a\', \'b\', \'c\']\n>>> n = [1, 2, 3]\n>>> x = [a, n]\n>>> x\n[[\'a\', \'b\', \'c\'], [1, 2, 3]]\n>>> x[0]\n[\'a\', \'b\', \'c\']\n>>> x[0][1]\n\'b\'\n3.2 First Steps Towards Programming\nOf course, we can use Python for more complicated tasks than adding two and two together. For instance, we can\nwrite an initial sub-sequence of the Fibonacci series as follows:\n>>> # Fibonacci series:\n>>> # the sum of two elements defines the next\n>>> a, b = 0, 1\n>>> while a < 10:\n...\nprint(a)\n...\na, b = b, a+b\n...\n0\n1\n1\n2\n3\n5\n8\nThis example introduces several new features. • The first line contains a multiple assignment: the variables a and b simultaneously get the new values 0 and 1. On the last line this is used again, demonstrating that the expressions on the right-hand side are all evaluated\nfirst before any of the assignments take place. The right-hand side expressions are evaluated from the left to\nthe right. • The while loop executes as long as the condition (here: a < 10) remains true. In Python, like in C, any non-\nzero integer value is true; zero is false. The condition may also be a string or list value, in fact any sequence;\n14\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\nanything with a non-zero length is true, empty sequences are false. The test used in the example is a simple\ncomparison. The standard comparison operators are written the same as in C: < (less than), > (greater than),\n== (equal to), <= (less than or equal to), >= (greater than or equal to) and != (not equal to). • The body of the loop is indented: indentation is Python’s way of grouping statements. At the interactive prompt,\nyou have to type a tab or space(s) for each indented line. In practice you will prepare more complicated input\nfor Python with a text editor; all decent text editors have an auto-indent facility. When a compound statement\nis entered interactively, it must be followed by a blank line to indicate completion (since the parser cannot\nguess when you have typed the last line). Note that each line within a basic block must be indented by the\nsame amount. • The print() function writes the value of the argument(s) it is given. It differs from just writing the expression\nyou want to write (as we did earlier in the calculator examples) in the way it handles multiple arguments,\nfloating-point quantities, and strings. Strings are printed without quotes, and a space is inserted between items,\nso you can format things nicely, like this:\n>>> i = 256*256\n>>> print(\'The value of i is\', i)\nThe value of i is 65536\nThe keyword argument end can be used to avoid the newline after the output, or end the output with a different\nstring:\n>>> a, b = 0, 1\n>>> while a < 1000:\n...\nprint(a, end=\',\')\n...\na, b = b, a+b\n...\n0,1,1,2,3,5,8,13,21,34,55,89,144,233,377,610,987,\n3.2. First Steps Towards Programming\n15\n\nPython Tutorial, Release 3.13.2\n16\nChapter 3. An Informal Introduction to Python\n\nCHAPTER\nFOUR\nMORE CONTROL FLOW TOOLS\nAs well as the while statement just introduced, Python uses a few more that we will encounter in this chapter. 4.1 if Statements\nPerhaps the most well-known statement type is the if statement. For example:\n>>> x = int(input(""Please enter an integer: ""))\nPlease enter an integer: 42\n>>> if x < 0:\n...\nx = 0\n...\nprint(\'Negative changed to zero\')\n... elif x == 0:\n...\nprint(\'Zero\')\n... elif x == 1:\n...\nprint(\'Single\')\n... else:\n...\nprint(\'More\')\n...\nMore\nThere can be zero or more elif parts, and the else part is optional. The keyword ‘elif’ is short for ‘else if’, and is\nuseful to avoid excessive indentation. An if … elif … elif … sequence is a substitute for the switch or case\nstatements found in other languages. If you’re comparing the same value to several constants, or checking for specific types or attributes, you may also\nfind the match statement useful. For more details see match Statements. 4.2 for Statements\nThe for statement in Python differs a bit from what you may be used to in C or Pascal.')",0.0034687979493771147,0.05517723066177754,0.1768475366178429,0.5664575695991516,0.4272905
How to find the index for a given item in a list?,">>> [""foo"", ""bar"", ""baz""].index(""bar"")
1



See 
the documentation
 for the built-in 
.index()
 method of the list:




list.index(x[, start[, end]])



Return zero-based index in the list of the first item whose value is equal to 
x
. Raises a 
ValueError
 if there is no such item.


The optional arguments 
start
 and 
end
 are interpreted as in the 
slice notation
 and are used to limit the search to a particular subsequence of the list. The returned index is computed relative to the beginning of the full sequence rather than the start argument.




Caveats


Linear time-complexity in list length


An 
index
 call checks every element of the list in order, until it finds a match. If the list is long, and if there is no guarantee that the value will be near the beginning, this can slow down the code.


This problem can only be completely avoided by using a different data structure. However, if the element is known to be within a certain part of the list, the 
start
 and 
end
 parameters can be used to narrow the search.


For example:


>>> import timeit
>>> timeit.timeit('l.index(999_999)', setup='l = list(range(0, 1_000_000))', number=1000)
9.356267921015387
>>> timeit.timeit('l.index(999_999, 999_990, 1_000_000)', setup='l = list(range(0, 1_000_000))', number=1000)
0.0004404920036904514



The second call is orders of magnitude faster, because it only has to search through 10 elements, rather than all 1 million.


Only the index of the 
first match
 is returned


A call to 
index
 searches through the list in order until it finds a match, and 
stops there.
 If there could be more than one occurrence of the value, and all indices are needed, 
index
 cannot solve the problem:


>>> [1, 1].index(1) # the `1` index is not found.
0



Instead, use a 
list comprehension or generator expression to do the search
, with 
enumerate
 to get indices
:


>>> # A list comprehension gives a list of indices directly:
>>> [i for i, e in enumerate([1, 2, 1]) if e == 1]
[0, 2]
>>> # A generator comprehension gives us an iterable object...
>>> g = (i for i, e in enumerate([1, 2, 1]) if e == 1)
>>> # which can be used in a `for` loop, or manually iterated with `next`:
>>> next(g)
0
>>> next(g)
2



The list comprehension and generator expression techniques still work if there is only one match, and are more generalizable.


Raises an exception if there is no match


As noted in the documentation above, using 
.index
 will raise an exception if the searched-for value is not in the list:


>>> [1, 1].index(2)
Traceback (most recent call last):
  File ""
"", line 1, in 

ValueError: 2 is not in list



If this is a concern, either 
explicitly check first
 using 
item in my_list
, or handle the exception with 
try
/
except
 as appropriate.


The explicit check is simple and readable, but it must iterate the list a second time. See 
What is the EAFP principle in Python?
 for more guidance on this choice.

","('Answer: The `list.index(x)` method returns the zero-based index of the first item in the list whose value is equal to x. If the item is not found, it raises a ValueError. You can also specify optional start and end arguments to limit the search to a subsequence of the list.\n\nReferences: [1]\n', '[1] list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression).\n\n[2] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",0.05585480810068036,0.16245627671978236,0.3328100775043926,0.654495358467102,0.78558666
Iterating over dictionaries using 'for' loops,"key
 is just a variable name.  


for key in d:



will simply loop over the keys in the dictionary, rather than the keys and values.  To loop over both key and value you can use the following:


For Python 3.x:


for key, value in d.items():



For Python 2.x:


for key, value in d.iteritems():



To test for yourself, change the word 
key
 to 
poop
.


In Python 3.x, 
iteritems()
 was replaced with simply 
items()
, which returns a set-like view backed by the dict, like 
iteritems()
 but even better. 
This is also available in 2.7 as 
viewitems()
. 


The operation 
items()
 will work for both 2 and 3, but in 2 it will return a list of the dictionary's 
(key, value)
 pairs, which will not reflect changes to the dict that happen after the 
items()
 call. If you want the 2.x behavior in 3.x, you can call 
list(d.items())
.

","('Answer: When looping through dictionaries, you can retrieve both the key and its corresponding value simultaneously by using the items() method in the for loop.\n\nReferences: [3]\n', ""[1] . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.4\nbreak and continue Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.5\nelse Clauses on Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.6\npass Statements . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n8.4.4\ndefaultdict objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n8.4.5\nnamedtuple() Factory Function for Tuples with Named Fields\n. . . . . . . . . . . . . 264\n8.4.6\nOrderedDict objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267\n8.4.7\nUserDict objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n8.4.8\nUserList objects . . . . . . . . . . . .\n\n[3] Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for\nstrings uses the Unicode code point number to order individual characters."")",4.6645860099544966e-79,0.07049459920409323,0.19548222490574932,0.5008640289306641,0.55070376
How can I iterate over rows in a Pandas DataFrame?,"DataFrame.iterrows
 is a generator which yields both the index and row (as a Series):


import pandas as pd

df = pd.DataFrame({'c1': [10, 11, 12], 'c2': [100, 110, 120]})
df = df.reset_index()  # make sure indexes pair with number of rows

for index, row in df.iterrows():
    print(row['c1'], row['c2'])



10 100
11 110
12 120





Obligatory disclaimer from the 
documentation




Iterating through pandas objects is generally 
slow
. In many cases, iterating manually over the rows is not needed and can be avoided with one of the following approaches:




Look for a 
vectorized
 solution: many operations can be performed using built-in methods or NumPy functions, (boolean) indexing, …


When you have a function that cannot work on the full DataFrame/Series at once, it is better to use 
apply()
 instead of iterating over the values. See the docs on 
function application
.


If you need to do iterative manipulations on the values but performance is important, consider writing the inner loop with cython or numba. See the 
enhancing performance
 section for some examples of this approach.






Other answers in this thread delve into greater depth on alternatives to iter* functions if you are interested to learn more.

","(""I'm sorry, I couldn't find relevant information in the provided context."", ""[1] filter(predicate, iter) returns an iterator over all the sequence elements that meet a certain condition, and is\nsimilarly duplicated by list comprehensions. A predicate is a function that returns the truth value of some condition;\nfor use with filter(), the predicate must take a single value. >>> def is_even(x):\n...\nreturn (x % 2) == 0\n>>> list(filter(is_even, range(10)))\n[0, 2, 4, 6, 8]\nThis can also be written as a list comprehension:\n>>> list(x for x in range(10) if is_even(x))\n[0, 2, 4, 6, 8]\nenumerate(iter, start=0) counts off the elements in the iterable returning 2-tuples containing the count (from\nstart) and each element. >>> for item in enumerate(['subject', 'verb', 'object']):\n...\nprint(item)\n(0, 'subject')\n(1, 'verb')\n(2, 'object')\nenumerate() is often used when looping through a list and recording the indexes at which certain conditions are\nmet:\nf = open('data.txt', 'r')\nfor i, line in enumerate(f):\nif line.strip() == '':\nprint('Blank line at line #%i' % i)\nsorted(iterable, key=None, reverse=False) collects all the elements of the iterable into a list, sorts the\nlist, and returns the sorted result. The key and reverse arguments are passed through to the constructed list’s sort()\nmethod. 10\n\n>>> import random\n>>> # Generate 8 random numbers between [0, 10000)\n>>> rand_list = random.sample(range(10000), 8)\n>>> rand_list\n[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]\n>>> sorted(rand_list)\n[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]\n>>> sorted(rand_list, reverse=True)\n[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]\n(For a more detailed discussion of sorting, see the sortinghowto.) The any(iter) and all(iter) built-ins look at the truth values of an iterable’s contents. any() returns True if\nany element in the iterable is a true value, and all() returns True if all of the elements are true values:\n>>> any([0, 1, 0])\nTrue\n>>> any([0, 0, 0])\nFalse\n>>> any([1, 1, 1])\nTrue\n>>> all([0, 1, 0])\nFalse\n>>> all([0, 0, 0])\nFalse\n>>> all([1, 1, 1])\nTrue\nzip(iterA, iterB, ...) takes one element from each iterable and returns them in a tuple:\nzip(['a', 'b', 'c'], (1, 2, 3)) =>\n('a', 1), ('b', 2), ('c', 3)\nIt doesn’t construct an in-memory list and exhaust all the input iterators before returning; instead tuples are constructed\nand returned only if they’re requested. (The technical term for this behaviour is lazy evaluation.) This iterator is intended to be used with iterables that are all of the same length. If the iterables are of different\nlengths, the resulting stream will be the same length as the shortest iterable. zip(['a', 'b'], (1, 2, 3)) =>\n('a', 1), ('b', 2)\nYou should avoid doing this, though, because an element may be taken from the longer iterators and discarded. This\nmeans you can’t go on to use the iterators further because you risk skipping a discarded element. 6 The itertools module\nThe itertools module contains a number of commonly used iterators as well as functions for combining several\niterators. This section will introduce the module’s contents by showing small examples. The module’s functions fall into a few broad classes:\n• Functions that create a new iterator based on an existing iterator. • Functions for treating an iterator’s elements as function arguments. • Functions for selecting portions of an iterator’s output. • A function for grouping an iterator’s output. 11\n\n6.1 Creating new iterators\nitertools.count(start, step) returns an infinite stream of evenly spaced values. You can optionally supply\nthe starting number, which defaults to 0, and the interval between numbers, which defaults to 1:\nitertools.count() =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nitertools.count(10) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.count(10, 5) =>\n10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ...\nitertools.cycle(iter) saves a copy of the contents of a provided iterable and returns a new iterator that returns\nits elements from first to last. The new iterator will repeat these elements infinitely. itertools.cycle([1, 2, 3, 4, 5]) =>\n1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...\nitertools.repeat(elem, [n]) returns the provided element n times, or returns the element endlessly if n is\nnot provided. itertools.repeat('abc') =>\nabc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...\nitertools.repeat('abc', 5) =>\nabc, abc, abc, abc, abc\nitertools.chain(iterA, iterB, ...) takes an arbitrary number of iterables as input, and returns all the\nelements of the first iterator, then all the elements of the second, and so on, until all of the iterables have been\nexhausted. itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>\na, b, c, 1, 2, 3\nitertools.islice(iter, [start], stop, [step]) returns a stream that’s a slice of the iterator. With a\nsingle stop argument, it will return the first stop elements. If you supply a starting index, you’ll get stop-start elements,\nand if you supply a value for step, elements will be skipped accordingly. Unlike Python’s string and list slicing, you\ncan’t use negative values for start, stop, or step. itertools.islice(range(10), 8) =>\n0, 1, 2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8) =>\n2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8, 2) =>\n2, 4, 6\nitertools.tee(iter, [n]) replicates an iterator; it returns n independent iterators that will all return the con-\ntents of the source iterator. If you don’t supply a value for n, the default is 2. Replicating iterators requires saving\nsome of the contents of the source iterator, so this can consume significant memory if the iterator is large and one\nof the new iterators is consumed more than the others. itertools.tee( itertools.count() ) =>\niterA, iterB\nwhere iterA ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nand\niterB ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\n12\n\n6.2 Calling functions on elements\nThe operator module contains a set of functions corresponding to Python’s operators. Some examples\nare operator.add(a, b) (adds two values), operator.ne(a, b) (same as a != b), and operator. attrgetter('id') (returns a callable that fetches the .id attribute). itertools.starmap(func, iter) assumes that the iterable will return a stream of tuples, and calls func using\nthese tuples as the arguments:\nitertools.starmap(os.path.join,\n[('/bin', 'python'), ('/usr', 'bin', 'java'),\n('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby\n6.3 Selecting elements\nAnother group of functions chooses a subset of an iterator’s elements based on a predicate. itertools.filterfalse(predicate, iter) is the opposite of filter(), returning all elements for which\nthe predicate returns false:\nitertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ...\nitertools.takewhile(predicate, iter) returns elements for as long as the predicate returns true. Once the\npredicate returns false, the iterator will signal the end of its results. def less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0\nitertools.dropwhile(predicate, iter) discards elements while the predicate returns true, and then returns\nthe rest of the iterable’s results. itertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\nitertools.compress(data, selectors) takes two iterators and returns only those elements of data for which\nthe corresponding element of selectors is true, stopping whenever either one is exhausted:\nitertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5\n6.4 Combinatoric functions\nThe itertools.combinations(iterable, r) returns an iterator giving all possible r-tuple combinations of\nthe elements contained in iterable. itertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(continues on next page)\n13\n\n(continued from previous page)\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5)\nThe elements within each tuple remain in the same order as iterable returned them. For example, the number 1 is\nalways before 2, 3, 4, or 5 in the examples above. A similar function, itertools.permutations(iterable,\nr=None), removes this constraint on the order, returning all possible arrangements of length r:\nitertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),\n...\n(5, 4, 3, 2, 1)\nIf you don’t supply a value for r the length of the iterable is used, meaning that all the elements are permuted. Note that these functions produce all of the possible combinations by position and don’t require that the contents of\niterable are unique:\nitertools.permutations('aba', 3) =>\n('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),\n('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a')\nThe identical tuple ('a', 'a', 'b') occurs twice, but the two ‘a’ strings came from different positions. The itertools.combinations_with_replacement(iterable, r) function relaxes a different constraint:\nelements can be repeated within a single tuple. Conceptually an element is selected for the first position of each tuple\nand then is replaced before the second element is selected. itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5)\n6.5 Grouping elements\nThe last function I’ll discuss, itertools.groupby(iter, key_func=None), is the most complicated. key_func(elem) is a function that can compute a key value for each element returned by the iterable. If you\ndon’t supply a key function, the key is simply each element itself. groupby() collects all the consecutive elements from the underlying iterable that have the same key value, and\nreturns a stream of 2-tuples containing a key value and an iterator for the elements with that key. city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),\n('Anchorage', 'AK'), ('Nome', 'AK'),\n(continues on next page)\n14\n\n(continued from previous page)\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n('AL', iterator-1),\n('AK', iterator-2),\n('AZ', iterator-3), ...\nwhere\niterator-1 =>\n('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')\niterator-2 =>\n('Anchorage', 'AK'), ('Nome', 'AK')\niterator-3 =>\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')\ngroupby() assumes that the underlying iterable’s contents will already be sorted based on the key. Note that the\nreturned iterators also use the underlying iterable, so you have to consume the results of iterator-1 before requesting\niterator-2 and its corresponding key.\n\n[2] >>> def is_even(x):\n...\nreturn (x % 2) == 0\n>>> list(filter(is_even, range(10)))\n[0, 2, 4, 6, 8]\nThis can also be written as a list comprehension:\n>>> list(x for x in range(10) if is_even(x))\n[0, 2, 4, 6, 8]\nenumerate(iter, start=0) counts off the elements in the iterable returning 2-tuples containing the count (from\nstart) and each element. >>> for item in enumerate(['subject', 'verb', 'object']):\n...\nprint(item)\n(0, 'subject')\n(1, 'verb')\n(2, 'object')\nenumerate() is often used when looping through a list and recording the indexes at which certain conditions are\nmet:\nf = open('data.txt', 'r')\nfor i, line in enumerate(f):\nif line.strip() == '':\nprint('Blank line at line #%i' % i)\nsorted(iterable, key=None, reverse=False) collects all the elements of the iterable into a list, sorts the\nlist, and returns the sorted result. The key and reverse arguments are passed through to the constructed list’s sort()\nmethod. 10\n\n>>> import random\n>>> # Generate 8 random numbers between [0, 10000)\n>>> rand_list = random.sample(range(10000), 8)\n>>> rand_list\n[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]\n>>> sorted(rand_list)\n[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]\n>>> sorted(rand_list, reverse=True)\n[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]\n(For a more detailed discussion of sorting, see the sortinghowto.) The any(iter) and all(iter) built-ins look at the truth values of an iterable’s contents. any() returns True if\nany element in the iterable is a true value, and all() returns True if all of the elements are true values:\n>>> any([0, 1, 0])\nTrue\n>>> any([0, 0, 0])\nFalse\n>>> any([1, 1, 1])\nTrue\n>>> all([0, 1, 0])\nFalse\n>>> all([0, 0, 0])\nFalse\n>>> all([1, 1, 1])\nTrue\nzip(iterA, iterB, ...) takes one element from each iterable and returns them in a tuple:\nzip(['a', 'b', 'c'], (1, 2, 3)) =>\n('a', 1), ('b', 2), ('c', 3)\nIt doesn’t construct an in-memory list and exhaust all the input iterators before returning; instead tuples are constructed\nand returned only if they’re requested. (The technical term for this behaviour is lazy evaluation.) This iterator is intended to be used with iterables that are all of the same length. If the iterables are of different\nlengths, the resulting stream will be the same length as the shortest iterable. zip(['a', 'b'], (1, 2, 3)) =>\n('a', 1), ('b', 2)\nYou should avoid doing this, though, because an element may be taken from the longer iterators and discarded. This\nmeans you can’t go on to use the iterators further because you risk skipping a discarded element. 6 The itertools module\nThe itertools module contains a number of commonly used iterators as well as functions for combining several\niterators. This section will introduce the module’s contents by showing small examples. The module’s functions fall into a few broad classes:\n• Functions that create a new iterator based on an existing iterator. • Functions for treating an iterator’s elements as function arguments. • Functions for selecting portions of an iterator’s output. • A function for grouping an iterator’s output. 11\n\n6.1 Creating new iterators\nitertools.count(start, step) returns an infinite stream of evenly spaced values. You can optionally supply\nthe starting number, which defaults to 0, and the interval between numbers, which defaults to 1:\nitertools.count() =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nitertools.count(10) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.count(10, 5) =>\n10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ...\nitertools.cycle(iter) saves a copy of the contents of a provided iterable and returns a new iterator that returns\nits elements from first to last. The new iterator will repeat these elements infinitely. itertools.cycle([1, 2, 3, 4, 5]) =>\n1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...\nitertools.repeat(elem, [n]) returns the provided element n times, or returns the element endlessly if n is\nnot provided. itertools.repeat('abc') =>\nabc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...\nitertools.repeat('abc', 5) =>\nabc, abc, abc, abc, abc\nitertools.chain(iterA, iterB, ...) takes an arbitrary number of iterables as input, and returns all the\nelements of the first iterator, then all the elements of the second, and so on, until all of the iterables have been\nexhausted. itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>\na, b, c, 1, 2, 3\nitertools.islice(iter, [start], stop, [step]) returns a stream that’s a slice of the iterator. With a\nsingle stop argument, it will return the first stop elements. If you supply a starting index, you’ll get stop-start elements,\nand if you supply a value for step, elements will be skipped accordingly. Unlike Python’s string and list slicing, you\ncan’t use negative values for start, stop, or step. itertools.islice(range(10), 8) =>\n0, 1, 2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8) =>\n2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8, 2) =>\n2, 4, 6\nitertools.tee(iter, [n]) replicates an iterator; it returns n independent iterators that will all return the con-\ntents of the source iterator. If you don’t supply a value for n, the default is 2. Replicating iterators requires saving\nsome of the contents of the source iterator, so this can consume significant memory if the iterator is large and one\nof the new iterators is consumed more than the others. itertools.tee( itertools.count() ) =>\niterA, iterB\nwhere iterA ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nand\niterB ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\n12\n\n6.2 Calling functions on elements\nThe operator module contains a set of functions corresponding to Python’s operators. Some examples\nare operator.add(a, b) (adds two values), operator.ne(a, b) (same as a != b), and operator. attrgetter('id') (returns a callable that fetches the .id attribute). itertools.starmap(func, iter) assumes that the iterable will return a stream of tuples, and calls func using\nthese tuples as the arguments:\nitertools.starmap(os.path.join,\n[('/bin', 'python'), ('/usr', 'bin', 'java'),\n('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby\n6.3 Selecting elements\nAnother group of functions chooses a subset of an iterator’s elements based on a predicate. itertools.filterfalse(predicate, iter) is the opposite of filter(), returning all elements for which\nthe predicate returns false:\nitertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ...\nitertools.takewhile(predicate, iter) returns elements for as long as the predicate returns true. Once the\npredicate returns false, the iterator will signal the end of its results. def less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0\nitertools.dropwhile(predicate, iter) discards elements while the predicate returns true, and then returns\nthe rest of the iterable’s results. itertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\nitertools.compress(data, selectors) takes two iterators and returns only those elements of data for which\nthe corresponding element of selectors is true, stopping whenever either one is exhausted:\nitertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5\n6.4 Combinatoric functions\nThe itertools.combinations(iterable, r) returns an iterator giving all possible r-tuple combinations of\nthe elements contained in iterable. itertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(continues on next page)\n13\n\n(continued from previous page)\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5)\nThe elements within each tuple remain in the same order as iterable returned them. For example, the number 1 is\nalways before 2, 3, 4, or 5 in the examples above. A similar function, itertools.permutations(iterable,\nr=None), removes this constraint on the order, returning all possible arrangements of length r:\nitertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),\n...\n(5, 4, 3, 2, 1)\nIf you don’t supply a value for r the length of the iterable is used, meaning that all the elements are permuted. Note that these functions produce all of the possible combinations by position and don’t require that the contents of\niterable are unique:\nitertools.permutations('aba', 3) =>\n('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),\n('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a')\nThe identical tuple ('a', 'a', 'b') occurs twice, but the two ‘a’ strings came from different positions. The itertools.combinations_with_replacement(iterable, r) function relaxes a different constraint:\nelements can be repeated within a single tuple. Conceptually an element is selected for the first position of each tuple\nand then is replaced before the second element is selected. itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5)\n6.5 Grouping elements\nThe last function I’ll discuss, itertools.groupby(iter, key_func=None), is the most complicated. key_func(elem) is a function that can compute a key value for each element returned by the iterable. If you\ndon’t supply a key function, the key is simply each element itself. groupby() collects all the consecutive elements from the underlying iterable that have the same key value, and\nreturns a stream of 2-tuples containing a key value and an iterator for the elements with that key. city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),\n('Anchorage', 'AK'), ('Nome', 'AK'),\n(continues on next page)\n14\n\n(continued from previous page)\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n('AL', iterator-1),\n('AK', iterator-2),\n('AZ', iterator-3), ...\nwhere\niterator-1 =>\n('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')\niterator-2 =>\n('Anchorage', 'AK'), ('Nome', 'AK')\niterator-3 =>\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')\ngroupby() assumes that the underlying iterable’s contents will already be sorted based on the key. Note that the\nreturned iterators also use the underlying iterable, so you have to consume the results of iterator-1 before requesting\niterator-2 and its corresponding key. 7 The functools module\nThe functools module contains some higher-order functions. A higher-order function takes one or more func-\ntions as input and returns a new function.\n\n[3] A predicate is a function that returns the truth value of some condition;\nfor use with filter(), the predicate must take a single value. >>> def is_even(x):\n...\nreturn (x % 2) == 0\n>>> list(filter(is_even, range(10)))\n[0, 2, 4, 6, 8]\nThis can also be written as a list comprehension:\n>>> list(x for x in range(10) if is_even(x))\n[0, 2, 4, 6, 8]\nenumerate(iter, start=0) counts off the elements in the iterable returning 2-tuples containing the count (from\nstart) and each element. >>> for item in enumerate(['subject', 'verb', 'object']):\n...\nprint(item)\n(0, 'subject')\n(1, 'verb')\n(2, 'object')\nenumerate() is often used when looping through a list and recording the indexes at which certain conditions are\nmet:\nf = open('data.txt', 'r')\nfor i, line in enumerate(f):\nif line.strip() == '':\nprint('Blank line at line #%i' % i)\nsorted(iterable, key=None, reverse=False) collects all the elements of the iterable into a list, sorts the\nlist, and returns the sorted result. The key and reverse arguments are passed through to the constructed list’s sort()\nmethod. 10\n\n>>> import random\n>>> # Generate 8 random numbers between [0, 10000)\n>>> rand_list = random.sample(range(10000), 8)\n>>> rand_list\n[769, 7953, 9828, 6431, 8442, 9878, 6213, 2207]\n>>> sorted(rand_list)\n[769, 2207, 6213, 6431, 7953, 8442, 9828, 9878]\n>>> sorted(rand_list, reverse=True)\n[9878, 9828, 8442, 7953, 6431, 6213, 2207, 769]\n(For a more detailed discussion of sorting, see the sortinghowto.) The any(iter) and all(iter) built-ins look at the truth values of an iterable’s contents. any() returns True if\nany element in the iterable is a true value, and all() returns True if all of the elements are true values:\n>>> any([0, 1, 0])\nTrue\n>>> any([0, 0, 0])\nFalse\n>>> any([1, 1, 1])\nTrue\n>>> all([0, 1, 0])\nFalse\n>>> all([0, 0, 0])\nFalse\n>>> all([1, 1, 1])\nTrue\nzip(iterA, iterB, ...) takes one element from each iterable and returns them in a tuple:\nzip(['a', 'b', 'c'], (1, 2, 3)) =>\n('a', 1), ('b', 2), ('c', 3)\nIt doesn’t construct an in-memory list and exhaust all the input iterators before returning; instead tuples are constructed\nand returned only if they’re requested. (The technical term for this behaviour is lazy evaluation.) This iterator is intended to be used with iterables that are all of the same length. If the iterables are of different\nlengths, the resulting stream will be the same length as the shortest iterable. zip(['a', 'b'], (1, 2, 3)) =>\n('a', 1), ('b', 2)\nYou should avoid doing this, though, because an element may be taken from the longer iterators and discarded. This\nmeans you can’t go on to use the iterators further because you risk skipping a discarded element. 6 The itertools module\nThe itertools module contains a number of commonly used iterators as well as functions for combining several\niterators. This section will introduce the module’s contents by showing small examples. The module’s functions fall into a few broad classes:\n• Functions that create a new iterator based on an existing iterator. • Functions for treating an iterator’s elements as function arguments. • Functions for selecting portions of an iterator’s output. • A function for grouping an iterator’s output. 11\n\n6.1 Creating new iterators\nitertools.count(start, step) returns an infinite stream of evenly spaced values. You can optionally supply\nthe starting number, which defaults to 0, and the interval between numbers, which defaults to 1:\nitertools.count() =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nitertools.count(10) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.count(10, 5) =>\n10, 15, 20, 25, 30, 35, 40, 45, 50, 55, ...\nitertools.cycle(iter) saves a copy of the contents of a provided iterable and returns a new iterator that returns\nits elements from first to last. The new iterator will repeat these elements infinitely. itertools.cycle([1, 2, 3, 4, 5]) =>\n1, 2, 3, 4, 5, 1, 2, 3, 4, 5, ...\nitertools.repeat(elem, [n]) returns the provided element n times, or returns the element endlessly if n is\nnot provided. itertools.repeat('abc') =>\nabc, abc, abc, abc, abc, abc, abc, abc, abc, abc, ...\nitertools.repeat('abc', 5) =>\nabc, abc, abc, abc, abc\nitertools.chain(iterA, iterB, ...) takes an arbitrary number of iterables as input, and returns all the\nelements of the first iterator, then all the elements of the second, and so on, until all of the iterables have been\nexhausted. itertools.chain(['a', 'b', 'c'], (1, 2, 3)) =>\na, b, c, 1, 2, 3\nitertools.islice(iter, [start], stop, [step]) returns a stream that’s a slice of the iterator. With a\nsingle stop argument, it will return the first stop elements. If you supply a starting index, you’ll get stop-start elements,\nand if you supply a value for step, elements will be skipped accordingly. Unlike Python’s string and list slicing, you\ncan’t use negative values for start, stop, or step. itertools.islice(range(10), 8) =>\n0, 1, 2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8) =>\n2, 3, 4, 5, 6, 7\nitertools.islice(range(10), 2, 8, 2) =>\n2, 4, 6\nitertools.tee(iter, [n]) replicates an iterator; it returns n independent iterators that will all return the con-\ntents of the source iterator. If you don’t supply a value for n, the default is 2. Replicating iterators requires saving\nsome of the contents of the source iterator, so this can consume significant memory if the iterator is large and one\nof the new iterators is consumed more than the others. itertools.tee( itertools.count() ) =>\niterA, iterB\nwhere iterA ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\nand\niterB ->\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, ...\n12\n\n6.2 Calling functions on elements\nThe operator module contains a set of functions corresponding to Python’s operators. Some examples\nare operator.add(a, b) (adds two values), operator.ne(a, b) (same as a != b), and operator. attrgetter('id') (returns a callable that fetches the .id attribute). itertools.starmap(func, iter) assumes that the iterable will return a stream of tuples, and calls func using\nthese tuples as the arguments:\nitertools.starmap(os.path.join,\n[('/bin', 'python'), ('/usr', 'bin', 'java'),\n('/usr', 'bin', 'perl'), ('/usr', 'bin', 'ruby')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby\n6.3 Selecting elements\nAnother group of functions chooses a subset of an iterator’s elements based on a predicate. itertools.filterfalse(predicate, iter) is the opposite of filter(), returning all elements for which\nthe predicate returns false:\nitertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ...\nitertools.takewhile(predicate, iter) returns elements for as long as the predicate returns true. Once the\npredicate returns false, the iterator will signal the end of its results. def less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0\nitertools.dropwhile(predicate, iter) discards elements while the predicate returns true, and then returns\nthe rest of the iterable’s results. itertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\nitertools.compress(data, selectors) takes two iterators and returns only those elements of data for which\nthe corresponding element of selectors is true, stopping whenever either one is exhausted:\nitertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5\n6.4 Combinatoric functions\nThe itertools.combinations(iterable, r) returns an iterator giving all possible r-tuple combinations of\nthe elements contained in iterable. itertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(continues on next page)\n13\n\n(continued from previous page)\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5)\nThe elements within each tuple remain in the same order as iterable returned them. For example, the number 1 is\nalways before 2, 3, 4, or 5 in the examples above. A similar function, itertools.permutations(iterable,\nr=None), removes this constraint on the order, returning all possible arrangements of length r:\nitertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),\n...\n(5, 4, 3, 2, 1)\nIf you don’t supply a value for r the length of the iterable is used, meaning that all the elements are permuted. Note that these functions produce all of the possible combinations by position and don’t require that the contents of\niterable are unique:\nitertools.permutations('aba', 3) =>\n('a', 'b', 'a'), ('a', 'a', 'b'), ('b', 'a', 'a'),\n('b', 'a', 'a'), ('a', 'a', 'b'), ('a', 'b', 'a')\nThe identical tuple ('a', 'a', 'b') occurs twice, but the two ‘a’ strings came from different positions. The itertools.combinations_with_replacement(iterable, r) function relaxes a different constraint:\nelements can be repeated within a single tuple. Conceptually an element is selected for the first position of each tuple\nand then is replaced before the second element is selected. itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5)\n6.5 Grouping elements\nThe last function I’ll discuss, itertools.groupby(iter, key_func=None), is the most complicated. key_func(elem) is a function that can compute a key value for each element returned by the iterable. If you\ndon’t supply a key function, the key is simply each element itself. groupby() collects all the consecutive elements from the underlying iterable that have the same key value, and\nreturns a stream of 2-tuples containing a key value and an iterator for the elements with that key. city_list = [('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL'),\n('Anchorage', 'AK'), ('Nome', 'AK'),\n(continues on next page)\n14\n\n(continued from previous page)\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n('AL', iterator-1),\n('AK', iterator-2),\n('AZ', iterator-3), ...\nwhere\niterator-1 =>\n('Decatur', 'AL'), ('Huntsville', 'AL'), ('Selma', 'AL')\niterator-2 =>\n('Anchorage', 'AK'), ('Nome', 'AK')\niterator-3 =>\n('Flagstaff', 'AZ'), ('Phoenix', 'AZ'), ('Tucson', 'AZ')\ngroupby() assumes that the underlying iterable’s contents will already be sorted based on the key. Note that the\nreturned iterators also use the underlying iterable, so you have to consume the results of iterator-1 before requesting\niterator-2 and its corresponding key. 7 The functools module\nThe functools module contains some higher-order functions."")",1.2594976245683791e-79,0.025737090731389477,0.07783259612112964,0.554298460483551,0.36966532
How can I use a global variable in a function?,"You can use a global variable within other functions by declaring it as 
global
 
within each function that assigns a value to it
:


globvar = 0

def set_globvar_to_one():
    global globvar    # Needed to modify global copy of globvar
    globvar = 1

def print_globvar():
    print(globvar)     # No need for global declaration to read value of globvar

set_globvar_to_one()
print_globvar()       # Prints 1



Since it's unclear whether 
globvar = 1
 is creating a local variable or changing a global variable, Python defaults to creating a local variable, and makes you explicitly choose the other behavior with the 
global
 keyword.


See other answers if you want to share a global variable across modules.

","(""Answer: To access a global variable within a function, you need to declare it using the `global` keyword inside the function before using it. This tells Python that you're referring to the variable in the outer scope, not creating a new local variable.\n\nReferences: [1]\n"", ""[1] Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nIn the example above you can access the outer scope variable by declaring it global:\n>>> x = 10\n>>> def foobar():\n...\nglobal x\n...\nprint(x)\n...\nx += 1\n...\n>>> foobar()\n10\nThis explicit declaration is required in order to remind you that (unlike the superficially analogous situation with class\nand instance variables) you are actually modifying the value of the variable in the outer scope:\n>>> print(x)\n11\nYou can do a similar thing in a nested scope using the nonlocal keyword:\n>>> def foo():\n...\nx = 10\n...\ndef bar():\n...\nnonlocal x\n...\nprint(x)\n...\nx += 1\n...\nbar()\n...\nprint(x)\n...\n>>> foo()\n10\n11\n2.2.2 What are the rules for local and global variables in Python? In Python, variables that are only referenced inside a function are implicitly global. If a variable is assigned a value\nanywhere within the function’s body, it’s assumed to be a local unless explicitly declared as global. Though a bit surprising at first, a moment’s consideration explains this. On one hand, requiring global for assigned\nvariables provides a bar against unintended side-effects. On the other hand, if global was required for all global\nreferences, you’d be using global all the time. You’d have to declare as global every reference to a built-in function\nor to a component of an imported module. This clutter would defeat the usefulness of the global declaration for\nidentifying side-effects. 2.2.3 Why do lambdas defined in a loop with different values all return the same\nresult? Assume you use a for loop to define a few different lambdas (or even plain functions), e.g. :\n>>> squares = []\n>>> for x in range(5):\n...\nsquares.append(lambda: x**2)\nThis gives you a list that contains 5 lambdas that calculate x**2. You might expect that, when called, they would\nreturn, respectively, 0, 1, 4, 9, and 16. However, when you actually try you will see that they all return 16:\n>>> squares[2]()\n16\n>>> squares[4]()\n16\n2.2. Core Language\n9\n\nPython Frequently Asked Questions, Release 3.13.2\nThis happens because x is not local to the lambdas, but is defined in the outer scope, and it is accessed when the\nlambda is called — not when it is defined. At the end of the loop, the value of x is 4, so all the functions now return\n4**2, i.e. 16. You can also verify this by changing the value of x and see how the results of the lambdas change:\n>>> x = 8\n>>> squares[2]()\n64\nIn order to avoid this, you need to save the values in variables local to the lambdas, so that they don’t rely on the value\nof the global x:\n>>> squares = []\n>>> for x in range(5):\n...\nsquares.append(lambda n=x: n**2)\nHere, n=x creates a new variable n local to the lambda and computed when the lambda is defined so that it has the\nsame value that x had at that point in the loop. This means that the value of n will be 0 in the first lambda, 1 in the\nsecond, 2 in the third, and so on. Therefore each lambda will now return the correct result:\n>>> squares[2]()\n4\n>>> squares[4]()\n16\nNote that this behaviour is not peculiar to lambdas, but applies to regular functions too. 2.2.4 How do I share global variables across modules? The canonical way to share information across modules within a single program is to create a special module (often\ncalled config or cfg). Just import the config module in all modules of your application; the module then becomes\navailable as a global name. Because there is only one instance of each module, any changes made to the module\nobject get reflected everywhere. For example:\nconfig.py:\nx = 0\n# Default value of the 'x' configuration setting\nmod.py:\nimport config\nconfig.x = 1\nmain.py:\nimport config\nimport mod\nprint(config.x)\nNote that using a module is also the basis for implementing the singleton design pattern, for the same reason. 2.2.5 What are the “best practices” for using import in a module? In general, don’t use from modulename import *. Doing so clutters the importer’s namespace, and makes it\nmuch harder for linters to detect undefined names. Import modules at the top of a file. Doing so makes it clear what other modules your code requires and avoids\nquestions of whether the module name is in scope. Using one import per line makes it easy to add and delete module\nimports, but using multiple imports per line uses less screen space. It’s good practice if you import modules in the following order:\n1. standard library modules – e.g. sys, os, argparse, re\n10\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2. third-party library modules (anything installed in Python’s site-packages directory) – e.g. dateutil,\nrequests, PIL.Image\n3. locally developed modules\nIt is sometimes necessary to move imports to a function or class to avoid problems with circular imports. Gordon\nMcMillan says:\nCircular imports are fine where both modules use the “import <module>” form of import. They fail\nwhen the 2nd module wants to grab a name out of the first (“from module import name”) and the import\nis at the top level. That’s because names in the 1st are not yet available, because the first module is busy\nimporting the 2nd. In this case, if the second module is only used in one function, then the import can easily be moved into that function. By the time the import is called, the first module will have finished initializing, and the second module can do its\nimport. It may also be necessary to move imports out of the top level of code if some of the modules are platform-specific. In that case, it may not even be possible to import all of the modules at the top of the file. In this case, importing the\ncorrect modules in the corresponding platform-specific code is a good option. Only move imports into a local scope, such as inside a function definition, if it’s necessary to solve a problem such\nas avoiding a circular import or are trying to reduce the initialization time of a module. This technique is especially\nhelpful if many of the imports are unnecessary depending on how the program executes. You may also want to move\nimports into a function if the modules are only ever used in that function. Note that loading a module the first time\nmay be expensive because of the one time initialization of the module, but loading a module multiple times is virtually\nfree, costing only a couple of dictionary lookups. Even if the module name has gone out of scope, the module is\nprobably available in sys.modules. 2.2.6 Why are default values shared between objects? This type of bug commonly bites neophyte programmers. Consider this function:\ndef foo(mydict={}):\n# Danger: shared reference to one dict for all calls\n... compute something ...\nmydict[key] = value\nreturn mydict\nThe first time you call this function, mydict contains a single item. The second time, mydict contains two items\nbecause when foo() begins executing, mydict starts out with an item already in it.\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . 8\n2.2.1\nWhy am I getting an UnboundLocalError when the variable has a value? . . . . . . . . . 8\n2.2.2\nWhat are the rules for local and global variables in Python? . . . . . . . . . . . . . . . . 9\n2.2.3\nWhy do lambdas defined in a loop with different values all return the same result? . . . . . 9\n2.2.4\nHow do I share global variables across modules? . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . 8\n2.2.2\nWhat are the rules for local and global variables in Python? . . . . . . . . . . . . . . . . 9\n2.2.3\nWhy do lambdas defined in a loop with different values all return the same result? . . . . . 9\n2.2.4\nHow do I share global variables across modules? . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.5\nWhat are the “best practices” for using import in a module? . . . . . . . . . . . . . . . . 10\n2.2.6\nWhy are default values shared between objects? . . . . . . . . . . . . . . . . ."")",0.005876914528056534,0.06781829814459374,0.18783396742739386,0.5524984002113342,0.5943459
How do I get the current time in Python?,"Use 
datetime
:


>>> import datetime
>>> now = datetime.datetime.now()
>>> now
datetime.datetime(2009, 1, 6, 15, 8, 24, 78915)
>>> print(now)
2009-01-06 15:08:24.789150



For just the clock time without the date:


>>> now.time()
datetime.time(15, 8, 24, 78915)
>>> print(now.time())
15:08:24.789150





To save typing, you can import the 
datetime
 object from the 
datetime
 module:


>>> from datetime import datetime



Then remove the prefix 
datetime.
 from all of the above.

","('Answer: You can get the current local date and time by using the `datetime.now()` method. If you want the current UTC date and time, you can use `datetime.now(timezone.utc)`.\n\nReferences: [1, 3]\n', '[1] classmethod datetime.now(tz=None)\nReturn the current local date and time. If optional argument tz is None or not specified, this is like today(), but, if possible, supplies more precision\nthan can be gotten from going through a time.time() timestamp (for example, this may be possible on\nplatforms supplying the C gettimeofday() function). If tz is not None, it must be an instance of a tzinfo subclass, and the current date and time are converted to\ntz’s time zone. This function is preferred over today() and utcnow(). ® Note\nSubsequent calls to datetime.now() may return the same instant depending on the precision of the\nunderlying clock. classmethod datetime.utcnow()\nReturn the current UTC date and time, with tzinfo None. This is like now(), but returns the current UTC date and time, as a naive datetime object. An aware current\nUTC datetime can be obtained by calling datetime.now(timezone.utc). See also now(). Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an object\nrepresenting the current time in UTC is by calling datetime.now(timezone.utc). Deprecated since version 3.12: Use datetime.now() with UTC instead. classmethod datetime.fromtimestamp(timestamp, tz=None)\nReturn the local date and time corresponding to the POSIX timestamp, such as is returned by time.time(). If optional argument tz is None or not specified, the timestamp is converted to the platform’s local date and\ntime, and the returned datetime object is naive. If tz is not None, it must be an instance of a tzinfo subclass, and the timestamp is converted to tz’s time zone. 214\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nfromtimestamp() may raise OverflowError, if the timestamp is out of the range of values supported\nby the platform C localtime() or gmtime() functions, and OSError on localtime() or gmtime()\nfailure. It’s common for this to be restricted to years in 1970 through 2038. Note that on non-POSIX systems\nthat include leap seconds in their notion of a timestamp, leap seconds are ignored by fromtimestamp(), and\nthen it’s possible to have two timestamps differing by a second that yield identical datetime objects. This\nmethod is preferred over utcfromtimestamp(). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C localtime() or gmtime() functions. Raise OSError instead of\nValueError on localtime() or gmtime() failure. Changed in version 3.6: fromtimestamp() may return instances with fold set to 1.\nclassmethod datetime.utcfromtimestamp(timestamp)\nReturn the UTC datetime corresponding to the POSIX timestamp, with tzinfo None. (The resulting object\nis naive.) This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C\ngmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,\nsecond and microsecond of the result are all 0, and tzinfo is None. classmethod datetime.combine(date, time, tzinfo=time.tzinfo)\nReturn a new datetime object whose date components are equal to the given date object’s, and whose time\ncomponents are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set\nthe tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date\nargument is a datetime object, its time components and tzinfo attributes are ignored. For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo). Changed in version 3.6: Added the tzinfo argument. classmethod datetime.fromisoformat(date_string)\nReturn a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:\n1. Time zone offsets may have fractional seconds. 8.1. datetime — Basic date and time types\n215\n\nThe Python Library Reference, Release 3.13.2\n2. The T separator may be replaced by any single unicode character. 3. Fractional hours and minutes are not supported. 4. Reduced precision dates are not currently supported (YYYY-MM, YYYY). 5. Extended date representations are not currently supported (±YYYYYY-MM-DD). 6.\n\n[2] This method is functionally equivalent to now(), but without a tz parameter. classmethod datetime.now(tz=None)\nReturn the current local date and time. If optional argument tz is None or not specified, this is like today(), but, if possible, supplies more precision\nthan can be gotten from going through a time.time() timestamp (for example, this may be possible on\nplatforms supplying the C gettimeofday() function). If tz is not None, it must be an instance of a tzinfo subclass, and the current date and time are converted to\ntz’s time zone. This function is preferred over today() and utcnow(). ® Note\nSubsequent calls to datetime.now() may return the same instant depending on the precision of the\nunderlying clock. classmethod datetime.utcnow()\nReturn the current UTC date and time, with tzinfo None. This is like now(), but returns the current UTC date and time, as a naive datetime object. An aware current\nUTC datetime can be obtained by calling datetime.now(timezone.utc). See also now(). Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an object\nrepresenting the current time in UTC is by calling datetime.now(timezone.utc). Deprecated since version 3.12: Use datetime.now() with UTC instead. classmethod datetime.fromtimestamp(timestamp, tz=None)\nReturn the local date and time corresponding to the POSIX timestamp, such as is returned by time.time(). If optional argument tz is None or not specified, the timestamp is converted to the platform’s local date and\ntime, and the returned datetime object is naive. If tz is not None, it must be an instance of a tzinfo subclass, and the timestamp is converted to tz’s time zone. 214\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nfromtimestamp() may raise OverflowError, if the timestamp is out of the range of values supported\nby the platform C localtime() or gmtime() functions, and OSError on localtime() or gmtime()\nfailure. It’s common for this to be restricted to years in 1970 through 2038. Note that on non-POSIX systems\nthat include leap seconds in their notion of a timestamp, leap seconds are ignored by fromtimestamp(), and\nthen it’s possible to have two timestamps differing by a second that yield identical datetime objects. This\nmethod is preferred over utcfromtimestamp(). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C localtime() or gmtime() functions. Raise OSError instead of\nValueError on localtime() or gmtime() failure. Changed in version 3.6: fromtimestamp() may return instances with fold set to 1.\nclassmethod datetime.utcfromtimestamp(timestamp)\nReturn the UTC datetime corresponding to the POSIX timestamp, with tzinfo None. (The resulting object\nis naive.) This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C\ngmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,\nsecond and microsecond of the result are all 0, and tzinfo is None. classmethod datetime.combine(date, time, tzinfo=time.tzinfo)\nReturn a new datetime object whose date components are equal to the given date object’s, and whose time\ncomponents are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set\nthe tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date\nargument is a datetime object, its time components and tzinfo attributes are ignored. For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo). Changed in version 3.6: Added the tzinfo argument. classmethod datetime.fromisoformat(date_string)\nReturn a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:\n1. Time zone offsets may have fractional seconds. 8.1. datetime — Basic date and time types\n215\n\nThe Python Library Reference, Release 3.13.2\n2. The T separator may be replaced by any single unicode character. 3. Fractional hours and minutes are not supported. 4. Reduced precision dates are not currently supported (YYYY-MM, YYYY). 5. Extended date representations are not currently supported (±YYYYYY-MM-DD).\n\n[3] Examples of Usage: date\nExample of counting days to an event:\n>>> import time\n>>> from datetime import date\n>>> today = date.today()\n>>> today\ndatetime.date(2007, 12, 5)\n>>> today == date.fromtimestamp(time.time())\nTrue\n>>> my_birthday = date(today.year, 6, 24)\n>>> if my_birthday < today:\n...\nmy_birthday = my_birthday.replace(year=today.year + 1)\n...\n>>> my_birthday\ndatetime.date(2008, 6, 24)\n>>> time_to_birthday = abs(my_birthday - today)\n>>> time_to_birthday.days\n202\nMore examples of working with date:\n212\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n>>> from datetime import date\n>>> d = date.fromordinal(730920) # 730920th day after 1. 1. 0001\n>>> d\ndatetime.date(2002, 3, 11)\n>>> # Methods related to formatting string output\n>>> d.isoformat()\n\'2002-03-11\'\n>>> d.strftime(""%d/%m/%y"")\n\'11/03/02\'\n>>> d.strftime(""%A %d. %B %Y"")\n\'Monday 11. March 2002\'\n>>> d.ctime()\n\'Mon Mar 11 00:00:00 2002\'\n>>> \'The {1} is {0:%d}, the {2} is {0:%B}. \'.format(d, ""day"", ""month"")\n\'The day is 11, the month is March.\' >>> # Methods for to extracting \'components\' under different calendars\n>>> t = d.timetuple()\n>>> for i in t:\n...\nprint(i)\n2002\n# year\n3\n# month\n11\n# day\n0\n0\n0\n0\n# weekday (0 = Monday)\n70\n# 70th day in the year\n-1\n>>> ic = d.isocalendar()\n>>> for i in ic:\n...\nprint(i)\n2002\n# ISO year\n11\n# ISO week number\n1\n# ISO day number ( 1 = Monday )\n>>> # A date object is immutable; all operations produce a new object\n>>> d.replace(year=2005)\ndatetime.date(2005, 3, 11)\n8.1.6 datetime Objects\nA datetime object is a single object containing all the information from a date object and a time object. Like a date object, datetime assumes the current Gregorian calendar extended in both directions; like a time\nobject, datetime assumes there are exactly 3600*24 seconds in every day. Constructor:\nclass datetime.datetime(year, month, day, hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *,\nfold=0)\nThe year, month and day arguments are required. tzinfo may be None, or an instance of a tzinfo subclass. The remaining arguments must be integers in the following ranges:\n• MINYEAR <= year <= MAXYEAR,\n• 1 <= month <= 12,\n• 1 <= day <= number of days in the given month and year,\n8.1. datetime — Basic date and time types\n213\n\nThe Python Library Reference, Release 3.13.2\n• 0 <= hour < 24,\n• 0 <= minute < 60,\n• 0 <= second < 60,\n• 0 <= microsecond < 1000000,\n• fold in [0, 1]. If an argument outside those ranges is given, ValueError is raised. Changed in version 3.6: Added the fold parameter. Other constructors, all class methods:\nclassmethod datetime.today()\nReturn the current local date and time, with tzinfo None. Equivalent to:\ndatetime.fromtimestamp(time.time())\nSee also now(), fromtimestamp(). This method is functionally equivalent to now(), but without a tz parameter. classmethod datetime.now(tz=None)\nReturn the current local date and time. If optional argument tz is None or not specified, this is like today(), but, if possible, supplies more precision\nthan can be gotten from going through a time.time() timestamp (for example, this may be possible on\nplatforms supplying the C gettimeofday() function). If tz is not None, it must be an instance of a tzinfo subclass, and the current date and time are converted to\ntz’s time zone. This function is preferred over today() and utcnow(). ® Note\nSubsequent calls to datetime.now() may return the same instant depending on the precision of the\nunderlying clock. classmethod datetime.utcnow()\nReturn the current UTC date and time, with tzinfo None. This is like now(), but returns the current UTC date and time, as a naive datetime object. An aware current\nUTC datetime can be obtained by calling datetime.now(timezone.utc). See also now(). Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an object\nrepresenting the current time in UTC is by calling datetime.now(timezone.utc). Deprecated since version 3.12: Use datetime.now() with UTC instead. classmethod datetime.fromtimestamp(timestamp, tz=None)\nReturn the local date and time corresponding to the POSIX timestamp, such as is returned by time.time(). If optional argument tz is None or not specified, the timestamp is converted to the platform’s local date and\ntime, and the returned datetime object is naive. If tz is not None, it must be an instance of a tzinfo subclass, and the timestamp is converted to tz’s time zone. 214\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nfromtimestamp() may raise OverflowError, if the timestamp is out of the range of values supported\nby the platform C localtime() or gmtime() functions, and OSError on localtime() or gmtime()\nfailure. It’s common for this to be restricted to years in 1970 through 2038. Note that on non-POSIX systems\nthat include leap seconds in their notion of a timestamp, leap seconds are ignored by fromtimestamp(), and\nthen it’s possible to have two timestamps differing by a second that yield identical datetime objects. This\nmethod is preferred over utcfromtimestamp(). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C localtime() or gmtime() functions. Raise OSError instead of\nValueError on localtime() or gmtime() failure. Changed in version 3.6: fromtimestamp() may return instances with fold set to 1.\nclassmethod datetime.utcfromtimestamp(timestamp)\nReturn the UTC datetime corresponding to the POSIX timestamp, with tzinfo None. (The resulting object\nis naive.) This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C\ngmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal().')",1.304460552226117e-79,0.02749360613810742,0.1400984551348756,0.5523146390914917,0.5864418
"How to catch multiple exceptions in one line? (in the ""except"" block)","From 
Python Documentation
:




An except clause may name multiple exceptions as a parenthesized tuple, for example




except (IDontLikeYouException, YouAreBeingMeanException) as e:
    pass



Or, for Python 2 only:


except (IDontLikeYouException, YouAreBeingMeanException), e:
    pass



Separating the exception from the variable with a comma will still work in Python 2.6 and 2.7, but is now deprecated and does not work in Python 3; now you should be using 
as
.

","('Answer: You can name multiple exceptions in an except clause by using a parenthesized tuple, like this: `except (RuntimeError, TypeError, NameError):`.\n\nReferences: [2, 3]\n', '[1] Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause.\n\n[2] A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised.\n\n[3] At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised. • If the try statement reaches a break, continue or return statement, the finally clause will execute just\nprior to the break, continue or return statement’s execution.')",0.003649960893056408,0.01943798859074583,0.049529049519622,0.5397105813026428,0.68118924
How do I copy a file?,"shutil
 has many methods you can use. One of which is:


import shutil

shutil.copyfile(src, dst)

# 2nd option
shutil.copy(src, dst)  # dst can be a folder; use shutil.copy2() to preserve timestamp





Copy the contents of the file named 
src
 to a file named 
dst
. Both 
src
 and 
dst
 need to be the entire filename of the files, including path.


The destination location must be writable; otherwise, an 
IOError
 exception will be raised.


If 
dst
 already exists, it will be replaced.


Special files such as character or block devices and pipes cannot be copied with this function.


With 
copy
, 
src
 and 
dst
 are path names given as 
str
s.




Another 
shutil
 method to look at is 
shutil.copy2()
. It's similar but preserves more metadata (e.g. time stamps).


If you use 
os.path
 operations, use 
copy
 rather than 
copyfile
. 
copyfile
 will only accept strings.

","(""Answer: I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . 55\n4.3.5\nCan’t we get rid of the Global Interpreter Lock? . . . . . . . . . . . . . . . . . . . . . . 55\n4.4\nInput and Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.4.1\nHow do I delete a file? (And other file questions…)\n. . . . . . . . . . . . . . . . . . . . 56\n4.4.2\nHow do I copy a file? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.4.3\nHow do I read (or write) binary data? . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . 3\n1.3\nLogging to a file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.4\nLogging variable data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.5\nChanging the format of displayed messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.6\nDisplaying the date/time in messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.7\nNext Steps . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.11\nLibraries options\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n3.3.12\nSecurity Options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n3.3.13\nmacOS Options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n3.3.14\niOS Options . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",2.741339522415519e-79,0.07665505226480837,0.09606721903133103,0.4565657079219818,0.45849878
What is __init__.py for?,"It used to be a required part of a package (
old, pre-3.3 ""regular package""
, not 
newer 3.3+ ""namespace package""
).


Here's the documentation.




Python defines two types of packages, regular packages and namespace packages. Regular packages are traditional packages as they existed in Python 3.2 and earlier. A regular package is typically implemented as a directory containing an 
__init__.py
 file. When a regular package is imported, this 
__init__.py
 file is implicitly executed, and the objects it defines are bound to names in the package’s namespace. The 
__init__.py
 file can contain the same Python code that any other module can contain, and Python will add some additional attributes to the module when it is imported.




But just click the link, it contains an example, more information, and an explanation of namespace packages, the kind of packages without 
__init__.py
.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", ""[1] . . . . . . . . . . . . . . 1941\n30.4\nbuiltins — Built-in objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1941\n30.5\n__main__ — Top-level code environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1942\n30.5.1\n__name__ == '__main__' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1942\n30.5.2\n__main__.py in Python Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1944\n30.5.3\nimport __main__ . . . . . . . . . . . . .\n\n[2] . . . 231\n10.6\nPyConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\n10.7\nInitialization with PyConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\n10.8\nIsolated Configuration\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n10.9\nPython Configuration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\n10.10 Python Path Configuration . . . .\n\n[3] . . . . . . . . . . . 228\n10.3\nPyStatus\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n10.4\nPyPreConfig\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n10.5\nPreinitialize Python with PyPreConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n10.6\nPyConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ."")",1.3047871020779247e-155,0.06299212598425197,0.0731170759075376,0.46025025844573975,0.42457297
Convert bytes to a string in Python 3,"Decode the 
bytes
 object
 to produce a string:


>>> b""abcde"".decode(""utf-8"")
'abcde'



The above example 
assumes
 that the 
bytes
 object is in UTF-8, because it is a common encoding. However, you should use the encoding your data is actually in!

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation. hex([sep[, bytes_per_sep]])\nReturn a string object containing two hexadecimal digits for each byte in the instance. 4.9. Binary Sequence Types — bytes, bytearray, memoryview\n63\n\nThe Python Library Reference, Release 3.13.2\n>>> b\'\\xf0\\xf1\\xf2\'.hex()\n\'f0f1f2\'\nIf you want to make the hex string easier to read, you can specify a single character separator sep param-\neter to include in the output. By default, this separator will be included between each byte. A second\noptional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position\nfrom the right, negative values from the left. >>> value = b\'\\xf0\\xf1\\xf2\'\n>>> value.hex(\'-\')\n\'f0-f1-f2\'\n>>> value.hex(\'_\', 2)\n\'f0_f1f2\'\n>>> b\'UUDDLRLRAB\'.hex(\' \', -4)\n\'55554444 4c524c52 4142\'\nAdded in version 3.5. Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert\nseparators between bytes in the hex output. Since bytes objects are sequences of integers (akin to a tuple), for a bytes object b, b[0] will be an integer, while\nb[0:1] will be a bytes object of length 1. (This contrasts with text strings, where both indexing and slicing will\nproduce a string of length 1)\nThe representation of bytes objects uses the literal format (b\'...\') since it is often more useful than e.g. bytes([46, 46, 46]). You can always convert a bytes object into a list of integers using list(b). 4.9.2 Bytearray Objects\nbytearray objects are a mutable counterpart to bytes objects. class bytearray([source[, encoding[, errors]]])\nThere is no dedicated literal syntax for bytearray objects, instead they are always created by calling the con-\nstructor:\n• Creating an empty instance: bytearray()\n• Creating a zero-filled instance with a given length: bytearray(10)\n• From an iterable of integers: bytearray(range(20))\n• Copying existing binary data via the buffer protocol: bytearray(b\'Hi!\') As bytearray objects are mutable, they support the mutable sequence operations in addition to the common\nbytes and bytearray operations described in Bytes and Bytearray Operations. Also see the bytearray built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytearray type has an additional class method to read data\nin that format:\nclassmethod fromhex(string)\nThis bytearray class method returns bytearray object, decoding the given string object. The string\nmust contain two hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytearray.fromhex(\'2Ef0 F1f2\n\')\nbytearray(b\'.\\xf0\\xf1\\xf2\')\nChanged in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytearray object into its hexadecimal representation.\n\n[2] The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation. hex([sep[, bytes_per_sep]])\nReturn a string object containing two hexadecimal digits for each byte in the instance. 4.9. Binary Sequence Types — bytes, bytearray, memoryview\n63\n\nThe Python Library Reference, Release 3.13.2\n>>> b\'\\xf0\\xf1\\xf2\'.hex()\n\'f0f1f2\'\nIf you want to make the hex string easier to read, you can specify a single character separator sep param-\neter to include in the output. By default, this separator will be included between each byte.\n\n[3] \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation. hex([sep[, bytes_per_sep]])\nReturn a string object containing two hexadecimal digits for each byte in the instance. 4.9. Binary Sequence Types — bytes, bytearray, memoryview\n63\n\nThe Python Library Reference, Release 3.13.2\n>>> b\'\\xf0\\xf1\\xf2\'.hex()\n\'f0f1f2\'\nIf you want to make the hex string easier to read, you can specify a single character separator sep param-\neter to include in the output. By default, this separator will be included between each byte. A second\noptional bytes_per_sep parameter controls the spacing.')",9.401070401357562e-156,0.017908538535337387,0.06340792584384727,0.4886859655380249,0.41227797
What is the difference between __str__ and __repr__?,"

Alex Martelli summarized well
 but, surprisingly, was too succinct.


First, let me reiterate the main points in 
Alex
’s post:




The default implementation is useless (it’s hard to think of one which wouldn’t be, but yeah)


__repr__
 goal is to be unambiguous


__str__
 goal is to be readable


Container’s 
__str__
 uses contained objects’ 
__repr__




Default implementation is useless


This is mostly a surprise because Python’s defaults tend to be fairly useful. However, in this case, having a default for 
__repr__
 which would act like:


return ""%s(%r)"" % (self.__class__, self.__dict__)



Or in new f-string formatting:


return f""{self.__class__!s}({self.__dict__!r})""



would have been too dangerous (for example, too easy to get into infinite recursion if objects reference each other). So Python cops out. Note that there is one default which is true: if 
__repr__
 is defined, and 
__str__
 is not, the object will behave as though 
__str__=__repr__
.


This means, in simple terms: almost every object you implement should have a functional 
__repr__
 that’s usable for understanding the object. Implementing 
__str__
 is optional: do that if you need a “pretty print” functionality (for example, used by a report generator).


The goal of 
__repr__
 is to be unambiguous


Let me come right out and say it — I do not believe in debuggers. I don’t really know how to use any debugger, and have never used one seriously. Furthermore, I believe that the big fault in debuggers is their basic nature — most failures I debug happened a long long time ago, in a galaxy far far away. This means that I do believe, with religious fervor, in logging. Logging is the lifeblood of any decent fire-and-forget server system. Python makes it easy to log: with maybe some project specific wrappers, all you need is a


log(INFO, ""I am in the weird function and a is"", a, ""and b is"", b, ""but I got a null C — using default"", default_c)



But you have to do the last step — make sure every object you implement has a useful repr, so code like that can just work. This is why the “eval” thing comes up: if you have enough information so 
eval(repr(c))==c
, that means you know everything there is to know about 
c
. If that’s easy enough, at least in a fuzzy way, do it. If not, make sure you have enough information about 
c
 anyway. I usually use an eval-like format: 
""MyClass(this=%r,that=%r)"" % (self.this,self.that)
. It does not mean that you can actually construct MyClass, or that those are the right constructor arguments — but it is a useful form to express “this is everything you need to know about this instance”.


Note: I used 
%r
 above, not 
%s
. You always want to use 
repr()
 [or 
%r
 formatting character, equivalently] inside 
__repr__
 implementation, or you’re defeating the goal of repr. You want to be able to differentiate 
MyClass(3)
 and 
MyClass(""3"")
.


The goal of 
__str__
 is to be readable


Specifically, it is not intended to be unambiguous — notice that 
str(3)==str(""3"")
. Likewise, if you implement an IP abstraction, having the str of it look like 192.168.1.1 is just fine. When implementing a date/time abstraction, the str can be ""2010/4/12 15:35:22"", etc. The goal is to represent it in a way that a user, not a programmer, would want to read it. Chop off useless digits, pretend to be some other class — as long is it supports readability, it is an improvement.


Container’s 
__str__
 uses contained objects’ 
__repr__


This seems surprising, doesn’t it? It is a little, but how readable would it be if it used their 
__str__
?


[moshe is, 3, hello
world, this is a list, oh I don't know, containing just 4 elements]



Not very. Specifically, the strings in a container would find it way too easy to disturb its string representation. In the face of ambiguity, remember, Python resists the temptation to guess. If you want the above behavior when you’re printing a list, just


print(""["" + "", "".join(lst) + ""]"")



(you can probably also figure out what to do about dictionaries).


Summary


Implement 
__repr__
 for any class you implement. This should be second nature. Implement 
__str__
 if you think it would be useful to have a string version which errs on the side of readability.

","(""Answer:\n`__repr__` is used to compute the “official” string representation of an object, ideally as a valid Python expression to recreate the object. It's used for debugging and should be information-rich and unambiguous. `__str__` is used to compute the “informal” or nicely printable string representation of an object. There is no expectation that `__str__` returns a valid Python expression; it can be a more convenient or concise representation. If a class defines `__repr__` but not `__str__`, then `__repr__` is also used when an “informal” string representation is required. The default implementation of `__str__` calls `__repr__`.\n\nReferences: [2]\n"", '[1] 3.3. Special method names\n35\n\nThe Python Language Reference, Release 3.13.2\nCPython implementation detail: It is possible for a reference cycle to prevent the reference count of an object\nfrom going to zero. In this case, the cycle will be later detected and deleted by the cyclic garbage collector. A\ncommon cause of reference cycles is when an exception has been caught in a local variable. The frame’s locals\nthen reference the exception, which references its own traceback, which references the locals of all frames\ncaught in the traceback. µ See also\nDocumentation for the gc module. Á Warning\nDue to the precarious circumstances under which __del__() methods are invoked, exceptions that occur\nduring their execution are ignored, and a warning is printed to sys.stderr instead. In particular:\n• __del__() can be invoked when arbitrary code is being executed, including from any arbitrary\nthread. If __del__() needs to take a lock or invoke any other blocking resource, it may deadlock\nas the resource may already be taken by the code that gets interrupted to execute __del__(). • __del__() can be executed during interpreter shutdown. As a consequence, the global variables\nit needs to access (including other modules) may already have been deleted or set to None. Python\nguarantees that globals whose name begins with a single underscore are deleted from their module\nbefore other globals are deleted; if no other references to such globals exist, this may help in assuring\nthat imported modules are still available at the time when the __del__() method is called. object.__repr__(self)\nCalled by the repr() built-in function to compute the “official” string representation of an object. If at\nall possible, this should look like a valid Python expression that could be used to recreate an object with\nthe same value (given an appropriate environment). If this is not possible, a string of the form <...some\nuseful description...> should be returned. The return value must be a string object. If a class defines\n__repr__() but not __str__(), then __repr__() is also used when an “informal” string representation\nof instances of that class is required. This is typically used for debugging, so it is important that the representation is information-rich and unam-\nbiguous. A default implementation is provided by the object class itself. object.__str__(self)\nCalled by str(object), the default __format__() implementation, and the built-in function print(), to\ncompute the “informal” or nicely printable string representation of an object. The return value must be a str\nobject. This method differs from object.__repr__() in that there is no expectation that __str__() return a valid\nPython expression: a more convenient or concise representation can be used. The default implementation defined by the built-in type object calls object.__repr__(). object.__bytes__(self)\nCalled by bytes to compute a byte-string representation of an object. This should return a bytes object. The\nobject class itself does not provide this method. object.__format__(self, format_spec)\nCalled by the format() built-in function, and by extension, evaluation of formatted string literals and the str. format() method, to produce a “formatted” string representation of an object. The format_spec argument\nis a string that contains a description of the formatting options desired. The interpretation of the format_spec\nargument is up to the type implementing __format__(), however most classes will either delegate formatting\nto one of the built-in types, or use a similar formatting option syntax. See formatspec for a description of the standard formatting syntax. The return value must be a string object. 36\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nThe default implementation by the object class should be given an empty format_spec string. It delegates to\n__str__(). Changed in version 3.4: The __format__ method of object itself raises a TypeError if passed any non-\nempty string. Changed in version 3.7:\nobject.__format__(x, \'\') is now equivalent to str(x) rather than\nformat(str(x), \'\'). object.__lt__(self, other)\nobject.__le__(self, other)\nobject.__eq__(self, other)\nobject.__ne__(self, other)\nobject.__gt__(self, other)\nobject.__ge__(self, other)\nThese are the so-called “rich comparison” methods. The correspondence between operator symbols and\nmethod names is as follows: x<y calls x.__lt__(y), x<=y calls x.__le__(y), x==y calls x.__eq__(y),\nx!=y calls x.__ne__(y), x>y calls x.__gt__(y), and x>=y calls x.__ge__(y). A rich comparison method may return the singleton NotImplemented if it does not implement the operation\nfor a given pair of arguments. By convention, False and True are returned for a successful comparison. However, these methods can return any value, so if the comparison operator is used in a Boolean context (e.g.,\nin the condition of an if statement), Python will call bool() on the value to determine if the result is true or\nfalse. By default, object implements __eq__() by using is, returning NotImplemented in the case of a\nfalse comparison: True if x is y else NotImplemented. For __ne__(), by default it delegates to\n__eq__() and inverts the result unless it is NotImplemented. There are no other implied relationships\namong the comparison operators or default implementations; for example, the truth of (x<y or x==y) does\nnot imply x<=y. To automatically generate ordering operations from a single root operation, see functools. total_ordering(). By default, the object class provides implementations consistent with Value comparisons: equality compares\naccording to object identity, and order comparisons raise TypeError. Each default method may generate\nthese results directly, but may also return NotImplemented. See the paragraph on __hash__() for some important notes on creating hashable objects which support\ncustom comparison operations and are usable as dictionary keys. There are no swapped-argument versions of these methods (to be used when the left argument does not sup-\nport the operation but the right argument does); rather, __lt__() and __gt__() are each other’s reflection,\n__le__() and __ge__() are each other’s reflection, and __eq__() and __ne__() are their own reflection.\n\n[2] object.__repr__(self)\nCalled by the repr() built-in function to compute the “official” string representation of an object. If at\nall possible, this should look like a valid Python expression that could be used to recreate an object with\nthe same value (given an appropriate environment). If this is not possible, a string of the form <...some\nuseful description...> should be returned. The return value must be a string object. If a class defines\n__repr__() but not __str__(), then __repr__() is also used when an “informal” string representation\nof instances of that class is required. This is typically used for debugging, so it is important that the representation is information-rich and unam-\nbiguous. A default implementation is provided by the object class itself. object.__str__(self)\nCalled by str(object), the default __format__() implementation, and the built-in function print(), to\ncompute the “informal” or nicely printable string representation of an object. The return value must be a str\nobject. This method differs from object.__repr__() in that there is no expectation that __str__() return a valid\nPython expression: a more convenient or concise representation can be used. The default implementation defined by the built-in type object calls object.__repr__(). object.__bytes__(self)\nCalled by bytes to compute a byte-string representation of an object. This should return a bytes object. The\nobject class itself does not provide this method. object.__format__(self, format_spec)\nCalled by the format() built-in function, and by extension, evaluation of formatted string literals and the str. format() method, to produce a “formatted” string representation of an object. The format_spec argument\nis a string that contains a description of the formatting options desired. The interpretation of the format_spec\nargument is up to the type implementing __format__(), however most classes will either delegate formatting\nto one of the built-in types, or use a similar formatting option syntax. See formatspec for a description of the standard formatting syntax. The return value must be a string object. 36\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nThe default implementation by the object class should be given an empty format_spec string. It delegates to\n__str__(). Changed in version 3.4: The __format__ method of object itself raises a TypeError if passed any non-\nempty string. Changed in version 3.7:\nobject.__format__(x, \'\') is now equivalent to str(x) rather than\nformat(str(x), \'\'). object.__lt__(self, other)\nobject.__le__(self, other)\nobject.__eq__(self, other)\nobject.__ne__(self, other)\nobject.__gt__(self, other)\nobject.__ge__(self, other)\nThese are the so-called “rich comparison” methods. The correspondence between operator symbols and\nmethod names is as follows: x<y calls x.__lt__(y), x<=y calls x.__le__(y), x==y calls x.__eq__(y),\nx!=y calls x.__ne__(y), x>y calls x.__gt__(y), and x>=y calls x.__ge__(y). A rich comparison method may return the singleton NotImplemented if it does not implement the operation\nfor a given pair of arguments. By convention, False and True are returned for a successful comparison. However, these methods can return any value, so if the comparison operator is used in a Boolean context (e.g.,\nin the condition of an if statement), Python will call bool() on the value to determine if the result is true or\nfalse. By default, object implements __eq__() by using is, returning NotImplemented in the case of a\nfalse comparison: True if x is y else NotImplemented. For __ne__(), by default it delegates to\n__eq__() and inverts the result unless it is NotImplemented. There are no other implied relationships\namong the comparison operators or default implementations; for example, the truth of (x<y or x==y) does\nnot imply x<=y. To automatically generate ordering operations from a single root operation, see functools. total_ordering(). By default, the object class provides implementations consistent with Value comparisons: equality compares\naccording to object identity, and order comparisons raise TypeError. Each default method may generate\nthese results directly, but may also return NotImplemented. See the paragraph on __hash__() for some important notes on creating hashable objects which support\ncustom comparison operations and are usable as dictionary keys. There are no swapped-argument versions of these methods (to be used when the left argument does not sup-\nport the operation but the right argument does); rather, __lt__() and __gt__() are each other’s reflection,\n__le__() and __ge__() are each other’s reflection, and __eq__() and __ne__() are their own reflection. If the operands are of different types, and the right operand’s type is a direct or indirect subclass of the left\noperand’s type, the reflected method of the right operand has priority, otherwise the left operand’s method has\npriority. Virtual subclassing is not considered. When no appropriate method returns any value other than NotImplemented, the == and != operators will\nfall back to is and is not, respectively. object.__hash__(self)\nCalled by built-in function hash() and for operations on members of hashed collections including set,\nfrozenset, and dict. The __hash__() method should return an integer. The only required property\nis that objects which compare equal have the same hash value; it is advised to mix together the hash values of\nthe components of the object that also play a part in comparison of objects by packing them into a tuple and\nhashing the tuple. Example:\ndef __hash__(self):\nreturn hash((self.name, self.nick, self.color))\n3.3. Special method names\n37\n\nThe Python Language Reference, Release 3.13.2\n® Note\nhash() truncates the value returned from an object’s custom __hash__() method to the size of a\nPy_ssize_t. This is typically 8 bytes on 64-bit builds and 4 bytes on 32-bit builds. If an object’s\n__hash__() must interoperate on builds of different bit sizes, be sure to check the width on all sup-\nported builds. An easy way to do this is with python -c ""import sys; print(sys.hash_info. width)"".\n\n[3] The frame’s locals\nthen reference the exception, which references its own traceback, which references the locals of all frames\ncaught in the traceback. µ See also\nDocumentation for the gc module. Á Warning\nDue to the precarious circumstances under which __del__() methods are invoked, exceptions that occur\nduring their execution are ignored, and a warning is printed to sys.stderr instead. In particular:\n• __del__() can be invoked when arbitrary code is being executed, including from any arbitrary\nthread. If __del__() needs to take a lock or invoke any other blocking resource, it may deadlock\nas the resource may already be taken by the code that gets interrupted to execute __del__(). • __del__() can be executed during interpreter shutdown. As a consequence, the global variables\nit needs to access (including other modules) may already have been deleted or set to None. Python\nguarantees that globals whose name begins with a single underscore are deleted from their module\nbefore other globals are deleted; if no other references to such globals exist, this may help in assuring\nthat imported modules are still available at the time when the __del__() method is called. object.__repr__(self)\nCalled by the repr() built-in function to compute the “official” string representation of an object. If at\nall possible, this should look like a valid Python expression that could be used to recreate an object with\nthe same value (given an appropriate environment). If this is not possible, a string of the form <...some\nuseful description...> should be returned. The return value must be a string object. If a class defines\n__repr__() but not __str__(), then __repr__() is also used when an “informal” string representation\nof instances of that class is required. This is typically used for debugging, so it is important that the representation is information-rich and unam-\nbiguous. A default implementation is provided by the object class itself. object.__str__(self)\nCalled by str(object), the default __format__() implementation, and the built-in function print(), to\ncompute the “informal” or nicely printable string representation of an object. The return value must be a str\nobject. This method differs from object.__repr__() in that there is no expectation that __str__() return a valid\nPython expression: a more convenient or concise representation can be used. The default implementation defined by the built-in type object calls object.__repr__(). object.__bytes__(self)\nCalled by bytes to compute a byte-string representation of an object. This should return a bytes object. The\nobject class itself does not provide this method. object.__format__(self, format_spec)\nCalled by the format() built-in function, and by extension, evaluation of formatted string literals and the str. format() method, to produce a “formatted” string representation of an object. The format_spec argument\nis a string that contains a description of the formatting options desired. The interpretation of the format_spec\nargument is up to the type implementing __format__(), however most classes will either delegate formatting\nto one of the built-in types, or use a similar formatting option syntax. See formatspec for a description of the standard formatting syntax. The return value must be a string object. 36\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nThe default implementation by the object class should be given an empty format_spec string. It delegates to\n__str__(). Changed in version 3.4: The __format__ method of object itself raises a TypeError if passed any non-\nempty string. Changed in version 3.7:\nobject.__format__(x, \'\') is now equivalent to str(x) rather than\nformat(str(x), \'\'). object.__lt__(self, other)\nobject.__le__(self, other)\nobject.__eq__(self, other)\nobject.__ne__(self, other)\nobject.__gt__(self, other)\nobject.__ge__(self, other)\nThese are the so-called “rich comparison” methods. The correspondence between operator symbols and\nmethod names is as follows: x<y calls x.__lt__(y), x<=y calls x.__le__(y), x==y calls x.__eq__(y),\nx!=y calls x.__ne__(y), x>y calls x.__gt__(y), and x>=y calls x.__ge__(y). A rich comparison method may return the singleton NotImplemented if it does not implement the operation\nfor a given pair of arguments. By convention, False and True are returned for a successful comparison. However, these methods can return any value, so if the comparison operator is used in a Boolean context (e.g.,\nin the condition of an if statement), Python will call bool() on the value to determine if the result is true or\nfalse. By default, object implements __eq__() by using is, returning NotImplemented in the case of a\nfalse comparison: True if x is y else NotImplemented. For __ne__(), by default it delegates to\n__eq__() and inverts the result unless it is NotImplemented. There are no other implied relationships\namong the comparison operators or default implementations; for example, the truth of (x<y or x==y) does\nnot imply x<=y. To automatically generate ordering operations from a single root operation, see functools. total_ordering(). By default, the object class provides implementations consistent with Value comparisons: equality compares\naccording to object identity, and order comparisons raise TypeError. Each default method may generate\nthese results directly, but may also return NotImplemented. See the paragraph on __hash__() for some important notes on creating hashable objects which support\ncustom comparison operations and are usable as dictionary keys. There are no swapped-argument versions of these methods (to be used when the left argument does not sup-\nport the operation but the right argument does); rather, __lt__() and __gt__() are each other’s reflection,\n__le__() and __ge__() are each other’s reflection, and __eq__() and __ne__() are their own reflection. If the operands are of different types, and the right operand’s type is a direct or indirect subclass of the left\noperand’s type, the reflected method of the right operand has priority, otherwise the left operand’s method has\npriority. Virtual subclassing is not considered. When no appropriate method returns any value other than NotImplemented, the == and != operators will\nfall back to is and is not, respectively. object.__hash__(self)\nCalled by built-in function hash() and for operations on members of hashed collections including set,\nfrozenset, and dict.')",4.4347020653345386e-79,0.09938837920489295,0.2622162881185673,0.5876217484474182,0.6863294
How do I select rows from a DataFrame based on column values?,"To select rows whose column value equals a scalar, 
some_value
, use 
==
:


df.loc[df['column_name'] == some_value]



To select rows whose column value is in an iterable, 
some_values
, use 
isin
:


df.loc[df['column_name'].isin(some_values)]



Combine multiple conditions with 
&
:


df.loc[(df['column_name'] >= A) & (df['column_name'] <= B)]



Note the parentheses. Due to Python's 
operator precedence rules
, 
&
 binds more tightly than 
<=
 and 
>=
. Thus, the parentheses in the last example are necessary. Without the parentheses


df['column_name'] >= A & df['column_name'] <= B



is parsed as


df['column_name'] >= (A & df['column_name']) <= B



which results in a 
Truth value of a Series is ambiguous error
.




To select rows whose column value 
does not equal
 
some_value
, use 
!=
:


df.loc[df['column_name'] != some_value]



The 
isin
 returns a boolean Series, so to select rows whose value is 
not
 in 
some_values
, negate the boolean Series using 
~
:


df = df.loc[~df['column_name'].isin(some_values)] # .loc is not in-place replacement





For example,


import pandas as pd
import numpy as np
df = pd.DataFrame({'A': 'foo bar foo bar foo bar foo foo'.split(),
                   'B': 'one one two three two two one three'.split(),
                   'C': np.arange(8), 'D': np.arange(8) * 2})
print(df)
#      A      B  C   D
# 0  foo    one  0   0
# 1  bar    one  1   2
# 2  foo    two  2   4
# 3  bar  three  3   6
# 4  foo    two  4   8
# 5  bar    two  5  10
# 6  foo    one  6  12
# 7  foo  three  7  14

print(df.loc[df['A'] == 'foo'])



yields


     A      B  C   D
0  foo    one  0   0
2  foo    two  2   4
4  foo    two  4   8
6  foo    one  6  12
7  foo  three  7  14





If you have multiple values you want to include, put them in a
list (or more generally, any iterable) and use 
isin
:


print(df.loc[df['B'].isin(['one','three'])])



yields


     A      B  C   D
0  foo    one  0   0
1  bar    one  1   2
3  bar  three  3   6
6  foo    one  6  12
7  foo  three  7  14





Note, however, that if you wish to do this many times, it is more efficient to
make an index first, and then use 
df.loc
:


df = df.set_index(['B'])
print(df.loc['one'])



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
one  foo  6  12



or, to include multiple values from the index use 
df.index.isin
:


df.loc[df.index.isin(['one','two'])]



yields


       A  C   D
B              
one  foo  0   0
one  bar  1   2
two  foo  2   4
two  foo  4   8
two  bar  5  10
one  foo  6  12


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] . . . . . 9\n3.1.3\nLists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2\nFirst Steps Towards Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4\nMore Control Flow Tools\n17\n4.1\nif Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function .\n\n[3] . . . . . . 35\n5.1.3\nList Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.4\nNested List Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.2\nThe del statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.3\nTuples and Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n5.4\nSets . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",1.5959723193458372e-155,0.07432432432432433,0.042188118293670515,0.49185866117477417,0.1925751
How can I add new keys to a dictionary?,"You create a new key/value pair on a dictionary by assigning a value to that key


d = {'key': 'value'}
print(d)  # {'key': 'value'}

d['mynewkey'] = 'mynewvalue'

print(d)  # {'key': 'value', 'mynewkey': 'mynewvalue'}



If the key doesn't exist, it's added and points to that value. If it exists, the current value it points to is overwritten.

","('Answer: You can add new keys to a dictionary by assigning a value to that key using `d[key] = value`.\n\nReferences: [3]\n', '[1] Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None.\n\n[2] add(elem)\nAdd element elem to the set. remove(elem)\nRemove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem)\nRemove element elem from the set if it is present. pop()\nRemove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear()\nRemove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(),\nand symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To\nsupport searching for an equivalent frozenset, a temporary one is created from elem. 4.11 Mapping Types — dict\nA mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only\none standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and\nthe collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-\nnaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary\nentry. class dict(**kwargs)\nclass dict(mapping, **kwargs)\n4.11. Mapping Types — dict\n87\n\nThe Python Library Reference, Release 3.13.2\nclass dict(iterable, **kwargs)\nReturn a new dictionary initialized from an optional positional argument and a possibly empty set of keyword\narguments. Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default.\n\n[3] d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6.')",0.005041634676476755,0.031378408666417626,0.09520236740268614,0.5748657584190369,0.66751677
Does Python have a string 'contains' substring method?,"Use the 
in
 operator
:


if ""blah"" not in somestring: 
    continue



Note: This is case-sensitive.

","(""I'm sorry, I couldn't find relevant information in the provided context."", ""[1] We’ll complicate the pattern again in an effort to fix it. . *[.]([^b].?.?|.[^a]?.?|..?[^t]? )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE.\n\n[2] *[.]([^b].?.?|.[^a]?.?|..?[^t]? )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate\nportions of the original text in the resulting replacement string. This example matches the word section followed by a string enclosed in {, }, and changes section to\nsubsection:\n>>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First} section{second}')\n'subsection{First} subsection{second}'\nThere’s also a syntax for referring to named groups as defined by the (?P<name>...) syntax.\n\n[3] . *[.]([^b].?.?|.[^a]?.?|..?[^t]? )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate\nportions of the original text in the resulting replacement string."")",4.1832989553583516e-232,0.0054832076764907475,0.015959872321021435,0.42817288637161255,0.3499011
How can I delete a file or folder in Python?,"Use one of these methods:




pathlib.Path.unlink()
 removes a file or symbolic link.




pathlib.Path.rmdir()
 removes an empty directory.




shutil.rmtree()
 deletes a directory and all its contents.








On Python 3.3 and below, you can use these methods instead of the 
pathlib
 ones:




os.remove()
 removes a file.




os.unlink()
 removes a symbolic link.




os.rmdir()
 removes an empty directory.





","('Answer: To delete a file, use `Path.unlink()`. To delete a directory, use `Path.rmdir()`, but note that the directory must be empty. To remove directories recursively, you can use `os.removedirs()`.\n\nReferences: [1, 2]\n', '[1] Walking the tree bottom-up is essential\nas rmdir() doesn’t allow deleting a directory before it is empty:\n# Delete everything reachable from the directory ""top"". # CAUTION:\nThis is dangerous! For example, if top == Path(\'/\'),\n# it could delete all of your files. for root, dirs, files in top.walk(top_down=False):\nfor name in files:\n(root / name).unlink()\nfor name in dirs:\n(root / name).rmdir()\nAdded in version 3.12. Creating files and directories\nPath.touch(mode=0o666, exist_ok=True)\nCreate a file at this given path. If mode is given, it is combined with the process’s umask value to determine\nthe file mode and access flags. If the file already exists, the function succeeds when exist_ok is true (and its\nmodification time is updated to the current time), otherwise FileExistsError is raised. µ See also\nThe open(), write_text() and write_bytes() methods are often used to create files. Path.mkdir(mode=0o777, parents=False, exist_ok=False)\nCreate a new directory at this given path. If mode is given, it is combined with the process’s umask value to\ndetermine the file mode and access flags. If the path already exists, FileExistsError is raised. If parents is true, any missing parents of this path are created as needed; they are created with the default\npermissions without taking mode into account (mimicking the POSIX mkdir -p command). If parents is false (the default), a missing parent raises FileNotFoundError. If exist_ok is false (the default), FileExistsError is raised if the target directory already exists. If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system\nand is not a directory (same behavior as the POSIX mkdir -p command). Changed in version 3.5: The exist_ok parameter was added. Path.symlink_to(target, target_is_directory=False)\nMake this path a symbolic link pointing to target. On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If\nthe target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as\na directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,\ntarget_is_directory is ignored. >>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\n>>> p.stat().st_size\n956\n>>> p.lstat().st_size\n8\n11.1. pathlib — Object-oriented filesystem paths\n459\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThe order of arguments (link, target) is the reverse of os.symlink()’s. Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous\nversions, NotImplementedError was raised. Path.hardlink_to(target)\nMake this path a hard link to the same file as target. ® Note\nThe order of arguments (link, target) is the reverse of os.link()’s. Added in version 3.10. Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-\nsions, NotImplementedError was raised. Renaming and deleting\nPath.rename(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,\nif target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,\nFileExistsError will be raised. target can be either a string or another path object:\n>>> p = Path(\'foo\')\n>>> p.open(\'w\').write(\'some text\')\n9\n>>> target = Path(\'bar\')\n>>> p.rename(target)\nPosixPath(\'bar\')\n>>> target.open().read()\n\'some text\'\nThe target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. It is implemented in terms of os.rename() and gives the same guarantees. Changed in version 3.8: Added return value, return the new Path instance. Path.replace(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. If target\npoints to an existing file or empty directory, it will be unconditionally replaced. The target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. Changed in version 3.8: Added return value, return the new Path instance. Path.unlink(missing_ok=False)\nRemove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead. If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist. If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f\ncommand). Changed in version 3.8: The missing_ok parameter was added. 460\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.rmdir()\nRemove this directory. The directory must be empty. Permissions and ownership\nPath.owner(*, follow_symlinks=True)\nReturn the name of the user owning the file. KeyError is raised if the file’s user identifier (UID) isn’t found\nin the system database.\n\n[2] Use rmdir() to remove directories. If the file does not exist, a FileNotFoundError is raised. This function can support paths relative to directory descriptors. On Windows, attempting to remove a file that is in use causes an exception to be raised; on Unix, the directory\nentry is removed but the storage allocated to the file is not made available until the original file is no longer in\nuse. This function is semantically identical to unlink(). Raises an auditing event os.remove with arguments path, dir_fd. Changed in version 3.3: Added the dir_fd parameter. Changed in version 3.6: Accepts a path-like object. os.removedirs(name)\nRemove directories recursively. Works like rmdir() except that, if the leaf directory is successfully re-\nmoved, removedirs() tries to successively remove every parent directory mentioned in path until an error\nis raised (which is ignored, because it generally means that a parent directory is not empty). For example, os. removedirs(\'foo/bar/baz\') will first remove the directory \'foo/bar/baz\', and then remove \'foo/\nbar\' and \'foo\' if they are empty. Raises OSError if the leaf directory could not be successfully removed. Raises an auditing event os.remove with arguments path, dir_fd. Changed in version 3.6: Accepts a path-like object. os.rename(src, dst, *, src_dir_fd=None, dst_dir_fd=None)\nRename the file or directory src to dst. If dst exists, the operation will fail with an OSError subclass in a\nnumber of cases:\nOn Windows, if dst exists a FileExistsError is always raised. The operation may fail if src and dst are on\ndifferent filesystems. Use shutil.move() to support moves to a different filesystem. On Unix, if src is a file and dst is a directory or vice-versa, an IsADirectoryError or a\nNotADirectoryError will be raised respectively. If both are directories and dst is empty, dst will be silently\nreplaced. If dst is a non-empty directory, an OSError is raised. If both are files, dst will be replaced silently if\nthe user has permission. The operation may fail on some Unix flavors if src and dst are on different filesystems. If successful, the renaming will be an atomic operation (this is a POSIX requirement). This function can support specifying src_dir_fd and/or dst_dir_fd to supply paths relative to directory descrip-\ntors. If you want cross-platform overwriting of the destination, use replace(). 16.1. os — Miscellaneous operating system interfaces\n683\n\nThe Python Library Reference, Release 3.13.2\nRaises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd. Changed in version 3.3: Added the src_dir_fd and dst_dir_fd parameters. Changed in version 3.6: Accepts a path-like object for src and dst. os.renames(old, new)\nRecursive directory or file renaming function. Works like rename(), except creation of any intermediate\ndirectories needed to make the new pathname good is attempted first. After the rename, directories corre-\nsponding to rightmost path segments of the old name will be pruned away using removedirs(). ® Note\nThis function can fail with the new directory structure made if you lack permissions needed to remove the\nleaf directory or file. Raises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd. Changed in version 3.6: Accepts a path-like object for old and new. os.replace(src, dst, *, src_dir_fd=None, dst_dir_fd=None)\nRename the file or directory src to dst. If dst is a non-empty directory, OSError will be raised. If dst exists\nand is a file, it will be replaced silently if the user has permission. The operation may fail if src and dst are on\ndifferent filesystems. If successful, the renaming will be an atomic operation (this is a POSIX requirement). This function can support specifying src_dir_fd and/or dst_dir_fd to supply paths relative to directory descrip-\ntors. Raises an auditing event os.rename with arguments src, dst, src_dir_fd, dst_dir_fd. Added in version 3.3. Changed in version 3.6: Accepts a path-like object for src and dst. os.rmdir(path, *, dir_fd=None)\nRemove (delete) the directory path. If the directory does not exist or is not empty, a FileNotFoundError\nor an OSError is raised respectively. In order to remove whole directory trees, shutil.rmtree() can be\nused. This function can support paths relative to directory descriptors. Raises an auditing event os.rmdir with arguments path, dir_fd. Changed in version 3.3: Added the dir_fd parameter.\n\n[3] File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nThis next example is a simple implementation of shutil.rmtree(). Walking the tree bottom-up is essential\nas rmdir() doesn’t allow deleting a directory before it is empty:\n# Delete everything reachable from the directory ""top"". # CAUTION:\nThis is dangerous! For example, if top == Path(\'/\'),\n# it could delete all of your files. for root, dirs, files in top.walk(top_down=False):\nfor name in files:\n(root / name).unlink()\nfor name in dirs:\n(root / name).rmdir()\nAdded in version 3.12. Creating files and directories\nPath.touch(mode=0o666, exist_ok=True)\nCreate a file at this given path. If mode is given, it is combined with the process’s umask value to determine\nthe file mode and access flags. If the file already exists, the function succeeds when exist_ok is true (and its\nmodification time is updated to the current time), otherwise FileExistsError is raised. µ See also\nThe open(), write_text() and write_bytes() methods are often used to create files. Path.mkdir(mode=0o777, parents=False, exist_ok=False)\nCreate a new directory at this given path. If mode is given, it is combined with the process’s umask value to\ndetermine the file mode and access flags. If the path already exists, FileExistsError is raised. If parents is true, any missing parents of this path are created as needed; they are created with the default\npermissions without taking mode into account (mimicking the POSIX mkdir -p command). If parents is false (the default), a missing parent raises FileNotFoundError. If exist_ok is false (the default), FileExistsError is raised if the target directory already exists. If exist_ok is true, FileExistsError will not be raised unless the given path already exists in the file system\nand is not a directory (same behavior as the POSIX mkdir -p command). Changed in version 3.5: The exist_ok parameter was added. Path.symlink_to(target, target_is_directory=False)\nMake this path a symbolic link pointing to target. On Windows, a symlink represents either a file or a directory, and does not morph to the target dynamically. If\nthe target is present, the type of the symlink will be created to match. Otherwise, the symlink will be created as\na directory if target_is_directory is true or a file symlink (the default) otherwise. On non-Windows platforms,\ntarget_is_directory is ignored. >>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\n>>> p.stat().st_size\n956\n>>> p.lstat().st_size\n8\n11.1. pathlib — Object-oriented filesystem paths\n459\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThe order of arguments (link, target) is the reverse of os.symlink()’s. Changed in version 3.13: Raises UnsupportedOperation if os.symlink() is not available. In previous\nversions, NotImplementedError was raised. Path.hardlink_to(target)\nMake this path a hard link to the same file as target. ® Note\nThe order of arguments (link, target) is the reverse of os.link()’s. Added in version 3.10. Changed in version 3.13: Raises UnsupportedOperation if os.link() is not available. In previous ver-\nsions, NotImplementedError was raised. Renaming and deleting\nPath.rename(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. On Unix,\nif target exists and is a file, it will be replaced silently if the user has permission. On Windows, if target exists,\nFileExistsError will be raised. target can be either a string or another path object:\n>>> p = Path(\'foo\')\n>>> p.open(\'w\').write(\'some text\')\n9\n>>> target = Path(\'bar\')\n>>> p.rename(target)\nPosixPath(\'bar\')\n>>> target.open().read()\n\'some text\'\nThe target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. It is implemented in terms of os.rename() and gives the same guarantees. Changed in version 3.8: Added return value, return the new Path instance. Path.replace(target)\nRename this file or directory to the given target, and return a new Path instance pointing to target. If target\npoints to an existing file or empty directory, it will be unconditionally replaced. The target path may be absolute or relative. Relative paths are interpreted relative to the current working\ndirectory, not the directory of the Path object. Changed in version 3.8: Added return value, return the new Path instance. Path.unlink(missing_ok=False)\nRemove this file or symbolic link. If the path points to a directory, use Path.rmdir() instead. If missing_ok is false (the default), FileNotFoundError is raised if the path does not exist. If missing_ok is true, FileNotFoundError exceptions will be ignored (same behavior as the POSIX rm -f\ncommand). Changed in version 3.8: The missing_ok parameter was added. 460\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.rmdir()\nRemove this directory. The directory must be empty. Permissions and ownership\nPath.owner(*, follow_symlinks=True)\nReturn the name of the user owning the file.')",0.0028819449177115435,0.030569354222392056,0.09814121523639965,0.5687604546546936,0.7672366
"""Least Astonishment"" and the Mutable Default Argument","Actually, this is not a design flaw, and it is not because of internals or performance. It comes simply from the fact that functions in Python are 
first-class objects
, and not only a piece of code.


As soon as you think of it this way, then it completely makes sense: a function is an 
object
 being evaluated on its definition; default parameters are kind of 
""member data""
 and therefore their state may change from one call to the other - exactly as in any other object.


In any case, the Effbot (
Fredrik Lundh
) has a very nice explanation of the reasons for this behavior in 
Default Parameter Values in Python
. I found it very clear, and I really suggest reading it for a better knowledge of how function objects work.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . 1962\n30.7.6\nInheritance\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1962\n30.7.7\nRe-ordering of keyword-only parameters in __init__() . . . . . . . . . . . . . . . . . 1962\n30.7.8\nDefault factory functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1963\n30.7.9\nMutable default values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1963\n30.7.10 Descriptor-typed fields\n. . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . 23\n4.9\nMore on Defining Functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.9.1\nDefault Argument Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.9.2\nKeyword Arguments\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.9.3\nSpecial parameters\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.9.4\nArbitrary Argument Lists . . . . . . . . . . . . . . .\n\n[3] Default parameter values are evaluated from left to right when the function definition is executed. This means\nthat the expression is evaluated once, when the function is defined, and that the same “pre-computed” value is used\nfor each call. This is especially important to understand when a default parameter value is a mutable object, such as\na list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default parameter\nvalue is in effect modified. This is generally not what was intended. A way around this is to use None as the default,\nand explicitly test for it in the body of the function, e.g. :\ndef whats_on_the_telly(penguin=None):\nif penguin is None:\npenguin = []\npenguin.append(""property of the zoo"")\nreturn penguin\nFunction call semantics are described in more detail in section Calls. A function call always assigns values to all pa-\nrameters mentioned in the parameter list, either from positional arguments, from keyword arguments, or from default\nvalues. If the form “*identifier” is present, it is initialized to a tuple receiving any excess positional parameters,\ndefaulting to the empty tuple. If the form “**identifier” is present, it is initialized to a new ordered mapping\nreceiving any excess keyword arguments, defaulting to a new empty mapping of the same type. Parameters after\n“*” or “*identifier” are keyword-only parameters and may only be passed by keyword arguments. Parameters\nbefore “/” are positional-only parameters and may only be passed by positional arguments. Changed in version 3.8: The / function parameter syntax may be used to indicate positional-only parameters. See\nPEP 570 for details. Parameters may have an annotation of the form “: expression” following the parameter name. Any parameter\nmay have an annotation, even those of the form *identifier or **identifier. (As a special case, parameters\nof the form *identifier may have an annotation “: *expression”.) Functions may have “return” annotation\nof the form “-> expression” after the parameter list. These annotations can be any valid Python expression. The presence of annotations does not change the semantics of a function. The annotation values are available as\nvalues of a dictionary keyed by the parameters’ names in the __annotations__ attribute of the function object. If\nthe annotations import from __future__ is used, annotations are preserved as strings at runtime which enables\npostponed evaluation. Otherwise, they are evaluated when the function definition is executed. In this case annotations\nmay be evaluated in a different order than they appear in the source code. Changed in version 3.11: Parameters of the form “*identifier” may have an annotation “: *expression”. See\nPEP 646. It is also possible to create anonymous functions (functions not bound to a name), for immediate use in expressions. This uses lambda expressions, described in section Lambdas. Note that the lambda expression is merely a shorthand\nfor a simplified function definition; a function defined in a “def” statement can be passed around or assigned to\nanother name just like a function defined by a lambda expression. The “def” form is actually more powerful since it\nallows the execution of multiple statements and annotations. 124\nChapter 8. Compound statements\n\nThe Python Language Reference, Release 3.13.2\nProgrammer’s note: Functions are first-class objects. A “def” statement executed inside a function definition\ndefines a local function that can be returned or passed around. Free variables used in the nested function can access\nthe local variables of the function containing the def. See section Naming and binding for details. µ See also\nPEP 3107 - Function Annotations\nThe original specification for function annotations. PEP 484 - Type Hints\nDefinition of a standard meaning for annotations: type hints. PEP 526 - Syntax for Variable Annotations\nAbility to type hint variable declarations, including class variables and instance variables. PEP 563 - Postponed Evaluation of Annotations\nSupport for forward references within annotations by preserving annotations in a string form at runtime\ninstead of eager evaluation. PEP 318 - Decorators for Functions and Methods\nFunction and method decorators were introduced. Class decorators were introduced in PEP 3129. 8.8 Class definitions\nA class definition defines a class object (see section The standard type hierarchy):\nclassdef\n::= [decorators] ""class"" classname [type_params] [inheritance] "":"" suite\ninheritance ::= ""("" [argument_list] "")""\nclassname\n::= identifier\nA class definition is an executable statement. The inheritance list usually gives a list of base classes (see Metaclasses\nfor more advanced uses), so each item in the list should evaluate to a class object which allows subclassing. Classes\nwithout an inheritance list inherit, by default, from the base class object; hence,\nclass Foo:\npass\nis equivalent to\nclass Foo(object):\npass\nThe class’s suite is then executed in a new execution frame (see Naming and binding), using a newly created local\nnamespace and the original global namespace. (Usually, the suite contains mostly function definitions.) When the\nclass’s suite finishes execution, its execution frame is discarded but its local namespace is saved.5 A class object is\nthen created using the inheritance list for the base classes and the saved local namespace for the attribute dictionary. The class name is bound to this class object in the original local namespace. The order in which attributes are defined in the class body is preserved in the new class’s __dict__. Note that this\nis reliable only right after the class is created and only for classes that were defined using the definition syntax. Class creation can be customized heavily using metaclasses. Classes can also be decorated: just like when decorating functions,\n@f1(arg)\n@f2\nclass Foo: pass\n5 A string literal appearing as the first statement in the class body is transformed into the namespace’s __doc__ item and therefore the class’s\ndocstring.')",2.243625343471912e-155,0.07100591715976332,0.20873262162255385,0.36603569984436035,0.14206676
What does ** (double star/asterisk) and * (star/asterisk) do for parameters?,"The 
*args
 and 
**kwargs
 are common idioms to allow an arbitrary number of arguments to functions, as described in the section 
more on defining functions
 in the Python tutorial.


The 
*args
 will give you all positional arguments 
as a tuple
:


def foo(*args):
    for a in args:
        print(a)        

foo(1)
# 1

foo(1, 2, 3)
# 1
# 2
# 3



The 
**kwargs
 will give you all
keyword arguments as a dictionary:


def bar(**kwargs):
    for a in kwargs:
        print(a, kwargs[a])  

bar(name='one', age=27)
# name one
# age 27



Both idioms can be mixed with normal arguments to allow a set of fixed and some variable arguments:


def foo(kind, *args, bar=None, **kwargs):
    print(kind, args, bar, kwargs)

foo(123, 'a', 'b', apple='red')
# 123 ('a', 'b') None {'apple': 'red'}



It is also possible to use this the other way around:


def foo(a, b, c):
    print(a, b, c)

obj = {'b':10, 'c':'lee'}

foo(100, **obj)
# 100 10 lee



Another usage of the 
*l
 idiom is to 
unpack argument lists
 when calling a function.


def foo(bar, lee):
    print(bar, lee)

baz = [1, 2]

foo(*baz)
# 1 2



In Python 3 it is possible to use 
*l
 on the left side of an assignment (
Extended Iterable Unpacking
), though it gives a list instead of a tuple in this context:


first, *rest = [1, 2, 3, 4]
# first = 1
# rest = [2, 3, 4]



Also Python 3 adds a new semantic (refer 
PEP 3102
):


def func(arg1, arg2, arg3, *, kwarg1, kwarg2):
    pass



Such function accepts only 3 positional arguments, and everything after 
*
 can only be passed as keyword arguments.


Note:


A Python 
dict
, semantically used for keyword argument passing, is arbitrarily ordered. However, in Python 3.6+, keyword arguments are guaranteed to remember insertion order.
""The order of elements in 
**kwargs
 now corresponds to the order in which keyword arguments were passed to the function."" - 
What’s New In Python 3.6
.
In fact, all dicts in CPython 3.6 will remember insertion order as an implementation detail, and this becomes standard in Python 3.7.

","('Answer: The context does not provide a clear explanation of what `*` and `**` do for parameters.\n\nReferences: None\n', '[1] duplicates parameters but without annotations\n# or type comments, and if there\'s no comma after a parameter, we expect\n# a colon, not a close parenthesis. (For more, see parameters above.) #\nlambda_parameters:\n| lambda_slash_no_default lambda_param_no_default* lambda_param_with_default*␣\n,→[lambda_star_etc]\n| lambda_slash_with_default lambda_param_with_default* [lambda_star_etc]\n| lambda_param_no_default+ lambda_param_with_default* [lambda_star_etc]\n| lambda_param_with_default+ [lambda_star_etc]\n| lambda_star_etc\nlambda_slash_no_default:\n| lambda_param_no_default+ \'/\' \',\'\n| lambda_param_no_default+ \'/\' &\':\'\n(continues on next page)\n147\n\nThe Python Language Reference, Release 3.13.2\n(continued from previous page)\nlambda_slash_with_default:\n| lambda_param_no_default* lambda_param_with_default+ \'/\' \',\'\n| lambda_param_no_default* lambda_param_with_default+ \'/\' &\':\'\nlambda_star_etc:\n| \'*\' lambda_param_no_default lambda_param_maybe_default* [lambda_kwds]\n| \'*\' \',\' lambda_param_maybe_default+ [lambda_kwds]\n| lambda_kwds\nlambda_kwds:\n| \'**\' lambda_param_no_default\nlambda_param_no_default:\n| lambda_param \',\'\n| lambda_param &\':\'\nlambda_param_with_default:\n| lambda_param default \',\'\n| lambda_param default &\':\'\nlambda_param_maybe_default:\n| lambda_param default? \',\'\n| lambda_param default? &\':\'\nlambda_param: NAME\n# LITERALS\n# ========\nfstring_middle:\n| fstring_replacement_field\n| FSTRING_MIDDLE\nfstring_replacement_field:\n| \'{\' annotated_rhs \'=\'? [fstring_conversion] [fstring_full_format_spec] \'}\'\nfstring_conversion:\n| ""!"" NAME\nfstring_full_format_spec:\n| \':\' fstring_format_spec*\nfstring_format_spec:\n| FSTRING_MIDDLE\n| fstring_replacement_field\nfstring:\n| FSTRING_START fstring_middle* FSTRING_END\nstring: STRING\nstrings: (fstring|string)+\nlist:\n| \'[\' [star_named_expressions] \']\'\ntuple:\n| \'(\' [star_named_expression \',\' [star_named_expressions]\n] \')\'\nset: \'{\' star_named_expressions \'}\'\n# Dicts\n# -----\ndict:\n(continues on next page)\n148\nChapter 10. Full Grammar specification\n\nThe Python Language Reference, Release 3.13.2\n(continued from previous page)\n| \'{\' [double_starred_kvpairs] \'}\'\ndouble_starred_kvpairs: \',\'.double_starred_kvpair+ [\',\']\ndouble_starred_kvpair:\n| \'**\' bitwise_or\n| kvpair\nkvpair: expression \':\' expression\n# Comprehensions & Generators\n# ---------------------------\nfor_if_clauses:\n| for_if_clause+\nfor_if_clause:\n| \'async\' \'for\' star_targets \'in\' ~ disjunction (\'if\' disjunction )*\n| \'for\' star_targets \'in\' ~ disjunction (\'if\' disjunction )*\nlistcomp:\n| \'[\' named_expression for_if_clauses \']\'\nsetcomp:\n| \'{\' named_expression for_if_clauses \'}\'\ngenexp:\n| \'(\' ( assignment_expression | expression ! \':=\') for_if_clauses \')\'\ndictcomp:\n| \'{\' kvpair for_if_clauses \'}\'\n# FUNCTION CALL ARGUMENTS\n# =======================\narguments:\n| args [\',\'] &\')\'\nargs:\n| \',\'. (starred_expression | ( assignment_expression | expression ! \':=\') ! \'=\')+␣\n,→[\',\' kwargs ]\n| kwargs\nkwargs:\n| \',\'.kwarg_or_starred+ \',\' \',\'.kwarg_or_double_starred+\n| \',\'.kwarg_or_starred+\n| \',\'.kwarg_or_double_starred+\nstarred_expression:\n| \'*\' expression\nkwarg_or_starred:\n| NAME \'=\' expression\n| starred_expression\nkwarg_or_double_starred:\n(continues on next page)\n149\n\nThe Python Language Reference, Release 3.13.2\n(continued from previous page)\n| NAME \'=\' expression\n| \'**\' expression\n# ASSIGNMENT TARGETS\n# ==================\n# Generic targets\n# ---------------\n# NOTE: star_targets may contain *bitwise_or, targets may not. star_targets:\n| star_target ! \',\'\n| star_target (\',\' star_target )* [\',\']\nstar_targets_list_seq: \',\'.star_target+ [\',\']\nstar_targets_tuple_seq:\n| star_target (\',\' star_target )+ [\',\']\n| star_target \',\'\nstar_target:\n| \'*\' (! \'*\' star_target)\n| target_with_star_atom\ntarget_with_star_atom:\n| t_primary \'.\' NAME !t_lookahead\n| t_primary \'[\' slices \']\' !t_lookahead\n| star_atom\nstar_atom:\n| NAME\n| \'(\' target_with_star_atom \')\'\n| \'(\' [star_targets_tuple_seq] \')\'\n| \'[\' [star_targets_list_seq] \']\'\nsingle_target:\n| single_subscript_attribute_target\n| NAME\n| \'(\' single_target \')\'\nsingle_subscript_attribute_target:\n| t_primary \'.\' NAME !t_lookahead\n| t_primary \'[\' slices \']\' !t_lookahead\nt_primary:\n| t_primary \'.\' NAME &t_lookahead\n| t_primary \'[\' slices \']\' &t_lookahead\n| t_primary genexp &t_lookahead\n| t_primary \'(\' [arguments] \')\' &t_lookahead\n| atom &t_lookahead\nt_lookahead: \'(\' | \'[\' | \'.\' # Targets for del statements\n# --------------------------\n(continues on next page)\n150\nChapter 10. Full Grammar specification\n\nThe Python Language Reference, Release 3.13.2\n(continued from previous page)\ndel_targets: \',\'.del_target+ [\',\']\ndel_target:\n| t_primary \'.\' NAME !t_lookahead\n| t_primary \'[\' slices \']\' !t_lookahead\n| del_t_atom\ndel_t_atom:\n| NAME\n| \'(\' del_target \')\'\n| \'(\' [del_targets] \')\'\n| \'[\' [del_targets] \']\'\n# TYPING ELEMENTS\n# ---------------\n# type_expressions allow */** but ignore them\ntype_expressions:\n| \',\'.expression+ \',\' \'*\' expression \',\' \'**\' expression\n| \',\'.expression+ \',\' \'*\' expression\n| \',\'.expression+ \',\' \'**\' expression\n| \'*\' expression \',\' \'**\' expression\n| \'*\' expression\n| \'**\' expression\n| \',\'.expression+\nfunc_type_comment:\n| NEWLINE TYPE_COMMENT &(NEWLINE INDENT)\n# Must be followed by indented block\n| TYPE_COMMENT\n# ========================= END OF THE GRAMMAR ===========================\n# ========================= START OF INVALID RULES =======================\n151\n\nThe Python Language Reference, Release 3.13.2\n152\nChapter 10. Full Grammar specification\n\nAPPENDIX\nA\nGLOSSARY\n>>>\nThe default Python prompt of the interactive shell. Often seen for code examples which can be executed\ninteractively in the interpreter. ...\nCan refer to:\n• The default Python prompt of the interactive shell when entering the code for an indented code block,\nwhen within a pair of matching left and right delimiters (parentheses, square brackets, curly braces or\ntriple quotes), or after specifying a decorator. • The Ellipsis built-in constant. abstract base class\nAbstract base classes complement duck-typing by providing a way to define interfaces when other techniques\nlike hasattr() would be clumsy or subtly wrong (for example with magic methods). ABCs introduce virtual\nsubclasses, which are classes that don’t inherit from a class but are still recognized by isinstance() and\nissubclass(); see the abc module documentation. Python comes with many built-in ABCs for data struc-\ntures (in the collections.abc module), numbers (in the numbers module), streams (in the io module),\nimport finders and loaders (in the importlib.abc module). You can create your own ABCs with the abc\nmodule. annotation\nA label associated with a variable, a class attribute or a function parameter or return value, used by convention\nas a type hint. Annotations of local variables cannot be accessed at runtime, but annotations of global variables, class at-\ntributes, and functions are stored in the __annotations__ special attribute of modules, classes, and func-\ntions, respectively. See variable annotation, function annotation, PEP 484 and PEP 526, which describe this functionality. Also\nsee annotations-howto for best practices on working with annotations. argument\nA value passed to a function (or method) when calling the function. There are two kinds of argument:\n• keyword argument: an argument preceded by an identifier (e.g. name=) in a function call or passed as a\nvalue in a dictionary preceded by **. For example, 3 and 5 are both keyword arguments in the following\ncalls to complex():\ncomplex(real=3, imag=5)\ncomplex(**{\'real\': 3, \'imag\': 5})\n• positional argument: an argument that is not a keyword argument. Positional arguments can appear at the\nbeginning of an argument list and/or be passed as elements of an iterable preceded by *. For example, 3\nand 5 are both positional arguments in the following calls:\ncomplex(3, 5)\ncomplex(*(3, 5))\n153\n\nThe Python Language Reference, Release 3.13.2\nArguments are assigned to the named local variables in a function body. See the Calls section for the rules\ngoverning this assignment. Syntactically, any expression can be used to represent an argument; the evaluated\nvalue is assigned to the local variable. See also the parameter glossary entry, the FAQ question on the difference between arguments and parameters,\nand PEP 362.\nasynchronous context manager\nAn object which controls the environment seen in an async with statement by defining __aenter__() and\n__aexit__() methods. Introduced by PEP 492.\nasynchronous generator\nA function which returns an asynchronous generator iterator. It looks like a coroutine function defined with\nasync def except that it contains yield expressions for producing a series of values usable in an async\nfor loop. Usually refers to an asynchronous generator function, but may refer to an asynchronous generator iterator in\nsome contexts. In cases where the intended meaning isn’t clear, using the full terms avoids ambiguity. An asynchronous generator function may contain await expressions as well as async for, and async with\nstatements. asynchronous generator iterator\nAn object created by a asynchronous generator function. This is an asynchronous iterator which when called using the __anext__() method returns an awaitable object\nwhich will execute the body of the asynchronous generator function until the next yield expression. Each yield temporarily suspends processing, remembering the execution state (including local variables and\npending try-statements). When the asynchronous generator iterator effectively resumes with another awaitable\nreturned by __anext__(), it picks up where it left off.\n\n[2] . . . . . . . . . . . . . 23\n4.9\nMore on Defining Functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.9.1\nDefault Argument Values . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\n4.9.2\nKeyword Arguments\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\n4.9.3\nSpecial parameters\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n4.9.4\nArbitrary Argument Lists . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n12.2 StrEnum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n12.3 IntFlag . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n12.4 Flag . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n12.5 Others . . . . . . . . . . . . . . . . . . . . . . . . . .')",3.3207805351509826e-79,0.0737527114967462,0.25273493189768736,0.5036130547523499,0.35739577
How can I access environment variables in Python?,"Environment variables are accessed through 
os.environ
:


import os
print(os.environ['HOME'])



To see a list of all environment variables:


print(os.environ)





If a key is not present, attempting to access it will raise a 
KeyError
. To avoid this:


# Returns `None` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST'))

# Returns `default_value` if the key doesn't exist
print(os.environ.get('KEY_THAT_MIGHT_EXIST', default_value))

# Returns `default_value` if the key doesn't exist
print(os.getenv('KEY_THAT_MIGHT_EXIST', default_value))


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] Thus, double-clicking an installed script in a Windows Explorer window should run it with the\ncorrect interpreter without the environment needing to be activated or on the PATH. 29.2. venv — Creation of virtual environments\n1893\n\nThe Python Library Reference, Release 3.13.2\nWhen a virtual environment has been activated, the VIRTUAL_ENV environment variable is set to the path of the\nenvironment. Since explicitly activating a virtual environment is not required to use it, VIRTUAL_ENV cannot be\nrelied upon to determine whether a virtual environment is being used. Á Warning\nBecause scripts installed in environments should not expect the environment to be activated, their shebang lines\ncontain the absolute paths to their environment’s interpreters. Because of this, environments are inherently non-\nportable, in the general case. You should always have a simple means of recreating an environment (for example,\nif you have a requirements file requirements.txt, you can invoke pip install -r requirements.txt\nusing the environment’s pip to install all of the packages needed by the environment). If for any reason you need\nto move the environment to a new location, you should recreate it at the desired location and delete the one at the\nold location. If you move an environment because you moved a parent directory of it, you should recreate the\nenvironment in its new location. Otherwise, software installed into the environment may not work as expected. You can deactivate a virtual environment by typing deactivate in your shell. The exact mechanism is platform-\nspecific and is an internal implementation detail (typically, a script or shell function will be used). 29.2.3 API\nThe high-level method described above makes use of a simple API which provides mechanisms for third-party virtual\nenvironment creators to customize environment creation according to their needs, the EnvBuilder class. class venv.EnvBuilder(system_site_packages=False, clear=False, symlinks=False, upgrade=False,\nwith_pip=False, prompt=None, upgrade_deps=False, *, scm_ignore_files=frozenset())\nThe EnvBuilder class accepts the following keyword arguments on instantiation:\n• system_site_packages – a boolean value indicating that the system Python site-packages should be avail-\nable to the environment (defaults to False). • clear – a boolean value which, if true, will delete the contents of any existing target directory, before\ncreating the environment. • symlinks – a boolean value indicating whether to attempt to symlink the Python binary rather than copy-\ning. • upgrade – a boolean value which, if true, will upgrade an existing environment with the running Python\n- for use when that Python has been upgraded in-place (defaults to False). • with_pip – a boolean value which, if true, ensures pip is installed in the virtual environment. This uses\nensurepip with the --default-pip option. • prompt – a string to be used after virtual environment is activated (defaults to None which means directory\nname of the environment would be used). If the special string ""."" is provided, the basename of the\ncurrent directory is used as the prompt. • upgrade_deps – Update the base venv modules to the latest on PyPI\n• scm_ignore_files – Create ignore files based for the specified source control managers (SCM) in the\niterable. Support is defined by having a method named create_{scm}_ignore_file. The only value\nsupported by default is ""git"" via create_git_ignore_file(). Changed in version 3.4: Added the with_pip parameter\nChanged in version 3.6: Added the prompt parameter\nChanged in version 3.9: Added the upgrade_deps parameter\nChanged in version 3.13: Added the scm_ignore_files parameter\nEnvBuilder may be used as a base class. 1894\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\ncreate(env_dir)\nCreate a virtual environment by specifying the target directory (absolute or relative to the current direc-\ntory) which is to contain the virtual environment. The create method will either create the environment\nin the specified directory, or raise an appropriate exception. The create method of the EnvBuilder class illustrates the hooks available for subclass customization:\ndef create(self, env_dir):\n""""""\nCreate a virtualized Python environment in a directory. env_dir is the target directory to create an environment in.\n"""""" env_dir = os.path.abspath(env_dir)\ncontext = self.ensure_directories(env_dir)\nself.create_configuration(context)\nself.setup_python(context)\nself.setup_scripts(context)\nself.post_setup(context)\nEach of the methods ensure_directories(), create_configuration(), setup_python(),\nsetup_scripts() and post_setup() can be overridden. ensure_directories(env_dir)\nCreates the environment directory and all necessary subdirectories that don’t already exist, and returns\na context object. This context object is just a holder for attributes (such as paths) for use by the other\nmethods. If the EnvBuilder is created with the arg clear=True, contents of the environment directory\nwill be cleared and then all necessary subdirectories will be recreated. The returned context object is a types.SimpleNamespace with the following attributes:\n• env_dir - The location of the virtual environment. Used for __VENV_DIR__ in activation scripts\n(see install_scripts()). • env_name - The name of the virtual environment. Used for __VENV_NAME__ in activation scripts\n(see install_scripts()). • prompt - The prompt to be used by the activation scripts. Used for __VENV_PROMPT__ in activation\nscripts (see install_scripts()). • executable - The underlying Python executable used by the virtual environment. This takes into\naccount the case where a virtual environment is created from another virtual environment. • inc_path - The include path for the virtual environment. • lib_path - The purelib path for the virtual environment. • bin_path - The script path for the virtual environment. • bin_name - The name of the script path relative to the virtual environment location. Used for\n__VENV_BIN_NAME__ in activation scripts (see install_scripts()). • env_exe - The name of the Python interpreter in the virtual environment. Used for\n__VENV_PYTHON__ in activation scripts (see install_scripts()). • env_exec_cmd - The name of the Python interpreter, taking into account filesystem redirections. This can be used to run Python in the virtual environment.\n\n[2] On Windows, “shebang” line processing is supported if you have the\nlauncher installed. Thus, double-clicking an installed script in a Windows Explorer window should run it with the\ncorrect interpreter without the environment needing to be activated or on the PATH. 29.2. venv — Creation of virtual environments\n1893\n\nThe Python Library Reference, Release 3.13.2\nWhen a virtual environment has been activated, the VIRTUAL_ENV environment variable is set to the path of the\nenvironment. Since explicitly activating a virtual environment is not required to use it, VIRTUAL_ENV cannot be\nrelied upon to determine whether a virtual environment is being used. Á Warning\nBecause scripts installed in environments should not expect the environment to be activated, their shebang lines\ncontain the absolute paths to their environment’s interpreters. Because of this, environments are inherently non-\nportable, in the general case. You should always have a simple means of recreating an environment (for example,\nif you have a requirements file requirements.txt, you can invoke pip install -r requirements.txt\nusing the environment’s pip to install all of the packages needed by the environment). If for any reason you need\nto move the environment to a new location, you should recreate it at the desired location and delete the one at the\nold location. If you move an environment because you moved a parent directory of it, you should recreate the\nenvironment in its new location. Otherwise, software installed into the environment may not work as expected. You can deactivate a virtual environment by typing deactivate in your shell. The exact mechanism is platform-\nspecific and is an internal implementation detail (typically, a script or shell function will be used). 29.2.3 API\nThe high-level method described above makes use of a simple API which provides mechanisms for third-party virtual\nenvironment creators to customize environment creation according to their needs, the EnvBuilder class. class venv.EnvBuilder(system_site_packages=False, clear=False, symlinks=False, upgrade=False,\nwith_pip=False, prompt=None, upgrade_deps=False, *, scm_ignore_files=frozenset())\nThe EnvBuilder class accepts the following keyword arguments on instantiation:\n• system_site_packages – a boolean value indicating that the system Python site-packages should be avail-\nable to the environment (defaults to False). • clear – a boolean value which, if true, will delete the contents of any existing target directory, before\ncreating the environment. • symlinks – a boolean value indicating whether to attempt to symlink the Python binary rather than copy-\ning. • upgrade – a boolean value which, if true, will upgrade an existing environment with the running Python\n- for use when that Python has been upgraded in-place (defaults to False). • with_pip – a boolean value which, if true, ensures pip is installed in the virtual environment. This uses\nensurepip with the --default-pip option. • prompt – a string to be used after virtual environment is activated (defaults to None which means directory\nname of the environment would be used). If the special string ""."" is provided, the basename of the\ncurrent directory is used as the prompt. • upgrade_deps – Update the base venv modules to the latest on PyPI\n• scm_ignore_files – Create ignore files based for the specified source control managers (SCM) in the\niterable. Support is defined by having a method named create_{scm}_ignore_file. The only value\nsupported by default is ""git"" via create_git_ignore_file(). Changed in version 3.4: Added the with_pip parameter\nChanged in version 3.6: Added the prompt parameter\nChanged in version 3.9: Added the upgrade_deps parameter\nChanged in version 3.13: Added the scm_ignore_files parameter\nEnvBuilder may be used as a base class. 1894\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\ncreate(env_dir)\nCreate a virtual environment by specifying the target directory (absolute or relative to the current direc-\ntory) which is to contain the virtual environment. The create method will either create the environment\nin the specified directory, or raise an appropriate exception. The create method of the EnvBuilder class illustrates the hooks available for subclass customization:\ndef create(self, env_dir):\n""""""\nCreate a virtualized Python environment in a directory. env_dir is the target directory to create an environment in.\n"""""" env_dir = os.path.abspath(env_dir)\ncontext = self.ensure_directories(env_dir)\nself.create_configuration(context)\nself.setup_python(context)\nself.setup_scripts(context)\nself.post_setup(context)\nEach of the methods ensure_directories(), create_configuration(), setup_python(),\nsetup_scripts() and post_setup() can be overridden. ensure_directories(env_dir)\nCreates the environment directory and all necessary subdirectories that don’t already exist, and returns\na context object. This context object is just a holder for attributes (such as paths) for use by the other\nmethods. If the EnvBuilder is created with the arg clear=True, contents of the environment directory\nwill be cleared and then all necessary subdirectories will be recreated. The returned context object is a types.SimpleNamespace with the following attributes:\n• env_dir - The location of the virtual environment. Used for __VENV_DIR__ in activation scripts\n(see install_scripts()). • env_name - The name of the virtual environment. Used for __VENV_NAME__ in activation scripts\n(see install_scripts()). • prompt - The prompt to be used by the activation scripts. Used for __VENV_PROMPT__ in activation\nscripts (see install_scripts()). • executable - The underlying Python executable used by the virtual environment. This takes into\naccount the case where a virtual environment is created from another virtual environment. • inc_path - The include path for the virtual environment. • lib_path - The purelib path for the virtual environment. • bin_path - The script path for the virtual environment. • bin_name - The name of the script path relative to the virtual environment location. Used for\n__VENV_BIN_NAME__ in activation scripts (see install_scripts()). • env_exe - The name of the Python interpreter in the virtual environment. Used for\n__VENV_PYTHON__ in activation scripts (see install_scripts()). • env_exec_cmd - The name of the Python interpreter, taking into account filesystem redirections.\n\n[3] This means that the script will run with that\ninterpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the\nlauncher installed. Thus, double-clicking an installed script in a Windows Explorer window should run it with the\ncorrect interpreter without the environment needing to be activated or on the PATH. 29.2. venv — Creation of virtual environments\n1893\n\nThe Python Library Reference, Release 3.13.2\nWhen a virtual environment has been activated, the VIRTUAL_ENV environment variable is set to the path of the\nenvironment. Since explicitly activating a virtual environment is not required to use it, VIRTUAL_ENV cannot be\nrelied upon to determine whether a virtual environment is being used. Á Warning\nBecause scripts installed in environments should not expect the environment to be activated, their shebang lines\ncontain the absolute paths to their environment’s interpreters. Because of this, environments are inherently non-\nportable, in the general case. You should always have a simple means of recreating an environment (for example,\nif you have a requirements file requirements.txt, you can invoke pip install -r requirements.txt\nusing the environment’s pip to install all of the packages needed by the environment). If for any reason you need\nto move the environment to a new location, you should recreate it at the desired location and delete the one at the\nold location. If you move an environment because you moved a parent directory of it, you should recreate the\nenvironment in its new location. Otherwise, software installed into the environment may not work as expected. You can deactivate a virtual environment by typing deactivate in your shell. The exact mechanism is platform-\nspecific and is an internal implementation detail (typically, a script or shell function will be used). 29.2.3 API\nThe high-level method described above makes use of a simple API which provides mechanisms for third-party virtual\nenvironment creators to customize environment creation according to their needs, the EnvBuilder class. class venv.EnvBuilder(system_site_packages=False, clear=False, symlinks=False, upgrade=False,\nwith_pip=False, prompt=None, upgrade_deps=False, *, scm_ignore_files=frozenset())\nThe EnvBuilder class accepts the following keyword arguments on instantiation:\n• system_site_packages – a boolean value indicating that the system Python site-packages should be avail-\nable to the environment (defaults to False). • clear – a boolean value which, if true, will delete the contents of any existing target directory, before\ncreating the environment. • symlinks – a boolean value indicating whether to attempt to symlink the Python binary rather than copy-\ning. • upgrade – a boolean value which, if true, will upgrade an existing environment with the running Python\n- for use when that Python has been upgraded in-place (defaults to False). • with_pip – a boolean value which, if true, ensures pip is installed in the virtual environment. This uses\nensurepip with the --default-pip option. • prompt – a string to be used after virtual environment is activated (defaults to None which means directory\nname of the environment would be used). If the special string ""."" is provided, the basename of the\ncurrent directory is used as the prompt. • upgrade_deps – Update the base venv modules to the latest on PyPI\n• scm_ignore_files – Create ignore files based for the specified source control managers (SCM) in the\niterable. Support is defined by having a method named create_{scm}_ignore_file. The only value\nsupported by default is ""git"" via create_git_ignore_file(). Changed in version 3.4: Added the with_pip parameter\nChanged in version 3.6: Added the prompt parameter\nChanged in version 3.9: Added the upgrade_deps parameter\nChanged in version 3.13: Added the scm_ignore_files parameter\nEnvBuilder may be used as a base class. 1894\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\ncreate(env_dir)\nCreate a virtual environment by specifying the target directory (absolute or relative to the current direc-\ntory) which is to contain the virtual environment. The create method will either create the environment\nin the specified directory, or raise an appropriate exception. The create method of the EnvBuilder class illustrates the hooks available for subclass customization:\ndef create(self, env_dir):\n""""""\nCreate a virtualized Python environment in a directory. env_dir is the target directory to create an environment in.\n"""""" env_dir = os.path.abspath(env_dir)\ncontext = self.ensure_directories(env_dir)\nself.create_configuration(context)\nself.setup_python(context)\nself.setup_scripts(context)\nself.post_setup(context)\nEach of the methods ensure_directories(), create_configuration(), setup_python(),\nsetup_scripts() and post_setup() can be overridden. ensure_directories(env_dir)\nCreates the environment directory and all necessary subdirectories that don’t already exist, and returns\na context object. This context object is just a holder for attributes (such as paths) for use by the other\nmethods. If the EnvBuilder is created with the arg clear=True, contents of the environment directory\nwill be cleared and then all necessary subdirectories will be recreated. The returned context object is a types.SimpleNamespace with the following attributes:\n• env_dir - The location of the virtual environment. Used for __VENV_DIR__ in activation scripts\n(see install_scripts()). • env_name - The name of the virtual environment. Used for __VENV_NAME__ in activation scripts\n(see install_scripts()). • prompt - The prompt to be used by the activation scripts. Used for __VENV_PROMPT__ in activation\nscripts (see install_scripts()). • executable - The underlying Python executable used by the virtual environment. This takes into\naccount the case where a virtual environment is created from another virtual environment. • inc_path - The include path for the virtual environment. • lib_path - The purelib path for the virtual environment. • bin_path - The script path for the virtual environment. • bin_name - The name of the script path relative to the virtual environment location. Used for\n__VENV_BIN_NAME__ in activation scripts (see install_scripts()). • env_exe - The name of the Python interpreter in the virtual environment. Used for\n__VENV_PYTHON__ in activation scripts (see install_scripts()).')",6.15401224711966e-156,0.028508077288565095,0.07908816003721797,0.520318329334259,0.44577634
How do I sort a dictionary by value?,"Python 3.7+ or CPython 3.6


Dicts preserve insertion order in Python 3.7+. Same in CPython 3.6, but 
it's an implementation detail
.


>>> x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
>>> {k: v for k, v in sorted(x.items(), key=lambda item: item[1])}
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



or


>>> dict(sorted(x.items(), key=lambda item: item[1]))
{0: 0, 2: 1, 1: 2, 4: 3, 3: 4}



Older Python


It is not possible to sort a dictionary, only to get a representation of a dictionary that is sorted. Dictionaries are inherently orderless, but other types, such as lists and tuples, are not. So you need an ordered data type to represent sorted values, which will be a list—probably a list of tuples.


For instance,


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(1))



sorted_x
 will be a list of tuples sorted by the second element in each tuple. 
dict(sorted_x) == x
.


And for those wishing to sort on keys instead of values:


import operator
x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=operator.itemgetter(0))



In Python3 since 
unpacking is not allowed
 we can use


x = {1: 2, 3: 4, 4: 3, 2: 1, 0: 0}
sorted_x = sorted(x.items(), key=lambda kv: kv[1])



If you want the output as a dict, you can use 
collections.OrderedDict
:


import collections

sorted_dict = collections.OrderedDict(sorted_x)


","('Answer: To sort a dictionary by value, you can use the `sorted()` function with a `key` parameter. The `key` parameter should be a function that takes a single argument and returns a key to use for sorting purposes.\n\nReferences: [2, 3]', '[1] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys. For example:\n>>> student_tuples = [\n...\n(\'john\', \'A\', 15),\n...\n(\'jane\', \'B\', 12),\n...\n(\'dave\', \'B\', 10),\n... ]\n>>> sorted(student_tuples, key=lambda student: student[2])\n# sort by age\n[(\'dave\', \'B\', 10), (\'jane\', \'B\', 12), (\'john\', \'A\', 15)]\nThe same technique works for objects with named attributes.\n\n[2] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys.\n\n[3] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord.')",3.8507630450370357e-79,0.11851851851851854,0.29872460314063365,0.5918534398078918,0.67009205
How do I clone a list so that it doesn't change unexpectedly after assignment?,"new_list = my_list
 doesn't actually create a second list. The assignment just copies the reference to the list, not the actual list, so both 
new_list
 and 
my_list
 refer to the same list after the assignment.


To actually copy the list, you have several options:




You can use the built-in 
list.copy()
 method (available since Python 3.3):


new_list = old_list.copy()





You can slice it:


new_list = old_list[:]



Alex Martelli
's opinion (at least 
back in 2007
) about this is, that 
it is a weird syntax and it does not make sense to use it ever
. ;) (In his opinion, the next one is more readable).




You can use the built-in 
list()
 constructor:


new_list = list(old_list)





You can use generic 
copy.copy()
:


import copy
new_list = copy.copy(old_list)



This is a little slower than 
list()
 because it has to find out the datatype of 
old_list
 first.




If you need to copy the elements of the list as well, use generic 
copy.deepcopy()
:


import copy
new_list = copy.deepcopy(old_list)



Obviously the slowest and most memory-needing method, but sometimes unavoidable. This operates recursively; it will handle any number of levels of nested lists (or other containers).






Example:


import copy

class Foo(object):
    def __init__(self, val):
         self.val = val

    def __repr__(self):
        return f'Foo({self.val!r})'

foo = Foo(1)

a = ['foo', foo]
b = a.copy()
c = a[:]
d = list(a)
e = copy.copy(a)
f = copy.deepcopy(a)

# edit orignal list and instance 
a.append('baz')
foo.val = 5

print(f'original: {a}\nlist.copy(): {b}\nslice: {c}\nlist(): {d}\ncopy: {e}\ndeepcopy: {f}')



Result:


original: ['foo', Foo(5), 'baz']
list.copy(): ['foo', Foo(5)]
slice: ['foo', Foo(5)]
list(): ['foo', Foo(5)]
copy: ['foo', Foo(5)]
deepcopy: ['foo', Foo(1)]


","('Answer: To create a copy of a list, you can use `Isorted = L[:]`. This will create a new list with the same elements as the original list.\n\nReferences: [1]\n', '[1] This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable. 2.5.10 I want to do a complicated sort: can you do a Schwartzian Transform in\nPython? The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which\nmaps each element to its “sort value”. In Python, use the key argument for the list.sort() method:\nIsorted = L[:]\nIsorted.sort(key=lambda s: int(s[10:15]))\n2.5.11 How can I sort one list by values from another list? Merge them into an iterator of tuples, sort the resulting list, and then pick out the element you want. >>> list1 = [""what"", ""I\'m"", ""sorting"", ""by""]\n>>> list2 = [""something"", ""else"", ""to"", ""sort""]\n>>> pairs = zip(list1, list2)\n>>> pairs = sorted(pairs)\n>>> pairs\n[(""I\'m"", \'else\'), (\'by\', \'sort\'), (\'sorting\', \'to\'), (\'what\', \'something\')]\n>>> result = [x[1] for x in pairs]\n>>> result\n[\'else\', \'sort\', \'to\', \'something\']\n2.6 Objects\n2.6.1 What is a class? A class is the particular object type created by executing a class statement. Class objects are used as templates to\ncreate instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and meth-\nods of its base classes. This allows an object model to be successively refined by inheritance. You might have a\ngeneric Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox,\nMaildirMailbox, OutlookMailbox that handle various specific mailbox formats. 26\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.2 What is a method? A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined\nas functions inside the class definition:\nclass C:\ndef meth(self, arg):\nreturn arg * 2 + self.attribute\n2.6.3 What is self? Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b,\nc) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called\nmethod will think it is called as meth(x, a, b, c).\n\n[2] they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable. 2.5.10 I want to do a complicated sort: can you do a Schwartzian Transform in\nPython? The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which\nmaps each element to its “sort value”. In Python, use the key argument for the list.sort() method:\nIsorted = L[:]\nIsorted.sort(key=lambda s: int(s[10:15]))\n2.5.11 How can I sort one list by values from another list? Merge them into an iterator of tuples, sort the resulting list, and then pick out the element you want. >>> list1 = [""what"", ""I\'m"", ""sorting"", ""by""]\n>>> list2 = [""something"", ""else"", ""to"", ""sort""]\n>>> pairs = zip(list1, list2)\n>>> pairs = sorted(pairs)\n>>> pairs\n[(""I\'m"", \'else\'), (\'by\', \'sort\'), (\'sorting\', \'to\'), (\'what\', \'something\')]\n>>> result = [x[1] for x in pairs]\n>>> result\n[\'else\', \'sort\', \'to\', \'something\']\n2.6 Objects\n2.6.1 What is a class? A class is the particular object type created by executing a class statement. Class objects are used as templates to\ncreate instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and meth-\nods of its base classes. This allows an object model to be successively refined by inheritance. You might have a\ngeneric Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox,\nMaildirMailbox, OutlookMailbox that handle various specific mailbox formats. 26\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.2 What is a method? A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined\nas functions inside the class definition:\nclass C:\ndef meth(self, arg):\nreturn arg * 2 + self.attribute\n2.6.3 What is self? Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b,\nc) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called\nmethod will think it is called as meth(x, a, b, c). See also Why must ‘self’ be used explicitly in method definitions and calls?. 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it? Use the built-in function isinstance(obj, cls).\n\n[3] Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable. 2.5.10 I want to do a complicated sort: can you do a Schwartzian Transform in\nPython? The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which\nmaps each element to its “sort value”. In Python, use the key argument for the list.sort() method:\nIsorted = L[:]\nIsorted.sort(key=lambda s: int(s[10:15]))\n2.5.11 How can I sort one list by values from another list? Merge them into an iterator of tuples, sort the resulting list, and then pick out the element you want. >>> list1 = [""what"", ""I\'m"", ""sorting"", ""by""]\n>>> list2 = [""something"", ""else"", ""to"", ""sort""]\n>>> pairs = zip(list1, list2)\n>>> pairs = sorted(pairs)\n>>> pairs\n[(""I\'m"", \'else\'), (\'by\', \'sort\'), (\'sorting\', \'to\'), (\'what\', \'something\')]\n>>> result = [x[1] for x in pairs]\n>>> result\n[\'else\', \'sort\', \'to\', \'something\']\n2.6 Objects\n2.6.1 What is a class? A class is the particular object type created by executing a class statement. Class objects are used as templates to\ncreate instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and meth-\nods of its base classes. This allows an object model to be successively refined by inheritance. You might have a\ngeneric Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox,\nMaildirMailbox, OutlookMailbox that handle various specific mailbox formats. 26\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.2 What is a method? A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined\nas functions inside the class definition:\nclass C:\ndef meth(self, arg):\nreturn arg * 2 + self.attribute\n2.6.3 What is self? Self is merely a conventional name for the first argument of a method.')",0.0038080994125168654,0.05148514851485148,0.16336868796870804,0.6138876676559448,0.60283124
How do I pass a variable by reference?,"Arguments are 
passed by assignment
. The rationale behind this is twofold:




the parameter passed in is actually a 
reference
 to an object (but the reference is passed by value)


some data types are mutable, but others aren't




So:




If you pass a 
mutable
 object into a method, the method gets a reference to that same object and you can mutate it to your heart's delight, but if you rebind the reference in the method, the outer scope will know nothing about it, and after you're done, the outer reference will still point at the original object. 


If you pass an 
immutable
 object to a method, you still can't rebind the outer reference, and you can't even mutate the object.




To make it even more clear, let's have some examples. 


List - a mutable type


Let's try to modify the list that was passed to a method:


def try_to_change_list_contents(the_list):
    print('got', the_list)
    the_list.append('four')
    print('changed to', the_list)

outer_list = ['one', 'two', 'three']

print('before, outer_list =', outer_list)
try_to_change_list_contents(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['one', 'two', 'three']
got ['one', 'two', 'three']
changed to ['one', 'two', 'three', 'four']
after, outer_list = ['one', 'two', 'three', 'four']



Since the parameter passed in is a reference to 
outer_list
, not a copy of it, we can use the mutating list methods to change it and have the changes reflected in the outer scope.


Now let's see what happens when we try to change the reference that was passed in as a parameter:


def try_to_change_list_reference(the_list):
    print('got', the_list)
    the_list = ['and', 'we', 'can', 'not', 'lie']
    print('set to', the_list)

outer_list = ['we', 'like', 'proper', 'English']

print('before, outer_list =', outer_list)
try_to_change_list_reference(outer_list)
print('after, outer_list =', outer_list)



Output:


before, outer_list = ['we', 'like', 'proper', 'English']
got ['we', 'like', 'proper', 'English']
set to ['and', 'we', 'can', 'not', 'lie']
after, outer_list = ['we', 'like', 'proper', 'English']



Since the 
the_list
 parameter was passed by value, assigning a new list to it had no effect that the code outside the method could see. The 
the_list
 was a copy of the 
outer_list
 reference, and we had 
the_list
 point to a new list, but there was no way to change where 
outer_list
 pointed.


String - an immutable type


It's immutable, so there's nothing we can do to change the contents of the string


Now, let's try to change the reference


def try_to_change_string_reference(the_string):
    print('got', the_string)
    the_string = 'In a kingdom by the sea'
    print('set to', the_string)

outer_string = 'It was many and many a year ago'

print('before, outer_string =', outer_string)
try_to_change_string_reference(outer_string)
print('after, outer_string =', outer_string)



Output:


before, outer_string = It was many and many a year ago
got It was many and many a year ago
set to In a kingdom by the sea
after, outer_string = It was many and many a year ago



Again, since the 
the_string
 parameter was passed by value, assigning a new string to it had no effect that the code outside the method could see. The 
the_string
 was a copy of the 
outer_string
 reference, and we had 
the_string
 point to a new string, but there was no way to change where 
outer_string
 pointed.


I hope this clears things up a little.


EDIT:
 It's been noted that this doesn't answer the question that @David originally asked, ""Is there something I can do to pass the variable by actual reference?"". Let's work on that.


How do we get around this?


As @Andrea's answer shows, you could return the new value. This doesn't change the way things are passed in, but does let you get the information you want back out:


def return_a_whole_new_string(the_string):
    new_string = something_to_do_with_the_old_string(the_string)
    return new_string

# then you could call it like
my_string = return_a_whole_new_string(my_string)



If you really wanted to avoid using a return value, you could create a class to hold your value and pass it into the function or use an existing class, like a list:


def use_a_wrapper_to_simulate_pass_by_reference(stuff_to_change):
    new_string = something_to_do_with_the_old_string(stuff_to_change[0])
    stuff_to_change[0] = new_string

# then you could call it like
wrapper = [my_string]
use_a_wrapper_to_simulate_pass_by_reference(wrapper)

do_something_with(wrapper[0])



Although this seems a little cumbersome.

","('Answer: To find out how to write a function with output parameters (call by reference), see section 2.2.10.\n\nReferences: [1, 2]\n', '[1] . . . . . . . . . . . . . . . . 11\n2.2.7\nHow can I pass optional or keyword parameters from one function to another? . . . . . . 12\n2.2.8\nWhat is the difference between arguments and parameters? . . . . . . . . . . . . . . . . 12\n2.2.9\nWhy did changing list ‘y’ also change list ‘x’? . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.2.10\nHow do I write a function with output parameters (call by reference)? . . . . . . . . . . . 13\ni\n\n2.2.11\nHow do you make a higher order function in Python? .\n\n[2] . . . . . . . . . . . 12\n2.2.9\nWhy did changing list ‘y’ also change list ‘x’? . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.2.10\nHow do I write a function with output parameters (call by reference)? . . . . . . . . . . . 13\ni\n\n2.2.11\nHow do you make a higher order function in Python? . . . . . . . . . . . . . . . . . . . 14\n2.2.12\nHow do I copy an object in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n2.2.13\nHow can I find the methods or attributes of an object? .\n\n[3] . . . . . . 3\n1.3\nUseful macros\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4\nObjects, Types and Reference Counts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.4.1\nReference Counts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.4.2\nTypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.5\nExceptions\n. . . . . . . . . . . . . . . . . . . . . . . . . . .')",1.2314157842651795e-155,0.0751730959446093,0.06408167698490279,0.4819933772087097,0.39651853
Manually raising (throwing) an exception in Python,"

How do I manually throw/raise an exception in Python?




Use the most specific Exception constructor that semantically fits your issue
.


Be specific in your message, e.g.:


raise ValueError('A very specific bad thing happened.')



Don't raise generic exceptions


Avoid raising a generic 
Exception
. To catch it, you'll have to catch all other more specific exceptions that subclass it.


Problem 1: Hiding bugs


raise Exception('I know Python!') # Don't! If you catch, likely to hide bugs.



For example:


def demo_bad_catch():
    try:
        raise ValueError('Represents a hidden bug, do not catch this')
        raise Exception('This is the exception you expect to handle')
    except Exception as error:
        print('Caught this error: ' + repr(error))

>>> demo_bad_catch()
Caught this error: ValueError('Represents a hidden bug, do not catch this',)



Problem 2: Won't catch


And more specific catches won't catch the general exception:


def demo_no_catch():
    try:
        raise Exception('general exceptions not caught by specific handling')
    except ValueError as e:
        print('we will not catch exception: Exception')
 

>>> demo_no_catch()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in demo_no_catch
Exception: general exceptions not caught by specific handling



Best Practices: 
raise
 statement


Instead, use the most specific Exception constructor that semantically fits your issue
.


raise ValueError('A very specific bad thing happened')



which also handily allows an arbitrary number of arguments to be passed to the constructor:


raise ValueError('A very specific bad thing happened', 'foo', 'bar', 'baz') 



These arguments are accessed by the 
args
 attribute on the 
Exception
 object. For example:


try:
    some_code_that_may_raise_our_value_error()
except ValueError as err:
    print(err.args)



prints


('message', 'foo', 'bar', 'baz')    



In Python 2.5, an actual 
message
 attribute was added to 
BaseException
 in favor of encouraging users to subclass Exceptions and stop using 
args
, but 
the introduction of 
message
 and the original deprecation of args has been retracted
.


Best Practices: 
except
 clause


When inside an except clause, you might want to, for example, log that a specific type of error happened, and then re-raise. The best way to do this while preserving the stack trace is to use a bare raise statement. For example:


logger = logging.getLogger(__name__)

try:
    do_something_in_app_that_breaks_easily()
except AppError as error:
    logger.error(error)
    raise                 # just this!
    # raise AppError      # Don't do this, you'll lose the stack trace!



Don't modify your errors... but if you insist.


You can preserve the stacktrace (and error value) with 
sys.exc_info()
, but 
this is way more error prone
 and 
has compatibility problems between Python 2 and 3
, prefer to use a bare 
raise
 to re-raise.


To explain - the 
sys.exc_info()
 returns the type, value, and traceback.


type, value, traceback = sys.exc_info()



This is the syntax in Python 2 - note this is not compatible with Python 3:


raise AppError, error, sys.exc_info()[2] # avoid this.
# Equivalently, as error *is* the second object:
raise sys.exc_info()[0], sys.exc_info()[1], sys.exc_info()[2]



If you want to, you can modify what happens with your new raise - e.g. setting new 
args
 for the instance:


def error():
    raise ValueError('oops!')

def catch_error_modify_message():
    try:
        error()
    except ValueError:
        error_type, error_instance, traceback = sys.exc_info()
        error_instance.args = (error_instance.args[0] + ' 
',)
        raise error_type, error_instance, traceback



And we have preserved the whole traceback while modifying the args. Note that this is 
not a best practice
 and it is 
invalid syntax
 in Python 3 (making keeping compatibility much harder to work around).


>>> catch_error_modify_message()
Traceback (most recent call last):
  File ""
"", line 1, in 

  File ""
"", line 3, in catch_error_modify_message
  File ""
"", line 2, in error
ValueError: oops! 




In 
Python 3
:


raise error.with_traceback(sys.exc_info()[2])



Again: avoid manually manipulating tracebacks. It's 
less efficient
 and more error prone. And if you're using threading and 
sys.exc_info
 you may even get the wrong traceback (especially if you're using exception handling for control flow - which I'd personally tend to avoid.)


Python 3, Exception chaining


In Python 3, you can chain Exceptions, which preserve tracebacks:


raise RuntimeError('specific message') from error



Be aware:




this 
does
 allow changing the error type raised, and


this is 
not
 compatible with Python 2.




Deprecated Methods:


These can easily hide and even get into production code. You want to raise an exception, and doing them will raise an exception, 
but not the one intended!


Valid in Python 2, but not in Python 3
 is the following:


raise ValueError, 'message' # Don't do this, it's deprecated!



Only 
valid in much older versions of Python
 (2.4 and lower), you may still see people raising strings:


raise 'message' # really really wrong. don't do this.



In all modern versions, this will actually raise a 
TypeError
, because you're not raising a 
BaseException
 type. If you're not checking for the right exception and don't have a reviewer that's aware of the issue, it could get into production.


Example Usage


I raise Exceptions to warn consumers of my API if they're using it incorrectly:


def api_func(foo):
    '''foo should be either 'baz' or 'bar'. returns something very useful.'''
    if foo not in _ALLOWED_ARGS:
        raise ValueError('{foo} wrong, use ""baz"" or ""bar""'.format(foo=repr(foo)))



Create your own error types when apropos




""I want to make an error on purpose, so that it would go into the except""




You can create your own error types, if you want to indicate something specific is wrong with your application, just subclass the appropriate point in the exception hierarchy:


class MyAppLookupError(LookupError):
    '''raise this when there's a lookup error for my app'''



and usage:


if important_key not in resource_dict and not ok_to_be_missing:
    raise MyAppLookupError('resource is missing, and that is not ok.')


","('Answer: The `raise` statement can be used to force a specified exception to occur. The argument indicates the exception to be raised and must be an exception instance or class derived from `BaseException`. If an exception class is passed, it will be implicitly instantiated by calling its constructor with no arguments.\n\nReferences: [1]\n', '[1] Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised. • If the try statement reaches a break, continue or return statement, the finally clause will execute just\nprior to the break, continue or return statement’s execution. • If a finally clause includes a return statement, the returned value will be the one from the finally\nclause’s return statement, not the value from the try clause’s return statement. For example:\n>>> def bool_return():\n...\ntry:\n...\nreturn True\n...\nfinally:\n...\nreturn False\n...\n>>> bool_return()\nFalse\nA more complicated example:\n>>> def divide(x, y):\n...\ntry:\n...\nresult = x / y\n...\nexcept ZeroDivisionError:\n...\nprint(""division by zero!"") ...\nelse:\n...\nprint(""result is"", result)\n...\nfinally:\n...\nprint(""executing finally clause"")\n...\n>>> divide(2, 1)\nresult is 2.0\nexecuting finally clause\n>>> divide(2, 0)\ndivision by zero! executing finally clause\n>>> divide(""2"", ""1"")\nexecuting finally clause\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\ndivide(""2"", ""1"")\n~~~~~~^^^^^^^^^^\nFile ""<stdin>"", line 3, in divide\nresult = x / y\n~~^~~\nTypeError: unsupported operand type(s) for /: \'str\' and \'str\'\nAs you can see, the finally clause is executed in any event.\n\n[2] Standard exception\nnames are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack\ntraceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from\nstandard input. bltin-exceptions lists the built-in exceptions and their meanings. 8.3 Handling Exceptions\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the\nuser for input until a valid integer has been entered, but allows the user to interrupt the program (using Control-\nC or whatever the operating system supports); note that a user-generated interruption is signalled by raising the\nKeyboardInterrupt exception. >>> while True:\n...\ntry:\n...\nx = int(input(""Please enter a number: ""))\n...\nbreak\n...\nexcept ValueError:\n...\nprint(""Oops! That was no valid number. Try again..."")\n... The try statement works as follows. • First, the try clause (the statement(s) between the try and except keywords) is executed. • If no exception occurs, the except clause is skipped and execution of the try statement is finished. • If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions.\n\n[3] The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in\nexceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception\nnames are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack\ntraceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from\nstandard input. bltin-exceptions lists the built-in exceptions and their meanings. 8.3 Handling Exceptions\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the\nuser for input until a valid integer has been entered, but allows the user to interrupt the program (using Control-\nC or whatever the operating system supports); note that a user-generated interruption is signalled by raising the\nKeyboardInterrupt exception. >>> while True:\n...\ntry:\n...\nx = int(input(""Please enter a number: ""))\n...\nbreak\n...\nexcept ValueError:\n...\nprint(""Oops! That was no valid number. Try again..."")\n... The try statement works as follows. • First, the try clause (the statement(s) between the try and except keywords) is executed. • If no exception occurs, the except clause is skipped and execution of the try statement is finished. • If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions.')",0.007513961285080028,0.09384587619563255,0.2780868753441079,0.5734236836433411,0.44097087
Understanding Python super() with __init__() methods,"super()
 lets you avoid referring to the base class explicitly, which can be nice. But the main advantage comes with multiple inheritance, where all sorts of 
fun stuff
 can happen. See the 
standard docs on super
 if you haven't already.


Note that 
the syntax changed in Python 3.0
: you can just say 
super().__init__()
 instead of 
super(ChildB, self).__init__()
 which IMO is quite a bit nicer. The standard docs also refer to a 
guide to using 
super()
 which is quite explanatory.

","('Answer: Super() returns a proxy object that delegates method calls to a parent or sibling class. This is helpful for accessing inherited methods overridden in a class. When called within a class method, super() will use the enclosing class as the type and self as the object. It can be used to refer to parent classes without explicitly naming them.\n\nReferences: [1]\n', ""[1] The @staticmethod form is a function decorator – see function for details. A static method can be called either on the class (such as C.f()) or on an instance (such as C().f()). Moreover, the static method descriptor is also callable, so it can be used in the class definition (such as f()). Static methods in Python are similar to those found in Java or C++. Also, see classmethod() for a variant\nthat is useful for creating alternate class constructors. Like all decorators, it is also possible to call staticmethod as a regular function and do something with its\nresult. This is needed in some cases where you need a reference to a function from a class body and you want\nto avoid the automatic transformation to instance method. For these cases, use this idiom:\ndef regular_function():\n...\nclass C:\nmethod = staticmethod(regular_function)\nFor more information on static methods, see types. Changed in version 3.10: Static methods now inherit the method attributes (__module__, __name__,\n__qualname__, __doc__ and __annotations__), have a new __wrapped__ attribute, and are now\ncallable as regular functions. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a str version of object. See str() for details. str is the built-in string class. For general information about strings, see Text Sequence Type — str. sum(iterable, /, start=0)\nSums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally\nnumbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of\nstrings is by calling ''.join(sequence). To add floating-point values with extended precision, see math. fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument. Changed in version 3.12: Summation of floats switched to an algorithm that gives higher accuracy and better\ncommutativity on most builds. class super\n29\n\nThe Python Library Reference, Release 3.13.2\nclass super(type, object_or_type=None)\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing\ninherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class\nright after the type. For example, if __mro__ of object_or_type is D -> B -> C -> A -> object and the value of type is B,\nthen super() searches C -> A -> object. The __mro__ attribute of the class corresponding to object_or_type lists the method resolution search order\nused by both getattr() and super(). The attribute is dynamic and can change whenever the inheritance\nhierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object,\nisinstance(obj, type) must be true. If the second argument is a type, issubclass(type2, type)\nmust be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument\nsuper()”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately\nenclosing function (typically self). (This means that zero-argument super() will not work as expected\nwithin nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer\nto parent classes without naming them explicitly, thus making the code more maintainable. This use closely\nparallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This\nuse case is unique to Python and is not found in statically compiled languages or languages that only support\nsingle inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes im-\nplement the same method. Good design dictates that such implementations have the same calling signature in\nevery case (because the order of calls is determined at runtime, because that order adapts to changes in the\nclass hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this:\nclass C(B):\ndef method(self, arg):\nsuper().method(arg)\n# This does the same thing as:\n# super(C, self).method(arg)\nIn addition to method lookups, super() also works for attribute lookups. One possible use case for this is\ncalling descriptors in a parent or sibling class. Note that super() is implemented as part of the binding process for explicit dotted attribute lookups such as\nsuper().__getitem__(name). It does so by implementing its own __getattribute__() method for\nsearching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, super()\nis undefined for implicit lookups using statements or operators such as super()[name]. Also note that, aside from the zero argument form, super() is not limited to use inside methods. The two\nargument form specifies the arguments exactly and makes the appropriate references. The zero argument form\nonly works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class\nbeing defined, as well as accessing the current instance for ordinary methods. For practical suggestions on how to design cooperative classes using super(), see guide to using super().\n\n[2] For sorting examples and a brief sorting tutorial, see sortinghowto. @staticmethod\nTransform a method into a static method. A static method does not receive an implicit first argument. To declare a static method, use this idiom:\nclass C:\n@staticmethod\ndef f(arg1, arg2, argN): ... The @staticmethod form is a function decorator – see function for details. A static method can be called either on the class (such as C.f()) or on an instance (such as C().f()). Moreover, the static method descriptor is also callable, so it can be used in the class definition (such as f()). Static methods in Python are similar to those found in Java or C++. Also, see classmethod() for a variant\nthat is useful for creating alternate class constructors. Like all decorators, it is also possible to call staticmethod as a regular function and do something with its\nresult. This is needed in some cases where you need a reference to a function from a class body and you want\nto avoid the automatic transformation to instance method. For these cases, use this idiom:\ndef regular_function():\n...\nclass C:\nmethod = staticmethod(regular_function)\nFor more information on static methods, see types. Changed in version 3.10: Static methods now inherit the method attributes (__module__, __name__,\n__qualname__, __doc__ and __annotations__), have a new __wrapped__ attribute, and are now\ncallable as regular functions. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a str version of object. See str() for details. str is the built-in string class. For general information about strings, see Text Sequence Type — str. sum(iterable, /, start=0)\nSums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally\nnumbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of\nstrings is by calling ''.join(sequence). To add floating-point values with extended precision, see math. fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument. Changed in version 3.12: Summation of floats switched to an algorithm that gives higher accuracy and better\ncommutativity on most builds. class super\n29\n\nThe Python Library Reference, Release 3.13.2\nclass super(type, object_or_type=None)\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing\ninherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class\nright after the type. For example, if __mro__ of object_or_type is D -> B -> C -> A -> object and the value of type is B,\nthen super() searches C -> A -> object. The __mro__ attribute of the class corresponding to object_or_type lists the method resolution search order\nused by both getattr() and super(). The attribute is dynamic and can change whenever the inheritance\nhierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object,\nisinstance(obj, type) must be true. If the second argument is a type, issubclass(type2, type)\nmust be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument\nsuper()”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately\nenclosing function (typically self). (This means that zero-argument super() will not work as expected\nwithin nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer\nto parent classes without naming them explicitly, thus making the code more maintainable. This use closely\nparallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This\nuse case is unique to Python and is not found in statically compiled languages or languages that only support\nsingle inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes im-\nplement the same method. Good design dictates that such implementations have the same calling signature in\nevery case (because the order of calls is determined at runtime, because that order adapts to changes in the\nclass hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this:\nclass C(B):\ndef method(self, arg):\nsuper().method(arg)\n# This does the same thing as:\n# super(C, self).method(arg)\nIn addition to method lookups, super() also works for attribute lookups. One possible use case for this is\ncalling descriptors in a parent or sibling class. Note that super() is implemented as part of the binding process for explicit dotted attribute lookups such as\nsuper().__getitem__(name). It does so by implementing its own __getattribute__() method for\nsearching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, super()\nis undefined for implicit lookups using statements or operators such as super()[name].\n\n[3] To declare a static method, use this idiom:\nclass C:\n@staticmethod\ndef f(arg1, arg2, argN): ... The @staticmethod form is a function decorator – see function for details. A static method can be called either on the class (such as C.f()) or on an instance (such as C().f()). Moreover, the static method descriptor is also callable, so it can be used in the class definition (such as f()). Static methods in Python are similar to those found in Java or C++. Also, see classmethod() for a variant\nthat is useful for creating alternate class constructors. Like all decorators, it is also possible to call staticmethod as a regular function and do something with its\nresult. This is needed in some cases where you need a reference to a function from a class body and you want\nto avoid the automatic transformation to instance method. For these cases, use this idiom:\ndef regular_function():\n...\nclass C:\nmethod = staticmethod(regular_function)\nFor more information on static methods, see types. Changed in version 3.10: Static methods now inherit the method attributes (__module__, __name__,\n__qualname__, __doc__ and __annotations__), have a new __wrapped__ attribute, and are now\ncallable as regular functions. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a str version of object. See str() for details. str is the built-in string class. For general information about strings, see Text Sequence Type — str. sum(iterable, /, start=0)\nSums start and the items of an iterable from left to right and returns the total. The iterable’s items are normally\nnumbers, and the start value is not allowed to be a string. For some use cases, there are good alternatives to sum(). The preferred, fast way to concatenate a sequence of\nstrings is by calling ''.join(sequence). To add floating-point values with extended precision, see math. fsum(). To concatenate a series of iterables, consider using itertools.chain(). Changed in version 3.8: The start parameter can be specified as a keyword argument. Changed in version 3.12: Summation of floats switched to an algorithm that gives higher accuracy and better\ncommutativity on most builds. class super\n29\n\nThe Python Library Reference, Release 3.13.2\nclass super(type, object_or_type=None)\nReturn a proxy object that delegates method calls to a parent or sibling class of type. This is useful for accessing\ninherited methods that have been overridden in a class. The object_or_type determines the method resolution order to be searched. The search starts from the class\nright after the type. For example, if __mro__ of object_or_type is D -> B -> C -> A -> object and the value of type is B,\nthen super() searches C -> A -> object. The __mro__ attribute of the class corresponding to object_or_type lists the method resolution search order\nused by both getattr() and super(). The attribute is dynamic and can change whenever the inheritance\nhierarchy is updated. If the second argument is omitted, the super object returned is unbound. If the second argument is an object,\nisinstance(obj, type) must be true. If the second argument is a type, issubclass(type2, type)\nmust be true (this is useful for classmethods). When called directly within an ordinary method of a class, both arguments may be omitted (“zero-argument\nsuper()”). In this case, type will be the enclosing class, and obj will be the first argument of the immediately\nenclosing function (typically self). (This means that zero-argument super() will not work as expected\nwithin nested functions, including generator expressions, which implicitly create nested functions.) There are two typical use cases for super. In a class hierarchy with single inheritance, super can be used to refer\nto parent classes without naming them explicitly, thus making the code more maintainable. This use closely\nparallels the use of super in other programming languages. The second use case is to support cooperative multiple inheritance in a dynamic execution environment. This\nuse case is unique to Python and is not found in statically compiled languages or languages that only support\nsingle inheritance. This makes it possible to implement “diamond diagrams” where multiple base classes im-\nplement the same method. Good design dictates that such implementations have the same calling signature in\nevery case (because the order of calls is determined at runtime, because that order adapts to changes in the\nclass hierarchy, and because that order can include sibling classes that are unknown prior to runtime). For both use cases, a typical superclass call looks like this:\nclass C(B):\ndef method(self, arg):\nsuper().method(arg)\n# This does the same thing as:\n# super(C, self).method(arg)\nIn addition to method lookups, super() also works for attribute lookups. One possible use case for this is\ncalling descriptors in a parent or sibling class. Note that super() is implemented as part of the binding process for explicit dotted attribute lookups such as\nsuper().__getitem__(name). It does so by implementing its own __getattribute__() method for\nsearching classes in a predictable order that supports cooperative multiple inheritance. Accordingly, super()\nis undefined for implicit lookups using statements or operators such as super()[name]. Also note that, aside from the zero argument form, super() is not limited to use inside methods. The two\nargument form specifies the arguments exactly and makes the appropriate references. The zero argument form\nonly works inside a class definition, as the compiler fills in the necessary details to correctly retrieve the class\nbeing defined, as well as accessing the current instance for ordinary methods."")",1.4538172302884614e-79,0.03027175782593739,0.10354593752078999,0.5658066272735596,0.7016146
How do I concatenate two lists in Python?,"Use the 
+
 operator to combine the lists:


listone = [1, 2, 3]
listtwo = [4, 5, 6]

joinedlist = listone + listtwo



Output:


>>> joinedlist
[1, 2, 3, 4, 5, 6]



NOTE: This will create a new list with a shallow copy of the items in the first list, followed by a shallow copy of the items in the second list. Use 
copy.deepcopy()
 to get deep copies of lists.

","('Answer: I am sorry, I cannot answer your question based on the context provided.\n\nReferences: []', '[1] µ See also\nThe wiki page devoted to performance tips. 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list.\n\n[2] 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5.\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",2.2272059720172468e-79,0.02924926876828079,0.09826825908711094,0.5473002791404724,0.33392465
How do I check if a list is empty?,"if not a:
    print(""List is empty"")



Using the 
implicit booleanness
 of the empty 
list
 is quite Pythonic.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 9\n3.1.3\nLists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2\nFirst Steps Towards Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4\nMore Control Flow Tools\n17\n4.1\nif Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function .\n\n[2] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[3] . . . . . 32\n5\nData Structures\n33\n5.1\nMore on Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.1.1\nUsing Lists as Stacks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.1.2\nUsing Lists as Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.3\nList Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.4\nNested List Comprehensions\n. . . . . . . .')",4.528277160929837e-232,0.04733727810650888,0.07822685788787485,0.34084993600845337,0.09097315
How do I make function decorators and chain them together?,"Check out 
the documentation
 to see how decorators work. Here is what you asked for:


from functools import wraps

def makebold(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

def makeitalic(fn):
    @wraps(fn)
    def wrapper(*args, **kwargs):
        return ""
"" + fn(*args, **kwargs) + ""
""
    return wrapper

@makebold
@makeitalic
def hello():
    return ""hello world""

@makebold
@makeitalic
def log(s):
    return s

print hello()        # returns ""
hello world
""
print hello.__name__ # with functools.wraps() this returns ""hello""
print log('hello')   # returns ""
hello
""


","('Answer: To create function decorators, you use the `@` syntax before a function definition. Applying multiple decorators is done by stacking them, one above the other, before the function definition. The decorators are applied in a nested fashion.\n\nReferences: [1]\n', '[1] Decorator expressions are evaluated\nwhen the function is defined, in the scope that contains the function definition. The result must be a callable, which\nis invoked with the function object as the only argument. The returned value is bound to the function name instead\nof the function object. Multiple decorators are applied in nested fashion. For example, the following code\n@f1(arg)\n@f2\ndef func(): pass\nis roughly equivalent to\n4 A string literal appearing as the first statement in the function body is transformed into the function’s __doc__ attribute and therefore the\nfunction’s docstring. 8.7. Function definitions\n123\n\nThe Python Language Reference, Release 3.13.2\ndef func(): pass\nfunc = f1(arg)(f2(func))\nexcept that the original function is not temporarily bound to the name func. Changed in version 3.9: Functions may be decorated with any valid assignment_expression. Previously, the\ngrammar was much more restrictive; see PEP 614 for details. A list of type parameters may be given in square brackets between the function’s name and the opening parenthesis for\nits parameter list. This indicates to static type checkers that the function is generic. At runtime, the type parameters\ncan be retrieved from the function’s __type_params__ attribute. See Generic functions for more. Changed in version 3.12: Type parameter lists are new in Python 3.12. When one or more parameters have the form parameter = expression, the function is said to have “default parameter\nvalues.” For a parameter with a default value, the corresponding argument may be omitted from a call, in which case\nthe parameter’s default value is substituted. If a parameter has a default value, all following parameters up until the\n“*” must also have a default value — this is a syntactic restriction that is not expressed by the grammar. Default parameter values are evaluated from left to right when the function definition is executed. This means\nthat the expression is evaluated once, when the function is defined, and that the same “pre-computed” value is used\nfor each call. This is especially important to understand when a default parameter value is a mutable object, such as\na list or a dictionary: if the function modifies the object (e.g. by appending an item to a list), the default parameter\nvalue is in effect modified. This is generally not what was intended. A way around this is to use None as the default,\nand explicitly test for it in the body of the function, e.g. :\ndef whats_on_the_telly(penguin=None):\nif penguin is None:\npenguin = []\npenguin.append(""property of the zoo"")\nreturn penguin\nFunction call semantics are described in more detail in section Calls. A function call always assigns values to all pa-\nrameters mentioned in the parameter list, either from positional arguments, from keyword arguments, or from default\nvalues. If the form “*identifier” is present, it is initialized to a tuple receiving any excess positional parameters,\ndefaulting to the empty tuple. If the form “**identifier” is present, it is initialized to a new ordered mapping\nreceiving any excess keyword arguments, defaulting to a new empty mapping of the same type. Parameters after\n“*” or “*identifier” are keyword-only parameters and may only be passed by keyword arguments. Parameters\nbefore “/” are positional-only parameters and may only be passed by positional arguments. Changed in version 3.8: The / function parameter syntax may be used to indicate positional-only parameters. See\nPEP 570 for details. Parameters may have an annotation of the form “: expression” following the parameter name. Any parameter\nmay have an annotation, even those of the form *identifier or **identifier. (As a special case, parameters\nof the form *identifier may have an annotation “: *expression”.) Functions may have “return” annotation\nof the form “-> expression” after the parameter list. These annotations can be any valid Python expression. The presence of annotations does not change the semantics of a function. The annotation values are available as\nvalues of a dictionary keyed by the parameters’ names in the __annotations__ attribute of the function object. If\nthe annotations import from __future__ is used, annotations are preserved as strings at runtime which enables\npostponed evaluation. Otherwise, they are evaluated when the function definition is executed. In this case annotations\nmay be evaluated in a different order than they appear in the source code. Changed in version 3.11: Parameters of the form “*identifier” may have an annotation “: *expression”. See\nPEP 646. It is also possible to create anonymous functions (functions not bound to a name), for immediate use in expressions. This uses lambda expressions, described in section Lambdas. Note that the lambda expression is merely a shorthand\nfor a simplified function definition; a function defined in a “def” statement can be passed around or assigned to\nanother name just like a function defined by a lambda expression. The “def” form is actually more powerful since it\nallows the execution of multiple statements and annotations. 124\nChapter 8. Compound statements\n\nThe Python Language Reference, Release 3.13.2\nProgrammer’s note: Functions are first-class objects. A “def” statement executed inside a function definition\ndefines a local function that can be returned or passed around. Free variables used in the nested function can access\nthe local variables of the function containing the def. See section Naming and binding for details.\n\n[2] In addition, the class should\nsupply an __eq__() method. For example:\n@total_ordering\nclass Student:\ndef _is_valid_operand(self, other):\nreturn (hasattr(other, ""lastname"") and\nhasattr(other, ""firstname""))\ndef __eq__(self, other):\nif not self._is_valid_operand(other):\nreturn NotImplemented\nreturn ((self.lastname.lower(), self.firstname.lower()) ==\n(other.lastname.lower(), other.firstname.lower()))\ndef __lt__(self, other):\nif not self._is_valid_operand(other):\nreturn NotImplemented\nreturn ((self.lastname.lower(), self.firstname.lower()) <\n(other.lastname.lower(), other.firstname.lower()))\n® Note\nWhile this decorator makes it easy to create well behaved totally ordered types, it does come at the cost\nof slower execution and more complex stack traces for the derived comparison methods. If performance\nbenchmarking indicates this is a bottleneck for a given application, implementing all six rich comparison\nmethods instead is likely to provide an easy speed boost. ® Note\nThis decorator makes no attempt to override methods that have been declared in the class or its superclasses. Meaning that if a superclass defines a comparison operator, total_ordering will not implement it again, even\nif the original method is abstract. Added in version 3.2. Changed in version 3.4: Returning NotImplemented from the underlying comparison function for unrecog-\nnised types is now supported. functools.partial(func, /, *args, **keywords)\nReturn a new partial object which when called will behave like func called with the positional arguments args\nand keyword arguments keywords. If more arguments are supplied to the call, they are appended to args. If\nadditional keyword arguments are supplied, they extend and override keywords. Roughly equivalent to:\ndef partial(func, /, *args, **keywords):\ndef newfunc(*fargs, **fkeywords):\nnewkeywords = {**keywords, **fkeywords}\nreturn func(*args, *fargs, **newkeywords)\nnewfunc.func = func\nnewfunc.args = args\nnewfunc.keywords = keywords\nreturn newfunc\nThe partial() is used for partial function application which “freezes” some portion of a function’s arguments\nand/or keywords resulting in a new object with a simplified signature. For example, partial() can be used\nto create a callable that behaves like the int() function where the base argument defaults to two:\n424\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> from functools import partial\n>>> basetwo = partial(int, base=2)\n>>> basetwo.__doc__ = \'Convert base 2 string to an int.\' >>> basetwo(\'10010\')\n18\nclass functools.partialmethod(func, /, *args, **keywords)\nReturn a new partialmethod descriptor which behaves like partial except that it is designed to be used\nas a method definition rather than being directly callable. func must be a descriptor or a callable (objects which are both, like normal functions, are handled as descrip-\ntors). When func is a descriptor (such as a normal Python function, classmethod(), staticmethod(),\nabstractmethod() or another instance of partialmethod), calls to __get__ are delegated to the un-\nderlying descriptor, and an appropriate partial object returned as the result. When func is a non-descriptor callable, an appropriate bound method is created dynamically. This behaves\nlike a normal Python function when used as a method: the self argument will be inserted as the first positional\nargument, even before the args and keywords supplied to the partialmethod constructor. Example:\n>>> class Cell:\n...\ndef __init__(self):\n...\nself._alive = False\n...\n@property\n...\ndef alive(self):\n...\nreturn self._alive\n...\ndef set_state(self, state):\n...\nself._alive = bool(state)\n...\nset_alive = partialmethod(set_state, True)\n...\nset_dead = partialmethod(set_state, False)\n...\n>>> c = Cell()\n>>> c.alive\nFalse\n>>> c.set_alive()\n>>> c.alive\nTrue\nAdded in version 3.4.\nfunctools.reduce(function, iterable, [initial, ]/)\nApply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the\niterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n((((1+2)+3)+4)+5). The left argument, x, is the accumulated value and the right argument, y, is the\nupdate value from the iterable. If the optional initial is present, it is placed before the items of the iterable in\nthe calculation, and serves as a default when the iterable is empty. If initial is not given and iterable contains\nonly one item, the first item is returned. Roughly equivalent to:\ninitial_missing = object()\ndef reduce(function, iterable, initial=initial_missing, /):\nit = iter(iterable)\nif initial is initial_missing:\nvalue = next(it)\nelse:\n(continues on next page)\n10.2. functools — Higher-order functions and operations on callable objects\n425\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nvalue = initial\nfor element in it:\nvalue = function(value, element)\nreturn value\nSee itertools.accumulate() for an iterator that yields all intermediate values. @functools.singledispatch\nTransform a function into a single-dispatch generic function. To define a generic function, decorate it with the @singledispatch decorator. When defining a function\nusing @singledispatch, note that the dispatch happens on the type of the first argument:\n>>> from functools import singledispatch\n>>> @singledispatch\n... def fun(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Let me just say,"", end="" "")\n...\nprint(arg)\nTo add overloaded implementations to the function, use the register() attribute of the generic function,\nwhich can be used as a decorator. For functions annotated with types, the decorator will infer the type of the\nfirst argument automatically:\n>>> @fun.register\n... def _(arg: int, verbose=False):\n...\nif verbose:\n...\nprint(""Strength in numbers, eh? "", end="" "")\n...\nprint(arg)\n...\n>>> @fun.register\n... def _(arg: list, verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\ntypes.UnionType and typing.Union can also be used:\n>>> @fun.register\n... def _(arg: int | float, verbose=False):\n...\nif verbose:\n...\nprint(""Strength in numbers, eh? "", end="" "")\n...\nprint(arg)\n...\n>>> from typing import Union\n>>> @fun.register\n... def _(arg: Union[list, set], verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\n...\nFor code which doesn’t use type annotations, the appropriate type argument can be passed explicitly to the\ndecorator itself:\n426\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> @fun.register(complex)\n... def _(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Better than complicated. "", end="" "")\n...\nprint(arg.real, arg.imag)\n...\nFor code that dispatches on a collections type (e.g., list), but wants to typehint the items of the collection\n(e.g., list[int]), the dispatch type should be passed explicitly to the decorator itself with the typehint going\ninto the function definition:\n>>> @fun.register(list)\n... def _(arg: list[int], verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\n® Note\nAt runtime the function will dispatch on an instance of a list regardless of the type contained within the\nlist i.e. [1,2,3] will be dispatched the same as [""foo"", ""bar"", ""baz""]. The annotation provided\nin this example is for static type checkers only and has no runtime impact. To enable registering lambdas and pre-existing functions, the register() attribute can also be used in a\nfunctional form:\n>>> def nothing(arg, verbose=False):\n... print(""Nothing."") ...\n>>> fun.register(type(None), nothing)\nThe register() attribute returns the undecorated function. This enables decorator stacking, pickling,\nand the creation of unit tests for each variant independently:\n>>> @fun.register(float)\n... @fun.register(Decimal)\n... def fun_num(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Half of your number:"", end="" "")\n...\nprint(arg / 2)\n...\n>>> fun_num is fun\nFalse\nWhen called, the generic function dispatches on the type of the first argument:\n>>> fun(""Hello, world."") Hello, world. >>> fun(""test. "", verbose=True)\nLet me just say, test. >>> fun(42, verbose=True)\nStrength in numbers, eh? 42\n>>> fun([\'spam\', \'spam\', \'eggs\', \'spam\'], verbose=True)\nEnumerate this:\n0 spam\n(continues on next page)\n10.2. functools — Higher-order functions and operations on callable objects\n427\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n1 spam\n2 eggs\n3 spam\n>>> fun(None)\nNothing. >>> fun(1.23)\n0.615\nWhere there is no registered implementation for a specific type, its method resolution order is used to find a\nmore generic implementation. The original function decorated with @singledispatch is registered for the\nbase object type, which means it is used if no better implementation is found. If an implementation is registered to an abstract base class, virtual subclasses of the base class will be dispatched\nto that implementation:\n>>> from collections.abc import Mapping\n>>> @fun.register\n... def _(arg: Mapping, verbose=False):\n...\nif verbose:\n...\nprint(""Keys & Values"")\n...\nfor key, value in arg.items():\n...\nprint(key, ""=>"", value)\n...\n>>> fun({""a"": ""b""})\na => b\nTo check which implementation the generic function will choose for a given type, use the dispatch() at-\ntribute:\n>>> fun.dispatch(float)\n<function fun_num at 0x1035a2840>\n>>> fun.dispatch(dict)\n# note: default implementation\n<function fun at 0x103fe0000>\nTo access all registered implementations, use the read-only registry attribute:\n>>> fun.registry.keys()\ndict_keys([<class \'NoneType\'>, <class \'int\'>, <class \'object\'>,\n<class \'decimal.Decimal\'>, <class \'list\'>,\n<class \'float\'>])\n>>> fun.registry[float]\n<function fun_num at 0x1035a2840>\n>>> fun.registry[object]\n<function fun at 0x103fe0000>\nAdded in version 3.4. Changed in version 3.7: The register() attribute now supports using type annotations. Changed in version 3.11: The register() attribute now supports types.UnionType and typing.Union\nas type annotations. class functools.singledispatchmethod(func)\nTransform a method into a single-dispatch generic function. To define a generic method, decorate it with the @singledispatchmethod decorator. When defining a\nfunction using @singledispatchmethod, note that the dispatch happens on the type of the first non-self or\nnon-cls argument:\n428\nChapter 10.\n\n[3] For example:\n@total_ordering\nclass Student:\ndef _is_valid_operand(self, other):\nreturn (hasattr(other, ""lastname"") and\nhasattr(other, ""firstname""))\ndef __eq__(self, other):\nif not self._is_valid_operand(other):\nreturn NotImplemented\nreturn ((self.lastname.lower(), self.firstname.lower()) ==\n(other.lastname.lower(), other.firstname.lower()))\ndef __lt__(self, other):\nif not self._is_valid_operand(other):\nreturn NotImplemented\nreturn ((self.lastname.lower(), self.firstname.lower()) <\n(other.lastname.lower(), other.firstname.lower()))\n® Note\nWhile this decorator makes it easy to create well behaved totally ordered types, it does come at the cost\nof slower execution and more complex stack traces for the derived comparison methods. If performance\nbenchmarking indicates this is a bottleneck for a given application, implementing all six rich comparison\nmethods instead is likely to provide an easy speed boost. ® Note\nThis decorator makes no attempt to override methods that have been declared in the class or its superclasses. Meaning that if a superclass defines a comparison operator, total_ordering will not implement it again, even\nif the original method is abstract. Added in version 3.2. Changed in version 3.4: Returning NotImplemented from the underlying comparison function for unrecog-\nnised types is now supported. functools.partial(func, /, *args, **keywords)\nReturn a new partial object which when called will behave like func called with the positional arguments args\nand keyword arguments keywords. If more arguments are supplied to the call, they are appended to args. If\nadditional keyword arguments are supplied, they extend and override keywords. Roughly equivalent to:\ndef partial(func, /, *args, **keywords):\ndef newfunc(*fargs, **fkeywords):\nnewkeywords = {**keywords, **fkeywords}\nreturn func(*args, *fargs, **newkeywords)\nnewfunc.func = func\nnewfunc.args = args\nnewfunc.keywords = keywords\nreturn newfunc\nThe partial() is used for partial function application which “freezes” some portion of a function’s arguments\nand/or keywords resulting in a new object with a simplified signature. For example, partial() can be used\nto create a callable that behaves like the int() function where the base argument defaults to two:\n424\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> from functools import partial\n>>> basetwo = partial(int, base=2)\n>>> basetwo.__doc__ = \'Convert base 2 string to an int.\' >>> basetwo(\'10010\')\n18\nclass functools.partialmethod(func, /, *args, **keywords)\nReturn a new partialmethod descriptor which behaves like partial except that it is designed to be used\nas a method definition rather than being directly callable. func must be a descriptor or a callable (objects which are both, like normal functions, are handled as descrip-\ntors). When func is a descriptor (such as a normal Python function, classmethod(), staticmethod(),\nabstractmethod() or another instance of partialmethod), calls to __get__ are delegated to the un-\nderlying descriptor, and an appropriate partial object returned as the result. When func is a non-descriptor callable, an appropriate bound method is created dynamically. This behaves\nlike a normal Python function when used as a method: the self argument will be inserted as the first positional\nargument, even before the args and keywords supplied to the partialmethod constructor. Example:\n>>> class Cell:\n...\ndef __init__(self):\n...\nself._alive = False\n...\n@property\n...\ndef alive(self):\n...\nreturn self._alive\n...\ndef set_state(self, state):\n...\nself._alive = bool(state)\n...\nset_alive = partialmethod(set_state, True)\n...\nset_dead = partialmethod(set_state, False)\n...\n>>> c = Cell()\n>>> c.alive\nFalse\n>>> c.set_alive()\n>>> c.alive\nTrue\nAdded in version 3.4.\nfunctools.reduce(function, iterable, [initial, ]/)\nApply function of two arguments cumulatively to the items of iterable, from left to right, so as to reduce the\niterable to a single value. For example, reduce(lambda x, y: x+y, [1, 2, 3, 4, 5]) calculates\n((((1+2)+3)+4)+5). The left argument, x, is the accumulated value and the right argument, y, is the\nupdate value from the iterable. If the optional initial is present, it is placed before the items of the iterable in\nthe calculation, and serves as a default when the iterable is empty. If initial is not given and iterable contains\nonly one item, the first item is returned. Roughly equivalent to:\ninitial_missing = object()\ndef reduce(function, iterable, initial=initial_missing, /):\nit = iter(iterable)\nif initial is initial_missing:\nvalue = next(it)\nelse:\n(continues on next page)\n10.2. functools — Higher-order functions and operations on callable objects\n425\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nvalue = initial\nfor element in it:\nvalue = function(value, element)\nreturn value\nSee itertools.accumulate() for an iterator that yields all intermediate values. @functools.singledispatch\nTransform a function into a single-dispatch generic function. To define a generic function, decorate it with the @singledispatch decorator. When defining a function\nusing @singledispatch, note that the dispatch happens on the type of the first argument:\n>>> from functools import singledispatch\n>>> @singledispatch\n... def fun(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Let me just say,"", end="" "")\n...\nprint(arg)\nTo add overloaded implementations to the function, use the register() attribute of the generic function,\nwhich can be used as a decorator. For functions annotated with types, the decorator will infer the type of the\nfirst argument automatically:\n>>> @fun.register\n... def _(arg: int, verbose=False):\n...\nif verbose:\n...\nprint(""Strength in numbers, eh? "", end="" "")\n...\nprint(arg)\n...\n>>> @fun.register\n... def _(arg: list, verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\ntypes.UnionType and typing.Union can also be used:\n>>> @fun.register\n... def _(arg: int | float, verbose=False):\n...\nif verbose:\n...\nprint(""Strength in numbers, eh? "", end="" "")\n...\nprint(arg)\n...\n>>> from typing import Union\n>>> @fun.register\n... def _(arg: Union[list, set], verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\n...\nFor code which doesn’t use type annotations, the appropriate type argument can be passed explicitly to the\ndecorator itself:\n426\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> @fun.register(complex)\n... def _(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Better than complicated. "", end="" "")\n...\nprint(arg.real, arg.imag)\n...\nFor code that dispatches on a collections type (e.g., list), but wants to typehint the items of the collection\n(e.g., list[int]), the dispatch type should be passed explicitly to the decorator itself with the typehint going\ninto the function definition:\n>>> @fun.register(list)\n... def _(arg: list[int], verbose=False):\n...\nif verbose:\n...\nprint(""Enumerate this:"")\n...\nfor i, elem in enumerate(arg):\n...\nprint(i, elem)\n® Note\nAt runtime the function will dispatch on an instance of a list regardless of the type contained within the\nlist i.e. [1,2,3] will be dispatched the same as [""foo"", ""bar"", ""baz""]. The annotation provided\nin this example is for static type checkers only and has no runtime impact. To enable registering lambdas and pre-existing functions, the register() attribute can also be used in a\nfunctional form:\n>>> def nothing(arg, verbose=False):\n... print(""Nothing."") ...\n>>> fun.register(type(None), nothing)\nThe register() attribute returns the undecorated function. This enables decorator stacking, pickling,\nand the creation of unit tests for each variant independently:\n>>> @fun.register(float)\n... @fun.register(Decimal)\n... def fun_num(arg, verbose=False):\n...\nif verbose:\n...\nprint(""Half of your number:"", end="" "")\n...\nprint(arg / 2)\n...\n>>> fun_num is fun\nFalse\nWhen called, the generic function dispatches on the type of the first argument:\n>>> fun(""Hello, world."") Hello, world. >>> fun(""test. "", verbose=True)\nLet me just say, test. >>> fun(42, verbose=True)\nStrength in numbers, eh? 42\n>>> fun([\'spam\', \'spam\', \'eggs\', \'spam\'], verbose=True)\nEnumerate this:\n0 spam\n(continues on next page)\n10.2. functools — Higher-order functions and operations on callable objects\n427\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n1 spam\n2 eggs\n3 spam\n>>> fun(None)\nNothing. >>> fun(1.23)\n0.615\nWhere there is no registered implementation for a specific type, its method resolution order is used to find a\nmore generic implementation. The original function decorated with @singledispatch is registered for the\nbase object type, which means it is used if no better implementation is found. If an implementation is registered to an abstract base class, virtual subclasses of the base class will be dispatched\nto that implementation:\n>>> from collections.abc import Mapping\n>>> @fun.register\n... def _(arg: Mapping, verbose=False):\n...\nif verbose:\n...\nprint(""Keys & Values"")\n...\nfor key, value in arg.items():\n...\nprint(key, ""=>"", value)\n...\n>>> fun({""a"": ""b""})\na => b\nTo check which implementation the generic function will choose for a given type, use the dispatch() at-\ntribute:\n>>> fun.dispatch(float)\n<function fun_num at 0x1035a2840>\n>>> fun.dispatch(dict)\n# note: default implementation\n<function fun at 0x103fe0000>\nTo access all registered implementations, use the read-only registry attribute:\n>>> fun.registry.keys()\ndict_keys([<class \'NoneType\'>, <class \'int\'>, <class \'object\'>,\n<class \'decimal.Decimal\'>, <class \'list\'>,\n<class \'float\'>])\n>>> fun.registry[float]\n<function fun_num at 0x1035a2840>\n>>> fun.registry[object]\n<function fun at 0x103fe0000>\nAdded in version 3.4. Changed in version 3.7: The register() attribute now supports using type annotations. Changed in version 3.11: The register() attribute now supports types.UnionType and typing.Union\nas type annotations. class functools.singledispatchmethod(func)\nTransform a method into a single-dispatch generic function. To define a generic method, decorate it with the @singledispatchmethod decorator. When defining a\nfunction using @singledispatchmethod, note that the dispatch happens on the type of the first non-self or\nnon-cls argument:\n428\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\nclass Negator:\n@singledispatchmethod\ndef neg(self, arg):\nraise NotImplementedError(""Cannot negate a"")\n@neg.register\ndef _(self, arg: int):\nreturn -arg\n@neg.register\ndef _(self, arg: bool):\nreturn not arg\n@singledispatchmethod supports nesting with other decorators such as @classmethod.')",7.048084247170792e-80,0.015003409865878607,0.0910112600071798,0.5055866241455078,0.6882752
How do I split a list into equally-sized chunks?,"Here's a generator that yields evenly-sized chunks:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in range(0, len(lst), n):
        yield lst[i:i + n]



import pprint
pprint.pprint(list(chunks(range(10, 75), 10)))
[[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],
 [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],
 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],
 [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],
 [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],
 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],
 [70, 71, 72, 73, 74]]



For Python 2, using 
xrange
 instead of 
range
:


def chunks(lst, n):
    """"""Yield successive n-sized chunks from lst.""""""
    for i in xrange(0, len(lst), n):
        yield lst[i:i + n]





Below is a list comprehension one-liner. The method above is preferable, though, since using named functions makes code easier to understand. For Python 3:


[lst[i:i + n] for i in range(0, len(lst), n)]



For Python 2:


[lst[i:i + n] for i in xrange(0, len(lst), n)]


","('Answer: You can use the `grouper` function to collect data into non-overlapping fixed-length chunks. Alternatively, the expression `list(islice(iterable, n))` will return the iterable up to length `n`.\n\nReferences: [1, 3]\n', '[1] # tail(3, \'ABCDEFG\') →E F G\nreturn iter(deque(iterable, maxlen=n))\ndef consume(iterator, n=None):\n""Advance the iterator n-steps ahead. If n is None, consume entirely."" # Use functions that consume iterators at C speed. if n is None:\ndeque(iterator, maxlen=0)\nelse:\nnext(islice(iterator, n, n), None)\ndef nth(iterable, n, default=None):\n""Returns the nth item or a default value."" return next(islice(iterable, n, None), default)\ndef quantify(iterable, predicate=bool):\n""Given a predicate that returns True or False, count the True results."" return sum(map(predicate, iterable))\ndef first_true(iterable, default=False, predicate=None):\n""Returns the first true value or the *default* if there is no true value."" # first_true([a,b,c], x) →a or b or c or x\n# first_true([a,b], x, f) →a if f(a) else b if f(b) else x\nreturn next(filter(predicate, iterable), default)\ndef all_equal(iterable, key=None):\n""Returns True if all the elements are equal to each other."" # all_equal(\'4\x00\x00\x00\x00\', key=int) →True\nreturn len(take(2, groupby(iterable, key))) <= 1\ndef unique_justseen(iterable, key=None):\n""Yield unique elements, preserving order. Remember only the element just seen."" # unique_justseen(\'AAAABBBCCDAABBB\') →A B C D A B\n# unique_justseen(\'ABBcCAD\', str.casefold) →A B c A D\nif key is None:\nreturn map(itemgetter(0), groupby(iterable))\nreturn map(next, map(itemgetter(1), groupby(iterable, key)))\ndef unique_everseen(iterable, key=None):\n""Yield unique elements, preserving order. Remember all elements ever seen."" # unique_everseen(\'AAAABBBCCDAABBB\') →A B C D\n# unique_everseen(\'ABBcCAD\', str.casefold) →A B c D\nseen = set()\nif key is None:\nfor element in filterfalse(seen.__contains__, iterable):\nseen.add(element)\nyield element\nelse:\nfor element in iterable:\nk = key(element)\nif k not in seen:\nseen.add(k)\n(continues on next page)\n416\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nyield element\ndef unique(iterable, key=None, reverse=False):\n""Yield unique elements in sorted order. Supports unhashable inputs."" # unique([[1, 2], [3, 4], [1, 2]]) →[1, 2] [3, 4]\nsequenced = sorted(iterable, key=key, reverse=reverse)\nreturn unique_justseen(sequenced, key=key)\ndef sliding_window(iterable, n):\n""Collect data into overlapping fixed-length chunks or blocks."" # sliding_window(\'ABCDEFG\', 4) →ABCD BCDE CDEF DEFG\niterator = iter(iterable)\nwindow = deque(islice(iterator, n - 1), maxlen=n)\nfor x in iterator:\nwindow.append(x)\nyield tuple(window)\ndef grouper(iterable, n, *, incomplete=\'fill\', fillvalue=None):\n""Collect data into non-overlapping fixed-length chunks or blocks."" # grouper(\'ABCDEFG\', 3, fillvalue=\'x\') →ABC DEF Gxx\n# grouper(\'ABCDEFG\', 3, incomplete=\'strict\') →ABC DEF ValueError\n# grouper(\'ABCDEFG\', 3, incomplete=\'ignore\') →ABC DEF\niterators = [iter(iterable)] * n\nmatch incomplete:\ncase \'fill\':\nreturn zip_longest(*iterators, fillvalue=fillvalue)\ncase \'strict\':\nreturn zip(*iterators, strict=True)\ncase \'ignore\':\nreturn zip(*iterators)\ncase _:\nraise ValueError(\'Expected fill, strict, or ignore\')\ndef roundrobin(*iterables):\n""Visit input iterables in a cycle until each is exhausted."" # roundrobin(\'ABC\', \'D\', \'EF\') →A D E B F C\n# Algorithm credited to George Sakkis\niterators = map(iter, iterables)\nfor num_active in range(len(iterables), 0, -1):\niterators = cycle(islice(iterators, num_active))\nyield from map(next, iterators)\ndef subslices(seq):\n""Return all contiguous non-empty subslices of a sequence."" # subslices(\'ABCD\') →A AB ABC ABCD B BC BCD C CD D\nslices = starmap(slice, combinations(range(len(seq) + 1), 2))\nreturn map(getitem, repeat(seq), slices)\ndef iter_index(iterable, value, start=0, stop=None):\n""Return indices where a value occurs in a sequence or iterable."" # iter_index(\'AABCADEAF\', \'A\') →0 1 4 7\nseq_index = getattr(iterable, \'index\', None)\nif seq_index is None:\niterator = islice(iterable, start, stop)\nfor i, element in enumerate(iterator, start):\nif element is value or element == value:\n(continues on next page)\n10.1. itertools — Functions creating iterators for efficient looping\n417\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nyield i\nelse:\nstop = len(iterable) if stop is None else stop\ni = start\nwith suppress(ValueError):\nwhile True:\nyield (i := seq_index(value, i, stop))\ni += 1\ndef iter_except(function, exception, first=None):\n""Convert a call-until-exception interface to an iterator interface."" # iter_except(d.popitem, KeyError) →non-blocking dictionary iterator\nwith suppress(exception):\nif first is not None:\nyield first()\nwhile True:\nyield function()\nThe following recipes have a more mathematical flavor:\ndef powerset(iterable):\n""Subsequences of the iterable from shortest to longest."" # powerset([1,2,3]) →() (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\ns = list(iterable)\nreturn chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\ndef sum_of_squares(iterable):\n""Add up the squares of the input values."" # sum_of_squares([10, 20, 30]) →1400\nreturn sumprod(*tee(iterable))\ndef reshape(matrix, columns):\n""Reshape a 2-D matrix to have a given number of columns."" # reshape([(0, 1), (2, 3), (4, 5)], 3) →\n(0, 1, 2), (3, 4, 5)\nreturn batched(chain.from_iterable(matrix), columns, strict=True)\ndef transpose(matrix):\n""Swap the rows and columns of a 2-D matrix."" # transpose([(1, 2, 3), (11, 22, 33)]) →(1, 11) (2, 22) (3, 33)\nreturn zip(*matrix, strict=True)\ndef matmul(m1, m2):\n""Multiply two matrices."" # matmul([(7, 5), (3, 5)], [(2, 5), (7, 9)]) →(49, 80), (41, 60)\nn = len(m2[0])\nreturn batched(starmap(sumprod, product(m1, transpose(m2))), n)\ndef convolve(signal, kernel):\n""""""Discrete linear convolution of two iterables. Equivalent to polynomial multiplication. Convolutions are mathematically commutative; however, the inputs are\nevaluated differently. The signal is consumed lazily and can be\ninfinite. The kernel is fully consumed before the calculations begin. Article:\nhttps://betterexplained.com/articles/intuitive-convolution/\n(continues on next page)\n418\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nVideo:\nhttps://www.youtube.com/watch?v=KuXjwB4LzSA\n""""""\n# convolve([1, -1, -20], [1, -3]) →1 -4 -17 60\n# convolve(data, [0.25, 0.25, 0.25, 0.25]) →Moving average (blur)\n# convolve(data, [1/2, 0, -1/2]) →1st derivative estimate\n# convolve(data, [1, -2, 1]) →2nd derivative estimate\nkernel = tuple(kernel)[::-1]\nn = len(kernel)\npadded_signal = chain(repeat(0, n-1), signal, repeat(0, n-1))\nwindowed_signal = sliding_window(padded_signal, n)\nreturn map(sumprod, repeat(kernel), windowed_signal)\ndef polynomial_from_roots(roots):\n""""""Compute a polynomial\'s coefficients from its roots. (x - 5) (x + 4) (x - 3)\nexpands to:\nx³ -4x² -17x + 60\n""""""\n# polynomial_from_roots([5, -4, 3]) →[1, -4, -17, 60]\nfactors = zip(repeat(1), map(neg, roots))\nreturn list(reduce(convolve, factors, [1]))\ndef polynomial_eval(coefficients, x):\n""""""Evaluate a polynomial at a specific value. Computes with better numeric stability than Horner\'s method.\n"""""" # Evaluate x³ -4x² -17x + 60 at x = 5\n# polynomial_eval([1, -4, -17, 60], x=5) →0\nn = len(coefficients)\nif not n:\nreturn type(x)(0)\npowers = map(pow, repeat(x), reversed(range(n)))\nreturn sumprod(coefficients, powers)\ndef polynomial_derivative(coefficients):\n""""""Compute the first derivative of a polynomial. f(x)\n=\nx³ -4x² -17x + 60\nf\'(x) = 3x² -8x\n-17\n""""""\n# polynomial_derivative([1, -4, -17, 60]) →[3, -8, -17]\nn = len(coefficients)\npowers = reversed(range(1, n))\nreturn list(map(mul, coefficients, powers))\ndef sieve(n):\n""Primes less than n.""\n# sieve(30) →2 3 5 7 11 13 17 19 23 29\nif n > 2:\nyield 2\ndata = bytearray((0, 1)) * (n // 2)\nfor p in iter_index(data, 1, start=3, stop=isqrt(n) + 1):\ndata[p*p : n : p+p] = bytes(len(range(p*p, n, p+p)))\nyield from iter_index(data, 1, start=3)\ndef factor(n):\n(continues on next page)\n10.1. itertools — Functions creating iterators for efficient looping\n419\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n""Prime factors of n.""\n# factor(99) →3 3 11\n# factor(1_000_000_000_000_007) →47 59 360620266859\n# factor(1_000_000_000_000_403) →1000000000000403\nfor prime in sieve(isqrt(n) + 1):\nwhile not n % prime:\nyield prime\nn //= prime\nif n == 1:\nreturn\nif n > 1:\nyield n\ndef is_prime(n):\n""Return True if n is prime."" # is_prime(1_000_000_000_000_403) →True\nreturn n > 1 and next(factor(n)) == n\ndef totient(n):\n""Count of natural numbers up to n that are coprime to n.""\n# https://mathworld.wolfram.com/TotientFunction.html\n# totient(12) →4 because len([1, 5, 7, 11]) == 4\nfor prime in set(factor(n)):\nn -= n // prime\nreturn n\ndef multinomial(*counts):\n""Number of distinct arrangements of a multiset."" # Counter(\'abracadabra\').values() -> 5 2 1 1 2\n# multinomial(5, 2, 1, 1, 2) →83160\nreturn prod(map(comb, accumulate(counts), counts))\n10.2 functools — Higher-order functions and operations on\ncallable objects\nSource code: Lib/functools.py\nThe functools module is for higher-order functions: functions that act on or return other functions. In general, any\ncallable object can be treated as a function for the purposes of this module. The functools module defines the following functions:\n@functools.cache(user_function)\nSimple lightweight unbounded function cache. Sometimes called “memoize”. Returns the same as lru_cache(maxsize=None), creating a thin wrapper around a dictionary lookup for\nthe function arguments. Because it never needs to evict old values, this is smaller and faster than lru_cache()\nwith a size limit. For example:\n@cache\ndef factorial(n):\nreturn n * factorial(n-1) if n else 1\n(continues on next page)\n420\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> factorial(10)\n# no previously cached result, makes 11 recursive calls\n3628800\n>>> factorial(5)\n# just looks up cached value result\n120\n>>> factorial(12)\n# makes two new recursive calls, the other 10 are cached\n479001600\nThe cache is threadsafe so that the wrapped function can be used in multiple threads. This means that the\nunderlying data structure will remain coherent during concurrent updates. It is possible for the wrapped function to be called more than once if another thread makes an additional call\nbefore the initial call has been completed and cached. Added in version 3.9. @functools.cached_property(func)\nTransform a method of a class into a property whose value is computed once and then cached as a normal\nattribute for the life of the instance. Similar to property(), with the addition of caching. Useful for expensive\ncomputed properties of instances that are otherwise effectively immutable.\n\n[2] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[3] return list(islice(iterable, n))\ndef prepend(value, iterable):\n""Prepend a single value in front of an iterable."" # prepend(1, [2, 3, 4]) →1 2 3 4\nreturn chain([value], iterable)\ndef tabulate(function, start=0):\n""Return function(0), function(1), ...""\nreturn map(function, count(start))\ndef repeatfunc(function, times=None, *args):\n""Repeat calls to a function with specified arguments."" if times is None:\nreturn starmap(function, repeat(args))\nreturn starmap(function, repeat(args, times))\ndef flatten(list_of_lists):\n""Flatten one level of nesting."" return chain.from_iterable(list_of_lists)\ndef ncycles(iterable, n):\n""Returns the sequence elements n times."" return chain.from_iterable(repeat(tuple(iterable), n))\ndef loops(n):\n""Loop n times. Like range(n) but without creating integers."" # for _ in loops(100): ...\n(continues on next page)\n10.1. itertools — Functions creating iterators for efficient looping\n415\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nreturn repeat(None, n)\ndef tail(n, iterable):\n""Return an iterator over the last n items."" # tail(3, \'ABCDEFG\') →E F G\nreturn iter(deque(iterable, maxlen=n))\ndef consume(iterator, n=None):\n""Advance the iterator n-steps ahead. If n is None, consume entirely."" # Use functions that consume iterators at C speed. if n is None:\ndeque(iterator, maxlen=0)\nelse:\nnext(islice(iterator, n, n), None)\ndef nth(iterable, n, default=None):\n""Returns the nth item or a default value."" return next(islice(iterable, n, None), default)\ndef quantify(iterable, predicate=bool):\n""Given a predicate that returns True or False, count the True results."" return sum(map(predicate, iterable))\ndef first_true(iterable, default=False, predicate=None):\n""Returns the first true value or the *default* if there is no true value."" # first_true([a,b,c], x) →a or b or c or x\n# first_true([a,b], x, f) →a if f(a) else b if f(b) else x\nreturn next(filter(predicate, iterable), default)\ndef all_equal(iterable, key=None):\n""Returns True if all the elements are equal to each other."" # all_equal(\'4\x00\x00\x00\x00\', key=int) →True\nreturn len(take(2, groupby(iterable, key))) <= 1\ndef unique_justseen(iterable, key=None):\n""Yield unique elements, preserving order. Remember only the element just seen."" # unique_justseen(\'AAAABBBCCDAABBB\') →A B C D A B\n# unique_justseen(\'ABBcCAD\', str.casefold) →A B c A D\nif key is None:\nreturn map(itemgetter(0), groupby(iterable))\nreturn map(next, map(itemgetter(1), groupby(iterable, key)))\ndef unique_everseen(iterable, key=None):\n""Yield unique elements, preserving order. Remember all elements ever seen."" # unique_everseen(\'AAAABBBCCDAABBB\') →A B C D\n# unique_everseen(\'ABBcCAD\', str.casefold) →A B c D\nseen = set()\nif key is None:\nfor element in filterfalse(seen.__contains__, iterable):\nseen.add(element)\nyield element\nelse:\nfor element in iterable:\nk = key(element)\nif k not in seen:\nseen.add(k)\n(continues on next page)\n416\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nyield element\ndef unique(iterable, key=None, reverse=False):\n""Yield unique elements in sorted order. Supports unhashable inputs."" # unique([[1, 2], [3, 4], [1, 2]]) →[1, 2] [3, 4]\nsequenced = sorted(iterable, key=key, reverse=reverse)\nreturn unique_justseen(sequenced, key=key)\ndef sliding_window(iterable, n):\n""Collect data into overlapping fixed-length chunks or blocks."" # sliding_window(\'ABCDEFG\', 4) →ABCD BCDE CDEF DEFG\niterator = iter(iterable)\nwindow = deque(islice(iterator, n - 1), maxlen=n)\nfor x in iterator:\nwindow.append(x)\nyield tuple(window)\ndef grouper(iterable, n, *, incomplete=\'fill\', fillvalue=None):\n""Collect data into non-overlapping fixed-length chunks or blocks."" # grouper(\'ABCDEFG\', 3, fillvalue=\'x\') →ABC DEF Gxx\n# grouper(\'ABCDEFG\', 3, incomplete=\'strict\') →ABC DEF ValueError\n# grouper(\'ABCDEFG\', 3, incomplete=\'ignore\') →ABC DEF\niterators = [iter(iterable)] * n\nmatch incomplete:\ncase \'fill\':\nreturn zip_longest(*iterators, fillvalue=fillvalue)\ncase \'strict\':\nreturn zip(*iterators, strict=True)\ncase \'ignore\':\nreturn zip(*iterators)\ncase _:\nraise ValueError(\'Expected fill, strict, or ignore\')\ndef roundrobin(*iterables):\n""Visit input iterables in a cycle until each is exhausted."" # roundrobin(\'ABC\', \'D\', \'EF\') →A D E B F C\n# Algorithm credited to George Sakkis\niterators = map(iter, iterables)\nfor num_active in range(len(iterables), 0, -1):\niterators = cycle(islice(iterators, num_active))\nyield from map(next, iterators)\ndef subslices(seq):\n""Return all contiguous non-empty subslices of a sequence."" # subslices(\'ABCD\') →A AB ABC ABCD B BC BCD C CD D\nslices = starmap(slice, combinations(range(len(seq) + 1), 2))\nreturn map(getitem, repeat(seq), slices)\ndef iter_index(iterable, value, start=0, stop=None):\n""Return indices where a value occurs in a sequence or iterable."" # iter_index(\'AABCADEAF\', \'A\') →0 1 4 7\nseq_index = getattr(iterable, \'index\', None)\nif seq_index is None:\niterator = islice(iterable, start, stop)\nfor i, element in enumerate(iterator, start):\nif element is value or element == value:\n(continues on next page)\n10.1. itertools — Functions creating iterators for efficient looping\n417\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nyield i\nelse:\nstop = len(iterable) if stop is None else stop\ni = start\nwith suppress(ValueError):\nwhile True:\nyield (i := seq_index(value, i, stop))\ni += 1\ndef iter_except(function, exception, first=None):\n""Convert a call-until-exception interface to an iterator interface."" # iter_except(d.popitem, KeyError) →non-blocking dictionary iterator\nwith suppress(exception):\nif first is not None:\nyield first()\nwhile True:\nyield function()\nThe following recipes have a more mathematical flavor:\ndef powerset(iterable):\n""Subsequences of the iterable from shortest to longest."" # powerset([1,2,3]) →() (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\ns = list(iterable)\nreturn chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\ndef sum_of_squares(iterable):\n""Add up the squares of the input values."" # sum_of_squares([10, 20, 30]) →1400\nreturn sumprod(*tee(iterable))\ndef reshape(matrix, columns):\n""Reshape a 2-D matrix to have a given number of columns."" # reshape([(0, 1), (2, 3), (4, 5)], 3) →\n(0, 1, 2), (3, 4, 5)\nreturn batched(chain.from_iterable(matrix), columns, strict=True)\ndef transpose(matrix):\n""Swap the rows and columns of a 2-D matrix."" # transpose([(1, 2, 3), (11, 22, 33)]) →(1, 11) (2, 22) (3, 33)\nreturn zip(*matrix, strict=True)\ndef matmul(m1, m2):\n""Multiply two matrices."" # matmul([(7, 5), (3, 5)], [(2, 5), (7, 9)]) →(49, 80), (41, 60)\nn = len(m2[0])\nreturn batched(starmap(sumprod, product(m1, transpose(m2))), n)\ndef convolve(signal, kernel):\n""""""Discrete linear convolution of two iterables. Equivalent to polynomial multiplication. Convolutions are mathematically commutative; however, the inputs are\nevaluated differently. The signal is consumed lazily and can be\ninfinite. The kernel is fully consumed before the calculations begin. Article:\nhttps://betterexplained.com/articles/intuitive-convolution/\n(continues on next page)\n418\nChapter 10. Functional Programming Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nVideo:\nhttps://www.youtube.com/watch?v=KuXjwB4LzSA\n""""""\n# convolve([1, -1, -20], [1, -3]) →1 -4 -17 60\n# convolve(data, [0.25, 0.25, 0.25, 0.25]) →Moving average (blur)\n# convolve(data, [1/2, 0, -1/2]) →1st derivative estimate\n# convolve(data, [1, -2, 1]) →2nd derivative estimate\nkernel = tuple(kernel)[::-1]\nn = len(kernel)\npadded_signal = chain(repeat(0, n-1), signal, repeat(0, n-1))\nwindowed_signal = sliding_window(padded_signal, n)\nreturn map(sumprod, repeat(kernel), windowed_signal)\ndef polynomial_from_roots(roots):\n""""""Compute a polynomial\'s coefficients from its roots. (x - 5) (x + 4) (x - 3)\nexpands to:\nx³ -4x² -17x + 60\n""""""\n# polynomial_from_roots([5, -4, 3]) →[1, -4, -17, 60]\nfactors = zip(repeat(1), map(neg, roots))\nreturn list(reduce(convolve, factors, [1]))\ndef polynomial_eval(coefficients, x):\n""""""Evaluate a polynomial at a specific value. Computes with better numeric stability than Horner\'s method.\n"""""" # Evaluate x³ -4x² -17x + 60 at x = 5\n# polynomial_eval([1, -4, -17, 60], x=5) →0\nn = len(coefficients)\nif not n:\nreturn type(x)(0)\npowers = map(pow, repeat(x), reversed(range(n)))\nreturn sumprod(coefficients, powers)\ndef polynomial_derivative(coefficients):\n""""""Compute the first derivative of a polynomial. f(x)\n=\nx³ -4x² -17x + 60\nf\'(x) = 3x² -8x\n-17\n""""""\n# polynomial_derivative([1, -4, -17, 60]) →[3, -8, -17]\nn = len(coefficients)\npowers = reversed(range(1, n))\nreturn list(map(mul, coefficients, powers))\ndef sieve(n):\n""Primes less than n.""\n# sieve(30) →2 3 5 7 11 13 17 19 23 29\nif n > 2:\nyield 2\ndata = bytearray((0, 1)) * (n // 2)\nfor p in iter_index(data, 1, start=3, stop=isqrt(n) + 1):\ndata[p*p : n : p+p] = bytes(len(range(p*p, n, p+p)))\nyield from iter_index(data, 1, start=3)\ndef factor(n):\n(continues on next page)\n10.1. itertools — Functions creating iterators for efficient looping\n419\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n""Prime factors of n.""\n# factor(99) →3 3 11\n# factor(1_000_000_000_000_007) →47 59 360620266859\n# factor(1_000_000_000_000_403) →1000000000000403\nfor prime in sieve(isqrt(n) + 1):\nwhile not n % prime:\nyield prime\nn //= prime\nif n == 1:\nreturn\nif n > 1:\nyield n\ndef is_prime(n):\n""Return True if n is prime."" # is_prime(1_000_000_000_000_403) →True\nreturn n > 1 and next(factor(n)) == n\ndef totient(n):\n""Count of natural numbers up to n that are coprime to n.""\n# https://mathworld.wolfram.com/TotientFunction.html\n# totient(12) →4 because len([1, 5, 7, 11]) == 4\nfor prime in set(factor(n)):\nn -= n // prime\nreturn n\ndef multinomial(*counts):\n""Number of distinct arrangements of a multiset."" # Counter(\'abracadabra\').values() -> 5 2 1 1 2\n# multinomial(5, 2, 1, 1, 2) →83160\nreturn prod(map(comb, accumulate(counts), counts))\n10.2 functools — Higher-order functions and operations on\ncallable objects\nSource code: Lib/functools.py\nThe functools module is for higher-order functions: functions that act on or return other functions. In general, any\ncallable object can be treated as a function for the purposes of this module. The functools module defines the following functions:\n@functools.cache(user_function)\nSimple lightweight unbounded function cache. Sometimes called “memoize”. Returns the same as lru_cache(maxsize=None), creating a thin wrapper around a dictionary lookup for\nthe function arguments. Because it never needs to evict old values, this is smaller and faster than lru_cache()\nwith a size limit. For example:\n@cache\ndef factorial(n):\nreturn n * factorial(n-1) if n else 1\n(continues on next page)\n420\nChapter 10.')",6.183105216370573e-232,0.03377867406100328,0.1521577874618764,0.5527687668800354,0.5018899
What is the difference between Python's list methods append and extend?,".append()
 appends a 
single object
 at the end of the list:


>>> x = [1, 2, 3]
>>> x.append([4, 5])
>>> print(x)
[1, 2, 3, [4, 5]]



.extend()
 appends 
multiple objects
 that are taken from inside the specified iterable:


>>> x = [1, 2, 3]
>>> x.extend([4, 5])
>>> print(x)
[1, 2, 3, 4, 5]


","('Answer: The `append` method adds an item to the end of a list. The `extend` method extends a list by adding all the items from an iterable to the end of the list.\n\nReferences: [2, 3]\n', '[1] list.extend(iterable)\nExtend the list by appending all the items from the iterable. Similar to a[len(a):] = iterable. list.insert(i, x)\nInsert an item at a given position. The first argument is the index of the element before which to insert, so a.\ninsert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x). list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice).\n\n[2] 5.1 More on Lists\nThe list data type has some more methods. Here are all of the methods of list objects:\nlist.append(x)\nAdd an item to the end of the list. Similar to a[len(a):] = [x]. list.extend(iterable)\nExtend the list by appending all the items from the iterable. Similar to a[len(a):] = iterable. list.insert(i, x)\nInsert an item at a given position. The first argument is the index of the element before which to insert, so a.\ninsert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x). list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line.\n\n[3] Similar to a[len(a):] = [x]. list.extend(iterable)\nExtend the list by appending all the items from the iterable. Similar to a[len(a):] = iterable. list.insert(i, x)\nInsert an item at a given position. The first argument is the index of the element before which to insert, so a.\ninsert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x). list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value.')",0.0012056239491190365,0.017013232514177693,0.07739584971482091,0.5925277471542358,0.6826666
Find the current directory and file's directory,"To get the full path to the directory a Python file is contained in, write this in that file:


import os 
dir_path = os.path.dirname(os.path.realpath(__file__))



(Note that the incantation above won't work if you've already used 
os.chdir()
 to change your current working directory, since the value of the 
__file__
 constant is relative to the current working directory and is not changed by an 
os.chdir()
 call.)




To get the current working directory use 


import os
cwd = os.getcwd()





Documentation references for the modules, constants and functions used above:




The 
os
 and 
os.path
 modules.


The 
__file__
 constant


os.path.realpath(path)
 (returns 
""the canonical path of the specified filename, eliminating any symbolic links encountered in the path""
)


os.path.dirname(path)
 (returns 
""the directory name of pathname 
path
""
)


os.getcwd()
 (returns 
""a string representing the current working directory""
)


os.chdir(path)
 (
""change the current working directory to 
path
""
)



","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . . 436\n11 File and Directory Access\n439\n11.1\npathlib — Object-oriented filesystem paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439\n11.1.1\nBasic use\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440\n11.1.2\nExceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n11.1.3\nPure paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . 464\n11.3\nstat — Interpreting stat() results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470\n11.4\nfilecmp — File and Directory Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . 476\n11.4.1\nThe dircmp class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477\n11.5\ntempfile — Generate temporary files and directories . . . . . . . . . . . . . . . . . . . . . . . 478\n11.5.1\nExamples\n. . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . 461\n11.1.6\nComparison to the glob module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462\n11.1.7\nComparison to the os and os.path modules . . . . . . . . . . . . . . . . . . . . . . . . 462\n11.2\nos.path — Common pathname manipulations . . . . . . . . . . . . . . . . . . . . . . . . . . . 464\n11.3\nstat — Interpreting stat() results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470\n11.4\nfilecmp — File and Directory Comparisons . . . .')",3.0816446245713875e-79,0.13793103448275862,0.08474542253199893,0.4784652292728424,0.30061772
"Why is ""1000000000000000 in range(1000000000000001)"" so fast in Python 3?","The Python 3 
range()
 object doesn't produce numbers immediately; it is a smart 
sequence object
 that produces numbers 
on demand
. All it contains is your start, stop and step values, then as you iterate over the object the next integer is calculated each iteration.


The object also implements the 
object.__contains__
 hook
, and 
calculates
 if your number is part of its range. Calculating is a (near) constant time operation 
*
. There is never a need to scan through all possible integers in the range.


From the 
range()
 object documentation
:




The advantage of the 
range
 type over a regular 
list
 or 
tuple
 is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the 
start
, 
stop
 and 
step
 values, calculating individual items and subranges as needed).




So at a minimum, your 
range()
 object would do:


class my_range:
    def __init__(self, start, stop=None, step=1, /):
        if stop is None:
            start, stop = 0, start
        self.start, self.stop, self.step = start, stop, step
        if step < 0:
            lo, hi, step = stop, start, -step
        else:
            lo, hi = start, stop
        self.length = 0 if lo > hi else ((hi - lo - 1) // step) + 1

    def __iter__(self):
        current = self.start
        if self.step < 0:
            while current > self.stop:
                yield current
                current += self.step
        else:
            while current < self.stop:
                yield current
                current += self.step

    def __len__(self):
        return self.length

    def __getitem__(self, i):
        if i < 0:
            i += self.length
        if 0 <= i < self.length:
            return self.start + i * self.step
        raise IndexError('my_range object index out of range')

    def __contains__(self, num):
        if self.step < 0:
            if not (self.stop < num <= self.start):
                return False
        else:
            if not (self.start <= num < self.stop):
                return False
        return (num - self.start) % self.step == 0



This is still missing several things that a real 
range()
 supports (such as the 
.index()
 or 
.count()
 methods, hashing, equality testing, or slicing), but should give you an idea.


I also simplified the 
__contains__
 implementation to only focus on integer tests; if you give a real 
range()
 object a non-integer value (including subclasses of 
int
), a slow scan is initiated to see if there is a match, just as if you use a containment test against a list of all the contained values. This was done to continue to support other numeric types that just happen to support equality testing with integers but are not expected to support integer arithmetic as well. See the original 
Python issue
 that implemented the containment test.




* 
Near
 constant time because Python integers are unbounded and so math operations also grow in time as N grows, making this a O(log N) operation. Since it’s all executed in optimised C code and Python stores integer values in 30-bit chunks, you’d run out of memory before you saw any performance impact due to the size of the integers involved here.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops). It calls timeit() with\nincreasing numbers from the sequence 1, 2, 5, 10, 20, 50, … until the time taken is at least 0.2 seconds. If callback is given and is not None, it will be called after each trial with two arguments:\ncallback(number, time_taken). Added in version 3.6.\nrepeat(repeat=5, number=1000000)\nCall timeit() a few times. This is a convenience function that calls the timeit() repeatedly, returning a list of results. The first\nargument specifies how many times to call timeit(). The second argument specifies the number argu-\nment for timeit(). ® Note\nIt’s tempting to calculate mean and standard deviation from the result vector and report these. How-\never, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy. So the\nmin() of the result is probably the only number you should be interested in.\n\n[2] (os.times() is pretty bad, as it returns a tuple of floating-point values). If you\nwant to substitute a better timer in the cleanest fashion, derive a class and hardwire a replacement dispatch\nmethod that best handles your timer call, along with the appropriate calibration constant. cProfile.Profile\nyour_time_func should return a single number. If it returns integers, you can also invoke the class\nconstructor with a second argument specifying the real duration of one unit of time. For example, if\nyour_integer_time_func returns times measured in thousands of seconds, you would construct the\nProfile instance as follows:\npr = cProfile.Profile(your_integer_time_func, 0.001)\nAs the cProfile.Profile class cannot be calibrated, custom timer functions should be used with care and\nshould be as fast as possible. For the best results with a custom timer, it might be necessary to hard-code it in\nthe C source of the internal _lsprof module. Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops). It calls timeit() with\nincreasing numbers from the sequence 1, 2, 5, 10, 20, 50, … until the time taken is at least 0.2 seconds. If callback is given and is not None, it will be called after each trial with two arguments:\ncallback(number, time_taken). Added in version 3.6.\nrepeat(repeat=5, number=1000000)\nCall timeit() a few times. This is a convenience function that calls the timeit() repeatedly, returning a list of results.\n\n[3] For the best results with a custom timer, it might be necessary to hard-code it in\nthe C source of the internal _lsprof module. Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops). It calls timeit() with\nincreasing numbers from the sequence 1, 2, 5, 10, 20, 50, … until the time taken is at least 0.2 seconds. If callback is given and is not None, it will be called after each trial with two arguments:\ncallback(number, time_taken). Added in version 3.6.\nrepeat(repeat=5, number=1000000)\nCall timeit() a few times. This is a convenience function that calls the timeit() repeatedly, returning a list of results. The first\nargument specifies how many times to call timeit(). The second argument specifies the number argu-\nment for timeit(). ® Note\nIt’s tempting to calculate mean and standard deviation from the result vector and report these. How-\never, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy.')",2.3517687656676343e-79,0.05802404600104548,0.20926674148255325,0.5291137099266052,0.44825372
Renaming column names in Pandas,"Just assign it to the 
.columns
 attribute:


>>> df = pd.DataFrame({'$a':[1,2], '$b': [10,20]})
>>> df
   $a  $b
0   1  10
1   2  20

>>> df.columns = ['a', 'b']
>>> df
   a   b
0  1  10
1  2  20


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] If rename is true, invalid fieldnames are automatically replaced with positional names. For example, [\'abc\',\n\'def\', \'ghi\', \'abc\'] is converted to [\'abc\', \'_1\', \'ghi\', \'_3\'], eliminating the keyword def\nand the duplicate fieldname abc. defaults can be None or an iterable of default values. Since fields with a default value must come after any\nfields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames\nare [\'x\', \'y\', \'z\'] and the defaults are (1, 2), then x will be a required argument, y will default to 1,\nand z will default to 2. If module is defined, the __module__ attribute of the named tuple is set to that value. Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more\nmemory than regular tuples. To support pickling, the named tuple class should be assigned to a variable that matches typename. Changed in version 3.1: Added support for rename. Changed in version 3.6: The verbose and rename parameters became keyword-only arguments. Changed in version 3.6: Added the module parameter. Changed in version 3.7: Removed the verbose parameter and the _source attribute. Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute. >>> # Basic example\n>>> Point = namedtuple(\'Point\', [\'x\', \'y\'])\n>>> p = Point(11, y=22)\n# instantiate with positional or keyword arguments\n>>> p[0] + p[1]\n# indexable like the plain tuple (11, 22)\n33\n>>> x, y = p\n# unpack like a regular tuple\n>>> x, y\n(11, 22)\n>>> p.x + p.y\n# fields also accessible by name\n33\n>>> p\n# readable __repr__ with a name=value style\nPoint(x=11, y=22)\nNamed tuples are especially useful for assigning field names to result tuples returned by the csv or sqlite3 modules:\nEmployeeRecord = namedtuple(\'EmployeeRecord\', \'name, age, title, department,␣\n,→paygrade\')\nimport csv\n(continues on next page)\n264\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nfor emp in map(EmployeeRecord._make, csv.reader(open(""employees.csv"", ""rb""))):\nprint(emp.name, emp.title)\nimport sqlite3\nconn = sqlite3.connect(\'/companydata\')\ncursor = conn.cursor()\ncursor.execute(\'SELECT name, age, title, department, paygrade FROM employees\')\nfor emp in map(EmployeeRecord._make, cursor.fetchall()):\nprint(emp.name, emp.title)\nIn addition to the methods inherited from tuples, named tuples support three additional methods and two attributes. To prevent conflicts with field names, the method and attribute names start with an underscore. classmethod somenamedtuple._make(iterable)\nClass method that makes a new instance from an existing sequence or iterable. >>> t = [11, 22]\n>>> Point._make(t)\nPoint(x=11, y=22)\nsomenamedtuple._asdict()\nReturn a new dict which maps field names to their corresponding values:\n>>> p = Point(x=11, y=22)\n>>> p._asdict()\n{\'x\': 11, \'y\': 22}\nChanged in version 3.1: Returns an OrderedDict instead of a regular dict. Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts\nare guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation\nis to cast the result to the desired type: OrderedDict(nt._asdict()). somenamedtuple._replace(**kwargs)\nReturn a new instance of the named tuple replacing specified fields with new values:\n>>> p = Point(x=11, y=22)\n>>> p._replace(x=33)\nPoint(x=33, y=22)\n>>> for partnum, record in inventory.items():\n...\ninventory[partnum] = record._replace(price=newprices[partnum],␣\n,→timestamp=time.now())\nNamed tuples are also supported by generic function copy.replace(). Changed in version 3.13: Raise TypeError instead of ValueError for invalid keyword arguments. somenamedtuple._fields\nTuple of strings listing the field names. Useful for introspection and for creating new named tuple types from\nexisting named tuples. >>> p._fields\n# view the field names\n(\'x\', \'y\')\n>>> Color = namedtuple(\'Color\', \'red green blue\')\n>>> Pixel = namedtuple(\'Pixel\', Point._fields + Color._fields)\n>>> Pixel(11, 22, 128, 255, 0)\nPixel(x=11, y=22, red=128, green=255, blue=0)\n8.4. collections — Container datatypes\n265\n\nThe Python Library Reference, Release 3.13.2\nsomenamedtuple._field_defaults\nDictionary mapping field names to default values. >>> Account = namedtuple(\'Account\', [\'type\', \'balance\'], defaults=[0])\n>>> Account._field_defaults\n{\'balance\': 0}\n>>> Account(\'premium\')\nAccount(type=\'premium\', balance=0)\nTo retrieve a field whose name is stored in a string, use the getattr() function:\n>>> getattr(p, \'x\')\n11\nTo convert a dictionary to a named tuple, use the double-star-operator (as described in tut-unpacking-arguments):\n>>> d = {\'x\': 11, \'y\': 22}\n>>> Point(**d)\nPoint(x=11, y=22)\nSince a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how\nto add a calculated field and a fixed-width print format:\n>>> class Point(namedtuple(\'Point\', [\'x\', \'y\'])):\n...\n__slots__ = ()\n...\n@property\n...\ndef hypot(self):\n...\nreturn (self.x ** 2 + self.y ** 2) ** 0.5\n...\ndef __str__(self):\n...\nreturn \'Point: x=%6.3f\ny=%6.3f\nhypot=%6.3f\' % (self.x, self.y, self. ,→hypot)\n>>> for p in Point(3, 4), Point(14, 5/7):\n...\nprint(p)\nPoint: x= 3.000\ny= 4.000\nhypot= 5.000\nPoint: x=14.000\ny= 0.714\nhypot=14.018\nThe subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by pre-\nventing the creation of instance dictionaries. Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the\n_fields attribute:\n>>> Point3D = namedtuple(\'Point3D\', Point._fields + (\'z\',))\nDocstrings can be customized by making direct assignments to the __doc__ fields:\n>>> Book = namedtuple(\'Book\', [\'id\', \'title\', \'authors\'])\n>>> Book.__doc__ += \': Hardcover book in active collection\'\n>>> Book.id.__doc__ = \'13-digit ISBN\'\n>>> Book.title.__doc__ = \'Title of first printing\'\n>>> Book.authors.__doc__ = \'List of authors sorted by last name\'\nChanged in version 3.5: Property docstrings became writeable. µ See also\n• See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation\nusing the class keyword:\n266\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nclass Component(NamedTuple):\npart_number: int\nweight: float\ndescription: Optional[str] = None\n• See types.SimpleNamespace() for a mutable namespace based on an underlying dictionary instead of\na tuple. • The dataclasses module provides a decorator and functions for automatically adding generated special\nmethods to user-defined classes. 8.4.6 OrderedDict objects\nOrdered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in dict class gained the ability to remember insertion order\n(this new behavior became guaranteed in Python 3.7). Some differences from dict still remain:\n• The regular dict was designed to be very good at mapping operations. Tracking insertion order was secondary. • The OrderedDict was designed to be good at reordering operations. Space efficiency, iteration speed, and\nthe performance of update operations were secondary. • The OrderedDict algorithm can handle frequent reordering operations better than dict. As shown in the\nrecipes below, this makes it suitable for implementing various kinds of LRU caches. • The equality operation for OrderedDict checks for matching order. A regular dict can emulate the order sensitive equality test with p == q and all(k1 == k2 for k1,\nk2 in zip(p, q)). • The popitem() method of OrderedDict has a different signature. It accepts an optional argument to specify\nwhich item is popped. A regular dict can emulate OrderedDict’s od.popitem(last=True) with d.popitem() which is guar-\nanteed to pop the rightmost (last) item. A regular dict can emulate OrderedDict’s od.popitem(last=False) with (k := next(iter(d)),\nd.pop(k)) which will return and remove the leftmost (first) item if it exists. • OrderedDict has a move_to_end() method to efficiently reposition an element to an endpoint.\n\n[2] Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid\nidentifiers consist of letters, digits, and underscores but do not start with a digit or underscore and cannot be a\nkeyword such as class, for, return, global, pass, or raise. If rename is true, invalid fieldnames are automatically replaced with positional names. For example, [\'abc\',\n\'def\', \'ghi\', \'abc\'] is converted to [\'abc\', \'_1\', \'ghi\', \'_3\'], eliminating the keyword def\nand the duplicate fieldname abc. defaults can be None or an iterable of default values. Since fields with a default value must come after any\nfields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames\nare [\'x\', \'y\', \'z\'] and the defaults are (1, 2), then x will be a required argument, y will default to 1,\nand z will default to 2. If module is defined, the __module__ attribute of the named tuple is set to that value. Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more\nmemory than regular tuples. To support pickling, the named tuple class should be assigned to a variable that matches typename. Changed in version 3.1: Added support for rename. Changed in version 3.6: The verbose and rename parameters became keyword-only arguments. Changed in version 3.6: Added the module parameter. Changed in version 3.7: Removed the verbose parameter and the _source attribute. Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute. >>> # Basic example\n>>> Point = namedtuple(\'Point\', [\'x\', \'y\'])\n>>> p = Point(11, y=22)\n# instantiate with positional or keyword arguments\n>>> p[0] + p[1]\n# indexable like the plain tuple (11, 22)\n33\n>>> x, y = p\n# unpack like a regular tuple\n>>> x, y\n(11, 22)\n>>> p.x + p.y\n# fields also accessible by name\n33\n>>> p\n# readable __repr__ with a name=value style\nPoint(x=11, y=22)\nNamed tuples are especially useful for assigning field names to result tuples returned by the csv or sqlite3 modules:\nEmployeeRecord = namedtuple(\'EmployeeRecord\', \'name, age, title, department,␣\n,→paygrade\')\nimport csv\n(continues on next page)\n264\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nfor emp in map(EmployeeRecord._make, csv.reader(open(""employees.csv"", ""rb""))):\nprint(emp.name, emp.title)\nimport sqlite3\nconn = sqlite3.connect(\'/companydata\')\ncursor = conn.cursor()\ncursor.execute(\'SELECT name, age, title, department, paygrade FROM employees\')\nfor emp in map(EmployeeRecord._make, cursor.fetchall()):\nprint(emp.name, emp.title)\nIn addition to the methods inherited from tuples, named tuples support three additional methods and two attributes. To prevent conflicts with field names, the method and attribute names start with an underscore. classmethod somenamedtuple._make(iterable)\nClass method that makes a new instance from an existing sequence or iterable. >>> t = [11, 22]\n>>> Point._make(t)\nPoint(x=11, y=22)\nsomenamedtuple._asdict()\nReturn a new dict which maps field names to their corresponding values:\n>>> p = Point(x=11, y=22)\n>>> p._asdict()\n{\'x\': 11, \'y\': 22}\nChanged in version 3.1: Returns an OrderedDict instead of a regular dict. Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts\nare guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation\nis to cast the result to the desired type: OrderedDict(nt._asdict()). somenamedtuple._replace(**kwargs)\nReturn a new instance of the named tuple replacing specified fields with new values:\n>>> p = Point(x=11, y=22)\n>>> p._replace(x=33)\nPoint(x=33, y=22)\n>>> for partnum, record in inventory.items():\n...\ninventory[partnum] = record._replace(price=newprices[partnum],␣\n,→timestamp=time.now())\nNamed tuples are also supported by generic function copy.replace(). Changed in version 3.13: Raise TypeError instead of ValueError for invalid keyword arguments. somenamedtuple._fields\nTuple of strings listing the field names. Useful for introspection and for creating new named tuple types from\nexisting named tuples. >>> p._fields\n# view the field names\n(\'x\', \'y\')\n>>> Color = namedtuple(\'Color\', \'red green blue\')\n>>> Pixel = namedtuple(\'Pixel\', Point._fields + Color._fields)\n>>> Pixel(11, 22, 128, 255, 0)\nPixel(x=11, y=22, red=128, green=255, blue=0)\n8.4. collections — Container datatypes\n265\n\nThe Python Library Reference, Release 3.13.2\nsomenamedtuple._field_defaults\nDictionary mapping field names to default values. >>> Account = namedtuple(\'Account\', [\'type\', \'balance\'], defaults=[0])\n>>> Account._field_defaults\n{\'balance\': 0}\n>>> Account(\'premium\')\nAccount(type=\'premium\', balance=0)\nTo retrieve a field whose name is stored in a string, use the getattr() function:\n>>> getattr(p, \'x\')\n11\nTo convert a dictionary to a named tuple, use the double-star-operator (as described in tut-unpacking-arguments):\n>>> d = {\'x\': 11, \'y\': 22}\n>>> Point(**d)\nPoint(x=11, y=22)\nSince a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how\nto add a calculated field and a fixed-width print format:\n>>> class Point(namedtuple(\'Point\', [\'x\', \'y\'])):\n...\n__slots__ = ()\n...\n@property\n...\ndef hypot(self):\n...\nreturn (self.x ** 2 + self.y ** 2) ** 0.5\n...\ndef __str__(self):\n...\nreturn \'Point: x=%6.3f\ny=%6.3f\nhypot=%6.3f\' % (self.x, self.y, self. ,→hypot)\n>>> for p in Point(3, 4), Point(14, 5/7):\n...\nprint(p)\nPoint: x= 3.000\ny= 4.000\nhypot= 5.000\nPoint: x=14.000\ny= 0.714\nhypot=14.018\nThe subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by pre-\nventing the creation of instance dictionaries. Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the\n_fields attribute:\n>>> Point3D = namedtuple(\'Point3D\', Point._fields + (\'z\',))\nDocstrings can be customized by making direct assignments to the __doc__ fields:\n>>> Book = namedtuple(\'Book\', [\'id\', \'title\', \'authors\'])\n>>> Book.__doc__ += \': Hardcover book in active collection\'\n>>> Book.id.__doc__ = \'13-digit ISBN\'\n>>> Book.title.__doc__ = \'Title of first printing\'\n>>> Book.authors.__doc__ = \'List of authors sorted by last name\'\nChanged in version 3.5: Property docstrings became writeable. µ See also\n• See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation\nusing the class keyword:\n266\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nclass Component(NamedTuple):\npart_number: int\nweight: float\ndescription: Optional[str] = None\n• See types.SimpleNamespace() for a mutable namespace based on an underlying dictionary instead of\na tuple. • The dataclasses module provides a decorator and functions for automatically adding generated special\nmethods to user-defined classes. 8.4.6 OrderedDict objects\nOrdered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in dict class gained the ability to remember insertion order\n(this new behavior became guaranteed in Python 3.7). Some differences from dict still remain:\n• The regular dict was designed to be very good at mapping operations. Tracking insertion order was secondary. • The OrderedDict was designed to be good at reordering operations. Space efficiency, iteration speed, and\nthe performance of update operations were secondary. • The OrderedDict algorithm can handle frequent reordering operations better than dict. As shown in the\nrecipes below, this makes it suitable for implementing various kinds of LRU caches. • The equality operation for OrderedDict checks for matching order. A regular dict can emulate the order sensitive equality test with p == q and all(k1 == k2 for k1,\nk2 in zip(p, q)). • The popitem() method of OrderedDict has a different signature. It accepts an optional argument to specify\nwhich item is popped. A regular dict can emulate OrderedDict’s od.popitem(last=True) with d.popitem() which is guar-\nanteed to pop the rightmost (last) item.\n\n[3] The field_names are a sequence of strings such as [\'x\', \'y\']. Alternatively, field_names can be a single\nstring with each fieldname separated by whitespace and/or commas, for example \'x y\' or \'x, y\'. Any valid Python identifier may be used for a fieldname except for names starting with an underscore. Valid\nidentifiers consist of letters, digits, and underscores but do not start with a digit or underscore and cannot be a\nkeyword such as class, for, return, global, pass, or raise. If rename is true, invalid fieldnames are automatically replaced with positional names. For example, [\'abc\',\n\'def\', \'ghi\', \'abc\'] is converted to [\'abc\', \'_1\', \'ghi\', \'_3\'], eliminating the keyword def\nand the duplicate fieldname abc. defaults can be None or an iterable of default values. Since fields with a default value must come after any\nfields without a default, the defaults are applied to the rightmost parameters. For example, if the fieldnames\nare [\'x\', \'y\', \'z\'] and the defaults are (1, 2), then x will be a required argument, y will default to 1,\nand z will default to 2. If module is defined, the __module__ attribute of the named tuple is set to that value. Named tuple instances do not have per-instance dictionaries, so they are lightweight and require no more\nmemory than regular tuples. To support pickling, the named tuple class should be assigned to a variable that matches typename. Changed in version 3.1: Added support for rename. Changed in version 3.6: The verbose and rename parameters became keyword-only arguments. Changed in version 3.6: Added the module parameter. Changed in version 3.7: Removed the verbose parameter and the _source attribute. Changed in version 3.7: Added the defaults parameter and the _field_defaults attribute. >>> # Basic example\n>>> Point = namedtuple(\'Point\', [\'x\', \'y\'])\n>>> p = Point(11, y=22)\n# instantiate with positional or keyword arguments\n>>> p[0] + p[1]\n# indexable like the plain tuple (11, 22)\n33\n>>> x, y = p\n# unpack like a regular tuple\n>>> x, y\n(11, 22)\n>>> p.x + p.y\n# fields also accessible by name\n33\n>>> p\n# readable __repr__ with a name=value style\nPoint(x=11, y=22)\nNamed tuples are especially useful for assigning field names to result tuples returned by the csv or sqlite3 modules:\nEmployeeRecord = namedtuple(\'EmployeeRecord\', \'name, age, title, department,␣\n,→paygrade\')\nimport csv\n(continues on next page)\n264\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nfor emp in map(EmployeeRecord._make, csv.reader(open(""employees.csv"", ""rb""))):\nprint(emp.name, emp.title)\nimport sqlite3\nconn = sqlite3.connect(\'/companydata\')\ncursor = conn.cursor()\ncursor.execute(\'SELECT name, age, title, department, paygrade FROM employees\')\nfor emp in map(EmployeeRecord._make, cursor.fetchall()):\nprint(emp.name, emp.title)\nIn addition to the methods inherited from tuples, named tuples support three additional methods and two attributes. To prevent conflicts with field names, the method and attribute names start with an underscore. classmethod somenamedtuple._make(iterable)\nClass method that makes a new instance from an existing sequence or iterable. >>> t = [11, 22]\n>>> Point._make(t)\nPoint(x=11, y=22)\nsomenamedtuple._asdict()\nReturn a new dict which maps field names to their corresponding values:\n>>> p = Point(x=11, y=22)\n>>> p._asdict()\n{\'x\': 11, \'y\': 22}\nChanged in version 3.1: Returns an OrderedDict instead of a regular dict. Changed in version 3.8: Returns a regular dict instead of an OrderedDict. As of Python 3.7, regular dicts\nare guaranteed to be ordered. If the extra features of OrderedDict are required, the suggested remediation\nis to cast the result to the desired type: OrderedDict(nt._asdict()). somenamedtuple._replace(**kwargs)\nReturn a new instance of the named tuple replacing specified fields with new values:\n>>> p = Point(x=11, y=22)\n>>> p._replace(x=33)\nPoint(x=33, y=22)\n>>> for partnum, record in inventory.items():\n...\ninventory[partnum] = record._replace(price=newprices[partnum],␣\n,→timestamp=time.now())\nNamed tuples are also supported by generic function copy.replace(). Changed in version 3.13: Raise TypeError instead of ValueError for invalid keyword arguments. somenamedtuple._fields\nTuple of strings listing the field names. Useful for introspection and for creating new named tuple types from\nexisting named tuples. >>> p._fields\n# view the field names\n(\'x\', \'y\')\n>>> Color = namedtuple(\'Color\', \'red green blue\')\n>>> Pixel = namedtuple(\'Pixel\', Point._fields + Color._fields)\n>>> Pixel(11, 22, 128, 255, 0)\nPixel(x=11, y=22, red=128, green=255, blue=0)\n8.4. collections — Container datatypes\n265\n\nThe Python Library Reference, Release 3.13.2\nsomenamedtuple._field_defaults\nDictionary mapping field names to default values. >>> Account = namedtuple(\'Account\', [\'type\', \'balance\'], defaults=[0])\n>>> Account._field_defaults\n{\'balance\': 0}\n>>> Account(\'premium\')\nAccount(type=\'premium\', balance=0)\nTo retrieve a field whose name is stored in a string, use the getattr() function:\n>>> getattr(p, \'x\')\n11\nTo convert a dictionary to a named tuple, use the double-star-operator (as described in tut-unpacking-arguments):\n>>> d = {\'x\': 11, \'y\': 22}\n>>> Point(**d)\nPoint(x=11, y=22)\nSince a named tuple is a regular Python class, it is easy to add or change functionality with a subclass. Here is how\nto add a calculated field and a fixed-width print format:\n>>> class Point(namedtuple(\'Point\', [\'x\', \'y\'])):\n...\n__slots__ = ()\n...\n@property\n...\ndef hypot(self):\n...\nreturn (self.x ** 2 + self.y ** 2) ** 0.5\n...\ndef __str__(self):\n...\nreturn \'Point: x=%6.3f\ny=%6.3f\nhypot=%6.3f\' % (self.x, self.y, self. ,→hypot)\n>>> for p in Point(3, 4), Point(14, 5/7):\n...\nprint(p)\nPoint: x= 3.000\ny= 4.000\nhypot= 5.000\nPoint: x=14.000\ny= 0.714\nhypot=14.018\nThe subclass shown above sets __slots__ to an empty tuple. This helps keep memory requirements low by pre-\nventing the creation of instance dictionaries. Subclassing is not useful for adding new, stored fields. Instead, simply create a new named tuple type from the\n_fields attribute:\n>>> Point3D = namedtuple(\'Point3D\', Point._fields + (\'z\',))\nDocstrings can be customized by making direct assignments to the __doc__ fields:\n>>> Book = namedtuple(\'Book\', [\'id\', \'title\', \'authors\'])\n>>> Book.__doc__ += \': Hardcover book in active collection\'\n>>> Book.id.__doc__ = \'13-digit ISBN\'\n>>> Book.title.__doc__ = \'Title of first printing\'\n>>> Book.authors.__doc__ = \'List of authors sorted by last name\'\nChanged in version 3.5: Property docstrings became writeable. µ See also\n• See typing.NamedTuple for a way to add type hints for named tuples. It also provides an elegant notation\nusing the class keyword:\n266\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\nclass Component(NamedTuple):\npart_number: int\nweight: float\ndescription: Optional[str] = None\n• See types.SimpleNamespace() for a mutable namespace based on an underlying dictionary instead of\na tuple. • The dataclasses module provides a decorator and functions for automatically adding generated special\nmethods to user-defined classes. 8.4.6 OrderedDict objects\nOrdered dictionaries are just like regular dictionaries but have some extra capabilities relating to ordering operations. They have become less important now that the built-in dict class gained the ability to remember insertion order\n(this new behavior became guaranteed in Python 3.7). Some differences from dict still remain:\n• The regular dict was designed to be very good at mapping operations. Tracking insertion order was secondary. • The OrderedDict was designed to be good at reordering operations. Space efficiency, iteration speed, and\nthe performance of update operations were secondary. • The OrderedDict algorithm can handle frequent reordering operations better than dict. As shown in the\nrecipes below, this makes it suitable for implementing various kinds of LRU caches. • The equality operation for OrderedDict checks for matching order. A regular dict can emulate the order sensitive equality test with p == q and all(k1 == k2 for k1,\nk2 in zip(p, q)). • The popitem() method of OrderedDict has a different signature.')",4.897544352921805e-156,0.009216589861751152,0.06406618835216535,0.5253665447235107,0.20461959
"Convert string ""Jun 1 2005 1:33PM"" into datetime","datetime.strptime
 parses an input string in the user-specified format into a 
timezone-naive
 
datetime
 object:


>>> from datetime import datetime
>>> datetime.strptime('Jun 1 2005  1:33PM', '%b %d %Y %I:%M%p')
datetime.datetime(2005, 6, 1, 13, 33)



To obtain a 
date
 object using an existing 
datetime
 object, convert it using 
.date()
:


>>> datetime.strptime('Jun 1 2005', '%b %d %Y').date()
date(2005, 6, 1)





Links:




strptime
 docs: 
Python 2
, 
Python 3




strptime
/
strftime
 format string docs: 
Python 2
, 
Python 3




strftime.org
 format string cheatsheet






Notes:




strptime
 = ""string parse time""


strftime
 = ""string format time""



","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . 213\n8.1.7\ntime Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225\n8.1.8\ntzinfo Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n8.1.9\ntimezone Objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235\n8.1.10\nstrftime() and strptime() Behavior\n. . . . . . . . . . . . . . . . . . . . . . . . . 236\n8.2\nzoneinfo — IANA time zone support\n. . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204\n8.1.4\ntimedelta Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\n8.1.5\ndate Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n8.1.6\ndatetime Objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\n8.1.7\ntime Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . 199\n7.2.5\nencodings.idna — Internationalized Domain Names in Applications . . . . . . . . . . 201\n7.2.6\nencodings.mbcs — Windows ANSI codepage . . . . . . . . . . . . . . . . . . . . . . 202\n7.2.7\nencodings.utf_8_sig — UTF-8 codec with BOM signature . . . . . . . . . . . . . . 202\n8\nData Types\n203\n8.1\ndatetime — Basic date and time types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203\n8.1.1\nAware and Naive Objects . . . . . . . . . . . . . .')",8.523342329921901e-156,0.11864406779661017,0.07045929018789143,0.46838438510894775,0.2621882
How can I remove a key from a Python dictionary?,"To delete a key regardless of whether it is in the dictionary, use the two-argument form of 
dict.pop()
:


my_dict.pop('key', None)



This will return 
my_dict[key]
 if 
key
 exists in the dictionary, and 
None
 otherwise. If the second parameter is not specified (i.e. 
my_dict.pop('key')
) and 
key
 does not exist, a 
KeyError
 is raised.


To delete a key that is guaranteed to exist, you can also use


del my_dict['key']



This will raise a 
KeyError
 if the key is not in the dictionary.

","('Answer: To remove a key from a dictionary, you can use `del d[key]`. If the key is not in the dictionary, it will raise a KeyError. You can also use `pop(key[, default])` which will remove the key and return its value, or return the default value if the key is not found and a default is specified. If the key is not in the dictionary and no default is given, a KeyError is raised.\n\nReferences: [1]\n', '[1] d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6.\n\n[2] key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nDictionaries and dictionary views are reversible. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(reversed(d))\n[\'four\', \'three\', \'two\', \'one\']\n>>> list(reversed(d.values()))\n[4, 3, 2, 1]\n>>> list(reversed(d.items()))\n[(\'four\', 4), (\'three\', 3), (\'two\', 2), (\'one\', 1)]\nChanged in version 3.8: Dictionaries are now reversible.\n\n[3] remove(elem)\nRemove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem)\nRemove element elem from the set if it is present. pop()\nRemove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear()\nRemove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(),\nand symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To\nsupport searching for an equivalent frozenset, a temporary one is created from elem. 4.11 Mapping Types — dict\nA mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only\none standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and\nthe collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-\nnaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary\nentry. class dict(**kwargs)\nclass dict(mapping, **kwargs)\n4.11. Mapping Types — dict\n87\n\nThe Python Library Reference, Release 3.13.2\nclass dict(iterable, **kwargs)\nReturn a new dictionary initialized from an optional positional argument and a possibly empty set of keyword\narguments. Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError.')",0.009602161247317813,0.047529234251225946,0.11675144400016756,0.634619414806366,0.72048163
How to upgrade all Python packages with pip,"There isn't a built-in flag yet. Starting with pip version 22.3, the 
--outdated
 and 
--format=freeze
 have become 
mutually exclusive
. Use Python, to parse the JSON output:


pip --disable-pip-version-check list --outdated --format=json | python -c ""import json, sys; print('\n'.join([x['name'] for x in json.load(sys.stdin)]))"" | xargs -n1 pip install -U



If you are using 
pip<22.3
 you can use:


pip list --outdated --format=freeze | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U



For older versions of 
pip
:


pip freeze --local | grep -v '^\-e' | cut -d = -f 1  | xargs -n1 pip install -U







The 
grep
 is to skip editable (""-e"") package definitions, as suggested by 
@jawache
. (Yes, you could replace 
grep
+
cut
 with 
sed
 or 
awk
 or 
perl
 or...).




The 
-n1
 flag for 
xargs
 prevents stopping everything if updating one package fails (thanks 
@andsens
).








Note:
 there are infinite potential variations for this. I'm trying to keep this answer short and simple, but please do suggest variations in the comments!

","('Answer: To upgrade a Python package, you can use the command `python -m pip install --upgrade SomePackage`.\n\nReferences: [1]\n', '[1] . . . . . . . . . . . . . . . . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide.\n\n[2] . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip. µ See also\nPython Packaging User Guide: Installing Scientific Packages\n3.4 … work with multiple versions of Python installed in parallel? On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch\nto run the appropriate copy of pip:\npython2\n-m pip install SomePackage\n# default Python 2\npython2.7 -m pip install SomePackage\n# specifically Python 2.7\npython3\n-m pip install SomePackage\n# default Python 3\npython3.4 -m pip install SomePackage\n# specifically Python 3.4\nAppropriately versioned pip commands may also be available. On Windows, use the py Python launcher in combination with the -m switch:\n7\n\nInstalling Python Modules, Release 3.13.2\npy -2\n-m pip install SomePackage\n# default Python 2\npy -2.7 -m pip install SomePackage\n# specifically Python 2.7\npy -3\n-m pip install SomePackage\n# default Python 3\npy -3.4 -m pip install SomePackage\n# specifically Python 3.4\n8\nChapter 3. How do I …? CHAPTER\nFOUR\nCOMMON INSTALLATION ISSUES\n4.1 Installing into the system Python on Linux\nOn Linux systems, a Python installation will typically be included as part of the distribution. Installing into this\nPython installation requires root access to the system, and may interfere with the operation of the system package\nmanager and other components of the system if a component is unexpectedly upgraded using pip. On such systems, it is often better to use a virtual environment or a per-user installation when installing packages\nwith pip. 4.2 Pip not installed\nIt is possible that pip does not get installed by default. One potential fix is:\npython -m ensurepip --default-pip\nThere are also additional resources for installing pip.\n\n[3] . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip. µ See also\nPython Packaging User Guide: Installing Scientific Packages\n3.4 … work with multiple versions of Python installed in parallel? On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch\nto run the appropriate copy of pip:\npython2\n-m pip install SomePackage\n# default Python 2\npython2.7 -m pip install SomePackage\n# specifically Python 2.7\npython3\n-m pip install SomePackage\n# default Python 3\npython3.4 -m pip install SomePackage\n# specifically Python 3.4\nAppropriately versioned pip commands may also be available.')",1.3224229780572956e-155,0.03889255108767303,0.12507565059511802,0.5572523474693298,0.43875867
How to sort a list of dictionaries by a value of the dictionary in Python?,"The 
sorted()
 function takes a 
key=
 parameter


newlist = sorted(list_to_be_sorted, key=lambda d: d['name'])



Alternatively, you can use 
operator.itemgetter
 instead of defining the function yourself


from operator import itemgetter
newlist = sorted(list_to_be_sorted, key=itemgetter('name'))



For completeness, add 
reverse=True
 to sort in descending order


newlist = sorted(list_to_be_sorted, key=itemgetter('name'), reverse=True)


","('Answer: To sort a list of dictionaries by a value, you can use the `sorted()` function with the `key` parameter. The `key` parameter should be a function that takes a single dictionary as an argument and returns the value to be used for sorting. A common way to define the key function is to use a lambda expression.\n\nReferences: [2]\n', '[1] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient.\n\n[2] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys. For example:\n>>> student_tuples = [\n...\n(\'john\', \'A\', 15),\n...\n(\'jane\', \'B\', 12),\n...\n(\'dave\', \'B\', 10),\n... ]\n>>> sorted(student_tuples, key=lambda student: student[2])\n# sort by age\n[(\'dave\', \'B\', 10), (\'jane\', \'B\', 12), (\'john\', \'A\', 15)]\nThe same technique works for objects with named attributes.\n\n[3] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys.')",2.390243934848516e-79,0.05779334500875656,0.12780312992945853,0.5016433596611023,0.7140908
How do I get the last element of a list?,"some_list[-1]
 is the shortest and most Pythonic.


In fact, you can do much more with this syntax. The 
some_list[-n]
 syntax gets the nth-to-last element. So 
some_list[-1]
 gets the last element, 
some_list[-2]
 gets the second to last, etc, all the way down to 
some_list[-len(some_list)]
, which gives you the first element.


You can also set list elements in this way. For instance:


>>> some_list = [1, 2, 3]
>>> some_list[-1] = 5 # Set the last element
>>> some_list[-2] = 3 # Set the second to last element
>>> some_list
[1, 3, 5]



Note that getting a list item by index will raise an 
IndexError
 if the expected item doesn't exist. This means that 
some_list[-1]
 will raise an exception if 
some_list
 is empty, because an empty list can't have a last element.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.1\nHow do I convert between tuples and lists? . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . 21\n2.3.11\nCan I end a raw string with an odd number of backslashes? . . . . . . . . . . . . . . . . 21\n2.4\nPerformance\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.4.1\nMy program is too slow. How do I speed it up? . . . . . . . . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . .')",1.4090566231949945e-155,0.1345565749235474,0.13458950201884254,0.46613186597824097,0.6098723
How to leave/exit/deactivate a Python virtualenv,"Usually, activating a virtualenv gives you a shell function named:


$ deactivate



which puts things back to normal.


I have just looked specifically again at the code for 
virtualenvwrapper
, and, yes, it too supports 
deactivate
 as the way to escape from all virtualenvs.


If you are trying to leave an 
Anaconda
 environment, the command depends upon your version of 
conda
. Recent versions (like 4.6) install a 
conda
 function directly in your shell, in which case you run:


conda deactivate



Older conda versions instead implement deactivation using a stand-alone script:


source deactivate


","('Answer: To deactivate a Python virtual environment, you can type `deactivate` in your shell.\n\nReferences: [1]\n', '[1] It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it. In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the envi-\nronment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that\ninterpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the\nlauncher installed. Thus, double-clicking an installed script in a Windows Explorer window should run it with the\ncorrect interpreter without the environment needing to be activated or on the PATH. 29.2. venv — Creation of virtual environments\n1893\n\nThe Python Library Reference, Release 3.13.2\nWhen a virtual environment has been activated, the VIRTUAL_ENV environment variable is set to the path of the\nenvironment. Since explicitly activating a virtual environment is not required to use it, VIRTUAL_ENV cannot be\nrelied upon to determine whether a virtual environment is being used. Á Warning\nBecause scripts installed in environments should not expect the environment to be activated, their shebang lines\ncontain the absolute paths to their environment’s interpreters. Because of this, environments are inherently non-\nportable, in the general case. You should always have a simple means of recreating an environment (for example,\nif you have a requirements file requirements.txt, you can invoke pip install -r requirements.txt\nusing the environment’s pip to install all of the packages needed by the environment). If for any reason you need\nto move the environment to a new location, you should recreate it at the desired location and delete the one at the\nold location. If you move an environment because you moved a parent directory of it, you should recreate the\nenvironment in its new location. Otherwise, software installed into the environment may not work as expected. You can deactivate a virtual environment by typing deactivate in your shell. The exact mechanism is platform-\nspecific and is an internal implementation detail (typically, a script or shell function will be used).\n\n[2] These are by default isolated from software in other virtual environments and\nPython interpreters and libraries installed in the operating system. • Contained in a directory, conventionally named .venv or venv in the project directory, or under a container\ndirectory for lots of virtual environments, such as ~/.virtualenvs. • Not checked into source control systems such as Git. • Considered as disposable – it should be simple to delete and recreate it from scratch. You don’t place any\nproject code in the environment. • Not considered as movable or copyable – you just recreate the same environment in the target location. See PEP 405 for more background on Python virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\nAvailability: not Android, not iOS, not WASI. This module is not supported on mobile platforms or WebAssembly platforms. 29.2.1 Creating virtual environments\nVirtual environments are created by executing the venv module:\npython -m venv /path/to/new/virtual/environment\nThis creates the target directory (including parent directories as needed) and places a pyvenv.cfg file in it with a\nhome key pointing to the Python installation from which the command was run. It also creates a bin (or Scripts\non Windows) subdirectory containing a copy or symlink of the Python executable (as appropriate for the platform\nor arguments used at environment creation time). It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it. In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the envi-\nronment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that\ninterpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the\nlauncher installed.\n\n[3] • Contained in a directory, conventionally named .venv or venv in the project directory, or under a container\ndirectory for lots of virtual environments, such as ~/.virtualenvs. • Not checked into source control systems such as Git. • Considered as disposable – it should be simple to delete and recreate it from scratch. You don’t place any\nproject code in the environment. • Not considered as movable or copyable – you just recreate the same environment in the target location. See PEP 405 for more background on Python virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\nAvailability: not Android, not iOS, not WASI. This module is not supported on mobile platforms or WebAssembly platforms. 29.2.1 Creating virtual environments\nVirtual environments are created by executing the venv module:\npython -m venv /path/to/new/virtual/environment\nThis creates the target directory (including parent directories as needed) and places a pyvenv.cfg file in it with a\nhome key pointing to the Python installation from which the command was run. It also creates a bin (or Scripts\non Windows) subdirectory containing a copy or symlink of the Python executable (as appropriate for the platform\nor arguments used at environment creation time). It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it. In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the envi-\nronment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that\ninterpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the\nlauncher installed. Thus, double-clicking an installed script in a Windows Explorer window should run it with the\ncorrect interpreter without the environment needing to be activated or on the PATH.')",1.3940313631177536e-79,0.022441160372194853,0.09114304096075487,0.515383780002594,0.55776066
How do I install pip on Windows?,"Python 3.4+ and 2.7.9+


Good news! 
Python 3.4
 (released March 2014) and 
Python 2.7.9
 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins 
Ruby
, 
Node.js
, 
Haskell
, 
Perl
, 
Go
—almost every other contemporary language with a majority open-source community. Thank you, Python.


If you do find that pip is not available, simply run 
ensurepip
.




On Windows:


py -3 -m ensurepip





Otherwise:


python3 -m ensurepip







Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this 
in the Stack Overflow question 
Does Python have a package/module management system?
.


Python 3 ≤ 3.3 and 2 ≤ 2.7.8


Flying in the face of its 
'batteries included'
 motto, Python ships without a package manager. To make matters worse, Pip was—until recently—ironically difficult to install.


Official instructions


Per 
https://pip.pypa.io/en/stable/installing/#do-i-need-to-install-pip
:


Download 
get-pip.py
, being careful to save it as a 
.py
 file rather than 
.txt
. Then, run it from the command prompt:


python get-pip.py



You possibly need an administrator command prompt to do this. Follow 
Start a Command Prompt as an Administrator
 (Microsoft TechNet).


This installs the pip package, which (in Windows) contains ...\Scripts\pip.exe that path must be in PATH environment variable to use pip from the command line (see the second part of 'Alternative Instructions' for adding it to your PATH,


Alternative instructions


The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced and prohibitively difficult for newbies.


For our sake, Christoph Gohlke prepares Windows installers (
.msi
) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to:




Install setuptools


Install pip




For me, this installed Pip at 
C:\Python27\Scripts\pip.exe
. Find 
pip.exe
 on your computer, then add its folder (for example, 
C:\Python27\Scripts
) to your path (Start / Edit environment variables). Now you should be able to run 
pip
 from the command line. Try installing a package:


pip install httpie



There you go (hopefully)! Solutions for common problems are given below:


Proxy problems


If you work in an office, you might be behind an HTTP proxy. If so, set the environment variables 
http_proxy
 and 
https_proxy
. Most Python applications (and other free software) respect these. Example syntax:


http://proxy_url:port
http://username:password@proxy_url:port



If you're really unlucky, your proxy might be a Microsoft 
NTLM
 proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. 
http://cntlm.sourceforge.net/


Unable to find vcvarsall.bat


Python modules can be partly written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.




Error: Unable to find vcvarsall.bat




You can fix that by 
installing a C++ compiler
 such as 
MinGW
 or 
Visual C++
. Microsoft actually ships one specifically for use with Python. Or try 
Microsoft Visual C++ Compiler for Python 2.7
.


Often though it's easier to check 
Christoph's site
 for your package.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . 7\n3.2\n… install packages just for the current user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3\n… install scientific Python packages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.4\n… work with multiple versions of Python installed in parallel? . . . . . . . . . . . . . . . . . . . 7\n4\nCommon installation issues\n9\n4.1\nInstalling into the system Python on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2\nPip not installed .\n\n[2] Installing Python Modules\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\n\n\nCONTENTS\n1\nKey terms\n3\n2\nBasic usage\n5\n3\nHow do I …? 7\n3.1\n… install pip in versions of Python prior to Python 3.4? . . . . . . . . . . . . . . . . . . . . . . 7\n3.2\n… install packages just for the current user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3\n… install scientific Python packages? . . . . . . . . . . . . . . .\n\n[3] This finder is enabled on Windows in 3.6.0 and earlier,\nbut may need to be explicitly added to sys.meta_path in the future. 4.9. Finding modules\n59\n\nPython Setup and Usage, Release 3.13.2\n4.10 Additional modules\nEven though Python aims to be portable among all platforms, there are features that are unique to Windows. A couple\nof modules, both in the standard library and external, and snippets exist to use these features. The Windows-specific standard modules are documented in mswin-specific-services. 4.10.1 PyWin32\nThe PyWin32 module by Mark Hammond is a collection of modules for advanced Windows-specific support. This\nincludes utilities for:\n• Component Object Model (COM)\n• Win32 API calls\n• Registry\n• Event log\n• Microsoft Foundation Classes (MFC) user interfaces\nPythonWin is a sample MFC application shipped with PyWin32. It is an embeddable IDE with a built-in debugger. µ See also\nWin32 How Do I…? by Tim Golden\nPython and COM\nby David and Paul Boddie\n4.10.2 cx_Freeze\ncx_Freeze wraps Python scripts into executable Windows programs (*.exe files). When you have done this, you\ncan distribute your application without requiring your users to install Python. 4.11 Compiling Python on Windows\nIf you want to compile CPython yourself, first thing you should do is get the source. You can download either the\nlatest release’s source or just grab a fresh checkout. The source tree contains a build solution and project files for Microsoft Visual Studio, which is the compiler used to\nbuild the official Python releases. These files are in the PCbuild directory. Check PCbuild/readme.txt for general information on the build process. For extension modules, consult building-on-windows. 4.12 Other Platforms\nWith ongoing development of Python, some platforms that used to be supported earlier are no longer supported (due\nto the lack of users or developers). Check PEP 11 for details on all unsupported platforms. • Windows CE is no longer supported since Python 3 (if it ever was). • The Cygwin installer offers to install the Python interpreter as well\nSee Python for Windows for detailed information about platforms with pre-compiled installers. 60\nChapter 4. Using Python on Windows\n\nCHAPTER\nFIVE\nUSING PYTHON ON MACOS\nThis document aims to give an overview of macOS-specific behavior you should know about to get started with Python\non Mac computers. Python on a Mac running macOS is very similar to Python on other Unix-derived platforms, but\nthere are some differences in installation and some features. There are various ways to obtain and install Python for macOS. Pre-built versions of the most recent versions of\nPython are available from a number of distributors. Much of this document describes use of the Pythons provided\nby the CPython release team for download from the python.org website. See Alternative Distributions for some other\noptions. 5.1 Using Python for macOS from python.org\n5.1.1 Installation steps\nFor current Python versions (other than those in security status), the release team produces a Python for macOS\ninstaller package for each new release. A list of available installers is available here. We recommend using the most\nrecent supported Python version where possible. Current installers provide a universal2 binary build of Python which\nruns natively on all Macs (Apple Silicon and Intel) that are supported by a wide range of macOS versions, currently\ntypically from at least macOS 10.13 High Sierra on. The downloaded file is a standard macOS installer package file (.pkg). File integrity information (checksum, size,\nsigstore signature, etc) for each file is included on the release download page. Installer packages and their contents\nare signed and notarized with Python Software Foundation Apple Developer ID certificates to meet macOS\nGatekeeper requirements. For a default installation, double-click on the downloaded installer package file. This should launch the standard\nmacOS Installer app and display the first of several installer windows steps. 61\n\nPython Setup and Usage, Release 3.13.2\nClicking on the Continue button brings up the Read Me for this installer. Besides other important information, the\nRead Me documents which Python version is going to be installed and on what versions of macOS it is supported. You\nmay need to scroll through to read the whole file. By default, this Read Me will also be installed in /Applications/\nPython 3.13/ and available to read anytime. 62\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\nClicking on Continue proceeds to display the license for Python and for other included software. You will then need\nto Agree to the license terms before proceeding to the next step. This license file will also be installed and available\nto be read later. 5.1. Using Python for macOS from python.org\n63\n\nPython Setup and Usage, Release 3.13.2\nAfter the license terms are accepted, the next step is the Installation Type display. For most uses, the standard set\nof installation operations is appropriate. 64\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\nBy pressing the Customize button, you can choose to omit or select certain package components of the installer. Click\non each package name to see a description of what it installs.')",6.257583678813946e-79,0.12192118226600987,0.26423069368204605,0.558313250541687,0.5316592
How do I parse a string to a float or int?,">>> a = ""545.2222""
>>> float(a)
545.22220000000004
>>> int(float(a))
545


","('Answer: To convert a string to an integer, use `int()`. To convert a string to a floating-point number, use `float()`. The `int()` function can also take an optional second argument specifying the base to convert from.\n\nReferences: [3]\n', '[1] If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task. 2.3.10 What does UnicodeDecodeError or UnicodeEncodeError error mean? See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this.\n\n[2] Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task.\n\n[3] Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task. 2.3.10 What does UnicodeDecodeError or UnicodeEncodeError error mean? See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this. One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython.')",4.3010941199411877e-156,0.00356718192627824,0.0412941561273441,0.4634188711643219,0.48396298
How do I get a substring of a string in Python?,">>> x = ""Hello World!""
>>> x[2:]
'llo World!'
>>> x[:2]
'He'
>>> x[:-2]
'Hello Worl'
>>> x[-2:]
'd!'
>>> x[2:-2]
'llo Worl'



Python calls this concept ""slicing"" and it works on more than just strings. Take a look 
here
 for a comprehensive introduction.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", ""[1] We’ll complicate the pattern again in an effort to fix it. . *[.]([^b].?.?|.[^a]?.?|..?[^t]? )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE.\n\n[2] )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate\nportions of the original text in the resulting replacement string. This example matches the word section followed by a string enclosed in {, }, and changes section to\nsubsection:\n>>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)\n>>> p.sub(r'subsection{\\1}','section{First} section{second}')\n'subsection{First} subsection{second}'\nThere’s also a syntax for referring to named groups as defined by the (?P<name>...) syntax. \\g<name> will use\nthe substring matched by the group named name, and \\g<number> uses the corresponding group number.\n\n[3] . *[.]([^b].?.?|.[^a]?.?|..?[^t]? )$\nIn the third attempt, the second and third letters are all made optional in order to allow matching extensions shorter\nthan three characters, such as sendmail.cf. The pattern’s getting really complicated now, which makes it hard to read and understand. Worse, if the problem\nchanges and you want to exclude both bat and exe as extensions, the pattern would get even more complicated and\nconfusing. A negative lookahead cuts through all this confusion:\n. *[.](?!bat$)[^. ]*$ The negative lookahead means: if the expression bat doesn’t match at this point, try the\nrest of the pattern; if bat$ does match, the whole pattern will fail. The trailing $ is required to ensure that something\nlike sample.batch, where the extension only starts with bat, will be allowed. The [^. ]* makes sure that the\npattern works when there are multiple dots in the filename. Excluding another filename extension is now easy; simply add it as an alternative inside the assertion. The following\npattern excludes filenames that end in either bat or exe:\n. *[.](?!bat$|exe$)[^. ]*$\n5 Modifying Strings\nUp to this point, we’ve simply performed searches against a static string. Regular expressions are also commonly\nused to modify strings in various ways, using the following pattern methods:\nMethod/Attribute\nPurpose\nsplit()\nSplit the string into a list, splitting it wherever the RE matches\nsub()\nFind all substrings where the RE matches, and replace them with a different string\nsubn()\nDoes the same thing as sub(), but returns the new string and the number of replacements\n5.1 Splitting Strings\nThe split() method of a pattern splits a string apart wherever the RE matches, returning a list of the pieces. It’s\nsimilar to the split() method of strings but provides much more generality in the delimiters that you can split by;\nstring split() only supports splitting by whitespace or by a fixed string. As you’d expect, there’s a module-level\nre.split() function, too. .split(string[, maxsplit=0])\nSplit string by the matches of the regular expression. If capturing parentheses are used in the RE, then their\ncontents will also be returned as part of the resulting list. If maxsplit is nonzero, at most maxsplit splits are\nperformed. You can limit the number of splits made, by passing a value for maxsplit. When maxsplit is nonzero, at most maxsplit\nsplits will be made, and the remainder of the string is returned as the final element of the list. In the following\nexample, the delimiter is any sequence of non-alphanumeric characters. 14\n\n>>> p = re.compile(r'\\W+')\n>>> p.split('This is a test, short and sweet, of split().') ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']\n>>> p.split('This is a test, short and sweet, of split(). ', 3)\n['This', 'is', 'a', 'test, short and sweet, of split().'] Sometimes you’re not only interested in what the text between delimiters is, but also need to know what the delimiter\nwas. If capturing parentheses are used in the RE, then their values are also returned as part of the list. Compare the\nfollowing calls:\n>>> p = re.compile(r'\\W+')\n>>> p2 = re.compile(r'(\\W+)')\n>>> p.split('This... is a test.') ['This', 'is', 'a', 'test', '']\n>>> p2.split('This... is a test.') ['This', '... ', 'is', ' ', 'a', ' ', 'test', '. ', '']\nThe module-level function re.split() adds the RE to be used as the first argument, but is otherwise the same. >>> re.split(r'[\\W]+', 'Words, words, words.') ['Words', 'words', 'words', '']\n>>> re.split(r'([\\W]+)', 'Words, words, words.') ['Words', ', ', 'words', ', ', 'words', '. ', '']\n>>> re.split(r'[\\W]+', 'Words, words, words. ', 1)\n['Words', 'words, words.'] 5.2 Search and Replace\nAnother common task is to find all the matches for a pattern, and replace them with a different string. The sub()\nmethod takes a replacement value, which can be either a string or a function, and the string to be processed. .sub(replacement, string[, count=0])\nReturns the string obtained by replacing the leftmost non-overlapping occurrences of the RE in string by the\nreplacement replacement. If the pattern isn’t found, string is returned unchanged. The optional argument count is the maximum number of pattern occurrences to be replaced; count must be a\nnon-negative integer. The default value of 0 means to replace all occurrences. Here’s a simple example of using the sub() method. It replaces colour names with the word colour:\n>>> p = re.compile('(blue|white|red)')\n>>> p.sub('colour', 'blue socks and red shoes')\n'colour socks and colour shoes'\n>>> p.sub('colour', 'blue socks and red shoes', count=1)\n'colour socks and red shoes'\nThe subn() method does the same work, but returns a 2-tuple containing the new string value and the number of\nreplacements that were performed:\n>>> p = re.compile('(blue|white|red)')\n>>> p.subn('colour', 'blue socks and red shoes')\n('colour socks and colour shoes', 2)\n>>> p.subn('colour', 'no colours at all')\n('no colours at all', 0)\nEmpty matches are replaced only when they’re not adjacent to a previous empty match. 15\n\n>>> p = re.compile('x*')\n>>> p.sub('-', 'abxd')\n'-a-b--d-'\nIf replacement is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline char-\nacter, \\r is converted to a carriage return, and so forth. Unknown escapes such as \\& are left alone. Backreferences,\nsuch as \\6, are replaced with the substring matched by the corresponding group in the RE. This lets you incorporate\nportions of the original text in the resulting replacement string."")",5.515781795406561e-156,0.012145748987854251,0.09666651353488027,0.4370841085910797,0.3008249
How do I escape curly-brace ({}) characters characters in a string while using .format?,"You need to double the 
{{
 and 
}}
:


>>> x = "" {{ Hello }} {0} ""
>>> print(x.format(42))
' { Hello } 42 '



Here's the relevant part of the 
Python documentation for format string syntax
:




Format strings contain “replacement fields” surrounded by curly braces 
{}
. Anything that is not contained in braces is considered literal text, which is copied unchanged to the output. If you need to include a brace character in the literal text, it can be escaped by doubling: 
{{
 and 
}}
.



","('Answer: To include a literal curly brace character in a string when using `.format()`, you can escape it by doubling it. So, `{{` will result in a literal `{` and `}}` will result in a literal `}`.\n\nReferences: [1, 2]\n', '[1] Format strings contain “replacement fields” surrounded by curly braces {}. Anything that is not contained in braces\nis considered literal text, which is copied unchanged to the output. If you need to include a brace character in the\nliteral text, it can be escaped by doubling: {{ and }}. The grammar for a replacement field is as follows:\nreplacement_field ::= ""{"" [field_name] [""!"" conversion] ["":"" format_spec] ""}""\nfield_name\n::= arg_name (""."" attribute_name | ""["" element_index ""]"")*\narg_name\n::= [identifier | digit+]\nattribute_name\n::= identifier\nelement_index\n::= digit+ | index_string\nindex_string\n::= <any source character except ""]""> +\nconversion\n::= ""r"" | ""s"" | ""a""\nformat_spec\n::= format-spec:format_spec\nIn less formal terms, the replacement field can start with a field_name that specifies the object whose value is to be\nformatted and inserted into the output instead of the replacement field. The field_name is optionally followed by a\nconversion field, which is preceded by an exclamation point \'! \', and a format_spec, which is preceded by a colon\n\':\'. These specify a non-default format for the replacement value. See also the Format Specification Mini-Language section. The field_name itself begins with an arg_name that is either a number or a keyword. If it’s a number, it refers to\na positional argument, and if it’s a keyword, it refers to a named keyword argument. An arg_name is treated as a\nnumber if a call to str.isdecimal() on the string would return true. If the numerical arg_names in a format string\nare 0, 1, 2, … in sequence, they can all be omitted (not just some) and the numbers 0, 1, 2, … will be automatically\ninserted in that order. Because arg_name is not quote-delimited, it is not possible to specify arbitrary dictionary keys\n(e.g., the strings \'10\' or \':-]\') within a format string. The arg_name can be followed by any number of index or\nattribute expressions. An expression of the form \'.name\' selects the named attribute using getattr(), while an\nexpression of the form \'[index]\' does an index lookup using __getitem__(). 6.1. string — Common string operations\n121\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.1: The positional argument specifiers can be omitted for str.format(), so \'{} {}\'. format(a, b) is equivalent to \'{0} {1}\'.format(a, b). Changed in version 3.4: The positional argument specifiers can be omitted for Formatter. Some simple format string examples:\n""First, thou shalt count to {0}""\n# References first positional argument\n""Bring me a {}""\n# Implicitly references the first positional␣\n,→argument\n""From {} to {}""\n# Same as ""From {0} to {1}""\n""My quest is {name}""\n# References keyword argument \'name\'\n""Weight in tons {0.weight}""\n# \'weight\' attribute of first positional arg\n""Units destroyed: {players[0]}""\n# First element of keyword argument \'players\'. The conversion field causes a type coercion before formatting. Normally, the job of formatting a value is done by the\n__format__() method of the value itself. However, in some cases it is desirable to force a type to be formatted as a\nstring, overriding its own definition of formatting. By converting the value to a string before calling __format__(),\nthe normal formatting logic is bypassed. Three conversion flags are currently supported: \'!s\' which calls str() on the value, \'!r\' which calls repr() and\n\'!a\' which calls ascii(). Some examples:\n""Harold\'s a clever {0!s}""\n# Calls str() on the argument first\n""Bring out the holy {name!r}""\n# Calls repr() on the argument first\n""More {!a}""\n# Calls ascii() on the argument first\nThe format_spec field contains a specification of how the value should be presented, including such details as field\nwidth, alignment, padding, decimal precision and so on. Each value type can define its own “formatting mini-\nlanguage” or interpretation of the format_spec. Most built-in types support a common formatting mini-language, which is described in the next section. A format_spec field can also include nested replacement fields within it. These nested replacement fields may contain\na field name, conversion flag and format specification, but deeper nesting is not allowed. The replacement fields\nwithin the format_spec are substituted before the format_spec string is interpreted. This allows the formatting of a\nvalue to be dynamically specified. See the Format examples section for some examples. Format Specification Mini-Language\n“Format specifications” are used within replacement fields contained within a format string to define how individ-\nual values are presented (see Format String Syntax and f-strings). They can also be passed directly to the built-in\nformat() function. Each formattable type may define how the format specification is to be interpreted. Most built-in types implement the following options for format specifications, although some of the formatting options\nare only supported by the numeric types. A general convention is that an empty format specification produces the same result as if you had called str() on\nthe value. A non-empty format specification typically modifies the result. The general form of a standard format specifier is:\nformat_spec\n::= [[fill]align][sign][""z""][""#""][""0""][width][grouping_option][""."" precision][ty\nfill\n::= <any character>\nalign\n::= ""<"" | "">"" | ""="" | ""^""\nsign\n::= ""+"" | ""-"" | "" ""\nwidth\n::= digit+\ngrouping_option ::= ""_"" | "",""\nprecision\n::= digit+\ntype\n::= ""b"" | ""c"" | ""d"" | ""e"" | ""E"" | ""f"" | ""F"" | ""g"" | ""G"" | ""n"" | ""o"" | ""s"" | ""x""\n122\nChapter 6. Text Processing Services\n\nThe Python Library Reference, Release 3.13.2\nIf a valid align value is specified, it can be preceded by a fill character that can be any character and defaults to a space\nif omitted. It is not possible to use a literal curly brace (”{” or “}”) as the fill character in a formatted string literal\nor when using the str.format() method. However, it is possible to insert a curly brace with a nested replacement\nfield. This limitation doesn’t affect the format() function. The meaning of the various alignment options is as follows:\nOp-\ntion\nMeaning\n\'<\'\nForces the field to be left-aligned within the available space (this is the default for most objects). \'>\'\nForces the field to be right-aligned within the available space (this is the default for numbers). \'=\'\nForces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields\nin the form ‘+000000120’. This alignment option is only valid for numeric types, excluding complex.\n\n[2] If you need to include a brace character in the\nliteral text, it can be escaped by doubling: {{ and }}. The grammar for a replacement field is as follows:\nreplacement_field ::= ""{"" [field_name] [""!"" conversion] ["":"" format_spec] ""}""\nfield_name\n::= arg_name (""."" attribute_name | ""["" element_index ""]"")*\narg_name\n::= [identifier | digit+]\nattribute_name\n::= identifier\nelement_index\n::= digit+ | index_string\nindex_string\n::= <any source character except ""]""> +\nconversion\n::= ""r"" | ""s"" | ""a""\nformat_spec\n::= format-spec:format_spec\nIn less formal terms, the replacement field can start with a field_name that specifies the object whose value is to be\nformatted and inserted into the output instead of the replacement field. The field_name is optionally followed by a\nconversion field, which is preceded by an exclamation point \'! \', and a format_spec, which is preceded by a colon\n\':\'. These specify a non-default format for the replacement value. See also the Format Specification Mini-Language section. The field_name itself begins with an arg_name that is either a number or a keyword. If it’s a number, it refers to\na positional argument, and if it’s a keyword, it refers to a named keyword argument. An arg_name is treated as a\nnumber if a call to str.isdecimal() on the string would return true. If the numerical arg_names in a format string\nare 0, 1, 2, … in sequence, they can all be omitted (not just some) and the numbers 0, 1, 2, … will be automatically\ninserted in that order. Because arg_name is not quote-delimited, it is not possible to specify arbitrary dictionary keys\n(e.g., the strings \'10\' or \':-]\') within a format string. The arg_name can be followed by any number of index or\nattribute expressions. An expression of the form \'.name\' selects the named attribute using getattr(), while an\nexpression of the form \'[index]\' does an index lookup using __getitem__(). 6.1. string — Common string operations\n121\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.1: The positional argument specifiers can be omitted for str.format(), so \'{} {}\'. format(a, b) is equivalent to \'{0} {1}\'.format(a, b). Changed in version 3.4: The positional argument specifiers can be omitted for Formatter. Some simple format string examples:\n""First, thou shalt count to {0}""\n# References first positional argument\n""Bring me a {}""\n# Implicitly references the first positional␣\n,→argument\n""From {} to {}""\n# Same as ""From {0} to {1}""\n""My quest is {name}""\n# References keyword argument \'name\'\n""Weight in tons {0.weight}""\n# \'weight\' attribute of first positional arg\n""Units destroyed: {players[0]}""\n# First element of keyword argument \'players\'. The conversion field causes a type coercion before formatting. Normally, the job of formatting a value is done by the\n__format__() method of the value itself. However, in some cases it is desirable to force a type to be formatted as a\nstring, overriding its own definition of formatting. By converting the value to a string before calling __format__(),\nthe normal formatting logic is bypassed. Three conversion flags are currently supported: \'!s\' which calls str() on the value, \'!r\' which calls repr() and\n\'!a\' which calls ascii(). Some examples:\n""Harold\'s a clever {0!s}""\n# Calls str() on the argument first\n""Bring out the holy {name!r}""\n# Calls repr() on the argument first\n""More {!a}""\n# Calls ascii() on the argument first\nThe format_spec field contains a specification of how the value should be presented, including such details as field\nwidth, alignment, padding, decimal precision and so on. Each value type can define its own “formatting mini-\nlanguage” or interpretation of the format_spec. Most built-in types support a common formatting mini-language, which is described in the next section. A format_spec field can also include nested replacement fields within it. These nested replacement fields may contain\na field name, conversion flag and format specification, but deeper nesting is not allowed. The replacement fields\nwithin the format_spec are substituted before the format_spec string is interpreted. This allows the formatting of a\nvalue to be dynamically specified. See the Format examples section for some examples. Format Specification Mini-Language\n“Format specifications” are used within replacement fields contained within a format string to define how individ-\nual values are presented (see Format String Syntax and f-strings). They can also be passed directly to the built-in\nformat() function. Each formattable type may define how the format specification is to be interpreted. Most built-in types implement the following options for format specifications, although some of the formatting options\nare only supported by the numeric types. A general convention is that an empty format specification produces the same result as if you had called str() on\nthe value. A non-empty format specification typically modifies the result. The general form of a standard format specifier is:\nformat_spec\n::= [[fill]align][sign][""z""][""#""][""0""][width][grouping_option][""."" precision][ty\nfill\n::= <any character>\nalign\n::= ""<"" | "">"" | ""="" | ""^""\nsign\n::= ""+"" | ""-"" | "" ""\nwidth\n::= digit+\ngrouping_option ::= ""_"" | "",""\nprecision\n::= digit+\ntype\n::= ""b"" | ""c"" | ""d"" | ""e"" | ""E"" | ""f"" | ""F"" | ""g"" | ""G"" | ""n"" | ""o"" | ""s"" | ""x""\n122\nChapter 6. Text Processing Services\n\nThe Python Library Reference, Release 3.13.2\nIf a valid align value is specified, it can be preceded by a fill character that can be any character and defaults to a space\nif omitted. It is not possible to use a literal curly brace (”{” or “}”) as the fill character in a formatted string literal\nor when using the str.format() method. However, it is possible to insert a curly brace with a nested replacement\nfield. This limitation doesn’t affect the format() function. The meaning of the various alignment options is as follows:\nOp-\ntion\nMeaning\n\'<\'\nForces the field to be left-aligned within the available space (this is the default for most objects). \'>\'\nForces the field to be right-aligned within the available space (this is the default for numbers). \'=\'\nForces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields\nin the form ‘+000000120’. This alignment option is only valid for numeric types, excluding complex. It\nbecomes the default for numbers when ‘0’ immediately precedes the field width. \'^\'\nForces the field to be centered within the available space.\n\n[3] (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more\neasily recognized as broken.) It is also important to note that the escape sequences only recognized in string literals\nfall into the category of unrecognized escapes for bytes literals. Changed in version 3.6: Unrecognized escape sequences produce a DeprecationWarning. Changed in version 3.12: Unrecognized escape sequences produce a SyntaxWarning. In a future Python version\nthey will be eventually a SyntaxError. 1 https://www.unicode.org/Public/15.1.0/ucd/NameAliases.txt\n2.4. Literals\n11\n\nThe Python Language Reference, Release 3.13.2\nEven in a raw literal, quotes can be escaped with a backslash, but the backslash remains in the result; for example,\nr""\\"""" is a valid string literal consisting of two characters: a backslash and a double quote; r""\\"" is not a valid string\nliteral (even a raw string cannot end in an odd number of backslashes). Specifically, a raw literal cannot end in a\nsingle backslash (since the backslash would escape the following quote character). Note also that a single backslash\nfollowed by a newline is interpreted as those two characters as part of the literal, not as a line continuation. 2.4.2 String literal concatenation\nMultiple adjacent string or bytes literals (delimited by whitespace), possibly using different quoting conventions,\nare allowed, and their meaning is the same as their concatenation. Thus, ""hello"" \'world\' is equivalent to\n""helloworld"". This feature can be used to reduce the number of backslashes needed, to split long strings conve-\nniently across long lines, or even to add comments to parts of strings, for example:\nre.compile(""[A-Za-z_]""\n# letter or underscore\n""[A-Za-z0-9_]*""\n# letter, digit or underscore\n)\nNote that this feature is defined at the syntactical level, but implemented at compile time. The ‘+’ operator must\nbe used to concatenate string expressions at run time. Also note that literal concatenation can use different quoting\nstyles for each component (even mixing raw strings and triple quoted strings), and formatted string literals may be\nconcatenated with plain string literals. 2.4.3 f-strings\nAdded in version 3.6. A formatted string literal or f-string is a string literal that is prefixed with \'f\' or \'F\'. These strings may contain\nreplacement fields, which are expressions delimited by curly braces {}. While other string literals always have a\nconstant value, formatted strings are really expressions evaluated at run time. Escape sequences are decoded like in ordinary string literals (except when a literal is also marked as a raw string). After decoding, the grammar for the contents of the string is:\nf_string\n::= (literal_char | ""{{"" | ""}}"" | replacement_field)*\nreplacement_field ::= ""{"" f_expression [""=""] [""!"" conversion] ["":"" format_spec] ""}""\nf_expression\n::= (conditional_expression | ""*"" or_expr)\n("","" conditional_expression | "","" ""*"" or_expr)* ["",""]\n| yield_expression\nconversion\n::= ""s"" | ""r"" | ""a""\nformat_spec\n::= (literal_char | replacement_field)*\nliteral_char\n::= <any code point except ""{"", ""}"" or NULL>\nThe parts of the string outside curly braces are treated literally, except that any doubled curly braces \'{{\' or \'}}\'\nare replaced with the corresponding single curly brace. A single opening curly bracket \'{\' marks a replacement field,\nwhich starts with a Python expression. To display both the expression text and its value after evaluation, (useful in\ndebugging), an equal sign \'=\' may be added after the expression. A conversion field, introduced by an exclamation\npoint \'!\' may follow. A format specifier may also be appended, introduced by a colon \':\'. A replacement field\nends with a closing curly bracket \'}\'. Expressions in formatted string literals are treated like regular Python expressions surrounded by parentheses, with\na few exceptions. An empty expression is not allowed, and both lambda and assignment expressions := must be\nsurrounded by explicit parentheses. Each expression is evaluated in the context where the formatted string literal\nappears, in order from left to right. Replacement expressions can contain newlines in both single-quoted and triple-\nquoted f-strings and they can contain comments. Everything that comes after a # inside a replacement field is a\ncomment (even closing braces and quotes). In that case, replacement fields must be closed in a different line. >>> f""abc{a # This is a comment }""\n... + 3}""\n\'abc5\'\n12\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nChanged in version 3.7: Prior to Python 3.7, an await expression and comprehensions containing an async for\nclause were illegal in the expressions in formatted string literals due to a problem with the implementation. Changed in version 3.12: Prior to Python 3.12, comments were not allowed inside f-string replacement fields. When the equal sign \'=\' is provided, the output will have the expression text, the \'=\' and the evaluated value. Spaces after the opening brace \'{\', within the expression and after the \'=\' are all retained in the output. By default,\nthe \'=\' causes the repr() of the expression to be provided, unless there is a format specified. When a format is\nspecified it defaults to the str() of the expression unless a conversion \'!r\' is declared. Added in version 3.8: The equal sign \'=\'. If a conversion is specified, the result of evaluating the expression is converted before formatting. Conversion \'!s\'\ncalls str() on the result, \'!r\' calls repr(), and \'!a\' calls ascii(). The result is then formatted using the format() protocol. The format specifier is passed to the __format__()\nmethod of the expression or conversion result. An empty string is passed when the format specifier is omitted. The\nformatted result is then included in the final value of the whole string. Top-level format specifiers may include nested replacement fields. These nested fields may include their own con-\nversion fields and format specifiers, but may not include more deeply nested replacement fields. The format specifier\nmini-language is the same as that used by the str.format() method. Formatted string literals may be concatenated, but replacement fields cannot be split across literals.')",0.015098849758972795,0.029484029484029485,0.1215072836480729,0.625835120677948,0.6140171
Check if a given key already exists in a dictionary,"in
 tests for the existence of a key in a 
dict
:


d = {""key1"": 10, ""key2"": 23}

if ""key1"" in d:
    print(""this will execute"")

if ""nonexistent key"" in d:
    print(""this will not"")





Use 
dict.get()
 to provide a default value when the key does not exist:


d = {}

for i in range(100):
    key = i % 10
    d[key] = d.get(key, 0) + 1





To provide a default value for 
every
 key, either use 
dict.setdefault()
 on each assignment:


d = {}

for i in range(100):
    d[i % 10] = d.setdefault(i % 10, 0) + 1    



...or better, use 
defaultdict
 from the 
collections
 module:


from collections import defaultdict

d = defaultdict(int)

for i in range(100):
    d[i % 10] += 1


","('Answer: To check if a key exists in a dictionary, use the `key in d` expression, which returns `True` if the dictionary `d` contains the key, and `False` otherwise.\n\nReferences: [1, 2]\n', '[1] key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nDictionaries and dictionary views are reversible.\n\n[2] del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4.\n\n[3] To\nsupport searching for an equivalent frozenset, a temporary one is created from elem. 4.11 Mapping Types — dict\nA mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only\none standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and\nthe collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-\nnaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary\nentry. class dict(**kwargs)\nclass dict(mapping, **kwargs)\n4.11. Mapping Types — dict\n87\n\nThe Python Library Reference, Release 3.13.2\nclass dict(iterable, **kwargs)\nReturn a new dictionary initialized from an optional positional argument and a possibly empty set of keyword\narguments. Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order.')",2.1154850290067288e-79,0.046638165565487756,0.15900021400585665,0.5676355361938477,0.63341534
Class (static) variables and methods,"Variables declared inside the class definition, but not inside a method are class or static variables:


>>> class MyClass:
...     i = 3
...
>>> MyClass.i
3 



As @
millerdev
 points out, this creates a class-level 
i
 variable, but this is distinct from any instance-level 
i
 variable, so you could have


>>> m = MyClass()
>>> m.i = 4
>>> MyClass.i, m.i
>>> (3, 4)



This is different from C++ and Java, but not so different from C#, where a static member can't be accessed using a reference to an instance.


See 
what the Python tutorial has to say on the subject of classes and class objects
.


@Steve Johnson has already answered regarding 
static methods
, also documented under 
""Built-in Functions"" in the Python Library Reference
.


class C:
    @staticmethod
    def f(arg1, arg2, ...): ...



@beidy recommends 
classmethod
s over staticmethod, as the method then receives the class type as the first argument.

","('Answer: Information about static methods and class methods can be found on pages 16 and 17. Information on how to create static class data and static class methods is available on page 29. Class and Instance Variables are mentioned on page 77.\n\nReferences: [1, 2, 3]\n', '[1] . . . . . . . 14\n4.3\nKinds of methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.4\nStatic methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.5\nClass methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.6\nMember objects and __slots__\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . 75\n9.3.1\nClass Definition Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n9.3.2\nClass Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n9.3.3\nInstance Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n9.3.4\nMethod Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n9.3.5\nClass and Instance Variables\n. . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] 27\n2.6.4\nHow do I check if an object is an instance of a given class or of a subclass of it? . . . . . . 27\n2.6.5\nWhat is delegation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . .')",2.159356986268029e-155,0.13294797687861273,0.12700778857640685,0.5546818971633911,0.40874922
How do I lowercase a string in Python?,"Use 
str.lower()
:


""Kilometer"".lower()


","('Answer: To lowercase a string in Python, you can use the `casefold()` method. This method is more aggressive than `lower()` because it intends to remove all case distinctions in a string.\n\nReferences: [1, 2, 3]\n', '[1] See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”)\nprefix that disables most escape sequence processing. Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details. For performance reasons, the value of errors is not checked for validity unless an encoding error actually occurs,\nPython Development Mode is enabled or a debug build is used. Changed in version 3.1: Added support for keyword arguments.\n\n[2] Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details. For performance reasons, the value of errors is not checked for validity unless an encoding error actually occurs,\nPython Development Mode is enabled or a debug build is used. Changed in version 3.1: Added support for keyword arguments. Changed in version 3.9: The value of the errors argument is now checked in Python Development Mode and in\ndebug mode.\n\n[3] String literals that are part of a single expression and have only whitespace between them will be implicitly converted\nto a single string literal. That is, (""spam "" ""eggs"") == ""spam eggs"". See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”)\nprefix that disables most escape sequence processing. Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details.')",0.0,0.0015741833923652107,0.012638230647709324,0.4224960207939148,0.3793077
How to check if an object has an attribute?,"Try 
hasattr()
:


if hasattr(a, 'property'):
    a.property



See 
zweiterlinde's answer
 below, who offers good advice about asking forgiveness! A very pythonic approach!


The general practice in python is that, if the property is likely to be there most of the time, simply call it and either let the exception propagate, or trap it with a try/except block. This will likely be faster than 
hasattr
. If the property is likely to not be there most of the time, or you're not sure, using 
hasattr
 will probably be faster than repeatedly falling into an exception block.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.7\nThe Null Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.8\nThe Ellipsis Object\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.9\nThe NotImplemented Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.10 Internal Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . 99\n4.14.3\nFunctions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.4\nMethods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.5\nCode Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.6\nType Objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\n4.14.7\nThe Null Object . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] 27\n2.6.4\nHow do I check if an object is an instance of a given class or of a subclass of it? . . . . . . 27\n2.6.5\nWhat is delegation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . .')",7.699078569444213e-232,0.07547169811320754,0.1063496436297928,0.40707477927207947,0.07900073
How to print without a newline or space,"In Python 3, you can use the 
sep=
 and 
end=
 parameters of the 
print
 function:


To not add a newline to the end of the string:


print('.', end='')



To not add a space between all the function arguments you want to print:


print('a', 'b', 'c', sep='')



You can pass any string to either parameter, and you can use both parameters at the same time.


If you are having trouble with buffering, you can flush the output by adding 
flush=True
 keyword argument:


print('.', end='', flush=True)



Python 2.6 and 2.7


From Python 2.6 you can either import the 
print
 function from Python 3 using the 
__future__
 module
:


from __future__ import print_function



which allows you to use the Python 3 solution above.


However, note that the 
flush
 keyword is not available in the version of the 
print
 function imported from 
__future__
 in Python 2; it only works in Python 3, more specifically 3.3 and later. In earlier versions you'll still need to flush manually with a call to 
sys.stdout.flush()
. You'll also have to rewrite all other print statements in the file where you do this import.


Or you can use 
sys.stdout.write()


import sys
sys.stdout.write('.')



You may also need to call


sys.stdout.flush()



to ensure 
stdout
 is flushed immediately.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.8\nIs there an equivalent to Perl’s chomp() for removing trailing newlines from strings? . . . 20\n2.3.9\nIs there a scanf() or sscanf() equivalent? . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3.10\nWhat does UnicodeDecodeError or UnicodeEncodeError error mean? . . . . . . . 21\n2.3.11\nCan I end a raw string with an odd number of backslashes? . . . . . . . . . . . . . . . . 21\n2.4\nPerformance\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . 5\n2.1.3\nComments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.4\nEncoding declarations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.5\nExplicit line joining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.6\nImplicit line joining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.7\nBlank lines . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 19\n2.3.6\nHow do I modify a string in place? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.7\nHow do I use strings to call functions/methods? . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.8\nIs there an equivalent to Perl’s chomp() for removing trailing newlines from strings? . . . 20\n2.3.9\nIs there a scanf() or sscanf() equivalent? . . . . . . . . . . . . . . . . . . . . . . .')",1.6984117052487695e-155,0.10796915167095116,0.102444816560618,0.4962548613548279,0.3406098
Calling a function of a module by using its name (a string),"Given a module 
foo
 with method 
bar
:


import foo
bar = getattr(foo, 'bar')
result = bar()



getattr
 can similarly be used on class instance bound methods, module-level methods, class methods... the list goes on.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . 44\n6.1.1\nExecuting modules as scripts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.1.2\nThe Module Search Path\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.1.3\n“Compiled” Python files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6.2\nStandard Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6.3\nThe dir() Function . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . 8\n2.1.4\nThe Module’s Method Table and Initialization Function\n. . . . . . . . . . . . . . . . . . 9\n2.1.5\nCompilation and Linkage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1.6\nCalling Python Functions from C . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.1.7\nExtracting Parameters in Extension Functions\n. . . . . . . . . . . . . . . . . . . . . . . 13\n2.1.8\nKeyword Parameters for Extension Functions . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . 40\n5.7\nMore on Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n5.8\nComparing Sequences and Other Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n6\nModules\n43\n6.1\nMore on Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n6.1.1\nExecuting modules as scripts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.1.2\nThe Module Search Path\n. . . . . . .')",4.5090392964675035e-232,0.04419889502762431,0.0766871165644172,0.4634833335876465,0.36813942
How can I randomly select (choose) an item from a list (get a random element)?,"Use 
random.choice()
:


import random

foo = ['a', 'b', 'c', 'd', 'e']
print(random.choice(foo))



For 
cryptographically secure
 random choices (e.g., for generating a passphrase from a wordlist), use 
secrets.choice()
:


import secrets

foo = ['battery', 'correct', 'horse', 'staple']
print(secrets.choice(foo))



secrets
 is new in Python 3.6. On older versions of Python you can use the 
random.SystemRandom
 class:


import random

secure_random = random.SystemRandom()
print(secure_random.choice(foo))


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . . 367\n9.4.10\nDecimal FAQ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370\n9.5\nfractions — Rational numbers\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373\n9.6\nrandom — Generate pseudo-random numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377\n9.6.1\nBookkeeping functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377\n9.6.2\nFunctions for bytes\n.\n\n[3] . . . . . . . . . . 95\n11.4\nMulti-threading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n11.5\nLogging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n11.6\nWeak References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\n11.7\nTools for Working with Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",1.096444033209466e-155,0.05825242718446602,0.07580543272267845,0.4653446078300476,0.30233973
How to remove an element from a list by index,"Use 
del
 and specify the index of the element you want to delete:


>>> a = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
>>> del a[-1]
>>> a
[0, 1, 2, 3, 4, 5, 6, 7, 8]



Also supports slices:


>>> del a[2:4]
>>> a
[0, 1, 4, 5, 6, 7, 8, 9]



Here
 is the section from the tutorial.

","('Answer: You can remove an item from a list if you know its index using the `del` statement or the `pop()` method. The `del` statement removes the item at the given index. The `pop()` method removes the item at the given position in the list and returns it.\n\nReferences: [1]\n', '[1] list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations.\n\n[2] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",0.006529406929653944,0.04630541871921182,0.16803935882166193,0.5021250247955322,0.6325768
Delete a column from a Pandas DataFrame,"As you've guessed, the right syntax is 


del df['column_name']



It's difficult to make 
del df.column_name
 work simply as the result of syntactic limitations in Python. 
del df[name]
 gets translated to 
df.__delitem__(name)
 under the covers by Python.

","('Answer: To remove an item from a list given its index, you can use the `del` statement.\n\nReferences: [3]\n', '[1] Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples\nare immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later\nin this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements\nare usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accom-\nmodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed\nby following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example:\n>>> empty = ()\n>>> singleton = \'hello\',\n# <-- note trailing comma\n>>> len(empty)\n0\n>>> len(singleton)\n1\n>>> singleton\n(\'hello\',)\nThe statement t = 12345, 54321, \'hello!\' is an example of tuple packing: the values 12345, 54321 and\n\'hello!\' are packed together in a tuple. The reverse operation is also possible:\n>>> x, y, z = t\nThis is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence\nunpacking requires that there are as many variables on the left side of the equals sign as there are elements in the\nsequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking. 38\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.4 Sets\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses\ninclude membership testing and eliminating duplicate entries. Set objects also support mathematical operations like\nunion, intersection, difference, and symmetric difference. Curly braces or the set() function can be used to create sets. Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {\'apple\', \'orange\', \'apple\', \'pear\', \'orange\', \'banana\'}\n>>> print(basket)\n# show that duplicates have been removed\n{\'orange\', \'banana\', \'pear\', \'apple\'}\n>>> \'orange\' in basket\n# fast membership testing\nTrue\n>>> \'crabgrass\' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set(\'abracadabra\')\n>>> b = set(\'alacazam\')\n>>> a\n# unique letters in a\n{\'a\', \'r\', \'b\', \'c\', \'d\'}\n>>> a - b\n# letters in a but not in b\n{\'r\', \'d\', \'b\'}\n>>> a | b\n# letters in a or b or both\n{\'a\', \'c\', \'r\', \'d\', \'b\', \'m\', \'z\', \'l\'}\n>>> a & b\n# letters in both a and b\n{\'a\', \'c\'}\n>>> a ^ b\n# letters in a or b but not both\n{\'r\', \'d\', \'b\', \'m\', \'z\', \'l\'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in \'abracadabra\' if x not in \'abc\'}\n>>> a\n{\'r\', \'d\'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword.\n\n[2] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[3] The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples\nare immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later\nin this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements\nare usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accom-\nmodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed\nby following a value with a comma (it is not sufficient to enclose a single value in parentheses). Ugly, but effective. For example:\n>>> empty = ()\n>>> singleton = \'hello\',\n# <-- note trailing comma\n>>> len(empty)\n0\n>>> len(singleton)\n1\n>>> singleton\n(\'hello\',)\nThe statement t = 12345, 54321, \'hello!\' is an example of tuple packing: the values 12345, 54321 and\n\'hello!\' are packed together in a tuple. The reverse operation is also possible:\n>>> x, y, z = t\nThis is called, appropriately enough, sequence unpacking and works for any sequence on the right-hand side. Sequence\nunpacking requires that there are as many variables on the left side of the equals sign as there are elements in the\nsequence. Note that multiple assignment is really just a combination of tuple packing and sequence unpacking. 38\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.4 Sets\nPython also includes a data type for sets. A set is an unordered collection with no duplicate elements. Basic uses\ninclude membership testing and eliminating duplicate entries. Set objects also support mathematical operations like\nunion, intersection, difference, and symmetric difference. Curly braces or the set() function can be used to create sets. Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {\'apple\', \'orange\', \'apple\', \'pear\', \'orange\', \'banana\'}\n>>> print(basket)\n# show that duplicates have been removed\n{\'orange\', \'banana\', \'pear\', \'apple\'}\n>>> \'orange\' in basket\n# fast membership testing\nTrue\n>>> \'crabgrass\' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set(\'abracadabra\')\n>>> b = set(\'alacazam\')\n>>> a\n# unique letters in a\n{\'a\', \'r\', \'b\', \'c\', \'d\'}\n>>> a - b\n# letters in a but not in b\n{\'r\', \'d\', \'b\'}\n>>> a | b\n# letters in a or b or both\n{\'a\', \'c\', \'r\', \'d\', \'b\', \'m\', \'z\', \'l\'}\n>>> a & b\n# letters in both a and b\n{\'a\', \'c\'}\n>>> a ^ b\n# letters in a or b but not both\n{\'r\', \'d\', \'b\', \'m\', \'z\', \'l\'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in \'abracadabra\' if x not in \'abc\'}\n>>> a\n{\'r\', \'d\'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {\'jack\': 4098, \'sape\': 4139}\n>>> tel[\'guido\'] = 4127\n>>> tel\n{\'jack\': 4098, \'sape\': 4139, \'guido\': 4127}\n>>> tel[\'jack\']\n4098\n>>> del tel[\'sape\']\n>>> tel[\'irv\'] = 4127\n>>> tel\n{\'jack\': 4098, \'guido\': 4127, \'irv\': 4127}\n>>> list(tel)\n[\'jack\', \'guido\', \'irv\']\n>>> sorted(tel)\n[\'guido\', \'irv\', \'jack\']\n>>> \'guido\' in tel\nTrue\n>>> \'jack\' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([(\'sape\', 4139), (\'guido\', 4127), (\'jack\', 4098)])\n{\'sape\': 4139, \'guido\': 4127, \'jack\': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{\'sape\': 4139, \'guido\': 4127, \'jack\': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method.')",5.012319284818066e-232,0.01341381623071764,0.04065040650406505,0.45072099566459656,0.3233199
How do I get the number of elements in a list (length of a list) in Python?,"The 
len()
 function can be used with several different types in Python - both built-in types and library types. For example:


>>> len([1, 2, 3])
3


","('Answer: To get the number of elements in a list, you can use `len(a)`, where a is the list.\n\nReferences: [1]\n', '[1] Similar to a[len(a):] = [x]. list.extend(iterable)\nExtend the list by appending all the items from the iterable. Similar to a[len(a):] = iterable. list.insert(i, x)\nInsert an item at a given position. The first argument is the index of the element before which to insert, so a.\ninsert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x). list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value.\n\n[2] Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists.\n\n[3] list.extend(iterable)\nExtend the list by appending all the items from the iterable. Similar to a[len(a):] = iterable. list.insert(i, x)\nInsert an item at a given position. The first argument is the index of the element before which to insert, so a.\ninsert(0, x) inserts at the front of the list, and a.insert(len(a), x) is equivalent to a.append(x). list.remove(x)\nRemove the first item from the list whose value is equal to x. It raises a ValueError if there is no such item. list.pop([i])\nRemove the item at the given position in the list, and return it. If no index is specified, a.pop() removes and\nreturns the last item in the list. It raises an IndexError if the list is empty or the index is outside the list\nrange. list.clear()\nRemove all items from the list. Similar to del a[:]. list.index(x[, start[, end]])\nReturn zero-based index in the list of the first item whose value is equal to x. Raises a ValueError if there\nis no such item. The optional arguments start and end are interpreted as in the slice notation and are used to limit the search\nto a particular subsequence of the list. The returned index is computed relative to the beginning of the full\nsequence rather than the start argument. list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice).')",5.6427765524508565e-80,0.007751937984496124,0.026732376753274768,0.45964112877845764,0.46826
How do I pad a string with zeros?,"To pad strings:


>>> n = '4'
>>> print(n.zfill(3))
004



To pad numbers:


>>> n = 4
>>> print(f'{n:03}') # Preferred method, python >= 3.6
004
>>> print('%03d' % n)
004
>>> print(format(n, '03')) # python >= 2.6
004
>>> print('{0:03d}'.format(n))  # python >= 2.6 + python 3
004
>>> print('{foo:03d}'.format(foo=n))  # python >= 2.6 + python 3
004
>>> print('{:03d}'.format(n))  # python >= 2.7 + python3
004



String formatting documentation
.

","(""Answer: You can use the `str.zfill(width)` method to pad a string with leading ASCII '0' digits. The `width` argument specifies the desired length of the string. If the original string's length is already greater than or equal to `width`, the original string is returned. This method handles leading signs ('+' or '-') by placing the padding after the sign character.\n\nReferences: [1, 2, 3]\n"", '[1] The uppercasing algorithm used is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. str.zfill(width)\nReturn a copy of the string left filled with ASCII \'0\' digits to make a string of length width. A leading sign\nprefix (\'+\'/\'-\') is handled by inserting the padding after the sign character rather than before. The original\nstring is returned if width is less than or equal to len(s). For example:\n60\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n>>> ""42"".zfill(5)\n\'00042\'\n>>> ""-42"".zfill(5)\n\'-0042\'\n4.8.2 printf-style String Formatting\n® Note\nThe formatting operations described here exhibit a variety of quirks that lead to a number of common errors\n(such as failing to display tuples and dictionaries correctly). Using the newer formatted string literals, the str. format() interface, or template strings may help avoid these errors. Each of these alternatives provides their\nown trade-offs and benefits of simplicity, flexibility, and/or extensibility. String objects have one unique built-in operation: the % operator (modulo). This is also known as the string formatting\nor interpolation operator. Given format % values (where format is a string), % conversion specifications in format\nare replaced with zero or more elements of values. The effect is similar to using the sprintf() function in the C\nlanguage. For example:\n>>> print(\'%s has %d quote types.\' % (\'Python\', 2))\nPython has 2 quote types. If format requires a single argument, values may be a single non-tuple object.5 Otherwise, values must be a tuple with\nexactly the number of items specified by the format string, or a single mapping object (for example, a dictionary). A conversion specifier contains two or more characters and has the following components, which must occur in this\norder:\n1. The \'%\' character, which marks the start of the specifier. 2. Mapping key (optional), consisting of a parenthesised sequence of characters (for example, (somename)). 3. Conversion flags (optional), which affect the result of some conversion types. 4. Minimum field width (optional). If specified as an \'*\' (asterisk), the actual width is read from the next element\nof the tuple in values, and the object to convert comes after the minimum field width and optional precision. 5. Precision (optional), given as a \'.\' (dot) followed by the precision. If specified as \'*\' (an asterisk), the actual\nprecision is read from the next element of the tuple in values, and the value to convert comes after the precision. 6. Length modifier (optional). 7. Conversion type. When the right argument is a dictionary (or other mapping type), then the formats in the string must include a\nparenthesised mapping key into that dictionary inserted immediately after the \'%\' character. The mapping key\nselects the value to be formatted from the mapping. For example:\n>>> print(\'%(language)s has %(number)03d quote types.\' %\n...\n{\'language\': ""Python"", ""number"": 2})\nPython has 002 quote types. In this case no * specifiers may occur in a format (since they require a sequential parameter list). The conversion flag characters are:\n5 To format only a tuple you should therefore provide a singleton tuple whose only element is the tuple to be formatted. 4.8. Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'.\n\n[2] str.zfill(width)\nReturn a copy of the string left filled with ASCII \'0\' digits to make a string of length width. A leading sign\nprefix (\'+\'/\'-\') is handled by inserting the padding after the sign character rather than before. The original\nstring is returned if width is less than or equal to len(s). For example:\n60\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n>>> ""42"".zfill(5)\n\'00042\'\n>>> ""-42"".zfill(5)\n\'-0042\'\n4.8.2 printf-style String Formatting\n® Note\nThe formatting operations described here exhibit a variety of quirks that lead to a number of common errors\n(such as failing to display tuples and dictionaries correctly). Using the newer formatted string literals, the str. format() interface, or template strings may help avoid these errors. Each of these alternatives provides their\nown trade-offs and benefits of simplicity, flexibility, and/or extensibility. String objects have one unique built-in operation: the % operator (modulo). This is also known as the string formatting\nor interpolation operator. Given format % values (where format is a string), % conversion specifications in format\nare replaced with zero or more elements of values. The effect is similar to using the sprintf() function in the C\nlanguage. For example:\n>>> print(\'%s has %d quote types.\' % (\'Python\', 2))\nPython has 2 quote types. If format requires a single argument, values may be a single non-tuple object.5 Otherwise, values must be a tuple with\nexactly the number of items specified by the format string, or a single mapping object (for example, a dictionary). A conversion specifier contains two or more characters and has the following components, which must occur in this\norder:\n1. The \'%\' character, which marks the start of the specifier. 2. Mapping key (optional), consisting of a parenthesised sequence of characters (for example, (somename)). 3. Conversion flags (optional), which affect the result of some conversion types. 4. Minimum field width (optional). If specified as an \'*\' (asterisk), the actual width is read from the next element\nof the tuple in values, and the object to convert comes after the minimum field width and optional precision. 5. Precision (optional), given as a \'.\' (dot) followed by the precision. If specified as \'*\' (an asterisk), the actual\nprecision is read from the next element of the tuple in values, and the value to convert comes after the precision. 6. Length modifier (optional). 7. Conversion type. When the right argument is a dictionary (or other mapping type), then the formats in the string must include a\nparenthesised mapping key into that dictionary inserted immediately after the \'%\' character. The mapping key\nselects the value to be formatted from the mapping. For example:\n>>> print(\'%(language)s has %(number)03d quote types.\' %\n...\n{\'language\': ""Python"", ""number"": 2})\nPython has 002 quote types. In this case no * specifiers may occur in a format (since they require a sequential parameter list). The conversion flag characters are:\n5 To format only a tuple you should therefore provide a singleton tuple whose only element is the tuple to be formatted. 4.8. Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase).\n\n[3] Note that s.upper(). isupper() might be False if s contains uncased characters or if the Unicode category of the resulting\ncharacter(s) is not “Lu” (Letter, uppercase), but e.g. “Lt” (Letter, titlecase). The uppercasing algorithm used is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. str.zfill(width)\nReturn a copy of the string left filled with ASCII \'0\' digits to make a string of length width. A leading sign\nprefix (\'+\'/\'-\') is handled by inserting the padding after the sign character rather than before. The original\nstring is returned if width is less than or equal to len(s). For example:\n60\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n>>> ""42"".zfill(5)\n\'00042\'\n>>> ""-42"".zfill(5)\n\'-0042\'\n4.8.2 printf-style String Formatting\n® Note\nThe formatting operations described here exhibit a variety of quirks that lead to a number of common errors\n(such as failing to display tuples and dictionaries correctly). Using the newer formatted string literals, the str. format() interface, or template strings may help avoid these errors. Each of these alternatives provides their\nown trade-offs and benefits of simplicity, flexibility, and/or extensibility. String objects have one unique built-in operation: the % operator (modulo). This is also known as the string formatting\nor interpolation operator. Given format % values (where format is a string), % conversion specifications in format\nare replaced with zero or more elements of values. The effect is similar to using the sprintf() function in the C\nlanguage. For example:\n>>> print(\'%s has %d quote types.\' % (\'Python\', 2))\nPython has 2 quote types. If format requires a single argument, values may be a single non-tuple object.5 Otherwise, values must be a tuple with\nexactly the number of items specified by the format string, or a single mapping object (for example, a dictionary). A conversion specifier contains two or more characters and has the following components, which must occur in this\norder:\n1. The \'%\' character, which marks the start of the specifier. 2. Mapping key (optional), consisting of a parenthesised sequence of characters (for example, (somename)). 3. Conversion flags (optional), which affect the result of some conversion types. 4. Minimum field width (optional). If specified as an \'*\' (asterisk), the actual width is read from the next element\nof the tuple in values, and the object to convert comes after the minimum field width and optional precision. 5. Precision (optional), given as a \'.\' (dot) followed by the precision. If specified as \'*\' (an asterisk), the actual\nprecision is read from the next element of the tuple in values, and the value to convert comes after the precision. 6. Length modifier (optional). 7. Conversion type. When the right argument is a dictionary (or other mapping type), then the formats in the string must include a\nparenthesised mapping key into that dictionary inserted immediately after the \'%\' character. The mapping key\nselects the value to be formatted from the mapping. For example:\n>>> print(\'%(language)s has %(number)03d quote types.\' %\n...\n{\'language\': ""Python"", ""number"": 2})\nPython has 002 quote types. In this case no * specifiers may occur in a format (since they require a sequential parameter list). The conversion flag characters are:\n5 To format only a tuple you should therefore provide a singleton tuple whose only element is the tuple to be formatted. 4.8. Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal.')",4.322163012517818e-232,0.03925148334094021,0.16738850619498521,0.5480287671089172,0.5528636
Delete an element from a dictionary,"The 
del
 statement
 removes an element:


del d[key]



Note that this mutates the existing dictionary, so the contents of the dictionary changes for anybody else who has a reference to the same instance. To return a 
new
 dictionary, make a copy of the dictionary:


def removekey(d, key):
    r = dict(d)
    del r[key]
    return r



The 
dict()
 constructor makes a 
shallow copy
. To make a deep copy, see the 
copy
 module
.




Note that making a copy for every dict 
del
/assignment/etc. means you're going from constant time to linear time, and also using linear space. For small dicts, this is not a problem. But if you're planning to make lots of copies of large dicts, you probably want a different data structure, like a HAMT (as described in 
this answer
).

","('Answer: To remove an element from a dictionary, use `del d[key]`. This will remove the item with the key `key` from the dictionary `d`. If the key is not in the dictionary, it raises a KeyError.\n\nReferences: [1, 3]\n', '[1] remove(elem)\nRemove element elem from the set. Raises KeyError if elem is not contained in the set. discard(elem)\nRemove element elem from the set if it is present. pop()\nRemove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear()\nRemove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(),\nand symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To\nsupport searching for an equivalent frozenset, a temporary one is created from elem. 4.11 Mapping Types — dict\nA mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only\none standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and\nthe collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-\nnaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary\nentry. class dict(**kwargs)\nclass dict(mapping, **kwargs)\n4.11. Mapping Types — dict\n87\n\nThe Python Library Reference, Release 3.13.2\nclass dict(iterable, **kwargs)\nReturn a new dictionary initialized from an optional positional argument and a possibly empty set of keyword\narguments. Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError.\n\n[2] discard(elem)\nRemove element elem from the set if it is present. pop()\nRemove and return an arbitrary element from the set. Raises KeyError if the set is empty. clear()\nRemove all elements from the set. Note, the non-operator versions of the update(), intersection_update(), difference_update(),\nand symmetric_difference_update() methods will accept any iterable as an argument. Note, the elem argument to the __contains__(), remove(), and discard() methods may be a set. To\nsupport searching for an equivalent frozenset, a temporary one is created from elem. 4.11 Mapping Types — dict\nA mapping object maps hashable values to arbitrary objects. Mappings are mutable objects. There is currently only\none standard mapping type, the dictionary. (For other containers see the built-in list, set, and tuple classes, and\nthe collections module.) A dictionary’s keys are almost arbitrary values. Values that are not hashable, that is, values containing lists, dictio-\nnaries or other mutable types (that are compared by value rather than by object identity) may not be used as keys. Values that compare equal (such as 1, 1.0, and True) can be used interchangeably to index the same dictionary\nentry. class dict(**kwargs)\nclass dict(mapping, **kwargs)\n4.11. Mapping Types — dict\n87\n\nThe Python Library Reference, Release 3.13.2\nclass dict(iterable, **kwargs)\nReturn a new dictionary initialized from an optional positional argument and a possibly empty set of keyword\narguments. Dictionaries can be created by several means:\n• Use a comma-separated list of key: value pairs within braces: {\'jack\': 4098, \'sjoerd\':\n4127} or {4098: \'jack\', 4127: \'sjoerd\'}\n• Use a dict comprehension: {}, {x: x ** 2 for x in range(10)}\n• Use the type constructor: dict(), dict([(\'foo\', 100), (\'bar\', 200)]), dict(foo=100,\nbar=200)\nIf no positional argument is given, an empty dictionary is created. If a positional argument is given and it\ndefines a keys() method, a dictionary is created by calling __getitem__() on the argument with each\nreturned key from the method. Otherwise, the positional argument must be an iterable object. Each item in\nthe iterable must itself be an iterable with exactly two elements. The first element of each item becomes a key\nin the new dictionary, and the second element the corresponding value. If a key occurs more than once, the\nlast value for that key becomes the corresponding value in the new dictionary. If keyword arguments are given, the keyword arguments and their values are added to the dictionary created\nfrom the positional argument. If a key being added is already present, the value from the keyword argument\nreplaces the value from the positional argument. To illustrate, the following examples all return a dictionary equal to {""one"": 1, ""two"": 2, ""three"":\n3}:\n>>> a = dict(one=1, two=2, three=3)\n>>> b = {\'one\': 1, \'two\': 2, \'three\': 3}\n>>> c = dict(zip([\'one\', \'two\', \'three\'], [1, 2, 3]))\n>>> d = dict([(\'two\', 2), (\'one\', 1), (\'three\', 3)])\n>>> e = dict({\'three\': 3, \'one\': 1, \'two\': 2})\n>>> f = dict({\'one\': 1, \'three\': 3}, two=2)\n>>> a == b == c == d == e == f\nTrue\nProviding keyword arguments as in the first example only works for keys that are valid Python identifiers. Otherwise, any valid keys can be used. These are the operations that dictionaries support (and therefore, custom mapping types should support too):\nlist(d)\nReturn a list of all the keys used in the dictionary d.\nlen(d)\nReturn the number of items in the dictionary d.\nd[key]\nReturn the item of d with key key. Raises a KeyError if key is not in the map. If a subclass of dict defines a method __missing__() and key is not present, the d[key] operation\ncalls that method with the key key as argument. The d[key] operation then returns or raises what-\never is returned or raised by the __missing__(key) call. No other operations or methods invoke\n__missing__(). If __missing__() is not defined, KeyError is raised. __missing__() must be\na method; it cannot be an instance variable:\n>>> class Counter(dict):\n...\ndef __missing__(self, key):\n...\nreturn 0\n...\n>>> c = Counter()\n>>> c[\'red\']\n(continues on next page)\n88\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n0\n>>> c[\'red\'] += 1\n>>> c[\'red\']\n1\nThe example above shows part of the implementation of collections.Counter. A different\n__missing__ method is used by collections.defaultdict. d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects.\n\n[3] del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4.')",2.5020673047505217e-79,0.04738330975954739,0.13320574345190198,0.5609495639801025,0.59547687
"What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc?","This is my personal recommendation for beginners:
 start by learning 
virtualenv
 and 
pip
, tools which work with both Python 2 and 3 and in a variety of situations, and pick up other tools once you start needing them.


Now on to answer the question: what is the difference between these similarly named things: venv, virtualenv, etc?


PyPI packages not in the standard library:




virtualenv
 is a very popular tool that creates isolated Python environments for Python libraries. If you're not familiar with this tool, I highly recommend learning it, as it is a very useful tool.


It works by installing a bunch of files in a directory (eg: 
env/
), and then modifying the 
PATH
 environment variable to prefix it with a custom 
bin
 directory (eg: 
env/bin/
). An exact copy of the 
python
 or 
python3
 binary is placed in this directory, but Python is programmed to look for libraries relative to its path first, in the environment directory. It's not part of Python's standard library, but is officially blessed by the PyPA (Python Packaging Authority). Once activated, you can install packages in the virtual environment using 
pip
.




pyenv
 is used to isolate Python versions. For example, you may want to test your code against Python 2.7, 3.6, 3.7 and 3.8, so you'll need a way to switch between them. Once activated, it prefixes the 
PATH
 environment variable with 
~/.pyenv/shims
, where there are special files matching the Python commands (
python
, 
pip
). These are not copies of the Python-shipped commands; they are special scripts that decide on the fly which version of Python to run based on the 
PYENV_VERSION
 environment variable, or the 
.python-version
 file, or the 
~/.pyenv/version
 file. 
pyenv
 also makes the process of downloading and installing multiple Python versions easier, using the command 
pyenv install
.




pyenv-virtualenv
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to allow you to use 
pyenv
 and 
virtualenv
 at the same time conveniently. However, if you're using Python 3.3 or later, 
pyenv-virtualenv
 will try to run 
python -m venv
 if it is available, instead of 
virtualenv
. You can use 
virtualenv
 and 
pyenv
 together without 
pyenv-virtualenv
, if you don't want the convenience features.




virtualenvwrapper
 is a set of extensions to 
virtualenv
 (see 
docs
). It gives you commands like 
mkvirtualenv
, 
lssitepackages
, and especially 
workon
 for switching between different 
virtualenv
 directories. This tool is especially useful if you want multiple 
virtualenv
 directories.




pyenv-virtualenvwrapper
 is a plugin for 
pyenv
 by the same author as 
pyenv
, to conveniently integrate 
virtualenvwrapper
 into 
pyenv
.




pipenv
 aims to combine 
Pipfile
, 
pip
 and 
virtualenv
 into one command on the command-line. The 
virtualenv
 directory typically gets placed in 
~/.local/share/virtualenvs/XXX
, with 
XXX
 being a hash of the path of the project directory. This is different from 
virtualenv
, where the directory is typically in the current working directory. 
pipenv
 is meant to be used when developing Python applications (as opposed to libraries). There are alternatives to 
pipenv
, such as 
poetry
, which I won't list here since this question is only about the packages that are similarly named.






Standard library:




pyvenv
 (not to be confused with 
pyenv
 in the previous section) is a script shipped with Python 3.3 to 3.7. It was 
removed from Python 3.8
 as it had problems (not to mention the confusing name). Running 
python3 -m venv
 has exactly the same effect as 
pyvenv
.




venv
 is a package shipped with Python 3, which you can run using 
python3 -m venv
 (although for some reason some distros separate it out into a separate distro package, such as 
python3-venv
 on Ubuntu/Debian). It serves the same purpose as 
virtualenv
, but only has a subset of its features (
see a comparison here
). 
virtualenv
 continues to be more popular than 
venv
, especially since the former supports both Python 2 and 3.





","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] These are by default isolated from software in other virtual environments and\nPython interpreters and libraries installed in the operating system. • Contained in a directory, conventionally named .venv or venv in the project directory, or under a container\ndirectory for lots of virtual environments, such as ~/.virtualenvs. • Not checked into source control systems such as Git. • Considered as disposable – it should be simple to delete and recreate it from scratch. You don’t place any\nproject code in the environment. • Not considered as movable or copyable – you just recreate the same environment in the target location. See PEP 405 for more background on Python virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\nAvailability: not Android, not iOS, not WASI. This module is not supported on mobile platforms or WebAssembly platforms. 29.2.1 Creating virtual environments\nVirtual environments are created by executing the venv module:\npython -m venv /path/to/new/virtual/environment\nThis creates the target directory (including parent directories as needed) and places a pyvenv.cfg file in it with a\nhome key pointing to the Python installation from which the command was run. It also creates a bin (or Scripts\non Windows) subdirectory containing a copy or symlink of the Python executable (as appropriate for the platform\nor arguments used at environment creation time). It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it. In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the envi-\nronment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that\ninterpreter regardless of the value of PATH. On Windows, “shebang” line processing is supported if you have the\nlauncher installed.\n\n[2] A virtual environment is (amongst other things):\n• Used to contain a specific Python interpreter and software libraries and binaries which are needed to support a\nproject (library or application). These are by default isolated from software in other virtual environments and\nPython interpreters and libraries installed in the operating system. • Contained in a directory, conventionally named .venv or venv in the project directory, or under a container\ndirectory for lots of virtual environments, such as ~/.virtualenvs. • Not checked into source control systems such as Git. • Considered as disposable – it should be simple to delete and recreate it from scratch. You don’t place any\nproject code in the environment. • Not considered as movable or copyable – you just recreate the same environment in the target location. See PEP 405 for more background on Python virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\nAvailability: not Android, not iOS, not WASI. This module is not supported on mobile platforms or WebAssembly platforms. 29.2.1 Creating virtual environments\nVirtual environments are created by executing the venv module:\npython -m venv /path/to/new/virtual/environment\nThis creates the target directory (including parent directories as needed) and places a pyvenv.cfg file in it with a\nhome key pointing to the Python installation from which the command was run. It also creates a bin (or Scripts\non Windows) subdirectory containing a copy or symlink of the Python executable (as appropriate for the platform\nor arguments used at environment creation time). It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it. In order to achieve this, scripts installed into virtual environments have a “shebang” line which points to the envi-\nronment’s Python interpreter, #!/<path-to-venv>/bin/python. This means that the script will run with that\ninterpreter regardless of the value of PATH.\n\n[3] A virtual environment is created on top of an existing Python installation,\nknown as the virtual environment’s “base” Python, and may optionally be isolated from the packages in the base\nenvironment, so only those explicitly installed in the virtual environment are available. When used from within a virtual environment, common installation tools such as pip will install Python packages\ninto a virtual environment without needing to be told to do so explicitly. A virtual environment is (amongst other things):\n• Used to contain a specific Python interpreter and software libraries and binaries which are needed to support a\nproject (library or application). These are by default isolated from software in other virtual environments and\nPython interpreters and libraries installed in the operating system. • Contained in a directory, conventionally named .venv or venv in the project directory, or under a container\ndirectory for lots of virtual environments, such as ~/.virtualenvs. • Not checked into source control systems such as Git. • Considered as disposable – it should be simple to delete and recreate it from scratch. You don’t place any\nproject code in the environment. • Not considered as movable or copyable – you just recreate the same environment in the target location. See PEP 405 for more background on Python virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\nAvailability: not Android, not iOS, not WASI. This module is not supported on mobile platforms or WebAssembly platforms. 29.2.1 Creating virtual environments\nVirtual environments are created by executing the venv module:\npython -m venv /path/to/new/virtual/environment\nThis creates the target directory (including parent directories as needed) and places a pyvenv.cfg file in it with a\nhome key pointing to the Python installation from which the command was run. It also creates a bin (or Scripts\non Windows) subdirectory containing a copy or symlink of the Python executable (as appropriate for the platform\nor arguments used at environment creation time). It also creates a lib/pythonX.Y/site-packages subdirectory\n(on Windows, this is Libsite-packages). If an existing directory is specified, it will be re-used. Changed in version 3.5: The use of venv is now recommended for creating virtual environments. 29.2. venv — Creation of virtual environments\n1891\n\nThe Python Library Reference, Release 3.13.2\nDeprecated since version 3.6, removed in version 3.8: pyvenv was the recommended tool for creating virtual envi-\nronments for Python 3.3 and 3.4, and replaced in 3.5 by executing venv directly. On Windows, invoke the venv command as follows:\nPS> python -m venv C:\\path\\to\\new\\virtual\\environment\nThe command, if run with -h, will show the available options:\nusage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]\n[--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]\n[--without-scm-ignore-files]\nENV_DIR [ENV_DIR ...]\nCreates virtual Python environments in one or more target directories. positional arguments:\nENV_DIR\nA directory to create the environment in. options:\n-h, --help\nshow this help message and exit\n--system-site-packages\nGive the virtual environment access to the system\nsite-packages dir. --symlinks\nTry to use symlinks rather than copies, when\nsymlinks are not the default for the platform. --copies\nTry to use copies rather than symlinks, even when\nsymlinks are the default for the platform. --clear\nDelete the contents of the environment directory\nif it already exists, before environment creation. --upgrade\nUpgrade the environment directory to use this\nversion of Python, assuming Python has been\nupgraded in-place. --without-pip\nSkips installing or upgrading pip in the virtual\nenvironment (pip is bootstrapped by default)\n--prompt PROMPT\nProvides an alternative prompt prefix for this\nenvironment. --upgrade-deps\nUpgrade core dependencies (pip) to the latest\nversion in PyPI\n--without-scm-ignore-files\nSkips adding SCM ignore files to the environment\ndirectory (Git is supported by default). Once an environment has been created, you may wish to activate it, e.g. by\nsourcing an activate script in its bin directory. Changed in version 3.4: Installs pip by default, added the --without-pip and --copies options. Changed in version 3.4: In earlier versions, if the target directory already existed, an error was raised, unless the\n--clear or --upgrade option was provided. Changed in version 3.9: Add --upgrade-deps option to upgrade pip + setuptools to the latest on PyPI. Changed in version 3.12: setuptools is no longer a core venv dependency. Changed in version 3.13: Added the --without-scm-ignore-files option. Changed in version 3.13: venv now creates a .gitignore file for Git by default. 1892\nChapter 29. Software Packaging and Distribution\n\nThe Python Library Reference, Release 3.13.2\n® Note\nWhile symlinks are supported on Windows, they are not recommended. Of particular note is that double-clicking\npython.exe in File Explorer will resolve the symlink eagerly and ignore the virtual environment. ® Note\nOn Microsoft Windows, it may be required to enable the Activate.ps1 script by setting the execution policy\nfor the user. You can do this by issuing the following PowerShell command:\nPS C:\\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser\nSee About Execution Policies for more information. The created pyvenv.cfg file also includes the include-system-site-packages key, set to true if venv is\nrun with the --system-site-packages option, false otherwise. Unless the --without-pip option is given, ensurepip will be invoked to bootstrap pip into the virtual environ-\nment. Multiple paths can be given to venv, in which case an identical virtual environment will be created, according to the\ngiven options, at each provided path. 29.2.2 How venvs work\nWhen a Python interpreter is running from a virtual environment, sys.prefix and sys.exec_prefix point to the\ndirectories of the virtual environment, whereas sys.base_prefix and sys.base_exec_prefix point to those\nof the base Python used to create the environment. It is sufficient to check sys.prefix != sys.base_prefix\nto determine if the current interpreter is running from a virtual environment. A virtual environment may be “activated” using a script in its binary directory (bin on POSIX; Scripts on Win-\ndows). This will prepend that directory to your PATH, so that running python will invoke the environment’s Python\ninterpreter and you can run installed scripts without having to use their full path. The invocation of the activation\nscript is platform-specific (<venv> must be replaced by the path to the directory containing the virtual environment):\nPlatform\nShell\nCommand to activate virtual environment\nPOSIX\nbash/zsh\n$ source <venv>/bin/activate\nfish\n$ source <venv>/bin/activate.fish\ncsh/tcsh\n$ source <venv>/bin/activate.csh\npwsh\n$ <venv>/bin/Activate.ps1\nWindows\ncmd.exe\nC:\\> <venv>\\Scripts\\activate.bat\nPowerShell\nPS C:\\> <venv>\\Scripts\\Activate.ps1\nAdded in version 3.4: fish and csh activation scripts. Added in version 3.8: PowerShell activation scripts installed under POSIX for PowerShell Core support. You don’t specifically need to activate a virtual environment, as you can just specify the full path to that environment’s\nPython interpreter when invoking Python. Furthermore, all scripts installed in the environment should be runnable\nwithout activating it.')",0.0062267445974568646,0.09437989091771401,0.2685339743567287,0.6083567142486572,0.49213746
How do I count the occurrences of a list item?,"If you only want a single item's count, use the 
count
 method:


>>> [1, 2, 3, 4, 1, 4, 1].count(1)
3





Important: this is very slow if you are counting 
multiple
 different items


Each 
count
 call goes over the entire list of 
n
 elements. Calling 
count
 in a loop 
n
 times means 
n * n
 total checks, which can be catastrophic for performance.


If you want to count multiple items, use 
Counter
, which only does 
n
 total checks.

","('Answer: You can count the number of times an item appears in a list using the `list.count(x)` method. This method returns the number of times `x` appears in the list.\n\nReferences: [1]\n', '[1] list.count(x)\nReturn the number of times x appears in the list. list.sort(* (Keyword-only parameters separator (PEP 3102)), key=None, reverse=False)\nSort the items of the list in place (the arguments can be used for sort customization, see sorted() for their\nexplanation). list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples\nare immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later\nin this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements\nare usually homogeneous and are accessed by iterating over the list.\n\n[2] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .')",1.9305931804091948e-79,0.03644859813084112,0.11421964950386738,0.5174657106399536,0.5089418
Determine the type of an object?,"There are two built-in functions that help you identify the type of an object. You can use 
type()
  if you need the exact type of an object, and 
isinstance()
 to 
check
 an object’s type against something. Usually, you want to use 
isinstance()
 most of the times since it is very robust and also supports type inheritance.




To get the actual type of an object, you use the built-in 
type()
 function. Passing an object as the only parameter will return the type object of that object:


>>> type([]) is list
True
>>> type({}) is dict
True
>>> type('') is str
True
>>> type(0) is int
True



This of course also works for custom types:


>>> class Test1 (object):
        pass
>>> class Test2 (Test1):
        pass
>>> a = Test1()
>>> b = Test2()
>>> type(a) is Test1
True
>>> type(b) is Test2
True



Note that 
type()
 will only return the immediate type of the object, but won’t be able to tell you about type inheritance.


>>> type(b) is Test1
False



To cover that, you should use the 
isinstance
 function. This of course also works for built-in types:


>>> isinstance(b, Test1)
True
>>> isinstance(b, Test2)
True
>>> isinstance(a, Test1)
True
>>> isinstance(a, Test2)
False
>>> isinstance([], list)
True
>>> isinstance({}, dict)
True



isinstance()
 is usually the preferred way to ensure the type of an object because it will also accept derived types. So unless you actually need the type object (for whatever reason), using 
isinstance()
 is preferred over 
type()
.


The second parameter of 
isinstance()
 also accepts a tuple of types, so it’s possible to check for multiple types at once. 
isinstance
 will then return true, if the object is of any of those types:


>>> isinstance([], (tuple, list, set))
True


","('Answer: To determine the type of an object, you can use `PyObject_Type(PyObject *o)`. This function returns a type object corresponding to the object type of object o, and it is equivalent to the Python expression `type(o)`.\n\nReferences: [1, 2]\n', '[1] Object Protocol\n95\n\nThe Python/C API, Release 3.13.2\nChanged in version 3.4: This function now includes a debug assertion to help ensure that it does not silently\ndiscard an active exception. PyObject *PyObject_Bytes(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. Compute a bytes representation of object o. NULL is\nreturned on failure and a bytes object on success. This is equivalent to the Python expression bytes(o), when\no is not an integer. Unlike bytes(o), a TypeError is raised when o is an integer instead of a zero-initialized\nbytes object. int PyObject_IsSubclass(PyObject *derived, PyObject *cls)\nPart of the Stable ABI. Return 1 if the class derived is identical to or derived from the class cls, otherwise\nreturn 0. In case of an error, return -1. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __subclasscheck__() method, it will be called to determine the subclass status as described\nin PEP 3119. Otherwise, derived is a subclass of cls if it is a direct or indirect subclass, i.e. contained in\ncls.__mro__. Normally only class objects, i.e. instances of type or a derived class, are considered classes. However, objects\ncan override this by having a __bases__ attribute (which must be a tuple of base classes). int PyObject_IsInstance(PyObject *inst, PyObject *cls)\nPart of the Stable ABI. Return 1 if inst is an instance of the class cls or a subclass of cls, or 0 if not. On error,\nreturns -1 and sets an exception. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __instancecheck__() method, it will be called to determine the subclass status as described in\nPEP 3119. Otherwise, inst is an instance of cls if its class is a subclass of cls. An instance inst can override what is considered its class by having a __class__ attribute. An object cls can override if it is considered a class, and what its base classes are, by having a __bases__\nattribute (which must be a tuple of base classes). Py_hash_t PyObject_Hash(PyObject *o)\nPart of the Stable ABI. Compute and return the hash value of an object o. On failure, return -1. This is the\nequivalent of the Python expression hash(o). Changed in version 3.2: The return type is now Py_hash_t. This is a signed integer the same size as\nPy_ssize_t. Py_hash_t PyObject_HashNotImplemented(PyObject *o)\nPart of the Stable ABI. Set a TypeError indicating that type(o) is not hashable and return -1. This function\nreceives special treatment when stored in a tp_hash slot, allowing a type to explicitly indicate to the interpreter\nthat it is not hashable. int PyObject_IsTrue(PyObject *o)\nPart of the Stable ABI. Returns 1 if the object o is considered to be true, and 0 otherwise. This is equivalent\nto the Python expression not not o. On failure, return -1.\nint PyObject_Not(PyObject *o)\nPart of the Stable ABI. Returns 0 if the object o is considered to be true, and 1 otherwise. This is equivalent\nto the Python expression not o. On failure, return -1. PyObject *PyObject_Type(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. When o is non-NULL, returns a type object correspond-\ning to the object type of object o. On failure, raises SystemError and returns NULL. This is equivalent to\nthe Python expression type(o). This function creates a new strong reference to the return value. There’s\nreally no reason to use this function instead of the Py_TYPE() function, which returns a pointer of type\nPyTypeObject*, except when a new strong reference is needed. 96\nChapter 7. Abstract Objects Layer\n\nThe Python/C API, Release 3.13.2\nint PyObject_TypeCheck(PyObject *o, PyTypeObject *type)\nReturn non-zero if the object o is of type type or a subtype of type, and 0 otherwise.\n\n[2] 7.1. Object Protocol\n95\n\nThe Python/C API, Release 3.13.2\nChanged in version 3.4: This function now includes a debug assertion to help ensure that it does not silently\ndiscard an active exception. PyObject *PyObject_Bytes(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. Compute a bytes representation of object o. NULL is\nreturned on failure and a bytes object on success. This is equivalent to the Python expression bytes(o), when\no is not an integer. Unlike bytes(o), a TypeError is raised when o is an integer instead of a zero-initialized\nbytes object. int PyObject_IsSubclass(PyObject *derived, PyObject *cls)\nPart of the Stable ABI. Return 1 if the class derived is identical to or derived from the class cls, otherwise\nreturn 0. In case of an error, return -1. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __subclasscheck__() method, it will be called to determine the subclass status as described\nin PEP 3119. Otherwise, derived is a subclass of cls if it is a direct or indirect subclass, i.e. contained in\ncls.__mro__. Normally only class objects, i.e. instances of type or a derived class, are considered classes. However, objects\ncan override this by having a __bases__ attribute (which must be a tuple of base classes). int PyObject_IsInstance(PyObject *inst, PyObject *cls)\nPart of the Stable ABI. Return 1 if inst is an instance of the class cls or a subclass of cls, or 0 if not. On error,\nreturns -1 and sets an exception. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __instancecheck__() method, it will be called to determine the subclass status as described in\nPEP 3119. Otherwise, inst is an instance of cls if its class is a subclass of cls. An instance inst can override what is considered its class by having a __class__ attribute. An object cls can override if it is considered a class, and what its base classes are, by having a __bases__\nattribute (which must be a tuple of base classes). Py_hash_t PyObject_Hash(PyObject *o)\nPart of the Stable ABI. Compute and return the hash value of an object o. On failure, return -1. This is the\nequivalent of the Python expression hash(o). Changed in version 3.2: The return type is now Py_hash_t. This is a signed integer the same size as\nPy_ssize_t. Py_hash_t PyObject_HashNotImplemented(PyObject *o)\nPart of the Stable ABI. Set a TypeError indicating that type(o) is not hashable and return -1. This function\nreceives special treatment when stored in a tp_hash slot, allowing a type to explicitly indicate to the interpreter\nthat it is not hashable. int PyObject_IsTrue(PyObject *o)\nPart of the Stable ABI. Returns 1 if the object o is considered to be true, and 0 otherwise. This is equivalent\nto the Python expression not not o. On failure, return -1.\nint PyObject_Not(PyObject *o)\nPart of the Stable ABI. Returns 0 if the object o is considered to be true, and 1 otherwise. This is equivalent\nto the Python expression not o. On failure, return -1. PyObject *PyObject_Type(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. When o is non-NULL, returns a type object correspond-\ning to the object type of object o. On failure, raises SystemError and returns NULL. This is equivalent to\nthe Python expression type(o). This function creates a new strong reference to the return value. There’s\nreally no reason to use this function instead of the Py_TYPE() function, which returns a pointer of type\nPyTypeObject*, except when a new strong reference is needed. 96\nChapter 7.\n\n[3] Called by the str() built-in function and, therefore, by the print() function. 7.1. Object Protocol\n95\n\nThe Python/C API, Release 3.13.2\nChanged in version 3.4: This function now includes a debug assertion to help ensure that it does not silently\ndiscard an active exception. PyObject *PyObject_Bytes(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. Compute a bytes representation of object o. NULL is\nreturned on failure and a bytes object on success. This is equivalent to the Python expression bytes(o), when\no is not an integer. Unlike bytes(o), a TypeError is raised when o is an integer instead of a zero-initialized\nbytes object. int PyObject_IsSubclass(PyObject *derived, PyObject *cls)\nPart of the Stable ABI. Return 1 if the class derived is identical to or derived from the class cls, otherwise\nreturn 0. In case of an error, return -1. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __subclasscheck__() method, it will be called to determine the subclass status as described\nin PEP 3119. Otherwise, derived is a subclass of cls if it is a direct or indirect subclass, i.e. contained in\ncls.__mro__. Normally only class objects, i.e. instances of type or a derived class, are considered classes. However, objects\ncan override this by having a __bases__ attribute (which must be a tuple of base classes). int PyObject_IsInstance(PyObject *inst, PyObject *cls)\nPart of the Stable ABI. Return 1 if inst is an instance of the class cls or a subclass of cls, or 0 if not. On error,\nreturns -1 and sets an exception. If cls is a tuple, the check will be done against every entry in cls. The result will be 1 when at least one of the\nchecks returns 1, otherwise it will be 0. If cls has a __instancecheck__() method, it will be called to determine the subclass status as described in\nPEP 3119. Otherwise, inst is an instance of cls if its class is a subclass of cls. An instance inst can override what is considered its class by having a __class__ attribute. An object cls can override if it is considered a class, and what its base classes are, by having a __bases__\nattribute (which must be a tuple of base classes). Py_hash_t PyObject_Hash(PyObject *o)\nPart of the Stable ABI. Compute and return the hash value of an object o. On failure, return -1. This is the\nequivalent of the Python expression hash(o). Changed in version 3.2: The return type is now Py_hash_t. This is a signed integer the same size as\nPy_ssize_t. Py_hash_t PyObject_HashNotImplemented(PyObject *o)\nPart of the Stable ABI. Set a TypeError indicating that type(o) is not hashable and return -1. This function\nreceives special treatment when stored in a tp_hash slot, allowing a type to explicitly indicate to the interpreter\nthat it is not hashable. int PyObject_IsTrue(PyObject *o)\nPart of the Stable ABI. Returns 1 if the object o is considered to be true, and 0 otherwise. This is equivalent\nto the Python expression not not o. On failure, return -1.\nint PyObject_Not(PyObject *o)\nPart of the Stable ABI. Returns 0 if the object o is considered to be true, and 1 otherwise. This is equivalent\nto the Python expression not o. On failure, return -1. PyObject *PyObject_Type(PyObject *o)\nReturn value: New reference. Part of the Stable ABI. When o is non-NULL, returns a type object correspond-\ning to the object type of object o. On failure, raises SystemError and returns NULL. This is equivalent to\nthe Python expression type(o). This function creates a new strong reference to the return value. There’s\nreally no reason to use this function instead of the Py_TYPE() function, which returns a pointer of type\nPyTypeObject*, except when a new strong reference is needed.')",0.00859920665540291,0.09229501442109599,0.20918527838943063,0.5755262970924377,0.5599102
How to check if the string is empty in Python?,"Empty strings are ""falsy"" (
python 2
 or 
python 3
 reference), which means they are considered false in a Boolean context, so you can just do this:


if not myString:



This is the preferred way if you know that your variable is a string.  If your variable could also be some other type then you should use:


if myString == """":



See the documentation on 
Truth Value Testing
 for other values that are false in Boolean contexts.

","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] If count is not specified or -1, then all occurrences are replaced. Changed in version 3.13: count is now supported as a keyword argument. str.rfind(sub[, start[, end]])\nReturn the highest index in the string where substring sub is found, such that sub is contained within\ns[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on fail-\nure. str.rindex(sub[, start[, end]])\nLike rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar])\nReturn the string right justified in a string of length width. Padding is done using the specified fillchar (default\nis an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep)\nSplit the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two\nempty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except\nfor splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars])\nReturn a copy of the string with trailing characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a suffix; rather, all combinations of its values are stripped:\n4.8. Text Sequence Type — str\n57\n\nThe Python Library Reference, Release 3.13.2\n>>> \'\nspacious\n\'.rstrip()\n\'\nspacious\'\n>>> \'mississippi\'.rstrip(\'ipz\')\n\'mississ\'\nSee str.removesuffix() for a method that will remove a single suffix string rather than all of a set of\ncharacters. For example:\n>>> \'Monty Python\'.rstrip(\' Python\')\n\'M\'\n>>> \'Monty Python\'.removesuffix(\' Python\')\n\'Monty\'\nstr.split(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then\nthere is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for\nexample, \'1,,2\'.split(\',\') returns [\'1\', \'\', \'2\']). The sep argument may consist of multiple char-\nacters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with\na specified separator returns [\'\']. For example:\n>>> \'1,2,3\'.split(\',\')\n[\'1\', \'2\', \'3\']\n>>> \'1,2,3\'.split(\',\', maxsplit=1)\n[\'1\', \'2,3\']\n>>> \'1,2,,3,\'.split(\',\')\n[\'1\', \'2\', \'\', \'3\', \'\']\n>>> \'1<>2<>3<4\'.split(\'<>\')\n[\'1\', \'2\', \'3<4\']\nIf sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are\nregarded as a single separator, and the result will contain no empty strings at the start or end if the string has\nleading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace\nwith a None separator returns []. For example:\n>>> \'1 2 3\'.split()\n[\'1\', \'2\', \'3\']\n>>> \'1 2 3\'.split(maxsplit=1)\n[\'1\', \'2 3\']\n>>> \'\n1\n2\n3\n\'.split()\n[\'1\', \'2\', \'3\']\nstr.splitlines(keepends=False)\nReturn a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting\nlist unless keepends is given and true. This method splits on the following line boundaries. In particular, the boundaries are a superset of universal\nnewlines. 58\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nRepresentation\nDescription\n\\n\nLine Feed\n\\r\nCarriage Return\n\\r\\n\nCarriage Return + Line Feed\n\\v or \\x0b\nLine Tabulation\n\\f or \\x0c\nForm Feed\n\\x1c\nFile Separator\n\\x1d\nGroup Separator\n\\x1e\nRecord Separator\n\\x85\nNext Line (C1 Control Code)\n\\u2028\nLine Separator\n\\u2029\nParagraph Separator\nChanged in version 3.2: \\v and \\f added to list of line boundaries. For example:\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines()\n[\'ab c\', \'\', \'de fg\', \'kl\']\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines(keepends=True)\n[\'ab c\\n\', \'\\n\', \'de fg\\r\', \'kl\\r\\n\']\nUnlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,\nand a terminal line break does not result in an extra line:\n>>> """".splitlines()\n[]\n>>> ""One line\\n"".splitlines()\n[\'One line\']\nFor comparison, split(\'\\n\') gives:\n>>> \'\'.split(\'\\n\')\n[\'\']\n>>> \'Two lines\\n\'.split(\'\\n\')\n[\'Two lines\', \'\']\nstr.startswith(prefix[, start[, end]])\nReturn True if string starts with the prefix, otherwise return False. prefix can also be a tuple of prefixes to\nlook for. With optional start, test string beginning at that position. With optional end, stop comparing string\nat that position. str.strip([chars])\nReturn a copy of the string with the leading and trailing characters removed. The chars argument is a string\nspecifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing\nwhitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:\n>>> \'\nspacious\n\'.strip()\n\'spacious\'\n>>> \'www.example.com\'.strip(\'cmowz.\') \'example\'\nThe outermost leading and trailing chars argument values are stripped from the string. Characters are removed\nfrom the leading end until reaching a string character that is not contained in the set of characters in chars. A\nsimilar action takes place on the trailing end. For example:\n4.8. Text Sequence Type — str\n59\n\nThe Python Library Reference, Release 3.13.2\n>>> comment_string = \'#....... Section 3.2.1 Issue #32 .......\'\n>>> comment_string.strip(\'.#! \') \'Section 3.2.1 Issue #32\'\nstr.swapcase()\nReturn a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is\nnot necessarily true that s.swapcase().swapcase() == s.\nstr.title()\nReturn a titlecased version of the string where words start with an uppercase character and the remaining\ncharacters are lowercase. For example:\n>>> \'Hello world\'.title()\n\'Hello World\'\nThe algorithm uses a simple language-independent definition of a word as groups of consecutive letters.\n\n[2] If count is given, only the\nfirst count occurrences are replaced. If count is not specified or -1, then all occurrences are replaced. Changed in version 3.13: count is now supported as a keyword argument. str.rfind(sub[, start[, end]])\nReturn the highest index in the string where substring sub is found, such that sub is contained within\ns[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on fail-\nure. str.rindex(sub[, start[, end]])\nLike rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar])\nReturn the string right justified in a string of length width. Padding is done using the specified fillchar (default\nis an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep)\nSplit the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two\nempty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except\nfor splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars])\nReturn a copy of the string with trailing characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a suffix; rather, all combinations of its values are stripped:\n4.8. Text Sequence Type — str\n57\n\nThe Python Library Reference, Release 3.13.2\n>>> \'\nspacious\n\'.rstrip()\n\'\nspacious\'\n>>> \'mississippi\'.rstrip(\'ipz\')\n\'mississ\'\nSee str.removesuffix() for a method that will remove a single suffix string rather than all of a set of\ncharacters. For example:\n>>> \'Monty Python\'.rstrip(\' Python\')\n\'M\'\n>>> \'Monty Python\'.removesuffix(\' Python\')\n\'Monty\'\nstr.split(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then\nthere is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for\nexample, \'1,,2\'.split(\',\') returns [\'1\', \'\', \'2\']). The sep argument may consist of multiple char-\nacters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with\na specified separator returns [\'\']. For example:\n>>> \'1,2,3\'.split(\',\')\n[\'1\', \'2\', \'3\']\n>>> \'1,2,3\'.split(\',\', maxsplit=1)\n[\'1\', \'2,3\']\n>>> \'1,2,,3,\'.split(\',\')\n[\'1\', \'2\', \'\', \'3\', \'\']\n>>> \'1<>2<>3<4\'.split(\'<>\')\n[\'1\', \'2\', \'3<4\']\nIf sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are\nregarded as a single separator, and the result will contain no empty strings at the start or end if the string has\nleading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace\nwith a None separator returns []. For example:\n>>> \'1 2 3\'.split()\n[\'1\', \'2\', \'3\']\n>>> \'1 2 3\'.split(maxsplit=1)\n[\'1\', \'2 3\']\n>>> \'\n1\n2\n3\n\'.split()\n[\'1\', \'2\', \'3\']\nstr.splitlines(keepends=False)\nReturn a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting\nlist unless keepends is given and true. This method splits on the following line boundaries. In particular, the boundaries are a superset of universal\nnewlines. 58\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nRepresentation\nDescription\n\\n\nLine Feed\n\\r\nCarriage Return\n\\r\\n\nCarriage Return + Line Feed\n\\v or \\x0b\nLine Tabulation\n\\f or \\x0c\nForm Feed\n\\x1c\nFile Separator\n\\x1d\nGroup Separator\n\\x1e\nRecord Separator\n\\x85\nNext Line (C1 Control Code)\n\\u2028\nLine Separator\n\\u2029\nParagraph Separator\nChanged in version 3.2: \\v and \\f added to list of line boundaries. For example:\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines()\n[\'ab c\', \'\', \'de fg\', \'kl\']\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines(keepends=True)\n[\'ab c\\n\', \'\\n\', \'de fg\\r\', \'kl\\r\\n\']\nUnlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,\nand a terminal line break does not result in an extra line:\n>>> """".splitlines()\n[]\n>>> ""One line\\n"".splitlines()\n[\'One line\']\nFor comparison, split(\'\\n\') gives:\n>>> \'\'.split(\'\\n\')\n[\'\']\n>>> \'Two lines\\n\'.split(\'\\n\')\n[\'Two lines\', \'\']\nstr.startswith(prefix[, start[, end]])\nReturn True if string starts with the prefix, otherwise return False. prefix can also be a tuple of prefixes to\nlook for. With optional start, test string beginning at that position. With optional end, stop comparing string\nat that position. str.strip([chars])\nReturn a copy of the string with the leading and trailing characters removed. The chars argument is a string\nspecifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing\nwhitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:\n>>> \'\nspacious\n\'.strip()\n\'spacious\'\n>>> \'www.example.com\'.strip(\'cmowz.\') \'example\'\nThe outermost leading and trailing chars argument values are stripped from the string. Characters are removed\nfrom the leading end until reaching a string character that is not contained in the set of characters in chars. A\nsimilar action takes place on the trailing end. For example:\n4.8. Text Sequence Type — str\n59\n\nThe Python Library Reference, Release 3.13.2\n>>> comment_string = \'#....... Section 3.2.1 Issue #32 .......\'\n>>> comment_string.strip(\'.#! \') \'Section 3.2.1 Issue #32\'\nstr.swapcase()\nReturn a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is\nnot necessarily true that s.swapcase().swapcase() == s.\nstr.title()\nReturn a titlecased version of the string where words start with an uppercase character and the remaining\ncharacters are lowercase.\n\n[3] Otherwise, return a copy of the\noriginal string:\n>>> \'TestHook\'.removeprefix(\'Test\')\n\'Hook\'\n>>> \'BaseTestCase\'.removeprefix(\'Test\')\n\'BaseTestCase\'\nAdded in version 3.9.\nstr.removesuffix(suffix, /)\nIf the string ends with the suffix string and that suffix is not empty, return string[:-len(suffix)]. Oth-\nerwise, return a copy of the original string:\n>>> \'MiscTests\'.removesuffix(\'Tests\')\n\'Misc\'\n>>> \'TmpDirMixin\'.removesuffix(\'Tests\')\n\'TmpDirMixin\'\nAdded in version 3.9.\nstr.replace(old, new, count=-1)\nReturn a copy of the string with all occurrences of substring old replaced by new. If count is given, only the\nfirst count occurrences are replaced. If count is not specified or -1, then all occurrences are replaced. Changed in version 3.13: count is now supported as a keyword argument. str.rfind(sub[, start[, end]])\nReturn the highest index in the string where substring sub is found, such that sub is contained within\ns[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on fail-\nure. str.rindex(sub[, start[, end]])\nLike rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar])\nReturn the string right justified in a string of length width. Padding is done using the specified fillchar (default\nis an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep)\nSplit the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two\nempty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except\nfor splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars])\nReturn a copy of the string with trailing characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a suffix; rather, all combinations of its values are stripped:\n4.8. Text Sequence Type — str\n57\n\nThe Python Library Reference, Release 3.13.2\n>>> \'\nspacious\n\'.rstrip()\n\'\nspacious\'\n>>> \'mississippi\'.rstrip(\'ipz\')\n\'mississ\'\nSee str.removesuffix() for a method that will remove a single suffix string rather than all of a set of\ncharacters. For example:\n>>> \'Monty Python\'.rstrip(\' Python\')\n\'M\'\n>>> \'Monty Python\'.removesuffix(\' Python\')\n\'Monty\'\nstr.split(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then\nthere is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for\nexample, \'1,,2\'.split(\',\') returns [\'1\', \'\', \'2\']). The sep argument may consist of multiple char-\nacters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with\na specified separator returns [\'\']. For example:\n>>> \'1,2,3\'.split(\',\')\n[\'1\', \'2\', \'3\']\n>>> \'1,2,3\'.split(\',\', maxsplit=1)\n[\'1\', \'2,3\']\n>>> \'1,2,,3,\'.split(\',\')\n[\'1\', \'2\', \'\', \'3\', \'\']\n>>> \'1<>2<>3<4\'.split(\'<>\')\n[\'1\', \'2\', \'3<4\']\nIf sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are\nregarded as a single separator, and the result will contain no empty strings at the start or end if the string has\nleading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace\nwith a None separator returns []. For example:\n>>> \'1 2 3\'.split()\n[\'1\', \'2\', \'3\']\n>>> \'1 2 3\'.split(maxsplit=1)\n[\'1\', \'2 3\']\n>>> \'\n1\n2\n3\n\'.split()\n[\'1\', \'2\', \'3\']\nstr.splitlines(keepends=False)\nReturn a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting\nlist unless keepends is given and true. This method splits on the following line boundaries. In particular, the boundaries are a superset of universal\nnewlines. 58\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nRepresentation\nDescription\n\\n\nLine Feed\n\\r\nCarriage Return\n\\r\\n\nCarriage Return + Line Feed\n\\v or \\x0b\nLine Tabulation\n\\f or \\x0c\nForm Feed\n\\x1c\nFile Separator\n\\x1d\nGroup Separator\n\\x1e\nRecord Separator\n\\x85\nNext Line (C1 Control Code)\n\\u2028\nLine Separator\n\\u2029\nParagraph Separator\nChanged in version 3.2: \\v and \\f added to list of line boundaries. For example:\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines()\n[\'ab c\', \'\', \'de fg\', \'kl\']\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines(keepends=True)\n[\'ab c\\n\', \'\\n\', \'de fg\\r\', \'kl\\r\\n\']\nUnlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,\nand a terminal line break does not result in an extra line:\n>>> """".splitlines()\n[]\n>>> ""One line\\n"".splitlines()\n[\'One line\']\nFor comparison, split(\'\\n\') gives:\n>>> \'\'.split(\'\\n\')\n[\'\']\n>>> \'Two lines\\n\'.split(\'\\n\')\n[\'Two lines\', \'\']\nstr.startswith(prefix[, start[, end]])\nReturn True if string starts with the prefix, otherwise return False. prefix can also be a tuple of prefixes to\nlook for. With optional start, test string beginning at that position. With optional end, stop comparing string\nat that position. str.strip([chars])\nReturn a copy of the string with the leading and trailing characters removed. The chars argument is a string\nspecifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing\nwhitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:\n>>> \'\nspacious\n\'.strip()\n\'spacious\'\n>>> \'www.example.com\'.strip(\'cmowz.\') \'example\'\nThe outermost leading and trailing chars argument values are stripped from the string. Characters are removed\nfrom the leading end until reaching a string character that is not contained in the set of characters in chars. A\nsimilar action takes place on the trailing end. For example:\n4.8. Text Sequence Type — str\n59\n\nThe Python Library Reference, Release 3.13.2\n>>> comment_string = \'#....... Section 3.2.1 Issue #32 .......\'\n>>> comment_string.strip(\'.#! \')')",9.951295849332922e-156,0.020184544405997693,0.0639600393013231,0.5000699758529663,0.24376504
Why is reading lines from stdin much slower in C++ than Python?,"tl;dr: Because of different default settings in C++ requiring more system calls.


By default, 
cin
 is synchronized with stdio, which causes it to avoid any input buffering.  If you add this to the top of your main, you should see much better performance:


std::ios_base::sync_with_stdio(false);



Normally, when an input stream is buffered, instead of reading one character at a time, the stream will be read in larger chunks.  This reduces the number of system calls, which are typically relatively expensive.  However, since the 
FILE*
 based 
stdio
 and 
iostreams
 often have separate implementations and therefore separate buffers, this could lead to a problem if both were used together.  For example:


int myvalue1;
cin >> myvalue1;
int myvalue2;
scanf(""%d"",&myvalue2);



If more input was read by 
cin
 than it actually needed, then the second integer value wouldn't be available for the 
scanf
 function, which has its own independent buffer.  This would lead to unexpected results.


To avoid this, by default, streams are synchronized with 
stdio
.  One common way to achieve this is to have 
cin
 read each character one at a time as needed using 
stdio
 functions.  Unfortunately, this introduces a lot of overhead.  For small amounts of input, this isn't a big problem, but when you are reading millions of lines, the performance penalty is significant.


Fortunately, the library designers decided that you should also be able to disable this feature to get improved performance if you knew what you were doing, so they provided the 
sync_with_stdio
 method. From this link (emphasis added):




If the synchronization is turned off, the C++ standard streams are allowed to buffer their I/O independently, 
which may be considerably faster in some cases
.



","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] How-\never, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy. So the\nmin() of the result is probably the only number you should be interested in. After that, you should\nlook at the entire vector and apply common sense rather than statistics. Changed in version 3.7: Default value of repeat changed from 3 to 5.\nprint_exc(file=None)\nHelper to print a traceback from the timed code. Typical use:\nt = Timer(...)\n# outside the try/except\ntry:\nt.timeit(...)\n# or t.repeat(...)\nexcept Exception:\nt.print_exc()\nThe advantage over the standard traceback is that source lines in the compiled template will be displayed. The optional file argument directs where the traceback is sent; it defaults to sys.stderr. 28.6. timeit — Measure execution time of small code snippets\n1873\n\nThe Python Library Reference, Release 3.13.2\n28.6.3 Command-Line Interface\nWhen called as a program from the command line, the following form is used:\npython -m timeit [-n N] [-r N] [-u U] [-s S] [-p] [-v] [-h] [statement ...]\nWhere the following options are understood:\n-n N, --number=N\nhow many times to execute ‘statement’\n-r N, --repeat=N\nhow many times to repeat the timer (default 5)\n-s S, --setup=S\nstatement to be executed once initially (default pass)\n-p, --process\nmeasure\nprocess\ntime,\nnot\nwallclock\ntime,\nusing\ntime.process_time()\ninstead\nof\ntime. perf_counter(), which is the default\nAdded in version 3.3. -u, --unit=U\nspecify a time unit for timer output; can select nsec, usec, msec, or sec\nAdded in version 3.5. -v, --verbose\nprint raw timing results; repeat for more digits precision\n-h, --help\nprint a short usage message and exit\nA multi-line statement may be given by specifying each line as a separate statement argument; indented lines are\npossible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly. If -n is not given, a suitable number of loops is calculated by trying increasing numbers from the sequence 1, 2, 5,\n10, 20, 50, … until the total time is at least 0.2 seconds. default_timer() measurements can be affected by other programs running on the same machine, so the best\nthing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option\nis good for this; the default of 5 repetitions is probably enough in most cases. You can use time.process_time()\nto measure CPU time. ® Note\nThere is a certain baseline overhead associated with executing a pass statement. The code here doesn’t try to\nhide it, but you should be aware of it. The baseline overhead can be measured by invoking the program without\narguments, and it might differ between Python versions. 28.6.4 Examples\nIt is possible to provide a setup statement that is executed only once at the beginning:\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""char in text""\n5000000 loops, best of 5: 0.0877 usec per loop\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""text.find(char)""\n1000000 loops, best of 5: 0.342 usec per loop\nIn the output, there are three fields. The loop count, which tells you how many times the statement body was run\nper timing loop repetition. The repetition count (‘best of 5’) which tells you how many times the timing loop was\n1874\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nrepeated, and finally the time the statement body took on average within the best repetition of the timing loop. That\nis, the time the fastest repetition took divided by the loop count. >>> import timeit\n>>> timeit.timeit(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n0.41440500499993504\n>>> timeit.timeit(\'text.find(char)\', setup=\'text = ""sample string""; char = ""g""\')\n1.7246671520006203\nThe same can be done using the Timer class and its methods:\n>>> import timeit\n>>> t = timeit.Timer(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n>>> t.timeit()\n0.3955516149999312\n>>> t.repeat()\n[0.40183617287970225, 0.37027556854118704, 0.38344867356679524, 0.3712595970846668,\n,→0.37866875250654886]\nThe following examples show how to time expressions that contain multiple lines. Here we compare the cost of using\nhasattr() vs. try/except to test for missing and present object attributes:\n$ python -m timeit ""try:"" ""\nstr.__bool__"" ""except AttributeError:"" ""\npass""\n20000 loops, best of 5: 15.7 usec per loop\n$ python -m timeit ""if hasattr(str, \'__bool__\'): pass""\n50000 loops, best of 5: 4.26 usec per loop\n$ python -m timeit ""try:"" ""\nint.__bool__"" ""except AttributeError:"" ""\npass""\n200000 loops, best of 5: 1.43 usec per loop\n$ python -m timeit ""if hasattr(int, \'__bool__\'): pass""\n100000 loops, best of 5: 2.23 usec per loop\n>>> import timeit\n>>> # attribute is missing\n>>> s = """"""\\\n... try:\n...\nstr.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.9138244460009446\n>>> s = ""if hasattr(str, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.5829014980008651\n>>>\n>>> # attribute is present\n>>> s = """"""\\\n... try:\n...\nint.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.04215312199994514\n>>> s = ""if hasattr(int, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.08588060699912603\n28.6. timeit — Measure execution time of small code snippets\n1875\n\nThe Python Library Reference, Release 3.13.2\nTo give the timeit module access to functions you define, you can pass a setup parameter which contains an import\nstatement:\ndef test():\n""""""Stupid test function""""""\nL = [i for i in range(100)]\nif __name__ == \'__main__\':\nimport timeit\nprint(timeit.timeit(""test()"", setup=""from __main__ import test""))\nAnother option is to pass globals() to the globals parameter, which will cause the code to be executed within your\ncurrent global namespace. This can be more convenient than individually specifying imports:\ndef f(x):\nreturn x**2\ndef g(x):\nreturn x**4\ndef h(x):\nreturn x**8\nimport timeit\nprint(timeit.timeit(\'[func(42) for func in (f,g,h)]\', globals=globals()))\n28.7 trace — Trace or track Python statement execution\nSource code: Lib/trace.py\nThe trace module allows you to trace program execution, generate annotated statement coverage listings, print\ncaller/callee relationships and list functions executed during a program run. It can be used in another program or\nfrom the command line. µ See also\nCoverage.py\nA popular third-party coverage tool that provides HTML output along with advanced features such as\nbranch coverage. 28.7.1 Command-Line Usage\nThe trace module can be invoked from the command line. It can be as simple as\npython -m trace --count -C . somefile.py ... The above will execute somefile.py and generate annotated listings of all Python modules imported during the\nexecution into the current directory. --help\nDisplay usage and exit. --version\nDisplay the version of the module and exit. Added in version 3.8: Added --module option that allows to run an executable module. 1876\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nMain options\nAt least one of the following options must be specified when invoking trace. The --listfuncs option is mu-\ntually exclusive with the --trace and --count options. When --listfuncs is provided, neither --count nor\n--trace are accepted, and vice versa. -c, --count\nProduce a set of annotated listing files upon program completion that shows how many times each statement\nwas executed. See also --coverdir, --file and --no-report below. -t, --trace\nDisplay lines as they are executed. -l, --listfuncs\nDisplay the functions executed by running the program. -r, --report\nProduce an annotated list from an earlier program run that used the --count and --file option. This does\nnot execute any code. -T, --trackcalls\nDisplay the calling relationships exposed by running the program. Modifiers\n-f, --file=<file>\nName of a file to accumulate counts over several tracing runs. Should be used with the --count option. -C, --coverdir=<dir>\nDirectory where the report files go. The coverage report for package.module is written to file dir/\npackage/module.cover.\n\n[2] In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy. So the\nmin() of the result is probably the only number you should be interested in. After that, you should\nlook at the entire vector and apply common sense rather than statistics. Changed in version 3.7: Default value of repeat changed from 3 to 5.\nprint_exc(file=None)\nHelper to print a traceback from the timed code. Typical use:\nt = Timer(...)\n# outside the try/except\ntry:\nt.timeit(...)\n# or t.repeat(...)\nexcept Exception:\nt.print_exc()\nThe advantage over the standard traceback is that source lines in the compiled template will be displayed. The optional file argument directs where the traceback is sent; it defaults to sys.stderr. 28.6. timeit — Measure execution time of small code snippets\n1873\n\nThe Python Library Reference, Release 3.13.2\n28.6.3 Command-Line Interface\nWhen called as a program from the command line, the following form is used:\npython -m timeit [-n N] [-r N] [-u U] [-s S] [-p] [-v] [-h] [statement ...]\nWhere the following options are understood:\n-n N, --number=N\nhow many times to execute ‘statement’\n-r N, --repeat=N\nhow many times to repeat the timer (default 5)\n-s S, --setup=S\nstatement to be executed once initially (default pass)\n-p, --process\nmeasure\nprocess\ntime,\nnot\nwallclock\ntime,\nusing\ntime.process_time()\ninstead\nof\ntime. perf_counter(), which is the default\nAdded in version 3.3. -u, --unit=U\nspecify a time unit for timer output; can select nsec, usec, msec, or sec\nAdded in version 3.5. -v, --verbose\nprint raw timing results; repeat for more digits precision\n-h, --help\nprint a short usage message and exit\nA multi-line statement may be given by specifying each line as a separate statement argument; indented lines are\npossible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly. If -n is not given, a suitable number of loops is calculated by trying increasing numbers from the sequence 1, 2, 5,\n10, 20, 50, … until the total time is at least 0.2 seconds. default_timer() measurements can be affected by other programs running on the same machine, so the best\nthing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option\nis good for this; the default of 5 repetitions is probably enough in most cases. You can use time.process_time()\nto measure CPU time. ® Note\nThere is a certain baseline overhead associated with executing a pass statement. The code here doesn’t try to\nhide it, but you should be aware of it. The baseline overhead can be measured by invoking the program without\narguments, and it might differ between Python versions. 28.6.4 Examples\nIt is possible to provide a setup statement that is executed only once at the beginning:\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""char in text""\n5000000 loops, best of 5: 0.0877 usec per loop\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""text.find(char)""\n1000000 loops, best of 5: 0.342 usec per loop\nIn the output, there are three fields. The loop count, which tells you how many times the statement body was run\nper timing loop repetition. The repetition count (‘best of 5’) which tells you how many times the timing loop was\n1874\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nrepeated, and finally the time the statement body took on average within the best repetition of the timing loop. That\nis, the time the fastest repetition took divided by the loop count. >>> import timeit\n>>> timeit.timeit(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n0.41440500499993504\n>>> timeit.timeit(\'text.find(char)\', setup=\'text = ""sample string""; char = ""g""\')\n1.7246671520006203\nThe same can be done using the Timer class and its methods:\n>>> import timeit\n>>> t = timeit.Timer(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n>>> t.timeit()\n0.3955516149999312\n>>> t.repeat()\n[0.40183617287970225, 0.37027556854118704, 0.38344867356679524, 0.3712595970846668,\n,→0.37866875250654886]\nThe following examples show how to time expressions that contain multiple lines. Here we compare the cost of using\nhasattr() vs. try/except to test for missing and present object attributes:\n$ python -m timeit ""try:"" ""\nstr.__bool__"" ""except AttributeError:"" ""\npass""\n20000 loops, best of 5: 15.7 usec per loop\n$ python -m timeit ""if hasattr(str, \'__bool__\'): pass""\n50000 loops, best of 5: 4.26 usec per loop\n$ python -m timeit ""try:"" ""\nint.__bool__"" ""except AttributeError:"" ""\npass""\n200000 loops, best of 5: 1.43 usec per loop\n$ python -m timeit ""if hasattr(int, \'__bool__\'): pass""\n100000 loops, best of 5: 2.23 usec per loop\n>>> import timeit\n>>> # attribute is missing\n>>> s = """"""\\\n... try:\n...\nstr.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.9138244460009446\n>>> s = ""if hasattr(str, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.5829014980008651\n>>>\n>>> # attribute is present\n>>> s = """"""\\\n... try:\n...\nint.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.04215312199994514\n>>> s = ""if hasattr(int, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.08588060699912603\n28.6. timeit — Measure execution time of small code snippets\n1875\n\nThe Python Library Reference, Release 3.13.2\nTo give the timeit module access to functions you define, you can pass a setup parameter which contains an import\nstatement:\ndef test():\n""""""Stupid test function""""""\nL = [i for i in range(100)]\nif __name__ == \'__main__\':\nimport timeit\nprint(timeit.timeit(""test()"", setup=""from __main__ import test""))\nAnother option is to pass globals() to the globals parameter, which will cause the code to be executed within your\ncurrent global namespace. This can be more convenient than individually specifying imports:\ndef f(x):\nreturn x**2\ndef g(x):\nreturn x**4\ndef h(x):\nreturn x**8\nimport timeit\nprint(timeit.timeit(\'[func(42) for func in (f,g,h)]\', globals=globals()))\n28.7 trace — Trace or track Python statement execution\nSource code: Lib/trace.py\nThe trace module allows you to trace program execution, generate annotated statement coverage listings, print\ncaller/callee relationships and list functions executed during a program run. It can be used in another program or\nfrom the command line. µ See also\nCoverage.py\nA popular third-party coverage tool that provides HTML output along with advanced features such as\nbranch coverage. 28.7.1 Command-Line Usage\nThe trace module can be invoked from the command line. It can be as simple as\npython -m trace --count -C . somefile.py ... The above will execute somefile.py and generate annotated listings of all Python modules imported during the\nexecution into the current directory. --help\nDisplay usage and exit. --version\nDisplay the version of the module and exit. Added in version 3.8: Added --module option that allows to run an executable module. 1876\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nMain options\nAt least one of the following options must be specified when invoking trace. The --listfuncs option is mu-\ntually exclusive with the --trace and --count options. When --listfuncs is provided, neither --count nor\n--trace are accepted, and vice versa. -c, --count\nProduce a set of annotated listing files upon program completion that shows how many times each statement\nwas executed. See also --coverdir, --file and --no-report below. -t, --trace\nDisplay lines as they are executed. -l, --listfuncs\nDisplay the functions executed by running the program. -r, --report\nProduce an annotated list from an earlier program run that used the --count and --file option. This does\nnot execute any code. -T, --trackcalls\nDisplay the calling relationships exposed by running the program. Modifiers\n-f, --file=<file>\nName of a file to accumulate counts over several tracing runs. Should be used with the --count option. -C, --coverdir=<dir>\nDirectory where the report files go. The coverage report for package.module is written to file dir/\npackage/module.cover. -m, --missing\nWhen generating annotated listings, mark lines which were not executed with >>>>>>.\n\n[3] The second argument specifies the number argu-\nment for timeit(). ® Note\nIt’s tempting to calculate mean and standard deviation from the result vector and report these. How-\never, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy. So the\nmin() of the result is probably the only number you should be interested in. After that, you should\nlook at the entire vector and apply common sense rather than statistics. Changed in version 3.7: Default value of repeat changed from 3 to 5.\nprint_exc(file=None)\nHelper to print a traceback from the timed code. Typical use:\nt = Timer(...)\n# outside the try/except\ntry:\nt.timeit(...)\n# or t.repeat(...)\nexcept Exception:\nt.print_exc()\nThe advantage over the standard traceback is that source lines in the compiled template will be displayed. The optional file argument directs where the traceback is sent; it defaults to sys.stderr. 28.6. timeit — Measure execution time of small code snippets\n1873\n\nThe Python Library Reference, Release 3.13.2\n28.6.3 Command-Line Interface\nWhen called as a program from the command line, the following form is used:\npython -m timeit [-n N] [-r N] [-u U] [-s S] [-p] [-v] [-h] [statement ...]\nWhere the following options are understood:\n-n N, --number=N\nhow many times to execute ‘statement’\n-r N, --repeat=N\nhow many times to repeat the timer (default 5)\n-s S, --setup=S\nstatement to be executed once initially (default pass)\n-p, --process\nmeasure\nprocess\ntime,\nnot\nwallclock\ntime,\nusing\ntime.process_time()\ninstead\nof\ntime. perf_counter(), which is the default\nAdded in version 3.3. -u, --unit=U\nspecify a time unit for timer output; can select nsec, usec, msec, or sec\nAdded in version 3.5. -v, --verbose\nprint raw timing results; repeat for more digits precision\n-h, --help\nprint a short usage message and exit\nA multi-line statement may be given by specifying each line as a separate statement argument; indented lines are\npossible by enclosing an argument in quotes and using leading spaces. Multiple -s options are treated similarly. If -n is not given, a suitable number of loops is calculated by trying increasing numbers from the sequence 1, 2, 5,\n10, 20, 50, … until the total time is at least 0.2 seconds. default_timer() measurements can be affected by other programs running on the same machine, so the best\nthing to do when accurate timing is necessary is to repeat the timing a few times and use the best time. The -r option\nis good for this; the default of 5 repetitions is probably enough in most cases. You can use time.process_time()\nto measure CPU time. ® Note\nThere is a certain baseline overhead associated with executing a pass statement. The code here doesn’t try to\nhide it, but you should be aware of it. The baseline overhead can be measured by invoking the program without\narguments, and it might differ between Python versions. 28.6.4 Examples\nIt is possible to provide a setup statement that is executed only once at the beginning:\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""char in text""\n5000000 loops, best of 5: 0.0877 usec per loop\n$ python -m timeit -s ""text = \'sample string\'; char = \'g\'"" ""text.find(char)""\n1000000 loops, best of 5: 0.342 usec per loop\nIn the output, there are three fields. The loop count, which tells you how many times the statement body was run\nper timing loop repetition. The repetition count (‘best of 5’) which tells you how many times the timing loop was\n1874\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nrepeated, and finally the time the statement body took on average within the best repetition of the timing loop. That\nis, the time the fastest repetition took divided by the loop count. >>> import timeit\n>>> timeit.timeit(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n0.41440500499993504\n>>> timeit.timeit(\'text.find(char)\', setup=\'text = ""sample string""; char = ""g""\')\n1.7246671520006203\nThe same can be done using the Timer class and its methods:\n>>> import timeit\n>>> t = timeit.Timer(\'char in text\', setup=\'text = ""sample string""; char = ""g""\')\n>>> t.timeit()\n0.3955516149999312\n>>> t.repeat()\n[0.40183617287970225, 0.37027556854118704, 0.38344867356679524, 0.3712595970846668,\n,→0.37866875250654886]\nThe following examples show how to time expressions that contain multiple lines. Here we compare the cost of using\nhasattr() vs. try/except to test for missing and present object attributes:\n$ python -m timeit ""try:"" ""\nstr.__bool__"" ""except AttributeError:"" ""\npass""\n20000 loops, best of 5: 15.7 usec per loop\n$ python -m timeit ""if hasattr(str, \'__bool__\'): pass""\n50000 loops, best of 5: 4.26 usec per loop\n$ python -m timeit ""try:"" ""\nint.__bool__"" ""except AttributeError:"" ""\npass""\n200000 loops, best of 5: 1.43 usec per loop\n$ python -m timeit ""if hasattr(int, \'__bool__\'): pass""\n100000 loops, best of 5: 2.23 usec per loop\n>>> import timeit\n>>> # attribute is missing\n>>> s = """"""\\\n... try:\n...\nstr.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.9138244460009446\n>>> s = ""if hasattr(str, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.5829014980008651\n>>>\n>>> # attribute is present\n>>> s = """"""\\\n... try:\n...\nint.__bool__\n... except AttributeError:\n...\npass\n... """"""\n>>> timeit.timeit(stmt=s, number=100000)\n0.04215312199994514\n>>> s = ""if hasattr(int, \'__bool__\'): pass""\n>>> timeit.timeit(stmt=s, number=100000)\n0.08588060699912603\n28.6. timeit — Measure execution time of small code snippets\n1875\n\nThe Python Library Reference, Release 3.13.2\nTo give the timeit module access to functions you define, you can pass a setup parameter which contains an import\nstatement:\ndef test():\n""""""Stupid test function""""""\nL = [i for i in range(100)]\nif __name__ == \'__main__\':\nimport timeit\nprint(timeit.timeit(""test()"", setup=""from __main__ import test""))\nAnother option is to pass globals() to the globals parameter, which will cause the code to be executed within your\ncurrent global namespace. This can be more convenient than individually specifying imports:\ndef f(x):\nreturn x**2\ndef g(x):\nreturn x**4\ndef h(x):\nreturn x**8\nimport timeit\nprint(timeit.timeit(\'[func(42) for func in (f,g,h)]\', globals=globals()))\n28.7 trace — Trace or track Python statement execution\nSource code: Lib/trace.py\nThe trace module allows you to trace program execution, generate annotated statement coverage listings, print\ncaller/callee relationships and list functions executed during a program run. It can be used in another program or\nfrom the command line. µ See also\nCoverage.py\nA popular third-party coverage tool that provides HTML output along with advanced features such as\nbranch coverage. 28.7.1 Command-Line Usage\nThe trace module can be invoked from the command line. It can be as simple as\npython -m trace --count -C . somefile.py ... The above will execute somefile.py and generate annotated listings of all Python modules imported during the\nexecution into the current directory. --help\nDisplay usage and exit. --version\nDisplay the version of the module and exit. Added in version 3.8: Added --module option that allows to run an executable module. 1876\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nMain options\nAt least one of the following options must be specified when invoking trace. The --listfuncs option is mu-\ntually exclusive with the --trace and --count options. When --listfuncs is provided, neither --count nor\n--trace are accepted, and vice versa. -c, --count\nProduce a set of annotated listing files upon program completion that shows how many times each statement\nwas executed. See also --coverdir, --file and --no-report below. -t, --trace\nDisplay lines as they are executed. -l, --listfuncs\nDisplay the functions executed by running the program. -r, --report\nProduce an annotated list from an earlier program run that used the --count and --file option. This does\nnot execute any code. -T, --trackcalls\nDisplay the calling relationships exposed by running the program. Modifiers\n-f, --file=<file>\nName of a file to accumulate counts over several tracing runs. Should be used with the --count option.')",1.5205949127057158e-155,0.041475660336171144,0.14525810324129654,0.5176734328269958,0.26530752
Why is it string.join(list) instead of list.join(string)?,"It's because any iterable can be joined (e.g, list, tuple, dict, set), but its contents and the ""joiner"" 
must be
 strings.


For example:


'_'.join(['welcome', 'to', 'stack', 'overflow'])
'_'.join(('welcome', 'to', 'stack', 'overflow'))



'welcome_to_stack_overflow'



Using something other than strings will raise the following error:




TypeError: sequence item 0: expected str instance, int found



","('Answer: When concatenating many strings, it is recommended to place the strings into a list and call str.join() at the end because strings are immutable. Concatenating strings creates a new object with each concatenation which is inefficient.\n\nReferences: [1, 2]\n', '[1] 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5.\n\n[2] To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable.\n\n[3] One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython. • Behaviour can vary across operating systems, especially when talking about I/O or multi-threading. • You should always find the hot spots in your program before attempting to optimize any code (see the profile\nmodule). • Writing benchmark scripts will allow you to iterate quickly when searching for improvements (see the timeit\nmodule). • It is highly recommended to have good code coverage (through unit testing or any other technique) before\npotentially introducing regressions hidden in sophisticated optimizations. That being said, there are many tricks to speed up Python code. Here are some general principles which go a long\nway towards reaching acceptable performance levels:\n2.4. Performance\n21\n\nPython Frequently Asked Questions, Release 3.13.2\n• Making your algorithms faster (or changing to faster ones) can yield much larger benefits than trying to sprinkle\nmicro-optimization tricks all over your code. • Use the right data structures. Study documentation for the bltin-types and the collections module. • When the standard library provides a primitive for doing something, it is likely (although not guaranteed) to\nbe faster than any alternative you may come up with. This is doubly true for primitives written in C, such as\nbuiltins and some extension types. For example, be sure to use either the list.sort() built-in method or\nthe related sorted() function to do sorting (and see the sortinghowto for examples of moderately advanced\nusage). • Abstractions tend to create indirections and force the interpreter to work more. If the levels of indirection\noutweigh the amount of useful work done, your program will be slower. You should avoid excessive abstraction,\nespecially under the form of tiny functions or methods (which are also often detrimental to readability). If you have reached the limit of what pure Python can allow, there are tools to take you further away. For example,\nCython can compile a slightly modified version of Python code into a C extension, and can be used on many different\nplatforms. Cython can take advantage of compilation (and optional type annotations) to make your code significantly\nfaster than when interpreted. If you are confident in your C programming skills, you can also write a C extension\nmodule yourself. µ See also\nThe wiki page devoted to performance tips. 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list.')",6.555209443938368e-156,0.014044943820224717,0.06186601381499975,0.5353665351867676,0.44432956
How do I append to a file?,"Set the mode in 
open()
 to 
""a""
 (append) instead of 
""w""
 (write):


with open(""test.txt"", ""a"") as myfile:
    myfile.write(""appended text"")



The 
documentation
 lists all the available modes.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . 3\n1.3\nLogging to a file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.4\nLogging variable data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.5\nChanging the format of displayed messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.6\nDisplaying the date/time in messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.7\nNext Steps . . . . . . . . . . . .\n\n[2] . 55\n4.3.5\nCan’t we get rid of the Global Interpreter Lock? . . . . . . . . . . . . . . . . . . . . . . 55\n4.4\nInput and Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.4.1\nHow do I delete a file? (And other file questions…)\n. . . . . . . . . . . . . . . . . . . . 56\n4.4.2\nHow do I copy a file? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.4.3\nHow do I read (or write) binary data? . . . . . . . . . . . . . . . . . .\n\n[3] . 56\n7.1.4\nOld string formatting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2\nReading and Writing Files\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2.1\nMethods of File Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n7.2.2\nSaving structured data with json . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n8\nErrors and Exceptions\n61\n8.1\nSyntax Errors . . . . . . . . . . . . . . . . .')",5.882492291217442e-232,0.0641711229946524,0.09980988593155894,0.43579575419425964,0.2665641
Is there a way to run Python on Android?,"One way is to use 
Kivy
:




Open source Python library for rapid development of applications
  that make use of innovative user interfaces, such as multi-touch apps.








Kivy runs on Linux, Windows, OS X, Android and iOS. You can run the same [python] code on all supported platforms.




Kivy Showcase app
 

","('Answer: The only way to use Python on Android is in embedded mode by writing a native Android application, embedding a Python interpreter using libpython, and invoking Python code using the Python embedding API. Some tools that provide an easier experience are Briefcase, Buildozer, Chaquopy, pyqtdeploy, and Termux.\n\nReferences: [3]\n', '[1] Using Python on macOS\n\nCHAPTER\nSIX\nUSING PYTHON ON ANDROID\nPython on Android is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On Android, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on Android is in embedded mode – that is, by writing a native Android\napplication, embedding a Python interpreter using libpython, and invoking Python code using the Python embed-\nding API. The full Python interpreter, the standard library, and all your Python code is then packaged into your app\nfor its own private use. The Python standard library has some notable omissions and restrictions on Android. See the API availability guide\nfor details. 6.1 Adding Python to an Android app\nMost app developers should use one of the following tools, which will provide a much easier experience:\n• Briefcase, from the BeeWare project\n• Buildozer, from the Kivy project\n• Chaquopy\n• pyqtdeploy\n• Termux\nIf you’re sure you want to do all of this manually, read on. You can use the testbed app as a guide; each step below\ncontains a link to the relevant file. • Build Python by following the instructions in Android/README.md. This will create the directory\ncross-build/HOST/prefix. • Add code to your build.gradle file to copy the following items into your project. All except your own Python\ncode can be copied from prefix/lib:\n– In your JNI libraries:\n∗libpython*. *.so\n∗lib*_python.so (external libraries such as OpenSSL)\n– In your assets:\n∗python*. * (the Python standard library)\n∗python*. */site-packages (your own Python code)\n• Add code to your app to extract the assets to the filesystem. • Add code to your app to start Python in embedded mode. This will need to be C code called via JNI. 75\n\nPython Setup and Usage, Release 3.13.2\n76\nChapter 6. Using Python on Android\n\nCHAPTER\nSEVEN\nUSING PYTHON ON IOS\nAuthors\nRussell Keith-Magee (2024-03)\nPython on iOS is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On iOS, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on iOS is in embedded mode - that is, by writing a native iOS application,\nand embedding a Python interpreter using libPython, and invoking Python code using the Python embedding API. The full Python interpreter, the standard library, and all your Python code is then packaged as a standalone bundle\nthat can be distributed via the iOS App Store. If you’re looking to experiment for the first time with writing an iOS app in Python, projects such as BeeWare and\nKivy will provide a much more approachable user experience. These projects manage the complexities associated\nwith getting an iOS project running, so you only need to deal with the Python code itself. 7.1 Python at runtime on iOS\n7.1.1 iOS version compatibility\nThe minimum supported iOS version is specified at compile time, using the --host option to configure. By\ndefault, when compiled for iOS, Python will be compiled with a minimum supported iOS version of 13.0. To\nuse a different minimum iOS version, provide the version number as part of the --host argument - for exam-\nple, --host=arm64-apple-ios15.4-simulator would compile an ARM64 simulator build with a deployment\ntarget of 15.4. 7.1.2 Platform identification\nWhen executing on iOS, sys.platform will report as ios. This value will be returned on an iPhone or iPad,\nregardless of whether the app is running on the simulator or a physical device. Information about the specific runtime environment, including the iOS version, device model, and whether the device\nis a simulator, can be obtained using platform.ios_ver(). platform.system() will report iOS or iPadOS,\ndepending on the device. os.uname() reports kernel-level details; it will report a name of Darwin. 7.1.3 Standard library availability\nThe Python standard library has some notable omissions and restrictions on iOS. See the API availability guide for\niOS for details. 77\n\nPython Setup and Usage, Release 3.13.2\n7.1.4 Binary extension modules\nOne notable difference about iOS as a platform is that App Store distribution imposes hard requirements on the\npackaging of an application. One of these requirements governs how binary extension modules are distributed. The iOS App Store requires that all binary modules in an iOS app must be dynamic libraries, contained in a framework\nwith appropriate metadata, stored in the Frameworks folder of the packaged app. There can be only a single binary\nper framework, and there can be no executable binary material outside the Frameworks folder. This conflicts with the usual Python approach for distributing binaries, which allows a binary extension module to be\nloaded from any location on sys.path. To ensure compliance with App Store policies, an iOS project must post-\nprocess any Python packages, converting .so binary modules into individual standalone frameworks with appropriate\nmetadata and signing. For details on how to perform this post-processing, see the guide for adding Python to your\nproject. To help Python discover binaries in their new location, the original .so file on sys.path is replaced with a .fwork\nfile. This file is a text file containing the location of the framework binary, relative to the app bundle.\n\n[2] 5.5. Advanced Topics\n73\n\nPython Setup and Usage, Release 3.13.2\n5.6 Other Resources\nThe python.org Help page has links to many useful resources. The Pythonmac-SIG mailing list is another support\nresource specifically for Python users and developers on the Mac. 74\nChapter 5. Using Python on macOS\n\nCHAPTER\nSIX\nUSING PYTHON ON ANDROID\nPython on Android is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On Android, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on Android is in embedded mode – that is, by writing a native Android\napplication, embedding a Python interpreter using libpython, and invoking Python code using the Python embed-\nding API. The full Python interpreter, the standard library, and all your Python code is then packaged into your app\nfor its own private use. The Python standard library has some notable omissions and restrictions on Android. See the API availability guide\nfor details. 6.1 Adding Python to an Android app\nMost app developers should use one of the following tools, which will provide a much easier experience:\n• Briefcase, from the BeeWare project\n• Buildozer, from the Kivy project\n• Chaquopy\n• pyqtdeploy\n• Termux\nIf you’re sure you want to do all of this manually, read on. You can use the testbed app as a guide; each step below\ncontains a link to the relevant file. • Build Python by following the instructions in Android/README.md. This will create the directory\ncross-build/HOST/prefix. • Add code to your build.gradle file to copy the following items into your project. All except your own Python\ncode can be copied from prefix/lib:\n– In your JNI libraries:\n∗libpython*. *.so\n∗lib*_python.so (external libraries such as OpenSSL)\n– In your assets:\n∗python*. * (the Python standard library)\n∗python*. */site-packages (your own Python code)\n• Add code to your app to extract the assets to the filesystem. • Add code to your app to start Python in embedded mode. This will need to be C code called via JNI. 75\n\nPython Setup and Usage, Release 3.13.2\n76\nChapter 6. Using Python on Android\n\nCHAPTER\nSEVEN\nUSING PYTHON ON IOS\nAuthors\nRussell Keith-Magee (2024-03)\nPython on iOS is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On iOS, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on iOS is in embedded mode - that is, by writing a native iOS application,\nand embedding a Python interpreter using libPython, and invoking Python code using the Python embedding API. The full Python interpreter, the standard library, and all your Python code is then packaged as a standalone bundle\nthat can be distributed via the iOS App Store. If you’re looking to experiment for the first time with writing an iOS app in Python, projects such as BeeWare and\nKivy will provide a much more approachable user experience. These projects manage the complexities associated\nwith getting an iOS project running, so you only need to deal with the Python code itself. 7.1 Python at runtime on iOS\n7.1.1 iOS version compatibility\nThe minimum supported iOS version is specified at compile time, using the --host option to configure. By\ndefault, when compiled for iOS, Python will be compiled with a minimum supported iOS version of 13.0. To\nuse a different minimum iOS version, provide the version number as part of the --host argument - for exam-\nple, --host=arm64-apple-ios15.4-simulator would compile an ARM64 simulator build with a deployment\ntarget of 15.4. 7.1.2 Platform identification\nWhen executing on iOS, sys.platform will report as ios. This value will be returned on an iPhone or iPad,\nregardless of whether the app is running on the simulator or a physical device. Information about the specific runtime environment, including the iOS version, device model, and whether the device\nis a simulator, can be obtained using platform.ios_ver(). platform.system() will report iOS or iPadOS,\ndepending on the device. os.uname() reports kernel-level details; it will report a name of Darwin. 7.1.3 Standard library availability\nThe Python standard library has some notable omissions and restrictions on iOS. See the API availability guide for\niOS for details. 77\n\nPython Setup and Usage, Release 3.13.2\n7.1.4 Binary extension modules\nOne notable difference about iOS as a platform is that App Store distribution imposes hard requirements on the\npackaging of an application. One of these requirements governs how binary extension modules are distributed. The iOS App Store requires that all binary modules in an iOS app must be dynamic libraries, contained in a framework\nwith appropriate metadata, stored in the Frameworks folder of the packaged app. There can be only a single binary\nper framework, and there can be no executable binary material outside the Frameworks folder. This conflicts with the usual Python approach for distributing binaries, which allows a binary extension module to be\nloaded from any location on sys.path.\n\n[3] 74\nChapter 5. Using Python on macOS\n\nCHAPTER\nSIX\nUSING PYTHON ON ANDROID\nPython on Android is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On Android, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on Android is in embedded mode – that is, by writing a native Android\napplication, embedding a Python interpreter using libpython, and invoking Python code using the Python embed-\nding API. The full Python interpreter, the standard library, and all your Python code is then packaged into your app\nfor its own private use. The Python standard library has some notable omissions and restrictions on Android. See the API availability guide\nfor details. 6.1 Adding Python to an Android app\nMost app developers should use one of the following tools, which will provide a much easier experience:\n• Briefcase, from the BeeWare project\n• Buildozer, from the Kivy project\n• Chaquopy\n• pyqtdeploy\n• Termux\nIf you’re sure you want to do all of this manually, read on. You can use the testbed app as a guide; each step below\ncontains a link to the relevant file. • Build Python by following the instructions in Android/README.md. This will create the directory\ncross-build/HOST/prefix. • Add code to your build.gradle file to copy the following items into your project. All except your own Python\ncode can be copied from prefix/lib:\n– In your JNI libraries:\n∗libpython*. *.so\n∗lib*_python.so (external libraries such as OpenSSL)\n– In your assets:\n∗python*. * (the Python standard library)\n∗python*. */site-packages (your own Python code)\n• Add code to your app to extract the assets to the filesystem. • Add code to your app to start Python in embedded mode. This will need to be C code called via JNI. 75\n\nPython Setup and Usage, Release 3.13.2\n76\nChapter 6. Using Python on Android\n\nCHAPTER\nSEVEN\nUSING PYTHON ON IOS\nAuthors\nRussell Keith-Magee (2024-03)\nPython on iOS is unlike Python on desktop platforms. On a desktop platform, Python is generally installed as a\nsystem resource that can be used by any user of that computer. Users then interact with Python by running a python\nexecutable and entering commands at an interactive prompt, or by running a Python script. On iOS, there is no concept of installing as a system resource. The only unit of software distribution is an “app”. There is also no console where you could run a python executable, or interact with a Python REPL. As a result, the only way you can use Python on iOS is in embedded mode - that is, by writing a native iOS application,\nand embedding a Python interpreter using libPython, and invoking Python code using the Python embedding API. The full Python interpreter, the standard library, and all your Python code is then packaged as a standalone bundle\nthat can be distributed via the iOS App Store. If you’re looking to experiment for the first time with writing an iOS app in Python, projects such as BeeWare and\nKivy will provide a much more approachable user experience. These projects manage the complexities associated\nwith getting an iOS project running, so you only need to deal with the Python code itself. 7.1 Python at runtime on iOS\n7.1.1 iOS version compatibility\nThe minimum supported iOS version is specified at compile time, using the --host option to configure. By\ndefault, when compiled for iOS, Python will be compiled with a minimum supported iOS version of 13.0. To\nuse a different minimum iOS version, provide the version number as part of the --host argument - for exam-\nple, --host=arm64-apple-ios15.4-simulator would compile an ARM64 simulator build with a deployment\ntarget of 15.4. 7.1.2 Platform identification\nWhen executing on iOS, sys.platform will report as ios. This value will be returned on an iPhone or iPad,\nregardless of whether the app is running on the simulator or a physical device. Information about the specific runtime environment, including the iOS version, device model, and whether the device\nis a simulator, can be obtained using platform.ios_ver(). platform.system() will report iOS or iPadOS,\ndepending on the device. os.uname() reports kernel-level details; it will report a name of Darwin. 7.1.3 Standard library availability\nThe Python standard library has some notable omissions and restrictions on iOS. See the API availability guide for\niOS for details. 77\n\nPython Setup and Usage, Release 3.13.2\n7.1.4 Binary extension modules\nOne notable difference about iOS as a platform is that App Store distribution imposes hard requirements on the\npackaging of an application. One of these requirements governs how binary extension modules are distributed. The iOS App Store requires that all binary modules in an iOS app must be dynamic libraries, contained in a framework\nwith appropriate metadata, stored in the Frameworks folder of the packaged app. There can be only a single binary\nper framework, and there can be no executable binary material outside the Frameworks folder. This conflicts with the usual Python approach for distributing binaries, which allows a binary extension module to be\nloaded from any location on sys.path. To ensure compliance with App Store policies, an iOS project must post-\nprocess any Python packages, converting .so binary modules into individual standalone frameworks with appropriate\nmetadata and signing. For details on how to perform this post-processing, see the guide for adding Python to your\nproject. To help Python discover binaries in their new location, the original .so file on sys.path is replaced with a .fwork\nfile.')",8.856389090645404e-156,0.02076777847702958,0.06339144215530905,0.5185525417327881,0.5074768
Static methods in Python?,"Yep, using the 
staticmethod
 decorator:


class MyClass(object):
    @staticmethod
    def the_static_method(x):
        print(x)

MyClass.the_static_method(2)  # outputs 2



Note that some code might use the old method of defining a static method, using 
staticmethod
 as a function rather than a decorator. This should only be used if you have to support ancient versions of Python (2.2 and 2.3):


class MyClass(object):
    def the_static_method(x):
        print(x)
    the_static_method = staticmethod(the_static_method)

MyClass.the_static_method(2)  # outputs 2



This is entirely identical to the first example (using 
@staticmethod
), just not using the nice decorator syntax.


Finally, use 
staticmethod
 sparingly! There are very few situations where static-methods are necessary in Python, and I've seen them used many times where a separate ""top-level"" function would have been clearer.




The following is verbatim from the documentation:
:




A static method does not receive an implicit first argument. To declare a static method, use this idiom:


class C:
    @staticmethod
    def f(arg1, arg2, ...): ...



The @staticmethod form is a function 
decorator
 – see the description of function definitions in 
Function definitions
 for details.


It can be called either on the class (such as 
C.f()
) or on an instance (such as 
C().f()
). The instance is ignored except for its class.


Static methods in Python are similar to those found in Java or C++. For a more advanced concept, see 
classmethod()
.


For more information on static methods, consult the documentation on the standard type hierarchy in 
The standard type hierarchy
.


New in version 2.2.


Changed in version 2.4: Function decorator syntax added.



","('Answer: Information on how to create static class data and static class methods is available.\n\nReferences: [1, 2, 3]\n', '[1] . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . . . . . . . . 29\n2.6.9\nHow can I overload constructors (or methods) in Python? . . . . . . . . . . . . . . . . . 30\n2.6.10\nI try to use __spam and I get an error about _SomeClassName__spam. . . . . . . . . . . 30\n2.6.11\nMy class defines __del__ but it is not called when I delete the object. . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . . . . . . . . 29\n2.6.9\nHow can I overload constructors (or methods) in Python? . . . . . . . . . . . . . . . . .\n\n[3] 27\n2.6.4\nHow do I check if an object is an instance of a given class or of a subclass of it? . . . . . . 27\n2.6.5\nWhat is delegation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . .')",2.008623672242912e-155,0.1340782122905028,0.14688772542175682,0.5591879487037659,0.50646496
Installing specific package version with pip,"TL;DR
:


Update as of 2022-12-28
:


pip install --force-reinstall -v


For example: 
pip install --force-reinstall -v ""MySQL_python==1.2.2""


What these options mean:




--force-reinstall
 is an option to reinstall all packages even if they are already up-to-date.


-v
 is for verbose. You can combine for even more verbosity (i.e. 
-vv
) up to 3 times (e.g. 
--force-reinstall -vvv
).




Thanks to 
@Peter
 for highlighting this (and it seems that the context of the question has broadened given the time when the question was first asked!), 
the documentation for Python
 discusses a caveat with using 
-I
, in that it can break your installation if it was installed with a different package manager or if if your package is/was a different version.




Original answer:




pip install -Iv
 (i.e. 
pip install -Iv MySQL_python==1.2.2
)






What these options mean:




-I
 stands for 
--ignore-installed
 which will ignore the installed packages, overwriting them.


-v
 is for verbose. You can combine for even more verbosity (i.e. 
-vv
) up to 3 times (e.g. 
-Ivvv
).




For more information, see 
pip install --help


First, I see two issues with what you're trying to do. Since you already have an installed version, you should either uninstall the current existing driver or use 
pip install -I MySQL_python==1.2.2


However, you'll soon find out that this doesn't work. If you look at pip's installation log, or if you do a 
pip install -Iv MySQL_python==1.2.2
 you'll find that the PyPI URL link does not work for MySQL_python v1.2.2. You can verify this here: 
http://pypi.python.org/pypi/MySQL-python/1.2.2


The download link 404s and the fallback URL links are re-directing infinitely due to sourceforge.net's recent upgrade and PyPI's stale URL.


So to properly install the driver, you can follow these steps:


pip uninstall MySQL_python
pip install -Iv http://sourceforge.net/projects/mysql-python/files/mysql-python/1.2.2/MySQL-python-1.2.2.tar.gz/download


","('Answer: To install a specific package version using pip, you can specify the exact version on the command line. When using comparator operators such as >, <, or other special characters interpreted by the shell, enclose the package name and version within double quotes. For example, to install version 1.0.4 of ""SomePackage"", use: `python -m pip install SomePackage==1.0.4`. To install a minimum version, for example 1.0.4 or higher of ""SomePackage"", use: `python -m pip install ""SomePackage>=1.0.4""`.\n\nReferences: [2, 3]\n', '[1] . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip. µ See also\nPython Packaging User Guide: Installing Scientific Packages\n3.4 … work with multiple versions of Python installed in parallel? On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch\nto run the appropriate copy of pip:\npython2\n-m pip install SomePackage\n# default Python 2\npython2.7 -m pip install SomePackage\n# specifically Python 2.7\npython3\n-m pip install SomePackage\n# default Python 3\npython3.4 -m pip install SomePackage\n# specifically Python 3.4\nAppropriately versioned pip commands may also be available. On Windows, use the py Python launcher in combination with the -m switch:\n7\n\nInstalling Python Modules, Release 3.13.2\npy -2\n-m pip install SomePackage\n# default Python 2\npy -2.7 -m pip install SomePackage\n# specifically Python 2.7\npy -3\n-m pip install SomePackage\n# default Python 3\npy -3.4 -m pip install SomePackage\n# specifically Python 3.4\n8\nChapter 3.\n\n[2] . . . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip.\n\n[3] . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip. µ See also\nPython Packaging User Guide: Installing Scientific Packages\n3.4 … work with multiple versions of Python installed in parallel? On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch\nto run the appropriate copy of pip:\npython2\n-m pip install SomePackage\n# default Python 2\npython2.7 -m pip install SomePackage\n# specifically Python 2.7\npython3\n-m pip install SomePackage\n# default Python 3\npython3.4 -m pip install SomePackage\n# specifically Python 3.4\nAppropriately versioned pip commands may also be available.')",1.9477884242305303e-155,0.0684931506849315,0.18960782490814046,0.5510927438735962,0.5606429
How do I split the definition of a long string over multiple lines?,"Are you talking about multi-line strings? Easy, use triple quotes to start and end them.


s = """""" this is a very
        long string if I had the
        energy to type more and more ...""""""



You can use single quotes too (3 of them of course at start and end) and treat the resulting string 
s
 just like any other string.


NOTE
: Just as with any string, anything between the starting and ending quotes becomes part of the string, so this example has a leading blank (as pointed out by @root45). This string will also contain both blanks and newlines.


I.e.,:


' this is a very\n        long string if I had the\n        energy to type more and more ...'



Finally, one can also construct long lines in Python like this:


 s = (""this is a very""
      ""long string too""
      ""for sure ...""
     )



which will 
not
 include any extra blanks or newlines (this is a deliberate example showing what the effect of skipping blanks will result in):


'this is a verylong string toofor sure ...'



No commas required, simply place the strings to be joined together into a pair of parenthesis and be sure to account for any needed blanks and newlines.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . 9\n4.2\nGrouping\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n4.3\nNon-capturing and Named Groups . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n4.4\nLookahead Assertions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\n5\nModifying Strings\n14\n5.1\nSplitting Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . 9\n2.4.2\nString literal concatenation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.4.3\nf-strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.4.4\nNumeric literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.4.5\nInteger literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n2.4.6\nFloating-point literals . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119\n6.1.2\nCustom String Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n6.1.3\nFormat String Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121\n6.1.4\nTemplate strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n6.1.5\nHelper functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",5.544133584587743e-232,0.0855263157894737,0.04538852578068265,0.5199598073959351,0.32500392
How to prettyprint a JSON file?,"Use the 
indent=
 parameter of 
json.dump()
 or 
json.dumps()
 to specify how many spaces to indent by:


>>> import json
>>> your_json = '[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]'
>>> parsed = json.loads(your_json)
>>> print(json.dumps(parsed, indent=4))
[
    ""foo"",
    {
        ""bar"": [
            ""baz"",
            null,
            1.0,
            2
        ]
    }
]



To parse a file, use 
json.load()
:


with open('filename.txt', 'r') as handle:
    parsed = json.load(handle)


","('Answer:\nTo pretty print a JSON object, you can use `json.dumps()` with the `sort_keys=True` and `indent=4` parameters. Alternatively, you can use `json.tool` from the shell to validate and pretty-print JSON.\n\nReferences: [1, 3]\n', '[1] Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n\'""foo\\x08ar\'\n>>> from io import StringIO\n>>> io = StringIO(\'[""streaming API""]\')\n>>> json.load(io)\n[\'streaming API\']\nSpecializing JSON object decoding:\n>>> import json\n>>> def as_complex(dct):\n...\nif \'__complex__\' in dct:\n...\nreturn complex(dct[\'real\'], dct[\'imag\'])\n...\nreturn dct\n...\n>>> json.loads(\'{""__complex__"": true, ""real"": 1, ""imag"": 2}\',\n...\nobject_hook=as_complex)\n(1+2j)\n>>> import decimal\n>>> json.loads(\'1.1\', parse_float=decimal.Decimal)\nDecimal(\'1.1\')\nExtending JSONEncoder:\n>>> import json\n>>> class ComplexEncoder(json.JSONEncoder):\n...\ndef default(self, obj):\n...\nif isinstance(obj, complex):\n...\nreturn [obj.real, obj.imag]\n...\n# Let the base class default method raise the TypeError\n...\nreturn super().default(obj)\n...\n>>> json.dumps(2 + 1j, cls=ComplexEncoder)\n\'[2.0, 1.0]\'\n>>> ComplexEncoder().encode(2 + 1j)\n\'[2.0, 1.0]\'\n>>> list(ComplexEncoder().iterencode(2 + 1j))\n[\'[2.0\', \', 1.0\', \']\']\nUsing json.tool from the shell to validate and pretty-print:\n$ echo \'{""json"":""obj""}\' | python -m json.tool\n{\n""json"": ""obj""\n}\n$ echo \'{1.2:3.4}\' | python -m json.tool\nExpecting property name enclosed in double quotes: line 1 column 2 (char 1)\nSee Command Line Interface for detailed documentation. ® Note\nJSON is a subset of YAML 1.2. The JSON produced by this module’s default settings (in particular, the default\nseparators value) is also a subset of YAML 1.0 and 1.1. This module can thus also be used as a YAML serializer. 20.2. json — JSON encoder and decoder\n1291\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThis module’s encoders and decoders preserve input and output order by default. Order is only lost if the under-\nlying containers are unordered. 20.2.1 Basic Usage\njson.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj as a JSON formatted stream to fp (a .write()-supporting file-like object) using this Python-to-\nJSON conversion table. ® Note\nUnlike pickle and marshal, JSON is not a framed protocol, so trying to serialize multiple objects with\nrepeated calls to dump() using the same fp will result in an invalid JSON file. Parameters\n• obj (object) – The Python object to be serialized. • fp (file-like object) – The file-like object obj will be serialized to. The json module always\nproduces str objects, not bytes objects, therefore fp.write() must support str input. • skipkeys (bool) – If True, keys that are not of a basic type (str, int, float, bool,\nNone) will be skipped instead of raising a TypeError. Default False. • ensure_ascii (bool) – If True (the default), the output is guaranteed to have all in-\ncoming non-ASCII characters escaped. If False, these characters will be outputted as-is. • check_circular (bool) – If False, the circular reference check for container types\nis skipped and a circular reference will result in a RecursionError (or worse). Default\nTrue. • allow_nan (bool) – If False, serialization of out-of-range float values (nan, inf,\n-inf) will result in a ValueError, in strict compliance with the JSON specification. If\nTrue (the default), their JavaScript equivalents (NaN, Infinity, -Infinity) are used. • cls (a JSONEncoder subclass) – If set, a custom JSON encoder with the default()\nmethod overridden, for serializing into custom datatypes. If None (the default),\nJSONEncoder is used. • indent (int | str | None) – If a positive integer or string, JSON array elements and\nobject members will be pretty-printed with that indent level. A positive integer indents\nthat many spaces per level; a string (such as ""\\t"") is used to indent each level. If zero,\nnegative, or """" (the empty string), only newlines are inserted. If None (the default), the\nmost compact representation is used. • separators\n(tuple | None)\n–\nA\ntwo-tuple:\n(item_separator,\nkey_separator). If None (the default), separators defaults to (\', \', \': \')\nif indent is None, and (\',\', \': \') otherwise. For the most compact JSON, specify\n(\',\', \':\') to eliminate whitespace. • default (callable | None) – A function that is called for objects that can’t otherwise be\nserialized. It should return a JSON encodable version of the object or raise a TypeError. If None (the default), TypeError is raised. • sort_keys (bool) – If True, dictionaries will be outputted sorted by key. Default\nFalse. Changed in version 3.2: Allow strings for indent in addition to integers. 1292\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.4: Use (\',\', \': \') as default if indent is not None. Changed in version 3.6: All optional parameters are now keyword-only. json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj to a JSON formatted str using this conversion table. The arguments have the same meaning as\nin dump(). ® Note\nKeys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all\nthe keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON\nand then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x))\n!= x if x has non-string keys. json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nDeserialize fp to a Python object using the JSON-to-Python conversion table. Parameters\n• fp (file-like object) – A .read()-supporting text file or binary file containing the JSON\ndocument to be deserialized. • cls (a JSONDecoder subclass) – If set, a custom JSON decoder. Additional keyword\narguments to load() will be passed to the constructor of cls. If None (the default),\nJSONDecoder is used. • object_hook (callable | None) – If set, a function that is called with the result of any\nobject literal decoded (a dict). The return value of this function will be used instead of\nthe dict. This feature can be used to implement custom decoders, for example JSON-\nRPC class hinting.\n\n[2] A malicious JSON string may cause the decoder\nto consume considerable CPU and memory resources. Limiting the size of data to be parsed is recommended. json exposes an API familiar to users of the standard library marshal and pickle modules. Encoding basic Python object hierarchies:\n>>> import json\n>>> json.dumps([\'foo\', {\'bar\': (\'baz\', None, 1.0, 2)}])\n\'[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]\'\n>>> print(json.dumps(""\\""foo\\bar""))\n""\\""foo\\bar""\n>>> print(json.dumps(\'\\u1234\'))\n""\\u1234""\n>>> print(json.dumps(\'\\\\\'))\n""\\\\""\n>>> print(json.dumps({""c"": 0, ""b"": 0, ""a"": 0}, sort_keys=True))\n{""a"": 0, ""b"": 0, ""c"": 0}\n>>> from io import StringIO\n>>> io = StringIO()\n>>> json.dump([\'streaming API\'], io)\n>>> io.getvalue()\n\'[""streaming API""]\'\nCompact encoding:\n>>> import json\n>>> json.dumps([1, 2, 3, {\'4\': 5, \'6\': 7}], separators=(\',\', \':\'))\n\'[1,2,3,{""4"":5,""6"":7}]\'\nPretty printing:\n>>> import json\n>>> print(json.dumps({\'6\': 7, \'4\': 5}, sort_keys=True, indent=4))\n{\n""4"": 5,\n""6"": 7\n}\nSpecializing JSON object encoding:\n>>> import json\n>>> def custom_json(obj):\n...\nif isinstance(obj, complex):\n...\nreturn {\'__complex__\': True, \'real\': obj.real, \'imag\': obj.imag}\n...\nraise TypeError(f\'Cannot serialize object of {type(obj)}\')\n...\n>>> json.dumps(1 + 2j, default=custom_json)\n\'{""__complex__"": true, ""real"": 1.0, ""imag"": 2.0}\'\nDecoding JSON:\n>>> import json\n>>> json.loads(\'[""foo"", {""bar"":[""baz"", null, 1.0, 2]}]\')\n[\'foo\', {\'bar\': [\'baz\', None, 1.0, 2]}]\n>>> json.loads(\'""\\\\""foo\\\\bar""\')\n(continues on next page)\n1290\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n\'""foo\\x08ar\'\n>>> from io import StringIO\n>>> io = StringIO(\'[""streaming API""]\')\n>>> json.load(io)\n[\'streaming API\']\nSpecializing JSON object decoding:\n>>> import json\n>>> def as_complex(dct):\n...\nif \'__complex__\' in dct:\n...\nreturn complex(dct[\'real\'], dct[\'imag\'])\n...\nreturn dct\n...\n>>> json.loads(\'{""__complex__"": true, ""real"": 1, ""imag"": 2}\',\n...\nobject_hook=as_complex)\n(1+2j)\n>>> import decimal\n>>> json.loads(\'1.1\', parse_float=decimal.Decimal)\nDecimal(\'1.1\')\nExtending JSONEncoder:\n>>> import json\n>>> class ComplexEncoder(json.JSONEncoder):\n...\ndef default(self, obj):\n...\nif isinstance(obj, complex):\n...\nreturn [obj.real, obj.imag]\n...\n# Let the base class default method raise the TypeError\n...\nreturn super().default(obj)\n...\n>>> json.dumps(2 + 1j, cls=ComplexEncoder)\n\'[2.0, 1.0]\'\n>>> ComplexEncoder().encode(2 + 1j)\n\'[2.0, 1.0]\'\n>>> list(ComplexEncoder().iterencode(2 + 1j))\n[\'[2.0\', \', 1.0\', \']\']\nUsing json.tool from the shell to validate and pretty-print:\n$ echo \'{""json"":""obj""}\' | python -m json.tool\n{\n""json"": ""obj""\n}\n$ echo \'{1.2:3.4}\' | python -m json.tool\nExpecting property name enclosed in double quotes: line 1 column 2 (char 1)\nSee Command Line Interface for detailed documentation. ® Note\nJSON is a subset of YAML 1.2. The JSON produced by this module’s default settings (in particular, the default\nseparators value) is also a subset of YAML 1.0 and 1.1. This module can thus also be used as a YAML serializer. 20.2. json — JSON encoder and decoder\n1291\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThis module’s encoders and decoders preserve input and output order by default. Order is only lost if the under-\nlying containers are unordered. 20.2.1 Basic Usage\njson.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj as a JSON formatted stream to fp (a .write()-supporting file-like object) using this Python-to-\nJSON conversion table. ® Note\nUnlike pickle and marshal, JSON is not a framed protocol, so trying to serialize multiple objects with\nrepeated calls to dump() using the same fp will result in an invalid JSON file. Parameters\n• obj (object) – The Python object to be serialized. • fp (file-like object) – The file-like object obj will be serialized to. The json module always\nproduces str objects, not bytes objects, therefore fp.write() must support str input. • skipkeys (bool) – If True, keys that are not of a basic type (str, int, float, bool,\nNone) will be skipped instead of raising a TypeError. Default False. • ensure_ascii (bool) – If True (the default), the output is guaranteed to have all in-\ncoming non-ASCII characters escaped. If False, these characters will be outputted as-is. • check_circular (bool) – If False, the circular reference check for container types\nis skipped and a circular reference will result in a RecursionError (or worse). Default\nTrue. • allow_nan (bool) – If False, serialization of out-of-range float values (nan, inf,\n-inf) will result in a ValueError, in strict compliance with the JSON specification. If\nTrue (the default), their JavaScript equivalents (NaN, Infinity, -Infinity) are used. • cls (a JSONEncoder subclass) – If set, a custom JSON encoder with the default()\nmethod overridden, for serializing into custom datatypes. If None (the default),\nJSONEncoder is used. • indent (int | str | None) – If a positive integer or string, JSON array elements and\nobject members will be pretty-printed with that indent level. A positive integer indents\nthat many spaces per level; a string (such as ""\\t"") is used to indent each level. If zero,\nnegative, or """" (the empty string), only newlines are inserted. If None (the default), the\nmost compact representation is used. • separators\n(tuple | None)\n–\nA\ntwo-tuple:\n(item_separator,\nkey_separator). If None (the default), separators defaults to (\', \', \': \')\nif indent is None, and (\',\', \': \') otherwise. For the most compact JSON, specify\n(\',\', \':\') to eliminate whitespace. • default (callable | None) – A function that is called for objects that can’t otherwise be\nserialized. It should return a JSON encodable version of the object or raise a TypeError. If None (the default), TypeError is raised. • sort_keys (bool) – If True, dictionaries will be outputted sorted by key. Default\nFalse. Changed in version 3.2: Allow strings for indent in addition to integers. 1292\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.4: Use (\',\', \': \') as default if indent is not None. Changed in version 3.6: All optional parameters are now keyword-only. json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj to a JSON formatted str using this conversion table. The arguments have the same meaning as\nin dump(). ® Note\nKeys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all\nthe keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON\nand then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x))\n!= x if x has non-string keys. json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nDeserialize fp to a Python object using the JSON-to-Python conversion table. Parameters\n• fp (file-like object) – A .read()-supporting text file or binary file containing the JSON\ndocument to be deserialized. • cls (a JSONDecoder subclass) – If set, a custom JSON decoder. Additional keyword\narguments to load() will be passed to the constructor of cls.\n\n[3] Limiting the size of data to be parsed is recommended. json exposes an API familiar to users of the standard library marshal and pickle modules. Encoding basic Python object hierarchies:\n>>> import json\n>>> json.dumps([\'foo\', {\'bar\': (\'baz\', None, 1.0, 2)}])\n\'[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]\'\n>>> print(json.dumps(""\\""foo\\bar""))\n""\\""foo\\bar""\n>>> print(json.dumps(\'\\u1234\'))\n""\\u1234""\n>>> print(json.dumps(\'\\\\\'))\n""\\\\""\n>>> print(json.dumps({""c"": 0, ""b"": 0, ""a"": 0}, sort_keys=True))\n{""a"": 0, ""b"": 0, ""c"": 0}\n>>> from io import StringIO\n>>> io = StringIO()\n>>> json.dump([\'streaming API\'], io)\n>>> io.getvalue()\n\'[""streaming API""]\'\nCompact encoding:\n>>> import json\n>>> json.dumps([1, 2, 3, {\'4\': 5, \'6\': 7}], separators=(\',\', \':\'))\n\'[1,2,3,{""4"":5,""6"":7}]\'\nPretty printing:\n>>> import json\n>>> print(json.dumps({\'6\': 7, \'4\': 5}, sort_keys=True, indent=4))\n{\n""4"": 5,\n""6"": 7\n}\nSpecializing JSON object encoding:\n>>> import json\n>>> def custom_json(obj):\n...\nif isinstance(obj, complex):\n...\nreturn {\'__complex__\': True, \'real\': obj.real, \'imag\': obj.imag}\n...\nraise TypeError(f\'Cannot serialize object of {type(obj)}\')\n...\n>>> json.dumps(1 + 2j, default=custom_json)\n\'{""__complex__"": true, ""real"": 1.0, ""imag"": 2.0}\'\nDecoding JSON:\n>>> import json\n>>> json.loads(\'[""foo"", {""bar"":[""baz"", null, 1.0, 2]}]\')\n[\'foo\', {\'bar\': [\'baz\', None, 1.0, 2]}]\n>>> json.loads(\'""\\\\""foo\\\\bar""\')\n(continues on next page)\n1290\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n\'""foo\\x08ar\'\n>>> from io import StringIO\n>>> io = StringIO(\'[""streaming API""]\')\n>>> json.load(io)\n[\'streaming API\']\nSpecializing JSON object decoding:\n>>> import json\n>>> def as_complex(dct):\n...\nif \'__complex__\' in dct:\n...\nreturn complex(dct[\'real\'], dct[\'imag\'])\n...\nreturn dct\n...\n>>> json.loads(\'{""__complex__"": true, ""real"": 1, ""imag"": 2}\',\n...\nobject_hook=as_complex)\n(1+2j)\n>>> import decimal\n>>> json.loads(\'1.1\', parse_float=decimal.Decimal)\nDecimal(\'1.1\')\nExtending JSONEncoder:\n>>> import json\n>>> class ComplexEncoder(json.JSONEncoder):\n...\ndef default(self, obj):\n...\nif isinstance(obj, complex):\n...\nreturn [obj.real, obj.imag]\n...\n# Let the base class default method raise the TypeError\n...\nreturn super().default(obj)\n...\n>>> json.dumps(2 + 1j, cls=ComplexEncoder)\n\'[2.0, 1.0]\'\n>>> ComplexEncoder().encode(2 + 1j)\n\'[2.0, 1.0]\'\n>>> list(ComplexEncoder().iterencode(2 + 1j))\n[\'[2.0\', \', 1.0\', \']\']\nUsing json.tool from the shell to validate and pretty-print:\n$ echo \'{""json"":""obj""}\' | python -m json.tool\n{\n""json"": ""obj""\n}\n$ echo \'{1.2:3.4}\' | python -m json.tool\nExpecting property name enclosed in double quotes: line 1 column 2 (char 1)\nSee Command Line Interface for detailed documentation. ® Note\nJSON is a subset of YAML 1.2. The JSON produced by this module’s default settings (in particular, the default\nseparators value) is also a subset of YAML 1.0 and 1.1. This module can thus also be used as a YAML serializer. 20.2. json — JSON encoder and decoder\n1291\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThis module’s encoders and decoders preserve input and output order by default. Order is only lost if the under-\nlying containers are unordered. 20.2.1 Basic Usage\njson.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj as a JSON formatted stream to fp (a .write()-supporting file-like object) using this Python-to-\nJSON conversion table. ® Note\nUnlike pickle and marshal, JSON is not a framed protocol, so trying to serialize multiple objects with\nrepeated calls to dump() using the same fp will result in an invalid JSON file. Parameters\n• obj (object) – The Python object to be serialized. • fp (file-like object) – The file-like object obj will be serialized to. The json module always\nproduces str objects, not bytes objects, therefore fp.write() must support str input. • skipkeys (bool) – If True, keys that are not of a basic type (str, int, float, bool,\nNone) will be skipped instead of raising a TypeError. Default False. • ensure_ascii (bool) – If True (the default), the output is guaranteed to have all in-\ncoming non-ASCII characters escaped. If False, these characters will be outputted as-is. • check_circular (bool) – If False, the circular reference check for container types\nis skipped and a circular reference will result in a RecursionError (or worse). Default\nTrue. • allow_nan (bool) – If False, serialization of out-of-range float values (nan, inf,\n-inf) will result in a ValueError, in strict compliance with the JSON specification. If\nTrue (the default), their JavaScript equivalents (NaN, Infinity, -Infinity) are used. • cls (a JSONEncoder subclass) – If set, a custom JSON encoder with the default()\nmethod overridden, for serializing into custom datatypes. If None (the default),\nJSONEncoder is used. • indent (int | str | None) – If a positive integer or string, JSON array elements and\nobject members will be pretty-printed with that indent level. A positive integer indents\nthat many spaces per level; a string (such as ""\\t"") is used to indent each level. If zero,\nnegative, or """" (the empty string), only newlines are inserted. If None (the default), the\nmost compact representation is used. • separators\n(tuple | None)\n–\nA\ntwo-tuple:\n(item_separator,\nkey_separator). If None (the default), separators defaults to (\', \', \': \')\nif indent is None, and (\',\', \': \') otherwise. For the most compact JSON, specify\n(\',\', \':\') to eliminate whitespace. • default (callable | None) – A function that is called for objects that can’t otherwise be\nserialized. It should return a JSON encodable version of the object or raise a TypeError. If None (the default), TypeError is raised. • sort_keys (bool) – If True, dictionaries will be outputted sorted by key. Default\nFalse. Changed in version 3.2: Allow strings for indent in addition to integers. 1292\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.4: Use (\',\', \': \') as default if indent is not None. Changed in version 3.6: All optional parameters are now keyword-only. json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj to a JSON formatted str using this conversion table. The arguments have the same meaning as\nin dump(). ® Note\nKeys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all\nthe keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON\nand then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x))\n!= x if x has non-string keys. json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nDeserialize fp to a Python object using the JSON-to-Python conversion table. Parameters\n• fp (file-like object) – A .read()-supporting text file or binary file containing the JSON\ndocument to be deserialized. • cls (a JSONDecoder subclass) – If set, a custom JSON decoder. Additional keyword\narguments to load() will be passed to the constructor of cls. If None (the default),\nJSONDecoder is used.')",0.0015453072441818075,0.028291621327529923,0.1096681070299295,0.6341111660003662,0.62327844
Getting the class name of an instance,"Have you tried the 
__name__
 attribute
 of the class? ie 
type(x).__name__
 will give you the name of the class, which I think is what you want.


>>> import itertools
>>> x = itertools.count(0)
>>> type(x).__name__
'count'



If you're still using Python 2, note that the above method works with 
new-style classes
 only (in Python 3+ all classes are ""new-style"" classes). Your code might use some old-style classes. The following works for both:


x.__class__.__name__


","('Answer: Each value in Python is an object, and its class (or type) is stored in the `__class__` attribute (e.g. `object.__class__`).\n\nReferences: [1]\n', '[1] A First Look at Classes\n77\n\nPython Tutorial, Release 3.13.2\n9.3.5 Class and Instance Variables\nGenerally speaking, instance variables are for data unique to each instance and class variables are for attributes and\nmethods shared by all instances of the class:\nclass Dog:\nkind = \'canine\'\n# class variable shared by all instances\ndef __init__(self, name):\nself.name = name\n# instance variable unique to each instance\n>>> d = Dog(\'Fido\')\n>>> e = Dog(\'Buddy\')\n>>> d.kind\n# shared by all dogs\n\'canine\'\n>>> e.kind\n# shared by all dogs\n\'canine\'\n>>> d.name\n# unique to d\n\'Fido\'\n>>> e.name\n# unique to e\n\'Buddy\'\nAs discussed in A Word About Names and Objects, shared data can have possibly surprising effects with involving\nmutable objects such as lists and dictionaries. For example, the tricks list in the following code should not be used as\na class variable because just a single list would be shared by all Dog instances:\nclass Dog:\ntricks = []\n# mistaken use of a class variable\ndef __init__(self, name):\nself.name = name\ndef add_trick(self, trick):\nself.tricks.append(trick)\n>>> d = Dog(\'Fido\')\n>>> e = Dog(\'Buddy\')\n>>> d.add_trick(\'roll over\')\n>>> e.add_trick(\'play dead\')\n>>> d.tricks\n# unexpectedly shared by all dogs\n[\'roll over\', \'play dead\']\nCorrect design of the class should use an instance variable instead:\nclass Dog:\ndef __init__(self, name):\nself.name = name\nself.tricks = []\n# creates a new empty list for each dog\ndef add_trick(self, trick):\nself.tricks.append(trick)\n>>> d = Dog(\'Fido\')\n>>> e = Dog(\'Buddy\')\n>>> d.add_trick(\'roll over\')\n(continues on next page)\n78\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n>>> e.add_trick(\'play dead\')\n>>> d.tricks\n[\'roll over\']\n>>> e.tricks\n[\'play dead\']\n9.4 Random Remarks\nIf the same attribute name occurs in both an instance and in a class, then attribute lookup prioritizes the instance:\n>>> class Warehouse:\n...\npurpose = \'storage\'\n...\nregion = \'west\'\n...\n>>> w1 = Warehouse()\n>>> print(w1.purpose, w1.region)\nstorage west\n>>> w2 = Warehouse()\n>>> w2.region = \'east\'\n>>> print(w2.purpose, w2.region)\nstorage east\nData attributes may be referenced by methods as well as by ordinary users (“clients”) of an object. In other words,\nclasses are not usable to implement pure abstract data types. In fact, nothing in Python makes it possible to enforce\ndata hiding — it is all based upon convention. (On the other hand, the Python implementation, written in C, can\ncompletely hide implementation details and control access to an object if necessary; this can be used by extensions\nto Python written in C.)\nClients should use data attributes with care — clients may mess up invariants maintained by the methods by stamping\non their data attributes. Note that clients may add data attributes of their own to an instance object without affecting\nthe validity of the methods, as long as name conflicts are avoided — again, a naming convention can save a lot of\nheadaches here. There is no shorthand for referencing data attributes (or other methods!) from within methods. I find that this\nactually increases the readability of methods: there is no chance of confusing local variables and instance variables\nwhen glancing through a method. Often, the first argument of a method is called self. This is nothing more than a convention: the name self has\nabsolutely no special meaning to Python. Note, however, that by not following the convention your code may be less\nreadable to other Python programmers, and it is also conceivable that a class browser program might be written that\nrelies upon such a convention. Any function object that is a class attribute defines a method for instances of that class. It is not necessary that the\nfunction definition is textually enclosed in the class definition: assigning a function object to a local variable in the\nclass is also ok. For example:\n# Function defined outside the class\ndef f1(self, x, y):\nreturn min(x, x+y)\nclass C:\nf = f1\ndef g(self):\nreturn \'hello world\'\nh = g\n9.4. Random Remarks\n79\n\nPython Tutorial, Release 3.13.2\nNow f, g and h are all attributes of class C that refer to function objects, and consequently they are all methods of\ninstances of C — h being exactly equivalent to g. Note that this practice usually only serves to confuse the reader of\na program. Methods may call other methods by using method attributes of the self argument:\nclass Bag:\ndef __init__(self):\nself.data = []\ndef add(self, x):\nself.data.append(x)\ndef addtwice(self, x):\nself.add(x)\nself.add(x)\nMethods may reference global names in the same way as ordinary functions. The global scope associated with a\nmethod is the module containing its definition. (A class is never used as a global scope.) While one rarely encounters\na good reason for using global data in a method, there are many legitimate uses of the global scope: for one thing,\nfunctions and modules imported into the global scope can be used by methods, as well as functions and classes defined\nin it. Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find\nsome good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as object.__class__. 9.5 Inheritance\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax\nfor a derived class definition looks like this:\nclass DerivedClassName(BaseClassName):\n<statement-1>\n. . . <statement-N>\nThe name BaseClassName must be defined in a namespace accessible from the scope containing the derived class\ndefinition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example,\nwhen the base class is defined in another module:\nclass DerivedClassName(modname.BaseClassName):\nExecution of a derived class definition proceeds the same as for a base class. When the class object is constructed,\nthe base class is remembered. This is used for resolving attribute references: if a requested attribute is not found\nin the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is\nderived from some other class. There’s nothing special about instantiation of derived classes: DerivedClassName() creates a new instance of the\nclass. Method references are resolved as follows: the corresponding class attribute is searched, descending down the\nchain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling\nother methods of the same object, a method of a base class that calls another method defined in the same base class\nmay end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are\neffectively virtual.) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method\nof the same name. There is a simple way to call the base class method directly: just call BaseClassName. 80\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\nmethodname(self, arguments). This is occasionally useful to clients as well. (Note that this only works if\nthe base class is accessible as BaseClassName in the global scope.) Python has two built-in functions that work with inheritance:\n• Use isinstance() to check an instance’s type: isinstance(obj, int) will be True only if obj. __class__ is int or some class derived from int. • Use issubclass() to check class inheritance: issubclass(bool, int) is True since bool is a subclass\nof int. However, issubclass(float, int) is False since float is not a subclass of int. 9.5.1 Multiple Inheritance\nPython supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this:\nclass DerivedClassName(Base1, Base2, Base3):\n<statement-1>\n. .\n\n[2] 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it? Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a num-\nber of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, .. . )), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or\nisinstance(obj, (int, float, complex)). Note that isinstance() also checks for virtual inheritance from an abstract base class. So, the test will return\nTrue for a registered class even if hasn’t directly or indirectly inherited from it. To test for “true inheritance”, scan\nthe MRO of the class:\nfrom collections.abc import Mapping\nclass P:\npass\nclass C(P):\npass\nMapping.register(P)\n>>> c = C()\n>>> isinstance(c, C)\n# direct\nTrue\n>>> isinstance(c, P)\n# indirect\nTrue\n>>> isinstance(c, Mapping)\n# virtual\nTrue\n# Actual inheritance chain\n>>> type(c).__mro__\n(<class \'C\'>, <class \'P\'>, <class \'object\'>)\n# Test for ""true inheritance""\n>>> Mapping in type(c).__mro__\nFalse\nNote that most programs do not use isinstance() on user-defined classes very often. If you are developing the\nclasses yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular\nbehaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if\nyou have a function that does something:\n2.6. Objects\n27\n\nPython Frequently Asked Questions, Release 3.13.2\ndef search(obj):\nif isinstance(obj, Mailbox):\n...\n# code to search a mailbox\nelif isinstance(obj, Document):\n...\n# code to search a document\nelif ...\nA better approach is to define a search() method on all the classes and just call it:\nclass Mailbox:\ndef search(self):\n...\n# code to search a mailbox\nclass Document:\ndef search(self):\n...\n# code to search a document\nobj.search()\n2.6.5 What is delegation? Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to\nchange the behaviour of just one of its methods. You can create a new class that provides a new implementation of\nthe method you’re interested in changing and delegates all other methods to the corresponding method of x.\nPython programmers can easily implement delegation. For example, the following class implements a class that\nbehaves like a file but converts all written data to uppercase:\nclass UpperOut:\ndef __init__(self, outfile):\nself._outfile = outfile\ndef write(self, s):\nself._outfile.write(s.upper())\ndef __getattr__(self, name):\nreturn getattr(self._outfile, name)\nHere the UpperOut class redefines the write() method to convert the argument string to uppercase before call-\ning the underlying self._outfile.write() method. All other methods are delegated to the underlying self. _outfile object. The delegation is accomplished via the __getattr__() method; consult the language reference\nfor more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved,\nthe class must define a __setattr__() method too, and it must do so carefully. The basic implementation of\n__setattr__() is roughly equivalent to the following:\nclass X:\n...\ndef __setattr__(self, name, value):\nself.__dict__[name] = value\n... Many __setattr__() implementations call object.__setattr__() to set an attribute on self without causing\ninfinite recursion:\n28\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nclass X:\ndef __setattr__(self, name, value):\n# Custom logic here...\nobject.__setattr__(self, name, value)\nAlternatively, it is possible to set attributes by inserting entries into self.__dict__ directly. 2.6.6 How do I call a method defined in a base class from a derived class that\nextends it? Use the built-in super() function:\nclass Derived(Base):\ndef meth(self):\nsuper().meth()\n# calls Base.meth\nIn the example, super() will automatically determine the instance from which it was called (the self value), look\nup the method resolution order (MRO) with type(self).__mro__, and return the next in line after Derived in\nthe MRO: Base. 2.6.7 How can I organize my code to make it easier to change the base class? You could assign the base class to an alias and derive from the alias. Then all you have to change is the value assigned\nto the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of\nresources) which base class to use. Example:\nclass Base:\n...\nBaseAlias = Base\nclass Derived(BaseAlias):\n...\n2.6.8 How do I create static class data and static class methods? Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the\nclass name in the assignment:\nclass C:\ncount = 0\n# number of times C.__init__ called\ndef __init__(self):\nC.count = C.count + 1\ndef getcount(self):\nreturn C.count\n# or return self.count\nc.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by\nsome class on the base-class search path from c.__class__ back to C.\nCaution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named\n“count” in self’s own dict. Rebinding of a class-static data name must always specify the class whether inside a\nmethod or not:\nC.count = 314\n2.6. Objects\n29\n\nPython Frequently Asked Questions, Release 3.13.2\nStatic methods are possible:\nclass C:\n@staticmethod\ndef static(arg1, arg2, arg3):\n# No \'self\' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function:\ndef getcount():\nreturn C.count\nIf your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the\ndesired encapsulation. 2.6.9 How can I overload constructors (or methods) in Python? This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write\nclass C {\nC() { cout << ""No arguments\\n""; }\nC(int i) { cout << ""Argument is "" << i << ""\\n""; }\n}\nIn Python you have to write a single constructor that catches all cases using default arguments. For example:\nclass C:\ndef __init__(self, i=None):\nif i is None:\nprint(""No arguments"")\nelse:\nprint(""Argument is"", i)\nThis is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args):\n... The same approach works for all method definitions. 2.6.10 I try to use __spam and I get an error about _SomeClassName__spam. Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class\nprivate variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing under-\nscore) is textually replaced with _classname__spam, where classname is the current class name with any leading\nunderscores stripped. The identifier can be used unchanged within the class, but to access it outside the class, the mangled name must be\nused:\nclass A:\ndef __one(self):\nreturn 1\ndef two(self):\nreturn 2 * self.__one()\n(continues on next page)\n30\nChapter 2.\n\n[3] Class variables must be accessed through the first parameter of instance or class\nmethods, or through the implicit lexically scoped __class__ reference described in the next section. Creating the class object\nOnce the class namespace has been populated by executing the class body, the class object is created by calling\nmetaclass(name, bases, namespace, **kwds) (the additional keywords passed here are the same as those\npassed to __prepare__). This class object is the one that will be referenced by the zero-argument form of super(). __class__ is an implicit\nclosure reference created by the compiler if any methods in a class body refer to either __class__ or super. This\nallows the zero argument form of super() to correctly identify the class being defined based on lexical scoping,\nwhile the class or instance that was used to make the current call is identified based on the first argument passed to\nthe method. CPython implementation detail: In CPython 3.6 and later, the __class__ cell is passed to the metaclass as a\n__classcell__ entry in the class namespace. If present, this must be propagated up to the type.__new__ call\nin order for the class to be initialised correctly. Failing to do so will result in a RuntimeError in Python 3.8. When using the default metaclass type, or any metaclass that ultimately calls type.__new__, the following addi-\ntional customization steps are invoked after creating the class object:\n1) The type.__new__ method collects all of the attributes in the class namespace that define a\n__set_name__() method;\n2) Those __set_name__ methods are called with the class being defined and the assigned name of that particular\nattribute;\n3) The __init_subclass__() hook is called on the immediate parent of the new class in its method resolution\norder. After the class object is created, it is passed to the class decorators included in the class definition (if any) and the\nresulting object is bound in the local namespace as the defined class. When a new class is created by type.__new__, the object provided as the namespace parameter is copied to a new\nordered mapping and the original object is discarded. The new copy is wrapped in a read-only proxy, which becomes\nthe __dict__ attribute of the class object. µ See also\nPEP 3135 - New super\nDescribes the implicit __class__ closure reference\nUses for metaclasses\nThe potential uses for metaclasses are boundless. Some ideas that have been explored include enum, logging, in-\nterface checking, automatic delegation, automatic property creation, proxies, frameworks, and automatic resource\nlocking/synchronization. 3.3. Special method names\n45\n\nThe Python Language Reference, Release 3.13.2\n3.3.4 Customizing instance and subclass checks\nThe following methods are used to override the default behavior of the isinstance() and issubclass() built-in\nfunctions. In particular, the metaclass abc.ABCMeta implements these methods in order to allow the addition of Abstract Base\nClasses (ABCs) as “virtual base classes” to any class or type (including built-in types), including other ABCs. type.__instancecheck__(self, instance)\nReturn true if instance should be considered a (direct or indirect) instance of class. If defined, called to imple-\nment isinstance(instance, class). type.__subclasscheck__(self, subclass)\nReturn true if subclass should be considered a (direct or indirect) subclass of class. If defined, called to imple-\nment issubclass(subclass, class). Note that these methods are looked up on the type (metaclass) of a class. They cannot be defined as class methods in\nthe actual class. This is consistent with the lookup of special methods that are called on instances, only in this case\nthe instance is itself a class. µ See also\nPEP 3119 - Introducing Abstract Base Classes\nIncludes the specification for customizing isinstance() and issubclass() behavior through\n__instancecheck__() and __subclasscheck__(), with motivation for this functionality in the con-\ntext of adding Abstract Base Classes (see the abc module) to the language. 3.3.5 Emulating generic types\nWhen using type annotations, it is often useful to parameterize a generic type using Python’s square-brackets notation. For example, the annotation list[int] might be used to signify a list in which all the elements are of type int. µ See also\nPEP 484 - Type Hints\nIntroducing Python’s framework for type annotations\nGeneric Alias Types\nDocumentation for objects representing parameterized generic classes\nGenerics, user-defined generics and typing.Generic\nDocumentation on how to implement generic classes that can be parameterized at runtime and understood\nby static type-checkers. A class can generally only be parameterized if it defines the special class method __class_getitem__(). classmethod object.__class_getitem__(cls, key)\nReturn an object representing the specialization of a generic class by type arguments found in key. When defined on a class, __class_getitem__() is automatically a class method. As such, there is no need\nfor it to be decorated with @classmethod when it is defined. The purpose of __class_getitem__\nThe purpose of __class_getitem__() is to allow runtime parameterization of standard-library generic classes in\norder to more easily apply type hints to these classes. To implement custom generic classes that can be parameterized at runtime and understood by static type-checkers,\nusers should either inherit from a standard library class that already implements __class_getitem__(), or inherit\nfrom typing.Generic, which has its own implementation of __class_getitem__(). 46\nChapter 3. Data model\n\nThe Python Language Reference, Release 3.13.2\nCustom implementations of __class_getitem__() on classes defined outside of the standard library may not be\nunderstood by third-party type-checkers such as mypy. Using __class_getitem__() on any class for purposes\nother than type hinting is discouraged. __class_getitem__ versus __getitem__\nUsually, the subscription of an object using square brackets will call the __getitem__() instance method defined on\nthe object’s class. However, if the object being subscribed is itself a class, the class method __class_getitem__()\nmay be called instead. __class_getitem__() should return a GenericAlias object if it is properly defined. Presented with the expression obj[x], the Python interpreter follows something like the following process to decide\nwhether __getitem__() or __class_getitem__() should be called:\nfrom inspect import isclass\ndef subscribe(obj, x):\n""""""Return the result of the expression \'obj[x]\'""""""\nclass_of_obj = type(obj)\n# If the class of obj defines __getitem__,\n# call class_of_obj.__getitem__(obj, x)\nif hasattr(class_of_obj, \'__getitem__\'):\nreturn class_of_obj.__getitem__(obj, x)\n# Else, if obj is a class and defines __class_getitem__,\n# call obj.__class_getitem__(x)\nelif isclass(obj) and hasattr(obj, \'__class_getitem__\'):\nreturn obj.__class_getitem__(x)\n# Else, raise an exception\nelse:\nraise TypeError(\nf""\'{class_of_obj.__name__}\' object is not subscriptable""\n)\nIn Python, all classes are themselves instances of other classes. The class of a class is known as that class’s metaclass,\nand most classes have the type class as their metaclass. type does not define __getitem__(), meaning that expres-\nsions such as list[int], dict[str, float] and tuple[str, bytes] all result in __class_getitem__()\nbeing called:\n>>> # list has class ""type"" as its metaclass, like most classes:\n>>> type(list)\n<class \'type\'>\n>>> type(dict) == type(list) == type(tuple) == type(str) == type(bytes)\nTrue\n>>> # ""list[int]"" calls ""list.__class_getitem__(int)""\n>>> list[int]\nlist[int]\n>>> # list.__class_getitem__ returns a GenericAlias object:\n>>> type(list[int])\n<class \'types.GenericAlias\'>\nHowever, if a class has a custom metaclass that defines __getitem__(), subscribing the class may result in different\nbehaviour. An example of this can be found in the enum module:\n>>> from enum import Enum\n>>> class Menu(Enum):\n...\n""""""A breakfast menu""""""\n(continues on next page)\n3.3. Special method names\n47\n\nThe Python Language Reference, Release 3.13.2\n(continued from previous page)\n...\nSPAM = \'spam\'\n...\nBACON = \'bacon\'\n...\n>>> # Enum classes have a custom metaclass:\n>>> type(Menu)\n<class \'enum.EnumMeta\'>\n>>> # EnumMeta defines __getitem__,\n>>> # so __class_getitem__ is not called,\n>>> # and the result is not a GenericAlias object:\n>>> Menu[\'SPAM\']\n<Menu.SPAM: \'spam\'>\n>>> type(Menu[\'SPAM\'])\n<enum \'Menu\'>\nµ See also\nPEP 560 - Core Support for typing module and generic types\nIntroducing\n__class_getitem__(),\nand\noutlining\nwhen\na\nsubscription\nresults\nin\n__class_getitem__() being called instead of __getitem__()\n3.3.6 Emulating callable objects\nobject.__call__(self[, args...])\nCalled when the instance is “called” as a function; if this method is defined, x(arg1, arg2, ...) roughly\ntranslates to type(x).__call__(x, arg1, ...). The object class itself does not provide this method. 3.3.7 Emulating container types\nThe following methods can be defined to implement container objects. None of them are provided by the object\nclass itself. Containers usually are sequences (such as lists or tuples) or mappings (like dictionaries), but can\nrepresent other containers as well. The first set of methods is used either to emulate a sequence or to emulate a\nmapping; the difference is that for a sequence, the allowable keys should be the integers k for which 0 <= k < N\nwhere N is the length of the sequence, or slice objects, which define a range of items. It is also recommended\nthat mappings provide the methods keys(), values(), items(), get(), clear(), setdefault(), pop(),\npopitem(), copy(), and update() behaving similar to those for Python’s standard dictionary objects.')",1.4675809154416516e-79,0.022497704315886134,0.08073048907123269,0.5473535656929016,0.56335837
How do I check if a string represents a number (float or int)?,"

Which, not only is ugly and slow




I'd dispute both.


A regex or other string parsing method would be uglier and slower.  


I'm not sure that anything much could be faster than the above.  It calls the function and returns.  Try/Catch doesn't introduce much overhead because the most common exception is caught without an extensive search of stack frames.


The issue is that any numeric conversion function has two kinds of results




A number, if the number is valid


A status code (e.g., via errno) or exception to show that no valid number could be parsed.




C (as an example) hacks around this a number of ways.  Python lays it out clearly and explicitly.


I think your code for doing this is perfect.

","(""Answer: To check if a string represents a number, you can use the built-in `int()` or `float()` type constructors. For example, `int('144') == 144` and `float('144') == 144.0`. If the string cannot be converted to an integer or float, a ValueError will be raised.\n\nReferences: [3]\n"", '[1] Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task.\n\n[2] Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task. 2.3.10 What does UnicodeDecodeError or UnicodeEncodeError error mean? See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this. One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython.\n\n[3] 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task. 2.3.10 What does UnicodeDecodeError or UnicodeEncodeError error mean? See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this. One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations.')",1.5237039304493973e-79,0.030379746835443033,0.0885809507104017,0.4785410165786743,0.49399778
How do I get the row count of a Pandas DataFrame?,"For a dataframe 
df
, one can use any of the following:




len(df.index)


df.shape[0]


df[df.columns[0]].count()
 (== 
number of non-NaN values
 in first column)








Code to reproduce the plot:


import numpy as np
import pandas as pd
import perfplot

perfplot.save(
    ""out.png"",
    setup=lambda n: pd.DataFrame(np.arange(n * 3).reshape(n, 3)),
    n_range=[2**k for k in range(25)],
    kernels=[
        lambda df: len(df.index),
        lambda df: df.shape[0],
        lambda df: df[df.columns[0]].count(),
    ],
    labels=[""len(df.index)"", ""df.shape[0]"", ""df[df.columns[0]].count()""],
    xlabel=""Number of rows"",
)


","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . 18\n2.3.3\nHow do I get int literal attribute instead of SyntaxError? . . . . . . . . . . . . . . . . . . 18\n2.3.4\nHow do I convert a string to a number? . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.3.5\nHow do I convert a number to a string? . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.6\nHow do I modify a string in place? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.7\nHow do I use strings to call functions/methods? . . .\n\n[3] It can be as simple as\npython -m trace --count -C . somefile.py ... The above will execute somefile.py and generate annotated listings of all Python modules imported during the\nexecution into the current directory. --help\nDisplay usage and exit. --version\nDisplay the version of the module and exit. Added in version 3.8: Added --module option that allows to run an executable module. 1876\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\nMain options\nAt least one of the following options must be specified when invoking trace. The --listfuncs option is mu-\ntually exclusive with the --trace and --count options. When --listfuncs is provided, neither --count nor\n--trace are accepted, and vice versa. -c, --count\nProduce a set of annotated listing files upon program completion that shows how many times each statement\nwas executed. See also --coverdir, --file and --no-report below. -t, --trace\nDisplay lines as they are executed. -l, --listfuncs\nDisplay the functions executed by running the program. -r, --report\nProduce an annotated list from an earlier program run that used the --count and --file option. This does\nnot execute any code. -T, --trackcalls\nDisplay the calling relationships exposed by running the program. Modifiers\n-f, --file=<file>\nName of a file to accumulate counts over several tracing runs. Should be used with the --count option. -C, --coverdir=<dir>\nDirectory where the report files go. The coverage report for package.module is written to file dir/\npackage/module.cover. -m, --missing\nWhen generating annotated listings, mark lines which were not executed with >>>>>>. -s, --summary\nWhen using --count or --report, write a brief summary to stdout for each file processed. -R, --no-report\nDo not generate annotated listings. This is useful if you intend to make several runs with --count, and then\nproduce a single set of annotated listings at the end. -g, --timing\nPrefix each line with the time since the program started. Only used while tracing. Filters\nThese options may be repeated multiple times. --ignore-module=<mod>\nIgnore each of the given module names and its submodules (if it is a package). The argument can be a list of\nnames separated by a comma. --ignore-dir=<dir>\nIgnore all modules and packages in the named directory and subdirectories. The argument can be a list of\ndirectories separated by os.pathsep. 28.7.2 Programmatic Interface\n28.7. trace — Trace or track Python statement execution\n1877\n\nThe Python Library Reference, Release 3.13.2\nclass trace.Trace(count=1, trace=1, countfuncs=0, countcallers=0, ignoremods=(), ignoredirs=(), infile=None,\noutfile=None, timing=False)\nCreate an object to trace execution of a single statement or expression. All parameters are optional. count\nenables counting of line numbers. trace enables line execution tracing. countfuncs enables listing of the func-\ntions called during the run. countcallers enables call relationship tracking. ignoremods is a list of modules or\npackages to ignore. ignoredirs is a list of directories whose modules or packages should be ignored. infile is the\nname of the file from which to read stored count information. outfile is the name of the file in which to write\nupdated count information. timing enables a timestamp relative to when tracing was started to be displayed. run(cmd)\nExecute the command and gather statistics from the execution with the current tracing parameters. cmd\nmust be a string or code object, suitable for passing into exec(). runctx(cmd, globals=None, locals=None)\nExecute the command and gather statistics from the execution with the current tracing parameters, in the\ndefined global and local environments. If not defined, globals and locals default to empty dictionaries. runfunc(func, /, *args, **kwds)\nCall func with the given arguments under control of the Trace object with the current tracing parameters. results()\nReturn a CoverageResults object that contains the cumulative results of all previous calls to run,\nrunctx and runfunc for the given Trace instance. Does not reset the accumulated trace results. class trace.CoverageResults\nA container for coverage results, created by Trace.results().')",1.0093519373539322e-155,0.0437636761487965,0.14820045038691906,0.5144963264465332,0.3040562
Meaning of @classmethod and @staticmethod for beginner,"Though 
classmethod
 and 
staticmethod
 are quite similar, there's a slight difference in usage for both entities: 
classmethod
 must have a reference to a class object as the first parameter, whereas 
staticmethod
 can have no parameters at all.


Example


class Date(object):
    
    def __init__(self, day=0, month=0, year=0):
        self.day = day
        self.month = month
        self.year = year

    @classmethod
    def from_string(cls, date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        date1 = cls(day, month, year)
        return date1

    @staticmethod
    def is_date_valid(date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        return day <= 31 and month <= 12 and year <= 3999

date2 = Date.from_string('11-09-2012')
is_date = Date.is_date_valid('11-09-2012')



Explanation


Let's assume an example of a class, dealing with date information (this will be our boilerplate):


class Date(object):
    
    def __init__(self, day=0, month=0, year=0):
        self.day = day
        self.month = month
        self.year = year



This class obviously could be used to store information about certain dates (without timezone information; let's assume all dates are presented in UTC).


Here we have 
__init__
, a typical initializer of Python class instances, which receives arguments as a typical instance method, having the first non-optional argument (
self
) that holds a reference to a newly created instance.


Class Method


We have some tasks that can be nicely done using 
classmethod
s.


Let's assume that we want to create a lot of 
Date
 class instances having date information coming from an outer source encoded as a string with format 'dd-mm-yyyy'. Suppose we have to do this in different places in the source code of our project.


So what we must do here is:




Parse a string to receive day, month and year as three integer variables or a 3-item tuple consisting of that variable.


Instantiate 
Date
 by passing those values to the initialization call.




This will look like:


day, month, year = map(int, string_date.split('-'))
date1 = Date(day, month, year)



For this purpose, C++ can implement such a feature with overloading, but Python lacks this overloading. Instead, we can use 
classmethod
. Let's create another 
constructor
.


    @classmethod
    def from_string(cls, date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        date1 = cls(day, month, year)
        return date1

date2 = Date.from_string('11-09-2012')



Let's look more carefully at the above implementation, and review what advantages we have here:




We've implemented date string parsing in one place and it's reusable now.


Encapsulation works fine here (if you think that you could implement string parsing as a single function elsewhere, this solution fits the OOP paradigm far better).


cls
 is the 
class itself
, not an instance of the class. It's pretty cool because if we inherit our 
Date
 class, all children will have 
from_string
 defined also.




Static method


What about 
staticmethod
? It's pretty similar to 
classmethod
 but doesn't take any obligatory parameters (like a class method or instance method does).


Let's look at the next use case.


We have a date string that we want to validate somehow. This task is also logically bound to the 
Date
 class we've used so far, but doesn't require instantiation of it.


Here is where 
staticmethod
 can be useful. Let's look at the next piece of code:


    @staticmethod
    def is_date_valid(date_as_string):
        day, month, year = map(int, date_as_string.split('-'))
        return day <= 31 and month <= 12 and year <= 3999

# usage:
is_date = Date.is_date_valid('11-09-2012')



So, as we can see from usage of 
staticmethod
, we don't have any access to what the class is---it's basically just a function,  called syntactically like a method, but without access to the object and its internals (fields and other methods), which 
classmethod
 does have.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] 27\n2.6.4\nHow do I check if an object is an instance of a given class or of a subclass of it? . . . . . . 27\n2.6.5\nWhat is delegation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . .\n\n[2] . . . . . . . 14\n4.3\nKinds of methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.4\nStatic methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n4.5\nClass methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.6\nMember objects and __slots__\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . 75\n9.3.1\nClass Definition Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n9.3.2\nClass Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n9.3.3\nInstance Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n9.3.4\nMethod Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\n9.3.5\nClass and Instance Variables\n. . . . . . . . . . . . . . . . . . . . . . . .')",3.624958709191263e-79,0.07588739290085678,0.06362084456523841,0.48312434554100037,0.30152306
What's the canonical way to check for type in Python?,"Use 
isinstance
 to check if 
o
 is an instance of 
str
 or any subclass of 
str
:


if isinstance(o, str):



To check if the type of 
o
 is exactly 
str
, 
excluding subclasses of 
str
:


if type(o) is str:



See 
Built-in Functions
 in the Python Library Reference for relevant information.




Checking for strings in Python 2


For Python 2, this is a better way to check if 
o
 is a string:


if isinstance(o, basestring):



because this will also catch Unicode strings. 
unicode
 is not a subclass of 
str
; both 
str
 and 
unicode
 are subclasses of 
basestring
. In Python 3, 
basestring
 no longer exists since there's 
a strict separation
 of strings (
str
) and binary data (
bytes
).


Alternatively, 
isinstance
 accepts a tuple of classes. This will return 
True
 if 
o
 is an instance of any subclass of any of 
(str, unicode)
:


if isinstance(o, (str, unicode)):


","('Answer: TypeGuard is used for user-defined functions that return whether their argument is an instance of a particular type. A TypeGuard function tells the static type checker that the return value is a boolean, and if the return value is True, the type of its argument is the type inside TypeGuard.\n\nReferences: [2, 3]\n', '[1] In short, the form def foo(arg: TypeA) -> TypeIs[TypeB]: ..., means that if foo(arg) returns\nTrue, then arg is an instance of TypeB, and if it returns False, it is not an instance of TypeB. TypeIs also works with type variables. For more information, see PEP 742 (Narrowing types with TypeIs). Added in version 3.13.\ntyping.TypeGuard\nSpecial typing construct for marking user-defined type predicate functions. Type predicate functions are user-defined functions that return whether their argument is an instance of a\nparticular type. TypeGuard works similarly to TypeIs, but has subtly different effects on type checking\nbehavior (see below). Using -> TypeGuard tells the static type checker that for a given function:\n1. The return value is a boolean. 2. If the return value is True, the type of its argument is the type inside TypeGuard. TypeGuard also works with type variables. See PEP 647 for more details. For example:\ndef is_str_list(val: list[object]) -> TypeGuard[list[str]]:\n\'\'\'Determines whether all objects in the list are strings\'\'\'\nreturn all(isinstance(x, str) for x in val)\ndef func1(val: list[object]):\nif is_str_list(val):\n# Type of ``val`` is narrowed to ``list[str]``. print("" "".join(val))\nelse:\n# Type of ``val`` remains as ``list[object]``. print(""Not a list of strings!"") TypeIs and TypeGuard differ in the following ways:\n27.1. typing — Support for type hints\n1673\n\nThe Python Library Reference, Release 3.13.2\n• TypeIs requires the narrowed type to be a subtype of the input type, while TypeGuard does not. The\nmain reason is to allow for things like narrowing list[object] to list[str] even though the latter\nis not a subtype of the former, since list is invariant. • When a TypeGuard function returns True, type checkers narrow the type of the variable to exactly the\nTypeGuard type. When a TypeIs function returns True, type checkers can infer a more precise type\ncombining the previously known type of the variable with the TypeIs type. (Technically, this is known\nas an intersection type.) • When a TypeGuard function returns False, type checkers cannot narrow the type of the variable at all. When a TypeIs function returns False, type checkers can narrow the type of the variable to exclude\nthe TypeIs type. Added in version 3.10.\ntyping.Unpack\nTyping operator to conceptually mark an object as having been unpacked. For example, using the unpack operator * on a type variable tuple is equivalent to using Unpack to mark the\ntype variable tuple as having been unpacked:\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Effectively does:\ntup: tuple[Unpack[Ts]]\nIn fact, Unpack can be used interchangeably with * in the context of typing.TypeVarTuple and\nbuiltins.tuple types. You might see Unpack being used explicitly in older versions of Python, where\n* couldn’t be used in certain places:\n# In older versions of Python, TypeVarTuple and Unpack\n# are located in the `typing_extensions` backports package. from typing_extensions import TypeVarTuple, Unpack\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Syntax error on Python <= 3.10! tup: tuple[Unpack[Ts]]\n# Semantically equivalent, and backwards-compatible\nUnpack can also be used along with typing.TypedDict for typing **kwargs in a function signature:\nfrom typing import TypedDict, Unpack\nclass Movie(TypedDict):\nname: str\nyear: int\n# This function expects two keyword arguments - `name` of type `str`\n# and `year` of type `int`. def foo(**kwargs: Unpack[Movie]): ...\nSee PEP 692 for more details on using Unpack for **kwargs typing. Added in version 3.11. Building generic types and type aliases\nThe following classes should not be used directly as annotations. Their intended purpose is to be building blocks for\ncreating generic types and type aliases. These objects can be created through special syntax (type parameter lists and the type statement). For compatibility\nwith Python 3.11 and earlier, they can also be created without the dedicated syntax, as documented below. 1674\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nclass typing.Generic\nAbstract base class for generic types. A generic type is typically declared by adding a list of type parameters after the class name:\nclass Mapping[KT, VT]:\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. Such a class implicitly inherits from Generic. The runtime semantics of this syntax are discussed in the\nLanguage Reference. This class can then be used as follows:\ndef lookup_name[X, Y](mapping: Mapping[X, Y], key: X, default: Y) -> Y:\ntry:\nreturn mapping[key]\nexcept KeyError:\nreturn default\nHere the brackets after the function name indicate a generic function. For backwards compatibility, generic classes can also be declared by explicitly inheriting from Generic. In\nthis case, the type parameters must be declared separately:\nKT = TypeVar(\'KT\')\nVT = TypeVar(\'VT\')\nclass Mapping(Generic[KT, VT]):\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. class typing.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False,\ninfer_variance=False, default=typing.NoDefault)\nType variable. The preferred way to construct a type variable is via the dedicated syntax for generic functions, generic classes,\nand generic type aliases:\nclass Sequence[T]:\n# T is a TypeVar\n... This syntax can also be used to create bounded and constrained type variables:\nclass StrSequence[S: str]:\n# S is a TypeVar with a `str` upper bound;\n...\n# we can say that S is ""bounded by `str`""\nclass StrOrBytesSequence[A: (str, bytes)]:\n# A is a TypeVar constrained to␣\n,→str or bytes\n... However, if desired, reusable type variables can also be constructed manually, like so:\nT = TypeVar(\'T\')\n# Can be anything\nS = TypeVar(\'S\', bound=str)\n# Can be any subtype of str\nA = TypeVar(\'A\', str, bytes)\n# Must be exactly str or bytes\n27.1. typing — Support for type hints\n1675\n\nThe Python Library Reference, Release 3.13.2\nType variables exist primarily for the benefit of static type checkers. They serve as the parameters for generic\ntypes as well as for generic function and type alias definitions. See Generic for more information on generic\ntypes. Generic functions work as follows:\ndef repeat[T](x: T, n: int) -> Sequence[T]:\n""""""Return a list containing n references to x."""""" return [x]*n\ndef print_capitalized[S: str](x: S) -> S:\n""""""Print x capitalized, and return x."""""" print(x.capitalize())\nreturn x\ndef concatenate[A: (str, bytes)](x: A, y: A) -> A:\n""""""Add two strings or bytes objects together."""""" return x + y\nNote that type variables can be bounded, constrained, or neither, but cannot be both bounded and constrained.\n\n[2] An incorrectly written TypeIs function can lead to unsound behavior in the type\nsystem; it is the user’s responsibility to write such functions in a type-safe manner. If a TypeIs function is a class or instance method, then the type in TypeIs maps to the type of the second\nparameter (after cls or self). In short, the form def foo(arg: TypeA) -> TypeIs[TypeB]: ..., means that if foo(arg) returns\nTrue, then arg is an instance of TypeB, and if it returns False, it is not an instance of TypeB. TypeIs also works with type variables. For more information, see PEP 742 (Narrowing types with TypeIs). Added in version 3.13.\ntyping.TypeGuard\nSpecial typing construct for marking user-defined type predicate functions. Type predicate functions are user-defined functions that return whether their argument is an instance of a\nparticular type. TypeGuard works similarly to TypeIs, but has subtly different effects on type checking\nbehavior (see below). Using -> TypeGuard tells the static type checker that for a given function:\n1. The return value is a boolean. 2. If the return value is True, the type of its argument is the type inside TypeGuard. TypeGuard also works with type variables. See PEP 647 for more details. For example:\ndef is_str_list(val: list[object]) -> TypeGuard[list[str]]:\n\'\'\'Determines whether all objects in the list are strings\'\'\'\nreturn all(isinstance(x, str) for x in val)\ndef func1(val: list[object]):\nif is_str_list(val):\n# Type of ``val`` is narrowed to ``list[str]``. print("" "".join(val))\nelse:\n# Type of ``val`` remains as ``list[object]``. print(""Not a list of strings!"") TypeIs and TypeGuard differ in the following ways:\n27.1. typing — Support for type hints\n1673\n\nThe Python Library Reference, Release 3.13.2\n• TypeIs requires the narrowed type to be a subtype of the input type, while TypeGuard does not. The\nmain reason is to allow for things like narrowing list[object] to list[str] even though the latter\nis not a subtype of the former, since list is invariant. • When a TypeGuard function returns True, type checkers narrow the type of the variable to exactly the\nTypeGuard type. When a TypeIs function returns True, type checkers can infer a more precise type\ncombining the previously known type of the variable with the TypeIs type. (Technically, this is known\nas an intersection type.) • When a TypeGuard function returns False, type checkers cannot narrow the type of the variable at all. When a TypeIs function returns False, type checkers can narrow the type of the variable to exclude\nthe TypeIs type. Added in version 3.10.\ntyping.Unpack\nTyping operator to conceptually mark an object as having been unpacked. For example, using the unpack operator * on a type variable tuple is equivalent to using Unpack to mark the\ntype variable tuple as having been unpacked:\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Effectively does:\ntup: tuple[Unpack[Ts]]\nIn fact, Unpack can be used interchangeably with * in the context of typing.TypeVarTuple and\nbuiltins.tuple types. You might see Unpack being used explicitly in older versions of Python, where\n* couldn’t be used in certain places:\n# In older versions of Python, TypeVarTuple and Unpack\n# are located in the `typing_extensions` backports package. from typing_extensions import TypeVarTuple, Unpack\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Syntax error on Python <= 3.10! tup: tuple[Unpack[Ts]]\n# Semantically equivalent, and backwards-compatible\nUnpack can also be used along with typing.TypedDict for typing **kwargs in a function signature:\nfrom typing import TypedDict, Unpack\nclass Movie(TypedDict):\nname: str\nyear: int\n# This function expects two keyword arguments - `name` of type `str`\n# and `year` of type `int`. def foo(**kwargs: Unpack[Movie]): ...\nSee PEP 692 for more details on using Unpack for **kwargs typing. Added in version 3.11. Building generic types and type aliases\nThe following classes should not be used directly as annotations. Their intended purpose is to be building blocks for\ncreating generic types and type aliases. These objects can be created through special syntax (type parameter lists and the type statement). For compatibility\nwith Python 3.11 and earlier, they can also be created without the dedicated syntax, as documented below. 1674\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nclass typing.Generic\nAbstract base class for generic types. A generic type is typically declared by adding a list of type parameters after the class name:\nclass Mapping[KT, VT]:\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. Such a class implicitly inherits from Generic. The runtime semantics of this syntax are discussed in the\nLanguage Reference. This class can then be used as follows:\ndef lookup_name[X, Y](mapping: Mapping[X, Y], key: X, default: Y) -> Y:\ntry:\nreturn mapping[key]\nexcept KeyError:\nreturn default\nHere the brackets after the function name indicate a generic function. For backwards compatibility, generic classes can also be declared by explicitly inheriting from Generic. In\nthis case, the type parameters must be declared separately:\nKT = TypeVar(\'KT\')\nVT = TypeVar(\'VT\')\nclass Mapping(Generic[KT, VT]):\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. class typing.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False,\ninfer_variance=False, default=typing.NoDefault)\nType variable. The preferred way to construct a type variable is via the dedicated syntax for generic functions, generic classes,\nand generic type aliases:\nclass Sequence[T]:\n# T is a TypeVar\n... This syntax can also be used to create bounded and constrained type variables:\nclass StrSequence[S: str]:\n# S is a TypeVar with a `str` upper bound;\n...\n# we can say that S is ""bounded by `str`""\nclass StrOrBytesSequence[A: (str, bytes)]:\n# A is a TypeVar constrained to␣\n,→str or bytes\n... However, if desired, reusable type variables can also be constructed manually, like so:\nT = TypeVar(\'T\')\n# Can be anything\nS = TypeVar(\'S\', bound=str)\n# Can be any subtype of str\nA = TypeVar(\'A\', str, bytes)\n# Must be exactly str or bytes\n27.1. typing — Support for type hints\n1675\n\nThe Python Library Reference, Release 3.13.2\nType variables exist primarily for the benefit of static type checkers. They serve as the parameters for generic\ntypes as well as for generic function and type alias definitions. See Generic for more information on generic\ntypes. Generic functions work as follows:\ndef repeat[T](x: T, n: int) -> Sequence[T]:\n""""""Return a list containing n references to x."""""" return [x]*n\ndef print_capitalized[S: str](x: S) -> S:\n""""""Print x capitalized, and return x.""""""\n\n[3] If a TypeIs function is a class or instance method, then the type in TypeIs maps to the type of the second\nparameter (after cls or self). In short, the form def foo(arg: TypeA) -> TypeIs[TypeB]: ..., means that if foo(arg) returns\nTrue, then arg is an instance of TypeB, and if it returns False, it is not an instance of TypeB. TypeIs also works with type variables. For more information, see PEP 742 (Narrowing types with TypeIs). Added in version 3.13.\ntyping.TypeGuard\nSpecial typing construct for marking user-defined type predicate functions. Type predicate functions are user-defined functions that return whether their argument is an instance of a\nparticular type. TypeGuard works similarly to TypeIs, but has subtly different effects on type checking\nbehavior (see below). Using -> TypeGuard tells the static type checker that for a given function:\n1. The return value is a boolean. 2. If the return value is True, the type of its argument is the type inside TypeGuard. TypeGuard also works with type variables. See PEP 647 for more details. For example:\ndef is_str_list(val: list[object]) -> TypeGuard[list[str]]:\n\'\'\'Determines whether all objects in the list are strings\'\'\'\nreturn all(isinstance(x, str) for x in val)\ndef func1(val: list[object]):\nif is_str_list(val):\n# Type of ``val`` is narrowed to ``list[str]``. print("" "".join(val))\nelse:\n# Type of ``val`` remains as ``list[object]``. print(""Not a list of strings!"") TypeIs and TypeGuard differ in the following ways:\n27.1. typing — Support for type hints\n1673\n\nThe Python Library Reference, Release 3.13.2\n• TypeIs requires the narrowed type to be a subtype of the input type, while TypeGuard does not. The\nmain reason is to allow for things like narrowing list[object] to list[str] even though the latter\nis not a subtype of the former, since list is invariant. • When a TypeGuard function returns True, type checkers narrow the type of the variable to exactly the\nTypeGuard type. When a TypeIs function returns True, type checkers can infer a more precise type\ncombining the previously known type of the variable with the TypeIs type. (Technically, this is known\nas an intersection type.) • When a TypeGuard function returns False, type checkers cannot narrow the type of the variable at all. When a TypeIs function returns False, type checkers can narrow the type of the variable to exclude\nthe TypeIs type. Added in version 3.10.\ntyping.Unpack\nTyping operator to conceptually mark an object as having been unpacked. For example, using the unpack operator * on a type variable tuple is equivalent to using Unpack to mark the\ntype variable tuple as having been unpacked:\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Effectively does:\ntup: tuple[Unpack[Ts]]\nIn fact, Unpack can be used interchangeably with * in the context of typing.TypeVarTuple and\nbuiltins.tuple types. You might see Unpack being used explicitly in older versions of Python, where\n* couldn’t be used in certain places:\n# In older versions of Python, TypeVarTuple and Unpack\n# are located in the `typing_extensions` backports package. from typing_extensions import TypeVarTuple, Unpack\nTs = TypeVarTuple(\'Ts\')\ntup: tuple[*Ts]\n# Syntax error on Python <= 3.10! tup: tuple[Unpack[Ts]]\n# Semantically equivalent, and backwards-compatible\nUnpack can also be used along with typing.TypedDict for typing **kwargs in a function signature:\nfrom typing import TypedDict, Unpack\nclass Movie(TypedDict):\nname: str\nyear: int\n# This function expects two keyword arguments - `name` of type `str`\n# and `year` of type `int`. def foo(**kwargs: Unpack[Movie]): ...\nSee PEP 692 for more details on using Unpack for **kwargs typing. Added in version 3.11. Building generic types and type aliases\nThe following classes should not be used directly as annotations. Their intended purpose is to be building blocks for\ncreating generic types and type aliases. These objects can be created through special syntax (type parameter lists and the type statement). For compatibility\nwith Python 3.11 and earlier, they can also be created without the dedicated syntax, as documented below. 1674\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nclass typing.Generic\nAbstract base class for generic types. A generic type is typically declared by adding a list of type parameters after the class name:\nclass Mapping[KT, VT]:\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. Such a class implicitly inherits from Generic. The runtime semantics of this syntax are discussed in the\nLanguage Reference. This class can then be used as follows:\ndef lookup_name[X, Y](mapping: Mapping[X, Y], key: X, default: Y) -> Y:\ntry:\nreturn mapping[key]\nexcept KeyError:\nreturn default\nHere the brackets after the function name indicate a generic function. For backwards compatibility, generic classes can also be declared by explicitly inheriting from Generic. In\nthis case, the type parameters must be declared separately:\nKT = TypeVar(\'KT\')\nVT = TypeVar(\'VT\')\nclass Mapping(Generic[KT, VT]):\ndef __getitem__(self, key: KT) -> VT:\n...\n# Etc. class typing.TypeVar(name, *constraints, bound=None, covariant=False, contravariant=False,\ninfer_variance=False, default=typing.NoDefault)\nType variable. The preferred way to construct a type variable is via the dedicated syntax for generic functions, generic classes,\nand generic type aliases:\nclass Sequence[T]:\n# T is a TypeVar\n... This syntax can also be used to create bounded and constrained type variables:\nclass StrSequence[S: str]:\n# S is a TypeVar with a `str` upper bound;\n...\n# we can say that S is ""bounded by `str`""\nclass StrOrBytesSequence[A: (str, bytes)]:\n# A is a TypeVar constrained to␣\n,→str or bytes\n... However, if desired, reusable type variables can also be constructed manually, like so:\nT = TypeVar(\'T\')\n# Can be anything\nS = TypeVar(\'S\', bound=str)\n# Can be any subtype of str\nA = TypeVar(\'A\', str, bytes)\n# Must be exactly str or bytes\n27.1. typing — Support for type hints\n1675\n\nThe Python Library Reference, Release 3.13.2\nType variables exist primarily for the benefit of static type checkers. They serve as the parameters for generic\ntypes as well as for generic function and type alias definitions. See Generic for more information on generic\ntypes. Generic functions work as follows:\ndef repeat[T](x: T, n: int) -> Sequence[T]:\n""""""Return a list containing n references to x."""""" return [x]*n\ndef print_capitalized[S: str](x: S) -> S:\n""""""Print x capitalized, and return x."""""" print(x.capitalize())\nreturn x\ndef concatenate[A: (str, bytes)](x: A, y: A) -> A:\n""""""Add two strings or bytes objects together.""""""')",0.003900819920373946,0.04180790960451978,0.12401160750268637,0.5803930163383484,0.31029412
Proper way to declare custom exceptions in modern Python?,"Maybe I missed the question, but why not:


class MyException(Exception):
    pass



To override something (or pass extra args), do this:


class ValidationError(Exception):
    def __init__(self, message, errors):            
        # Call the base class constructor with the parameters it needs
        super().__init__(message)
            
        # Now for your custom code...
        self.errors = errors



That way you could pass dict of error messages to the second param, and get to it later with 
e.errors
.


In Python 2, you have to use this slightly more complex form of 
super()
:


super(ValidationError, self).__init__(message)


","('Answer: To declare custom exceptions in Python, you create a new class that inherits from the base `Exception` class or one of its subclasses. These classes are usually kept simple and often only offer attributes to extract information about the error. It\'s common to name custom exceptions with names that end in ""Error"".\n\nReferences: [1, 3]\n', '[1] The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised. • If the try statement reaches a break, continue or return statement, the finally clause will execute just\nprior to the break, continue or return statement’s execution. • If a finally clause includes a return statement, the returned value will be the one from the finally\nclause’s return statement, not the value from the try clause’s return statement. For example:\n>>> def bool_return():\n...\ntry:\n...\nreturn True\n...\nfinally:\n...\nreturn False\n...\n>>> bool_return()\nFalse\nA more complicated example:\n>>> def divide(x, y):\n...\ntry:\n...\nresult = x / y\n...\nexcept ZeroDivisionError:\n...\nprint(""division by zero!"") ...\nelse:\n...\nprint(""result is"", result)\n...\nfinally:\n...\nprint(""executing finally clause"")\n...\n>>> divide(2, 1)\nresult is 2.0\nexecuting finally clause\n>>> divide(2, 0)\ndivision by zero! executing finally clause\n>>> divide(""2"", ""1"")\nexecuting finally clause\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\ndivide(""2"", ""1"")\n~~~~~~^^^^^^^^^^\nFile ""<stdin>"", line 3, in divide\nresult = x / y\n~~^~~\nTypeError: unsupported operand type(s) for /: \'str\' and \'str\'\nAs you can see, the finally clause is executed in any event. The TypeError raised by dividing two strings is not\nhandled by the except clause and therefore re-raised after the finally clause has been executed. In real world applications, the finally clause is useful for releasing external resources (such as files or network\nconnections), regardless of whether the use of the resource was successful.\n\n[2] The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised. • If the try statement reaches a break, continue or return statement, the finally clause will execute just\nprior to the break, continue or return statement’s execution. • If a finally clause includes a return statement, the returned value will be the one from the finally\nclause’s return statement, not the value from the try clause’s return statement. For example:\n>>> def bool_return():\n...\ntry:\n...\nreturn True\n...\nfinally:\n...\nreturn False\n...\n>>> bool_return()\nFalse\nA more complicated example:\n>>> def divide(x, y):\n...\ntry:\n...\nresult = x / y\n...\nexcept ZeroDivisionError:\n...\nprint(""division by zero!"") ...\nelse:\n...\nprint(""result is"", result)\n...\nfinally:\n...\nprint(""executing finally clause"")\n...\n>>> divide(2, 1)\nresult is 2.0\nexecuting finally clause\n>>> divide(2, 0)\ndivision by zero! executing finally clause\n>>> divide(""2"", ""1"")\nexecuting finally clause\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\ndivide(""2"", ""1"")\n~~~~~~^^^^^^^^^^\nFile ""<stdin>"", line 3, in divide\nresult = x / y\n~~^~~\nTypeError: unsupported operand type(s) for /: \'str\' and \'str\'\nAs you can see, the finally clause is executed in any event. The TypeError raised by dividing two strings is not\nhandled by the except clause and therefore re-raised after the finally clause has been executed. In real world applications, the finally clause is useful for releasing external resources (such as files or network\nconnections), regardless of whether the use of the resource was successful. 8.7. Defining Clean-up Actions\n67\n\nPython Tutorial, Release 3.13.2\n8.8 Predefined Clean-up Actions\nSome objects define standard clean-up actions to be undertaken when the object is no longer needed, regardless of\nwhether or not the operation using the object succeeded or failed.\n\n[3] For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions. For example:\n>>> def func():\n...\nraise ConnectionError\n...\n>>> try:\n...\nfunc()\n... except ConnectionError as exc:\n...\nraise RuntimeError(\'Failed to open database\') from exc\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nfunc()\n~~~~^^\n(continues on next page)\n8.5. Exception Chaining\n65\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nFile ""<stdin>"", line 2, in func\nConnectionError\nThe above exception was the direct cause of the following exception:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(\'Failed to open database\') from exc\nRuntimeError: Failed to open database\nIt also allows disabling automatic exception chaining using the from None idiom:\n>>> try:\n...\nopen(\'database.sqlite\')\n... except OSError:\n...\nraise RuntimeError from None\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError from None\nRuntimeError\nFor more information about chaining mechanics, see bltin-exceptions. 8.6 User-defined Exceptions\nPrograms may name their own exceptions by creating a new exception class (see Classes for more about Python\nclasses). Exceptions should typically be derived from the Exception class, either directly or indirectly. Exception classes can be defined which do anything any other class can do, but are usually kept simple, often only\noffering a number of attributes that allow information about the error to be extracted by handlers for the exception. Most exceptions are defined with names that end in “Error”, similar to the naming of the standard exceptions. Many standard modules define their own exceptions to report errors that may occur in functions they define. 8.7 Defining Clean-up Actions\nThe try statement has another optional clause which is intended to define clean-up actions that must be executed\nunder all circumstances. For example:\n>>> try:\n...\nraise KeyboardInterrupt\n... finally:\n...\nprint(\'Goodbye, world!\') ...\nGoodbye, world! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise KeyboardInterrupt\nKeyboardInterrupt\nIf a finally clause is present, the finally clause will execute as the last task before the try statement completes. The finally clause runs whether or not the try statement produces an exception. The following points discuss\nmore complex cases when an exception occurs:\n• If an exception occurs during execution of the try clause, the exception may be handled by an except clause. If the exception is not handled by an except clause, the exception is re-raised after the finally clause has\n66\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nbeen executed. • An exception could occur during execution of an except or else clause. Again, the exception is re-raised\nafter the finally clause has been executed. • If the finally clause executes a break, continue or return statement, exceptions are not re-raised. • If the try statement reaches a break, continue or return statement, the finally clause will execute just\nprior to the break, continue or return statement’s execution. • If a finally clause includes a return statement, the returned value will be the one from the finally\nclause’s return statement, not the value from the try clause’s return statement. For example:\n>>> def bool_return():\n...\ntry:\n...\nreturn True\n...\nfinally:\n...\nreturn False\n...\n>>> bool_return()\nFalse\nA more complicated example:\n>>> def divide(x, y):\n...\ntry:\n...\nresult = x / y\n...\nexcept ZeroDivisionError:\n...\nprint(""division by zero!"") ...\nelse:\n...\nprint(""result is"", result)\n...\nfinally:\n...\nprint(""executing finally clause"")\n...\n>>> divide(2, 1)\nresult is 2.0\nexecuting finally clause\n>>> divide(2, 0)\ndivision by zero! executing finally clause\n>>> divide(""2"", ""1"")\nexecuting finally clause\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\ndivide(""2"", ""1"")\n~~~~~~^^^^^^^^^^\nFile ""<stdin>"", line 3, in divide\nresult = x / y\n~~^~~\nTypeError: unsupported operand type(s) for /: \'str\' and \'str\'\nAs you can see, the finally clause is executed in any event. The TypeError raised by dividing two strings is not\nhandled by the except clause and therefore re-raised after the finally clause has been executed. In real world applications, the finally clause is useful for releasing external resources (such as files or network\nconnections), regardless of whether the use of the resource was successful. 8.7. Defining Clean-up Actions\n67\n\nPython Tutorial, Release 3.13.2\n8.8 Predefined Clean-up Actions\nSome objects define standard clean-up actions to be undertaken when the object is no longer needed, regardless of\nwhether or not the operation using the object succeeded or failed. Look at the following example, which tries to open\na file and print its contents to the screen.')",9.831014764376062e-80,0.01845018450184502,0.06758327369265046,0.5617930889129639,0.58972055
How can I install packages using pip according to the requirements.txt file from a local directory?,"This works for me:


$ pip install -r requirements.txt --no-index --find-links file:///tmp/packages



--no-index
 - Ignore package index (only look at 
--find-links
 URLs instead).


-f, --find-links 
 - If 
 is a URL or a path to an HTML file, then parse for links to archives. If 
 is a local path or a 
file://
 URL that's a directory, then look for archives in the directory listing.

","(""Answer: I'm sorry, I couldn't find relevant information in the provided context.\n\n"", '[1] . . . . 7\n3.2\n… install packages just for the current user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3\n… install scientific Python packages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.4\n… work with multiple versions of Python installed in parallel? . . . . . . . . . . . . . . . . . . . 7\n4\nCommon installation issues\n9\n4.1\nInstalling into the system Python on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2\nPip not installed .\n\n[2] . . . . . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages?\n\n[3] . . . . . . . . . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system.')",1.1309829994200213e-155,0.029850746268656716,0.09859689040576412,0.449752539396286,0.28653052
Generate random integers between 0 and 9,"Try 
random.randrange
:


from random import randrange
print(randrange(10))


","('Answer: You can use `random.randrange(10)` or `random.randint(0, 9)` to generate a random integer N such that 0 <= N <= 9.\n\nReferences: [1]\n', '[1] 376\nChapter 9. Numeric and Mathematical Modules\n\nThe Python Library Reference, Release 3.13.2\n9.6 random — Generate pseudo-random numbers\nSource code: Lib/random.py\nThis module implements pseudo-random number generators for various distributions. For integers, there is uniform selection from a range. For sequences, there is uniform selection of a random element, a\nfunction to generate a random permutation of a list in-place, and a function for random sampling without replacement. On the real line, there are functions to compute uniform, normal (Gaussian), lognormal, negative exponential, gamma,\nand beta distributions. For generating distributions of angles, the von Mises distribution is available. Almost all module functions depend on the basic function random(), which generates a random float uniformly in\nthe half-open range 0.0 <= X < 1.0. Python uses the Mersenne Twister as the core generator. It produces 53-bit\nprecision floats and has a period of 2**19937-1. The underlying implementation in C is both fast and threadsafe. The Mersenne Twister is one of the most extensively tested random number generators in existence. However, being\ncompletely deterministic, it is not suitable for all purposes, and is completely unsuitable for cryptographic purposes. The functions supplied by this module are actually bound methods of a hidden instance of the random.Random\nclass. You can instantiate your own instances of Random to get generators that don’t share state. Class Random can also be subclassed if you want to use a different basic generator of your own devising: see the\ndocumentation on that class for more details. The random module also provides the SystemRandom class which uses the system function os.urandom() to\ngenerate random numbers from sources provided by the operating system. Á Warning\nThe pseudo-random generators of this module should not be used for security purposes. For security or crypto-\ngraphic uses, see the secrets module. µ See also\nM. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudo-\nrandom number generator”, ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January\npp.3–30 1998. Complementary-Multiply-with-Carry recipe for a compatible alternative random number generator with a long\nperiod and comparatively simple update operations. ® Note\nThe global random number generator and instances of Random are thread-safe. However, in the free-threaded\nbuild, concurrent calls to the global generator or to the same instance of Random may encounter contention and\npoor performance. Consider using separate instances of Random per thread instead. 9.6.1 Bookkeeping functions\nrandom.seed(a=None, version=2)\nInitialize the random number generator. If a is omitted or None, the current system time is used. If randomness sources are provided by the operating\nsystem, they are used instead of the system time (see the os.urandom() function for details on availability). If a is an int, it is used directly. 9.6. random — Generate pseudo-random numbers\n377\n\nThe Python Library Reference, Release 3.13.2\nWith version 2 (the default), a str, bytes, or bytearray object gets converted to an int and all of its bits\nare used. With version 1 (provided for reproducing random sequences from older versions of Python), the algorithm for\nstr and bytes generates a narrower range of seeds. Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed. Changed in version 3.11: The seed must be one of the following types: None, int, float, str, bytes, or\nbytearray. random.getstate()\nReturn an object capturing the current internal state of the generator. This object can be passed to setstate()\nto restore the state. random.setstate(state)\nstate should have been obtained from a previous call to getstate(), and setstate() restores the internal\nstate of the generator to what it was at the time getstate() was called. 9.6.2 Functions for bytes\nrandom.randbytes(n)\nGenerate n random bytes. This method should not be used for generating security tokens. Use secrets.token_bytes() instead. Added in version 3.9. 9.6.3 Functions for integers\nrandom.randrange(stop)\nrandom.randrange(start, stop[, step])\nReturn a randomly selected element from range(start, stop, step). This is roughly equivalent to choice(range(start, stop, step)) but supports arbitrarily large ranges\nand is optimized for common cases. The positional argument pattern matches the range() function. Keyword arguments should not be used because they can be interpreted in unexpected ways. For example\nrandrange(start=100) is interpreted as randrange(0, 100, 1). Changed in version 3.2: randrange() is more sophisticated about producing equally distributed values. Formerly it used a style like int(random()*n) which could produce slightly uneven distributions. Changed in version 3.12: Automatic conversion of non-integer types is no longer supported. Calls such as\nrandrange(10.0) and randrange(Fraction(10, 1)) now raise a TypeError. random.randint(a, b)\nReturn a random integer N such that a <= N <= b. Alias for randrange(a, b+1). random.getrandbits(k)\nReturns a non-negative Python integer with k random bits.\n\n[2] Numeric and Mathematical Modules\n\nThe Python Library Reference, Release 3.13.2\n9.6 random — Generate pseudo-random numbers\nSource code: Lib/random.py\nThis module implements pseudo-random number generators for various distributions. For integers, there is uniform selection from a range. For sequences, there is uniform selection of a random element, a\nfunction to generate a random permutation of a list in-place, and a function for random sampling without replacement. On the real line, there are functions to compute uniform, normal (Gaussian), lognormal, negative exponential, gamma,\nand beta distributions. For generating distributions of angles, the von Mises distribution is available. Almost all module functions depend on the basic function random(), which generates a random float uniformly in\nthe half-open range 0.0 <= X < 1.0. Python uses the Mersenne Twister as the core generator. It produces 53-bit\nprecision floats and has a period of 2**19937-1. The underlying implementation in C is both fast and threadsafe. The Mersenne Twister is one of the most extensively tested random number generators in existence. However, being\ncompletely deterministic, it is not suitable for all purposes, and is completely unsuitable for cryptographic purposes. The functions supplied by this module are actually bound methods of a hidden instance of the random.Random\nclass. You can instantiate your own instances of Random to get generators that don’t share state. Class Random can also be subclassed if you want to use a different basic generator of your own devising: see the\ndocumentation on that class for more details. The random module also provides the SystemRandom class which uses the system function os.urandom() to\ngenerate random numbers from sources provided by the operating system. Á Warning\nThe pseudo-random generators of this module should not be used for security purposes. For security or crypto-\ngraphic uses, see the secrets module. µ See also\nM. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudo-\nrandom number generator”, ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January\npp.3–30 1998. Complementary-Multiply-with-Carry recipe for a compatible alternative random number generator with a long\nperiod and comparatively simple update operations. ® Note\nThe global random number generator and instances of Random are thread-safe. However, in the free-threaded\nbuild, concurrent calls to the global generator or to the same instance of Random may encounter contention and\npoor performance. Consider using separate instances of Random per thread instead. 9.6.1 Bookkeeping functions\nrandom.seed(a=None, version=2)\nInitialize the random number generator. If a is omitted or None, the current system time is used. If randomness sources are provided by the operating\nsystem, they are used instead of the system time (see the os.urandom() function for details on availability). If a is an int, it is used directly. 9.6. random — Generate pseudo-random numbers\n377\n\nThe Python Library Reference, Release 3.13.2\nWith version 2 (the default), a str, bytes, or bytearray object gets converted to an int and all of its bits\nare used. With version 1 (provided for reproducing random sequences from older versions of Python), the algorithm for\nstr and bytes generates a narrower range of seeds. Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed. Changed in version 3.11: The seed must be one of the following types: None, int, float, str, bytes, or\nbytearray. random.getstate()\nReturn an object capturing the current internal state of the generator. This object can be passed to setstate()\nto restore the state. random.setstate(state)\nstate should have been obtained from a previous call to getstate(), and setstate() restores the internal\nstate of the generator to what it was at the time getstate() was called. 9.6.2 Functions for bytes\nrandom.randbytes(n)\nGenerate n random bytes. This method should not be used for generating security tokens. Use secrets.token_bytes() instead. Added in version 3.9. 9.6.3 Functions for integers\nrandom.randrange(stop)\nrandom.randrange(start, stop[, step])\nReturn a randomly selected element from range(start, stop, step). This is roughly equivalent to choice(range(start, stop, step)) but supports arbitrarily large ranges\nand is optimized for common cases. The positional argument pattern matches the range() function. Keyword arguments should not be used because they can be interpreted in unexpected ways. For example\nrandrange(start=100) is interpreted as randrange(0, 100, 1). Changed in version 3.2: randrange() is more sophisticated about producing equally distributed values. Formerly it used a style like int(random()*n) which could produce slightly uneven distributions. Changed in version 3.12: Automatic conversion of non-integer types is no longer supported. Calls such as\nrandrange(10.0) and randrange(Fraction(10, 1)) now raise a TypeError. random.randint(a, b)\nReturn a random integer N such that a <= N <= b. Alias for randrange(a, b+1). random.getrandbits(k)\nReturns a non-negative Python integer with k random bits. This method is supplied with the Mersenne Twister\ngenerator and some other generators may also provide it as an optional part of the API.\n\n[3] For integers, there is uniform selection from a range. For sequences, there is uniform selection of a random element, a\nfunction to generate a random permutation of a list in-place, and a function for random sampling without replacement. On the real line, there are functions to compute uniform, normal (Gaussian), lognormal, negative exponential, gamma,\nand beta distributions. For generating distributions of angles, the von Mises distribution is available. Almost all module functions depend on the basic function random(), which generates a random float uniformly in\nthe half-open range 0.0 <= X < 1.0. Python uses the Mersenne Twister as the core generator. It produces 53-bit\nprecision floats and has a period of 2**19937-1. The underlying implementation in C is both fast and threadsafe. The Mersenne Twister is one of the most extensively tested random number generators in existence. However, being\ncompletely deterministic, it is not suitable for all purposes, and is completely unsuitable for cryptographic purposes. The functions supplied by this module are actually bound methods of a hidden instance of the random.Random\nclass. You can instantiate your own instances of Random to get generators that don’t share state. Class Random can also be subclassed if you want to use a different basic generator of your own devising: see the\ndocumentation on that class for more details. The random module also provides the SystemRandom class which uses the system function os.urandom() to\ngenerate random numbers from sources provided by the operating system. Á Warning\nThe pseudo-random generators of this module should not be used for security purposes. For security or crypto-\ngraphic uses, see the secrets module. µ See also\nM. Matsumoto and T. Nishimura, “Mersenne Twister: A 623-dimensionally equidistributed uniform pseudo-\nrandom number generator”, ACM Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January\npp.3–30 1998. Complementary-Multiply-with-Carry recipe for a compatible alternative random number generator with a long\nperiod and comparatively simple update operations. ® Note\nThe global random number generator and instances of Random are thread-safe. However, in the free-threaded\nbuild, concurrent calls to the global generator or to the same instance of Random may encounter contention and\npoor performance. Consider using separate instances of Random per thread instead. 9.6.1 Bookkeeping functions\nrandom.seed(a=None, version=2)\nInitialize the random number generator. If a is omitted or None, the current system time is used. If randomness sources are provided by the operating\nsystem, they are used instead of the system time (see the os.urandom() function for details on availability). If a is an int, it is used directly. 9.6. random — Generate pseudo-random numbers\n377\n\nThe Python Library Reference, Release 3.13.2\nWith version 2 (the default), a str, bytes, or bytearray object gets converted to an int and all of its bits\nare used. With version 1 (provided for reproducing random sequences from older versions of Python), the algorithm for\nstr and bytes generates a narrower range of seeds. Changed in version 3.2: Moved to the version 2 scheme which uses all of the bits in a string seed. Changed in version 3.11: The seed must be one of the following types: None, int, float, str, bytes, or\nbytearray. random.getstate()\nReturn an object capturing the current internal state of the generator. This object can be passed to setstate()\nto restore the state. random.setstate(state)\nstate should have been obtained from a previous call to getstate(), and setstate() restores the internal\nstate of the generator to what it was at the time getstate() was called. 9.6.2 Functions for bytes\nrandom.randbytes(n)\nGenerate n random bytes. This method should not be used for generating security tokens. Use secrets.token_bytes() instead. Added in version 3.9. 9.6.3 Functions for integers\nrandom.randrange(stop)\nrandom.randrange(start, stop[, step])\nReturn a randomly selected element from range(start, stop, step). This is roughly equivalent to choice(range(start, stop, step)) but supports arbitrarily large ranges\nand is optimized for common cases. The positional argument pattern matches the range() function. Keyword arguments should not be used because they can be interpreted in unexpected ways. For example\nrandrange(start=100) is interpreted as randrange(0, 100, 1). Changed in version 3.2: randrange() is more sophisticated about producing equally distributed values. Formerly it used a style like int(random()*n) which could produce slightly uneven distributions. Changed in version 3.12: Automatic conversion of non-integer types is no longer supported. Calls such as\nrandrange(10.0) and randrange(Fraction(10, 1)) now raise a TypeError. random.randint(a, b)\nReturn a random integer N such that a <= N <= b. Alias for randrange(a, b+1). random.getrandbits(k)\nReturns a non-negative Python integer with k random bits. This method is supplied with the Mersenne Twister\ngenerator and some other generators may also provide it as an optional part of the API. When available,\ngetrandbits() enables randrange() to handle arbitrarily large ranges.')",3.1481723777889673e-232,0.005386687187379762,0.022509893789057107,0.4508397877216339,0.60375154
fatal error: Python.h: No such file or directory,"I managed to solve this issue and generate the .so file in one command 


gcc -shared -o UtilcS.so
-fPIC -I/usr/include/python2.7 -lpython2.7  utilsmodule.c


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . 19\n2.1.1\nOn Linux\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.1.2\nOn FreeBSD and OpenBSD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.2\nBuilding Python\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3\nPython-related paths and files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.4\nMiscellaneous . . . . . . . .\n\n[2] . . . . . 20\n2.3\nPython-related paths and files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.4\nMiscellaneous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.5\nCustom OpenSSL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3\nConfigure Python\n23\n3.1\nBuild Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2\nGenerated files . .\n\n[3] . . . . . . . . . 39\n3.5.3\nLinker flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4\nUsing Python on Windows\n43\n4.1\nThe full installer\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.1.1\nInstallation steps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.1.2\nRemoving the MAX_PATH Limitation . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.1.3\nInstalling Without UI . .')",5.2729615860448925e-232,0.038709677419354833,0.038022813688212934,0.44870540499687195,0.41147417
What is the meaning of single and double underscore before an object name?,"Single Underscore


In a class, names with a leading underscore indicate to other programmers that the attribute or method is intended to be be used inside that class. However, privacy is not 
enforced
 in any way.
Using leading underscores for functions in a module indicates it should not be imported from somewhere else.


From the 
PEP-8
 style guide:




_single_leading_underscore
: weak ""internal use"" indicator. E.g. 
from M import *
 does not import objects whose name starts with an underscore.




Double Underscore (Name Mangling)


From 
the Python docs
:




Any identifier of the form 
__spam
 (at least two leading underscores, at most one trailing underscore) is textually replaced with 
_classname__spam
, where 
classname
 is the current class name with leading underscore(s) stripped. This mangling is done without regard to the syntactic position of the identifier, so it can be used to define class-private instance and class variables, methods, variables stored in globals, and even variables stored in instances. private to this class on instances of other classes.




And a warning from the same page:




Name mangling is intended to give classes an easy way to define “private” instance variables and methods, without having to worry about instance variables defined by derived classes, or mucking with instance variables by code outside the class. Note that the mangling rules are designed mostly to avoid accidents; 
it still is possible for a determined soul to access or modify a variable that is considered private.




Example


>>> class MyClass():
...     def __init__(self):
...             self.__superprivate = ""Hello""
...             self._semiprivate = "", world!""
...
>>> mc = MyClass()
>>> print mc.__superprivate
Traceback (most recent call last):
  File ""
"", line 1, in 

AttributeError: myClass instance has no attribute '__superprivate'
>>> print mc._semiprivate
, world!
>>> print mc.__dict__
{'_MyClass__superprivate': 'Hello', '_semiprivate': ', world!'}


","('Answer: Identifiers with a single underscore are not imported by `from module import *`. A single underscore is a soft keyword that denotes a wildcard in a case pattern within a match statement. The interactive interpreter stores the result of the last evaluation in a variable with a single underscore. Names with double leading and trailing underscores are system-defined names, also known as ""dunder"" names, and any use of these names that does not follow explicitly documented use is subject to breakage without warning. Names with double leading underscores are class-private names and are rewritten to use a mangled form to help avoid name clashes between ""private"" attributes of base and derived classes when used within a class definition.\n\nReferences: [3]\n', '[1] Other tokens\n7\n\nThe Python Language Reference, Release 3.13.2\n2.3 Identifiers and keywords\nIdentifiers (also referred to as names) are described by the following lexical definitions. The syntax of identifiers in Python is based on the Unicode standard annex UAX-31, with elaboration and changes\nas defined below; see also PEP 3131 for further details. Within the ASCII range (U+0001..U+007F), the valid characters for identifiers include the uppercase and lowercase\nletters A through Z, the underscore _ and, except for the first character, the digits 0 through 9. Python 3.0 introduced\nadditional characters from outside the ASCII range (see PEP 3131). For these characters, the classification uses the\nversion of the Unicode Character Database as included in the unicodedata module. Identifiers are unlimited in length. Case is significant. identifier\n::= xid_start xid_continue*\nid_start\n::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, a\nid_continue\n::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc a\nxid_start\n::= <all characters in id_start whose NFKC normalization is in ""id_start xid_contin\nxid_continue ::= <all characters in id_continue whose NFKC normalization is in ""id_continue*"">\nThe Unicode category codes mentioned above stand for:\n• Lu - uppercase letters\n• Ll - lowercase letters\n• Lt - titlecase letters\n• Lm - modifier letters\n• Lo - other letters\n• Nl - letter numbers\n• Mn - nonspacing marks\n• Mc - spacing combining marks\n• Nd - decimal numbers\n• Pc - connector punctuations\n• Other_ID_Start - explicit list of characters in PropList.txt to support backwards compatibility\n• Other_ID_Continue - likewise\nAll identifiers are converted into the normal form NFKC while parsing; comparison of identifiers is based on NFKC. A non-normative HTML file listing all valid identifier characters for Unicode 15.1.0 can be found at https://www. unicode.org/Public/15.1.0/ucd/DerivedCoreProperties.txt\n2.3.1 Keywords\nThe following identifiers are used as reserved words, or keywords of the language, and cannot be used as ordinary\nidentifiers. They must be spelled exactly as written here:\nFalse\nawait\nelse\nimport\npass\nNone\nbreak\nexcept\nin\nraise\nTrue\nclass\nfinally\nis\nreturn\nand\ncontinue\nfor\nlambda\ntry\nas\ndef\nfrom\nnonlocal\nwhile\nassert\ndel\nglobal\nnot\nwith\nasync\nelif\nif\nor\nyield\n8\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\n2.3.2 Soft Keywords\nAdded in version 3.10. Some identifiers are only reserved under specific contexts. These are known as soft keywords. The identifiers match,\ncase, type and _ can syntactically act as keywords in certain contexts, but this distinction is done at the parser level,\nnot when tokenizing. As soft keywords, their use in the grammar is possible while still preserving compatibility with existing code that\nuses these names as identifier names. match, case, and _ are used in the match statement. type is used in the type statement. Changed in version 3.12: type is now a soft keyword. 2.3.3 Reserved classes of identifiers\nCertain classes of identifiers (besides keywords) have special meanings. These classes are identified by the patterns\nof leading and trailing underscore characters:\n_*\nNot imported by from module import *. _\nIn a case pattern within a match statement, _ is a soft keyword that denotes a wildcard. Separately, the interactive interpreter makes the result of the last evaluation available in the variable _. (It is\nstored in the builtins module, alongside built-in functions like print.) Elsewhere, _ is a regular identifier. It is often used to name “special” items, but it is not special to Python itself. ® Note\nThe name _ is often used in conjunction with internationalization; refer to the documentation for the\ngettext module for more information on this convention. It is also commonly used for unused variables. __*__\nSystem-defined names, informally known as “dunder” names. These names are defined by the interpreter and\nits implementation (including the standard library). Current system names are discussed in the Special method\nnames section and elsewhere. More will likely be defined in future versions of Python. Any use of __*__\nnames, in any context, that does not follow explicitly documented use, is subject to breakage without warning. __*\nClass-private names. Names in this category, when used within the context of a class definition, are re-written\nto use a mangled form to help avoid name clashes between “private” attributes of base and derived classes. See\nsection Identifiers (Names). 2.4 Literals\nLiterals are notations for constant values of some built-in types. 2.4.1 String and Bytes literals\nString literals are described by the following lexical definitions:\nstringliteral\n::= [stringprefix](shortstring | longstring)\nstringprefix\n::= ""r"" | ""u"" | ""R"" | ""U"" | ""f"" | ""F""\n| ""fr"" | ""Fr"" | ""fR"" | ""FR"" | ""rf"" | ""rF"" | ""Rf"" | ""RF""\nshortstring\n::= ""\'"" shortstringitem* ""\'"" | \'""\' shortstringitem* \'""\'\nlongstring\n::= ""\'\'\'"" longstringitem* ""\'\'\'"" | \'""""""\' longstringitem* \'""""""\'\n2.4. Literals\n9\n\nThe Python Language Reference, Release 3.13.2\nshortstringitem ::= shortstringchar | stringescapeseq\nlongstringitem\n::= longstringchar | stringescapeseq\nshortstringchar ::= <any source character except ""\\"" or newline or the quote>\nlongstringchar\n::= <any source character except ""\\"">\nstringescapeseq ::= ""\\"" <any source character>\nbytesliteral\n::= bytesprefix(shortbytes | longbytes)\nbytesprefix\n::= ""b"" | ""B"" | ""br"" | ""Br"" | ""bR"" | ""BR"" | ""rb"" | ""rB"" | ""Rb"" | ""RB""\nshortbytes\n::= ""\'"" shortbytesitem* ""\'"" | \'""\' shortbytesitem* \'""\'\nlongbytes\n::= ""\'\'\'"" longbytesitem* ""\'\'\'"" | \'""""""\' longbytesitem* \'""""""\'\nshortbytesitem ::= shortbyteschar | bytesescapeseq\nlongbytesitem\n::= longbyteschar | bytesescapeseq\nshortbyteschar ::= <any ASCII character except ""\\"" or newline or the quote>\nlongbyteschar\n::= <any ASCII character except ""\\"">\nbytesescapeseq ::= ""\\"" <any ASCII character>\nOne syntactic restriction not indicated by these productions is that whitespace is not allowed between the\nstringprefix or bytesprefix and the rest of the literal. The source character set is defined by the encoding\ndeclaration; it is UTF-8 if no encoding declaration is given in the source file; see section Encoding declarations. In plain English: Both types of literals can be enclosed in matching single quotes (\') or double quotes (""). They can\nalso be enclosed in matching groups of three single or double quotes (these are generally referred to as triple-quoted\nstrings). The backslash (\\) character is used to give special meaning to otherwise ordinary characters like n, which\nmeans ‘newline’ when escaped (\\n). It can also be used to escape characters that otherwise have a special meaning,\nsuch as newline, backslash itself, or the quote character. See escape sequences below for examples. Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'. Support for the unicode legacy literal (u\'value\') was reintroduced to simplify the maintenance of dual Python 2.x\nand 3.x codebases.\n\n[2] 2.2. Other tokens\n7\n\nThe Python Language Reference, Release 3.13.2\n2.3 Identifiers and keywords\nIdentifiers (also referred to as names) are described by the following lexical definitions. The syntax of identifiers in Python is based on the Unicode standard annex UAX-31, with elaboration and changes\nas defined below; see also PEP 3131 for further details. Within the ASCII range (U+0001..U+007F), the valid characters for identifiers include the uppercase and lowercase\nletters A through Z, the underscore _ and, except for the first character, the digits 0 through 9. Python 3.0 introduced\nadditional characters from outside the ASCII range (see PEP 3131). For these characters, the classification uses the\nversion of the Unicode Character Database as included in the unicodedata module. Identifiers are unlimited in length. Case is significant. identifier\n::= xid_start xid_continue*\nid_start\n::= <all characters in general categories Lu, Ll, Lt, Lm, Lo, Nl, the underscore, a\nid_continue\n::= <all characters in id_start, plus characters in the categories Mn, Mc, Nd, Pc a\nxid_start\n::= <all characters in id_start whose NFKC normalization is in ""id_start xid_contin\nxid_continue ::= <all characters in id_continue whose NFKC normalization is in ""id_continue*"">\nThe Unicode category codes mentioned above stand for:\n• Lu - uppercase letters\n• Ll - lowercase letters\n• Lt - titlecase letters\n• Lm - modifier letters\n• Lo - other letters\n• Nl - letter numbers\n• Mn - nonspacing marks\n• Mc - spacing combining marks\n• Nd - decimal numbers\n• Pc - connector punctuations\n• Other_ID_Start - explicit list of characters in PropList.txt to support backwards compatibility\n• Other_ID_Continue - likewise\nAll identifiers are converted into the normal form NFKC while parsing; comparison of identifiers is based on NFKC. A non-normative HTML file listing all valid identifier characters for Unicode 15.1.0 can be found at https://www. unicode.org/Public/15.1.0/ucd/DerivedCoreProperties.txt\n2.3.1 Keywords\nThe following identifiers are used as reserved words, or keywords of the language, and cannot be used as ordinary\nidentifiers. They must be spelled exactly as written here:\nFalse\nawait\nelse\nimport\npass\nNone\nbreak\nexcept\nin\nraise\nTrue\nclass\nfinally\nis\nreturn\nand\ncontinue\nfor\nlambda\ntry\nas\ndef\nfrom\nnonlocal\nwhile\nassert\ndel\nglobal\nnot\nwith\nasync\nelif\nif\nor\nyield\n8\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\n2.3.2 Soft Keywords\nAdded in version 3.10. Some identifiers are only reserved under specific contexts. These are known as soft keywords. The identifiers match,\ncase, type and _ can syntactically act as keywords in certain contexts, but this distinction is done at the parser level,\nnot when tokenizing. As soft keywords, their use in the grammar is possible while still preserving compatibility with existing code that\nuses these names as identifier names. match, case, and _ are used in the match statement. type is used in the type statement. Changed in version 3.12: type is now a soft keyword. 2.3.3 Reserved classes of identifiers\nCertain classes of identifiers (besides keywords) have special meanings. These classes are identified by the patterns\nof leading and trailing underscore characters:\n_*\nNot imported by from module import *. _\nIn a case pattern within a match statement, _ is a soft keyword that denotes a wildcard. Separately, the interactive interpreter makes the result of the last evaluation available in the variable _. (It is\nstored in the builtins module, alongside built-in functions like print.) Elsewhere, _ is a regular identifier. It is often used to name “special” items, but it is not special to Python itself. ® Note\nThe name _ is often used in conjunction with internationalization; refer to the documentation for the\ngettext module for more information on this convention. It is also commonly used for unused variables. __*__\nSystem-defined names, informally known as “dunder” names. These names are defined by the interpreter and\nits implementation (including the standard library). Current system names are discussed in the Special method\nnames section and elsewhere. More will likely be defined in future versions of Python. Any use of __*__\nnames, in any context, that does not follow explicitly documented use, is subject to breakage without warning. __*\nClass-private names. Names in this category, when used within the context of a class definition, are re-written\nto use a mangled form to help avoid name clashes between “private” attributes of base and derived classes. See\nsection Identifiers (Names). 2.4 Literals\nLiterals are notations for constant values of some built-in types. 2.4.1 String and Bytes literals\nString literals are described by the following lexical definitions:\nstringliteral\n::= [stringprefix](shortstring | longstring)\nstringprefix\n::= ""r"" | ""u"" | ""R"" | ""U"" | ""f"" | ""F""\n| ""fr"" | ""Fr"" | ""fR"" | ""FR"" | ""rf"" | ""rF"" | ""Rf"" | ""RF""\nshortstring\n::= ""\'"" shortstringitem* ""\'"" | \'""\' shortstringitem* \'""\'\nlongstring\n::= ""\'\'\'"" longstringitem* ""\'\'\'"" | \'""""""\' longstringitem* \'""""""\'\n2.4. Literals\n9\n\nThe Python Language Reference, Release 3.13.2\nshortstringitem ::= shortstringchar | stringescapeseq\nlongstringitem\n::= longstringchar | stringescapeseq\nshortstringchar ::= <any source character except ""\\"" or newline or the quote>\nlongstringchar\n::= <any source character except ""\\"">\nstringescapeseq ::= ""\\"" <any source character>\nbytesliteral\n::= bytesprefix(shortbytes | longbytes)\nbytesprefix\n::= ""b"" | ""B"" | ""br"" | ""Br"" | ""bR"" | ""BR"" | ""rb"" | ""rB"" | ""Rb"" | ""RB""\nshortbytes\n::= ""\'"" shortbytesitem* ""\'"" | \'""\' shortbytesitem* \'""\'\nlongbytes\n::= ""\'\'\'"" longbytesitem* ""\'\'\'"" | \'""""""\' longbytesitem* \'""""""\'\nshortbytesitem ::= shortbyteschar | bytesescapeseq\nlongbytesitem\n::= longbyteschar | bytesescapeseq\nshortbyteschar ::= <any ASCII character except ""\\"" or newline or the quote>\nlongbyteschar\n::= <any ASCII character except ""\\"">\nbytesescapeseq ::= ""\\"" <any ASCII character>\nOne syntactic restriction not indicated by these productions is that whitespace is not allowed between the\nstringprefix or bytesprefix and the rest of the literal. The source character set is defined by the encoding\ndeclaration; it is UTF-8 if no encoding declaration is given in the source file; see section Encoding declarations. In plain English: Both types of literals can be enclosed in matching single quotes (\') or double quotes (""). They can\nalso be enclosed in matching groups of three single or double quotes (these are generally referred to as triple-quoted\nstrings). The backslash (\\) character is used to give special meaning to otherwise ordinary characters like n, which\nmeans ‘newline’ when escaped (\\n). It can also be used to escape characters that otherwise have a special meaning,\nsuch as newline, backslash itself, or the quote character. See escape sequences below for examples. Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'.\n\n[3] These classes are identified by the patterns\nof leading and trailing underscore characters:\n_*\nNot imported by from module import *. _\nIn a case pattern within a match statement, _ is a soft keyword that denotes a wildcard. Separately, the interactive interpreter makes the result of the last evaluation available in the variable _. (It is\nstored in the builtins module, alongside built-in functions like print.) Elsewhere, _ is a regular identifier. It is often used to name “special” items, but it is not special to Python itself. ® Note\nThe name _ is often used in conjunction with internationalization; refer to the documentation for the\ngettext module for more information on this convention. It is also commonly used for unused variables. __*__\nSystem-defined names, informally known as “dunder” names. These names are defined by the interpreter and\nits implementation (including the standard library). Current system names are discussed in the Special method\nnames section and elsewhere. More will likely be defined in future versions of Python. Any use of __*__\nnames, in any context, that does not follow explicitly documented use, is subject to breakage without warning. __*\nClass-private names. Names in this category, when used within the context of a class definition, are re-written\nto use a mangled form to help avoid name clashes between “private” attributes of base and derived classes. See\nsection Identifiers (Names). 2.4 Literals\nLiterals are notations for constant values of some built-in types. 2.4.1 String and Bytes literals\nString literals are described by the following lexical definitions:\nstringliteral\n::= [stringprefix](shortstring | longstring)\nstringprefix\n::= ""r"" | ""u"" | ""R"" | ""U"" | ""f"" | ""F""\n| ""fr"" | ""Fr"" | ""fR"" | ""FR"" | ""rf"" | ""rF"" | ""Rf"" | ""RF""\nshortstring\n::= ""\'"" shortstringitem* ""\'"" | \'""\' shortstringitem* \'""\'\nlongstring\n::= ""\'\'\'"" longstringitem* ""\'\'\'"" | \'""""""\' longstringitem* \'""""""\'\n2.4. Literals\n9\n\nThe Python Language Reference, Release 3.13.2\nshortstringitem ::= shortstringchar | stringescapeseq\nlongstringitem\n::= longstringchar | stringescapeseq\nshortstringchar ::= <any source character except ""\\"" or newline or the quote>\nlongstringchar\n::= <any source character except ""\\"">\nstringescapeseq ::= ""\\"" <any source character>\nbytesliteral\n::= bytesprefix(shortbytes | longbytes)\nbytesprefix\n::= ""b"" | ""B"" | ""br"" | ""Br"" | ""bR"" | ""BR"" | ""rb"" | ""rB"" | ""Rb"" | ""RB""\nshortbytes\n::= ""\'"" shortbytesitem* ""\'"" | \'""\' shortbytesitem* \'""\'\nlongbytes\n::= ""\'\'\'"" longbytesitem* ""\'\'\'"" | \'""""""\' longbytesitem* \'""""""\'\nshortbytesitem ::= shortbyteschar | bytesescapeseq\nlongbytesitem\n::= longbyteschar | bytesescapeseq\nshortbyteschar ::= <any ASCII character except ""\\"" or newline or the quote>\nlongbyteschar\n::= <any ASCII character except ""\\"">\nbytesescapeseq ::= ""\\"" <any ASCII character>\nOne syntactic restriction not indicated by these productions is that whitespace is not allowed between the\nstringprefix or bytesprefix and the rest of the literal. The source character set is defined by the encoding\ndeclaration; it is UTF-8 if no encoding declaration is given in the source file; see section Encoding declarations. In plain English: Both types of literals can be enclosed in matching single quotes (\') or double quotes (""). They can\nalso be enclosed in matching groups of three single or double quotes (these are generally referred to as triple-quoted\nstrings). The backslash (\\) character is used to give special meaning to otherwise ordinary characters like n, which\nmeans ‘newline’ when escaped (\\n). It can also be used to escape characters that otherwise have a special meaning,\nsuch as newline, backslash itself, or the quote character. See escape sequences below for examples. Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'. Support for the unicode legacy literal (u\'value\') was reintroduced to simplify the maintenance of dual Python 2.x\nand 3.x codebases. See PEP 414 for more information. A string literal with \'f\' or \'F\' in its prefix is a formatted string literal; see f-strings. The \'f\' may be combined\nwith \'r\', but not with \'b\' or \'u\', therefore raw formatted strings are possible, but formatted bytes literals are not. In triple-quoted literals, unescaped newlines and quotes are allowed (and are retained), except that three unescaped\nquotes in a row terminate the literal. (A “quote” is the character used to open the literal, i.e. either \' or "".) Escape sequences\nUnless an \'r\' or \'R\' prefix is present, escape sequences in string and bytes literals are interpreted according to rules\nsimilar to those used by Standard C. The recognized escape sequences are:\n10\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nEscape Sequence\nMeaning\nNotes\n\\<newline>\nBackslash and newline ignored\n(1)\n\\\\\nBackslash (\\)\n\\\'\nSingle quote (\')\n\\""\nDouble quote ("")\n\\a\nASCII Bell (BEL)\n\\b\nASCII Backspace (BS)\n\\f\nASCII Formfeed (FF)\n\\n\nASCII Linefeed (LF)\n\\r\nASCII Carriage Return (CR)\n\\t\nASCII Horizontal Tab (TAB)\n\\v\nASCII Vertical Tab (VT)\n\\ooo\nCharacter with octal value ooo\n(2,4)\n\\xhh\nCharacter with hex value hh\n(3,4)\nEscape sequences only recognized in string literals are:\nEscape Sequence\nMeaning\nNotes\n\\N{name}\nCharacter named name in the Unicode database\n(5)\n\\uxxxx\nCharacter with 16-bit hex value xxxx\n(6)\n\\Uxxxxxxxx\nCharacter with 32-bit hex value xxxxxxxx\n(7)\nNotes:\n(1) A backslash can be added at the end of a line to ignore the newline:\n>>> \'This string will not include \\\n... backslashes or newline characters.\' \'This string will not include backslashes or newline characters.\' The same result can be achieved using triple-quoted strings, or parentheses and string literal concatenation. (2) As in Standard C, up to three octal digits are accepted. Changed in version 3.11: Octal escapes with value larger than 0o377 produce a DeprecationWarning. Changed in version 3.12: Octal escapes with value larger than 0o377 produce a SyntaxWarning. In a future\nPython version they will be eventually a SyntaxError. (3) Unlike in Standard C, exactly two hex digits are required. (4) In a bytes literal, hexadecimal and octal escapes denote the byte with the given value. In a string literal, these\nescapes denote a Unicode character with the given value. (5) Changed in version 3.3: Support for name aliases1 has been added. (6) Exactly four hex digits are required. (7) Any Unicode character can be encoded this way.')",2.1071811334295165e-79,0.052686489306207625,0.1946989941452514,0.5818307399749756,0.7165932
Relative imports for the billionth time,"Script vs. Module


Here's an explanation.  The short version is that there is a big difference between directly running a Python file, and importing that file from somewhere else.  
Just knowing what directory a file is in does not determine what package Python thinks it is in.
  That depends, additionally, on how you load the file into Python (by running or by importing).


There are two ways to load a Python file: as the top-level script, or as a
module.  A file is loaded as the top-level script if you execute it directly, for instance by typing 
python myfile.py
 on the command line.  It is loaded as a module when an 
import
 statement is encountered inside some other file.  There can only be one top-level script at a time; the top-level script is the Python file you ran to start things off.


Naming


When a file is loaded, it is given a name (which is stored in its 
__name__
 attribute).  If it was loaded as the top-level script, its name is 
__main__
.  If it was loaded as a module, its name is the filename, preceded by the names of any packages/subpackages of which it is a part, separated by dots.


So for instance in your example:


package/
    __init__.py
    subpackage1/
        __init__.py
        moduleX.py
    moduleA.py



if you imported 
moduleX
 (note: 
imported
, not directly executed), its name would be 
package.subpackage1.moduleX
.  If you imported 
moduleA
, its name would be 
package.moduleA
.  However, if you 
directly run
 
moduleX
 from the command line, its name will instead be 
__main__
, and if you directly run 
moduleA
 from the command line, its name will be 
__main__
.  When a module is run as the top-level script, it loses its normal name and its name is instead 
__main__
.


Accessing a module NOT through its containing package


There is an additional wrinkle: the module's name depends on whether it was imported ""directly"" from the directory it is in or imported via a package.  This only makes a difference if you run Python in a directory, and try to import a file in that same directory (or a subdirectory of it).  For instance, if you start the Python interpreter in the directory 
package/subpackage1
 and then do 
import moduleX
, the name of 
moduleX
 will just be 
moduleX
, and not 
package.subpackage1.moduleX
.  This is because Python adds the current directory to its search path when the interpreter is entered interactively; if it finds the to-be-imported module in the current directory, it will not know that that directory is part of a package, and the package information will not become part of the module's name.


A special case is if you run the interpreter interactively (e.g., just type 
python
 and start entering Python code on the fly).  In this case, the name of that interactive session is 
__main__
.


Now here is the crucial thing for your error message: 
if a module's name has no dots, it is not considered to be part of a package
.  It doesn't matter where the file actually is on disk.  All that matters is what its name is, and its name depends on how you loaded it.


Now look at the quote you included in your question:




Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top-level module, regardless of where the module is actually located on the file system.




Relative imports...


Relative imports use the module's 
name
 to determine where it is in a package.  When you use a relative import like 
from .. import foo
, the dots indicate to step up some number of levels in the package hierarchy.  For instance, if your current module's name is 
package.subpackage1.moduleX
, then 
..moduleA
 would mean 
package.moduleA
.  For a 
from .. import
 to work, the module's name must have at least as many dots as there are in the 
import
 statement.


... are only relative in a package


However, if your module's name is 
__main__
, it is not considered to be in a package.  Its name has no dots, and therefore you cannot use 
from .. import
 statements inside it.  If you try to do so, you will get the ""relative-import in non-package"" error.


Scripts can't import relative


What you probably did is you tried to run 
moduleX
 or the like from the command line.  When you did this, its name was set to 
__main__
, which means that relative imports within it will fail, because its name does not reveal that it is in a package. Note that this will also happen if you run Python from the same directory where a module is, and then try to import that module, because, as described above, Python will find the module in the current directory ""too early"" without realizing it is part of a package.


Also remember that when you run the interactive interpreter, the ""name"" of that interactive session is always 
__main__
.  Thus 
you cannot do relative imports directly from an interactive session
.  Relative imports are only for use within module files.


Two solutions:




If you really do want to run 
moduleX
 directly, but you still want it to be considered part of a package, you can do 
python -m package.subpackage1.moduleX
.  The 
-m
 tells Python to load it as a module, not as the top-level script.




Or perhaps you don't actually want to 
run
 
moduleX
, you just want to run some other script, say 
myfile.py
, that 
uses
 functions inside 
moduleX
.  If that is the case, put 
myfile.py
 
somewhere else
 – 
not
 inside the 
package
 directory – and run it.  If inside 
myfile.py
 you do things like 
from package.moduleA import spam
, it will work fine.






Notes




For either of these solutions, the package directory (
package
 in your example) must be accessible from the Python module search path (
sys.path
).  If it is not, you will not be able to use anything in the package reliably at all.




Since Python 2.6, the module's ""name"" for package-resolution purposes is determined not just by its 
__name__
 attributes but also by the 
__package__
 attribute.  That's why I'm avoiding using the explicit symbol 
__name__
 to refer to the module's ""name"".  Since Python 2.6 a module's ""name"" is effectively 
__package__ + '.' + __name__
, or just 
__name__
 if 
__package__
 is 
None
.)





","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] locale.ABMON_1\nlocale.ABMON_2\nlocale.ABMON_3\nlocale.ABMON_4\nlocale.ABMON_5\nlocale.ABMON_6\nlocale.ABMON_7\nlocale.ABMON_8\nlocale.ABMON_9\nlocale.ABMON_10\nlocale.ABMON_11\nlocale.ABMON_12\nGet the abbreviated name of the n-th month. locale.RADIXCHAR\nGet the radix character (decimal dot, decimal comma, etc.). locale.THOUSEP\nGet the separator character for thousands (groups of three digits). locale.YESEXPR\nGet a regular expression that can be used with the regex function to recognize a positive response to a\nyes/no question. locale.NOEXPR\nGet a regular expression that can be used with the regex(3) function to recognize a negative response\nto a yes/no question. ® Note\nThe regular expressions for YESEXPR and NOEXPR use syntax suitable for the regex function from\nthe C library, which might differ from the syntax used in re. locale.CRNCYSTR\nGet the currency symbol, preceded by “-” if the symbol should appear before the value, “+” if the symbol\nshould appear after the value, or “.” if the symbol should replace the radix character. locale.ERA\nGet a string which describes how years are counted and displayed for each era in a locale. Most locales do not define this value. An example of a locale which does define this value is the Japanese\none. In Japan, the traditional representation of dates includes the name of the era corresponding to the\nthen-emperor’s reign. Normally it should not be necessary to use this value directly. Specifying the E modifier in their format\nstrings causes the time.strftime() function to use this information. The format of the returned string\nis specified in The Open Group Base Specifications Issue 8, paragraph 7.3.5.2 LC_TIME C-Language\nAccess. 1546\nChapter 24. Internationalization\n\nThe Python Library Reference, Release 3.13.2\nlocale.ERA_D_T_FMT\nGet a format string for time.strftime() to represent date and time in a locale-specific era-based way. locale.ERA_D_FMT\nGet a format string for time.strftime() to represent a date in a locale-specific era-based way. locale.ERA_T_FMT\nGet a format string for time.strftime() to represent a time in a locale-specific era-based way. locale.ALT_DIGITS\nGet a string consisting of up to 100 semicolon-separated symbols used to represent the values 0 to 99 in\na locale-specific way. In most locales this is an empty string. locale.getdefaultlocale([envvars])\nTries to determine the default locale settings and returns them as a tuple of the form (language code,\nencoding). According to POSIX, a program which has not called setlocale(LC_ALL, \'\') runs using the portable \'C\'\nlocale. Calling setlocale(LC_ALL, \'\') lets it use the default locale as defined by the LANG variable. Since\nwe do not want to interfere with the current locale setting we thus emulate the behavior in the way described\nabove. To maintain compatibility with other platforms, not only the LANG variable is tested, but a list of variables\ngiven as envvars parameter. The first found to be defined will be used. envvars defaults to the search path used\nin GNU gettext; it must always contain the variable name \'LANG\'. The GNU gettext search path contains\n\'LC_ALL\', \'LC_CTYPE\', \'LANG\' and \'LANGUAGE\', in that order. Except for the code \'C\', the language code corresponds to RFC 1766. language code and encoding may be\nNone if their values cannot be determined. Deprecated since version 3.11, will be removed in version 3.15.\nlocale.getlocale(category=LC_CTYPE)\nReturns the current setting for the given locale category as sequence containing language code, encoding. cat-\negory may be one of the LC_* values except LC_ALL. It defaults to LC_CTYPE. Except for the code \'C\', the language code corresponds to RFC 1766. language code and encoding may be\nNone if their values cannot be determined. locale.getpreferredencoding(do_setlocale=True)\nReturn the locale encoding used for text data, according to user preferences. User preferences are expressed\ndifferently on different systems, and might not be available programmatically on some systems, so this function\nonly returns a guess. On some systems, it is necessary to invoke setlocale() to obtain the user preferences, so this function is\nnot thread-safe. If invoking setlocale is not necessary or desired, do_setlocale should be set to False. On Android or if the Python UTF-8 Mode is enabled, always return \'utf-8\', the locale encoding and the\ndo_setlocale argument are ignored. The Python preinitialization configures the LC_CTYPE locale. See also the filesystem encoding and error\nhandler. Changed in version 3.7: The function now always returns ""utf-8"" on Android or if the Python UTF-8 Mode\nis enabled. locale.getencoding()\nGet the current locale encoding:\n• On Android and VxWorks, return ""utf-8"". • On\nUnix,\nreturn\nthe\nencoding\nof\nthe\ncurrent\nLC_CTYPE\nlocale. Return\n""utf-8""\nif\nnl_langinfo(CODESET) returns an empty string:\nfor example, if the current LC_CTYPE lo-\ncale is not supported. • On Windows, return the ANSI code page. 24.2. locale — Internationalization services\n1547\n\nThe Python Library Reference, Release 3.13.2\nThe Python preinitialization configures the LC_CTYPE locale. See also the filesystem encoding and error\nhandler. This function is similar to getpreferredencoding(False) except this function ignores the Python UTF-8\nMode. Added in version 3.11.\nlocale.normalize(localename)\nReturns a normalized locale code for the given locale name. The returned locale code is formatted for use with\nsetlocale(). If normalization fails, the original name is returned unchanged.\n\n[2] \'mon_thousands_sep\'\nGroup separator used for monetary\nvalues. \'mon_grouping\'\nEquivalent to \'grouping\', used for\nmonetary values. \'positive_sign\'\nSymbol used to annotate a positive\nmonetary value. \'negative_sign\'\nSymbol used to annotate a negative\nmonetary value. \'p_sign_posn/n_sign_posn\'\nThe position of the sign (for positive\nresp. negative values), see below. All numeric values can be set to CHAR_MAX to indicate that there is no value specified in this locale. The possible values for \'p_sign_posn\' and \'n_sign_posn\' are given below. Value\nExplanation\n0\nCurrency and value are surrounded by parentheses. 1\nThe sign should precede the value and currency symbol. 2\nThe sign should follow the value and currency symbol. 3\nThe sign should immediately precede the value. 4\nThe sign should immediately follow the value. CHAR_MAX\nNothing is specified in this locale. The function temporarily sets the LC_CTYPE locale to the LC_NUMERIC locale or the LC_MONETARY locale\nif locales are different and numeric or monetary strings are non-ASCII. This temporary change affects other\nthreads. Changed in version 3.7: The function now temporarily sets the LC_CTYPE locale to the LC_NUMERIC locale\nin some cases. locale.nl_langinfo(option)\n1544\nChapter 24. Internationalization\n\nThe Python Library Reference, Release 3.13.2\nReturn some locale-specific information as a string. This function is not available on all systems, and the set\nof possible options might also vary across platforms. The possible argument values are numbers, for which\nsymbolic constants are available in the locale module. The nl_langinfo() function accepts one of the following keys. Most descriptions are taken from the cor-\nresponding description in the GNU C library. locale.CODESET\nGet a string with the name of the character encoding used in the selected locale. locale.D_T_FMT\nGet a string that can be used as a format string for time.strftime() to represent date and time in a\nlocale-specific way. locale.D_FMT\nGet a string that can be used as a format string for time.strftime() to represent a date in a locale-\nspecific way. locale.T_FMT\nGet a string that can be used as a format string for time.strftime() to represent a time in a locale-\nspecific way. locale.T_FMT_AMPM\nGet a format string for time.strftime() to represent time in the am/pm format. locale.DAY_1\nlocale.DAY_2\nlocale.DAY_3\nlocale.DAY_4\nlocale.DAY_5\nlocale.DAY_6\nlocale.DAY_7\nGet the name of the n-th day of the week. ® Note\nThis follows the US convention of DAY_1 being Sunday, not the international convention (ISO 8601)\nthat Monday is the first day of the week. locale.ABDAY_1\nlocale.ABDAY_2\nlocale.ABDAY_3\nlocale.ABDAY_4\nlocale.ABDAY_5\nlocale.ABDAY_6\nlocale.ABDAY_7\nGet the abbreviated name of the n-th day of the week. locale.MON_1\nlocale.MON_2\nlocale.MON_3\nlocale.MON_4\nlocale.MON_5\nlocale.MON_6\n24.2. locale — Internationalization services\n1545\n\nThe Python Library Reference, Release 3.13.2\nlocale.MON_7\nlocale.MON_8\nlocale.MON_9\nlocale.MON_10\nlocale.MON_11\nlocale.MON_12\nGet the name of the n-th month. locale.ABMON_1\nlocale.ABMON_2\nlocale.ABMON_3\nlocale.ABMON_4\nlocale.ABMON_5\nlocale.ABMON_6\nlocale.ABMON_7\nlocale.ABMON_8\nlocale.ABMON_9\nlocale.ABMON_10\nlocale.ABMON_11\nlocale.ABMON_12\nGet the abbreviated name of the n-th month. locale.RADIXCHAR\nGet the radix character (decimal dot, decimal comma, etc.). locale.THOUSEP\nGet the separator character for thousands (groups of three digits). locale.YESEXPR\nGet a regular expression that can be used with the regex function to recognize a positive response to a\nyes/no question. locale.NOEXPR\nGet a regular expression that can be used with the regex(3) function to recognize a negative response\nto a yes/no question. ® Note\nThe regular expressions for YESEXPR and NOEXPR use syntax suitable for the regex function from\nthe C library, which might differ from the syntax used in re. locale.CRNCYSTR\nGet the currency symbol, preceded by “-” if the symbol should appear before the value, “+” if the symbol\nshould appear after the value, or “.” if the symbol should replace the radix character. locale.ERA\nGet a string which describes how years are counted and displayed for each era in a locale. Most locales do not define this value. An example of a locale which does define this value is the Japanese\none. In Japan, the traditional representation of dates includes the name of the era corresponding to the\nthen-emperor’s reign. Normally it should not be necessary to use this value directly. Specifying the E modifier in their format\nstrings causes the time.strftime() function to use this information. The format of the returned string\nis specified in The Open Group Base Specifications Issue 8, paragraph 7.3.5.2 LC_TIME C-Language\nAccess. 1546\nChapter 24. Internationalization\n\nThe Python Library Reference, Release 3.13.2\nlocale.ERA_D_T_FMT\nGet a format string for time.strftime() to represent date and time in a locale-specific era-based way. locale.ERA_D_FMT\nGet a format string for time.strftime() to represent a date in a locale-specific era-based way. locale.ERA_T_FMT\nGet a format string for time.strftime() to represent a time in a locale-specific era-based way. locale.ALT_DIGITS\nGet a string consisting of up to 100 semicolon-separated symbols used to represent the values 0 to 99 in\na locale-specific way.\n\n[3] locale.THOUSEP\nGet the separator character for thousands (groups of three digits). locale.YESEXPR\nGet a regular expression that can be used with the regex function to recognize a positive response to a\nyes/no question. locale.NOEXPR\nGet a regular expression that can be used with the regex(3) function to recognize a negative response\nto a yes/no question. ® Note\nThe regular expressions for YESEXPR and NOEXPR use syntax suitable for the regex function from\nthe C library, which might differ from the syntax used in re. locale.CRNCYSTR\nGet the currency symbol, preceded by “-” if the symbol should appear before the value, “+” if the symbol\nshould appear after the value, or “.” if the symbol should replace the radix character. locale.ERA\nGet a string which describes how years are counted and displayed for each era in a locale. Most locales do not define this value. An example of a locale which does define this value is the Japanese\none. In Japan, the traditional representation of dates includes the name of the era corresponding to the\nthen-emperor’s reign. Normally it should not be necessary to use this value directly. Specifying the E modifier in their format\nstrings causes the time.strftime() function to use this information. The format of the returned string\nis specified in The Open Group Base Specifications Issue 8, paragraph 7.3.5.2 LC_TIME C-Language\nAccess. 1546\nChapter 24. Internationalization\n\nThe Python Library Reference, Release 3.13.2\nlocale.ERA_D_T_FMT\nGet a format string for time.strftime() to represent date and time in a locale-specific era-based way. locale.ERA_D_FMT\nGet a format string for time.strftime() to represent a date in a locale-specific era-based way. locale.ERA_T_FMT\nGet a format string for time.strftime() to represent a time in a locale-specific era-based way. locale.ALT_DIGITS\nGet a string consisting of up to 100 semicolon-separated symbols used to represent the values 0 to 99 in\na locale-specific way. In most locales this is an empty string. locale.getdefaultlocale([envvars])\nTries to determine the default locale settings and returns them as a tuple of the form (language code,\nencoding). According to POSIX, a program which has not called setlocale(LC_ALL, \'\') runs using the portable \'C\'\nlocale. Calling setlocale(LC_ALL, \'\') lets it use the default locale as defined by the LANG variable. Since\nwe do not want to interfere with the current locale setting we thus emulate the behavior in the way described\nabove. To maintain compatibility with other platforms, not only the LANG variable is tested, but a list of variables\ngiven as envvars parameter. The first found to be defined will be used. envvars defaults to the search path used\nin GNU gettext; it must always contain the variable name \'LANG\'. The GNU gettext search path contains\n\'LC_ALL\', \'LC_CTYPE\', \'LANG\' and \'LANGUAGE\', in that order. Except for the code \'C\', the language code corresponds to RFC 1766. language code and encoding may be\nNone if their values cannot be determined. Deprecated since version 3.11, will be removed in version 3.15.\nlocale.getlocale(category=LC_CTYPE)\nReturns the current setting for the given locale category as sequence containing language code, encoding. cat-\negory may be one of the LC_* values except LC_ALL. It defaults to LC_CTYPE. Except for the code \'C\', the language code corresponds to RFC 1766. language code and encoding may be\nNone if their values cannot be determined. locale.getpreferredencoding(do_setlocale=True)\nReturn the locale encoding used for text data, according to user preferences. User preferences are expressed\ndifferently on different systems, and might not be available programmatically on some systems, so this function\nonly returns a guess. On some systems, it is necessary to invoke setlocale() to obtain the user preferences, so this function is\nnot thread-safe. If invoking setlocale is not necessary or desired, do_setlocale should be set to False. On Android or if the Python UTF-8 Mode is enabled, always return \'utf-8\', the locale encoding and the\ndo_setlocale argument are ignored. The Python preinitialization configures the LC_CTYPE locale. See also the filesystem encoding and error\nhandler. Changed in version 3.7: The function now always returns ""utf-8"" on Android or if the Python UTF-8 Mode\nis enabled. locale.getencoding()\nGet the current locale encoding:\n• On Android and VxWorks, return ""utf-8"". • On\nUnix,\nreturn\nthe\nencoding\nof\nthe\ncurrent\nLC_CTYPE\nlocale. Return\n""utf-8""\nif\nnl_langinfo(CODESET) returns an empty string:\nfor example, if the current LC_CTYPE lo-\ncale is not supported. • On Windows, return the ANSI code page. 24.2. locale — Internationalization services\n1547\n\nThe Python Library Reference, Release 3.13.2\nThe Python preinitialization configures the LC_CTYPE locale. See also the filesystem encoding and error\nhandler. This function is similar to getpreferredencoding(False) except this function ignores the Python UTF-8\nMode. Added in version 3.11.\nlocale.normalize(localename)\nReturns a normalized locale code for the given locale name. The returned locale code is formatted for use with\nsetlocale(). If normalization fails, the original name is returned unchanged. If the given encoding is not known, the function defaults to the default encoding for the locale code just like\nsetlocale(). locale.strcoll(string1, string2)\nCompares two strings according to the current LC_COLLATE setting.')",6.604786423778278e-79,0.10719754977029096,0.25970746557066804,0.51290363073349,0.15034664
Extracting extension from filename,"Use 
os.path.splitext
:


>>> import os
>>> filename, file_extension = os.path.splitext('/path/to/somefile.ext')
>>> filename
'/path/to/somefile'
>>> file_extension
'.ext'



Unlike most manual string-splitting attempts, 
os.path.splitext
 will correctly treat 
/a/b.c/d
 as having no extension instead of having extension 
.c/d
, and it will treat 
.bashrc
 as having no extension instead of having extension 
.bashrc
:


>>> os.path.splitext('/a/b.c/d')
('/a/b.c/d', '')
>>> os.path.splitext('.bashrc')
('.bashrc', '')


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . 586\n13.6\ntarfile — Read and write tar archive files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587\nvi\n\n13.6.1\nTarFile Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591\n13.6.2\nTarInfo Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594\n13.6.3\nExtraction filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . 477\n11.5\ntempfile — Generate temporary files and directories . . . . . . . . . . . . . . . . . . . . . . . 478\n11.5.1\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482\n11.5.2\nDeprecated functions and variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483\n11.6\nglob — Unix style pathname pattern expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 484\n11.6.1\nExamples\n. . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1309\n20.3.3\nExceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1317\n20.3.4\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1317\n20.4\nmimetypes — Map filenames to MIME types\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 1318\n20.4.1\nMimeTypes Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",3.753488397773257e-232,0.030769230769230767,0.034698126301179744,0.4687020182609558,0.08443123
How do I write JSON data to a file?,"data
 is a Python dictionary. It needs to be encoded as JSON before writing.


Use this for maximum compatibility (Python 2 and 3):


import json
with open('data.json', 'w') as f:
    json.dump(data, f)



On a modern system (i.e. Python 3 and UTF-8 support), you can write a nicer file using:


import json
with open('data.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, ensure_ascii=False, indent=4)



See 
json
 documentation.

","('Answer: To write JSON data to a file, you can use the `json.dump(x, f)` function where `x` is the object to be serialized and `f` is the text file object opened for writing. Ensure the file is opened with `encoding=""utf-8""` for proper encoding.\n\nReferences: [3]\n', '[1] . 56\n7.1.4\nOld string formatting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2\nReading and Writing Files\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2.1\nMethods of File Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n7.2.2\nSaving structured data with json . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n8\nErrors and Exceptions\n61\n8.1\nSyntax Errors . . . . . . . . . . . . . . . . .\n\n[2] . . . 58\n7.2.2\nSaving structured data with json . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n8\nErrors and Exceptions\n61\n8.1\nSyntax Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n8.2\nExceptions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61\n8.3\nHandling Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\n8.4\nRaising Exceptions . . . . .\n\n[3] Appending a \'b\' to the mode opens the file in binary mode. Binary mode data is read and written\nas bytes objects. You can not specify encoding when opening file in binary mode. In text mode, the default when reading is to convert platform-specific line endings (\\n on Unix, \\r\\n on Windows)\nto just \\n. When writing in text mode, the default is to convert occurrences of \\n back to platform-specific line\nendings. This behind-the-scenes modification to file data is fine for text files, but will corrupt binary data like that in\nJPEG or EXE files. Be very careful to use binary mode when reading and writing such files. It is good practice to use the with keyword when dealing with file objects. The advantage is that the file is properly\nclosed after its suite finishes, even if an exception is raised at some point. Using with is also much shorter than\nwriting equivalent try-finally blocks:\n>>> with open(\'workfile\', encoding=""utf-8"") as f:\n...\nread_data = f.read()\n>>> # We can check that the file has been automatically closed. >>> f.closed\nTrue\nIf you’re not using the with keyword, then you should call f.close() to close the file and immediately free up any\nsystem resources used by it. Á Warning\nCalling f.write() without using the with keyword or calling f.close() might result in the arguments of\nf.write() not being completely written to the disk, even if the program exits successfully. 7.2. Reading and Writing Files\n57\n\nPython Tutorial, Release 3.13.2\nAfter a file object is closed, either by a with statement or by calling f.close(), attempts to use the file object will\nautomatically fail. >>> f.close()\n>>> f.read()\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nValueError: I/O operation on closed file. 7.2.1 Methods of File Objects\nThe rest of the examples in this section will assume that a file object called f has already been created. To read a file’s contents, call f.read(size), which reads some quantity of data and returns it as a string (in text\nmode) or bytes object (in binary mode). size is an optional numeric argument. When size is omitted or negative, the\nentire contents of the file will be read and returned; it’s your problem if the file is twice as large as your machine’s\nmemory. Otherwise, at most size characters (in text mode) or size bytes (in binary mode) are read and returned. If\nthe end of the file has been reached, f.read() will return an empty string (\'\'). >>> f.read()\n\'This is the entire file.\\n\'\n>>> f.read()\n\'\'\nf.readline() reads a single line from the file; a newline character (\\n) is left at the end of the string, and is only\nomitted on the last line of the file if the file doesn’t end in a newline. This makes the return value unambiguous; if\nf.readline() returns an empty string, the end of the file has been reached, while a blank line is represented by\n\'\\n\', a string containing only a single newline. >>> f.readline()\n\'This is the first line of the file.\\n\'\n>>> f.readline()\n\'Second line of the file\\n\'\n>>> f.readline()\n\'\'\nFor reading lines from a file, you can loop over the file object. This is memory efficient, fast, and leads to simple\ncode:\n>>> for line in f:\n...\nprint(line, end=\'\')\n... This is the first line of the file. Second line of the file\nIf you want to read all the lines of a file in a list you can also use list(f) or f.readlines(). f.write(string) writes the contents of string to the file, returning the number of characters written. >>> f.write(\'This is a test\\n\')\n15\nOther types of objects need to be converted – either to a string (in text mode) or a bytes object (in binary mode) –\nbefore writing them:\n>>> value = (\'the answer\', 42)\n>>> s = str(value)\n# convert the tuple to string\n>>> f.write(s)\n18\n58\nChapter 7. Input and Output\n\nPython Tutorial, Release 3.13.2\nf.tell() returns an integer giving the file object’s current position in the file represented as number of bytes from\nthe beginning of the file when in binary mode and an opaque number when in text mode. To change the file object’s position, use f.seek(offset, whence). The position is computed from adding offset\nto a reference point; the reference point is selected by the whence argument. A whence value of 0 measures from the\nbeginning of the file, 1 uses the current file position, and 2 uses the end of the file as the reference point. whence can\nbe omitted and defaults to 0, using the beginning of the file as the reference point. >>> f = open(\'workfile\', \'rb+\')\n>>> f.write(b\'0123456789abcdef\')\n16\n>>> f.seek(5)\n# Go to the 6th byte in the file\n5\n>>> f.read(1)\nb\'5\'\n>>> f.seek(-3, 2)\n# Go to the 3rd byte before the end\n13\n>>> f.read(1)\nb\'d\'\nIn text files (those opened without a b in the mode string), only seeks relative to the beginning of the file are allowed\n(the exception being seeking to the very file end with seek(0, 2)) and the only valid offset values are those returned\nfrom the f.tell(), or zero. Any other offset value produces undefined behaviour. File objects have some additional methods, such as isatty() and truncate() which are less frequently used;\nconsult the Library Reference for a complete guide to file objects. 7.2.2 Saving structured data with json\nStrings can easily be written to and read from a file. Numbers take a bit more effort, since the read() method only\nreturns strings, which will have to be passed to a function like int(), which takes a string like \'123\' and returns its\nnumeric value 123. When you want to save more complex data types like nested lists and dictionaries, parsing and\nserializing by hand becomes complicated. Rather than having users constantly writing and debugging code to save complicated data types to files, Python allows\nyou to use the popular data interchange format called JSON (JavaScript Object Notation). The standard module called\njson can take Python data hierarchies, and convert them to string representations; this process is called serializing. Reconstructing the data from the string representation is called deserializing. Between serializing and deserializing,\nthe string representing the object may have been stored in a file or data, or sent over a network connection to some\ndistant machine. ® Note\nThe JSON format is commonly used by modern applications to allow for data exchange. Many programmers are\nalready familiar with it, which makes it a good choice for interoperability. If you have an object x, you can view its JSON string representation with a simple line of code:\n>>> import json\n>>> x = [1, \'simple\', \'list\']\n>>> json.dumps(x)\n\'[1, ""simple"", ""list""]\'\nAnother variant of the dumps() function, called dump(), simply serializes the object to a text file. So if f is a text\nfile object opened for writing, we can do this:\njson.dump(x, f)\nTo decode the object again, if f is a binary file or text file object which has been opened for reading:\n7.2. Reading and Writing Files\n59\n\nPython Tutorial, Release 3.13.2\nx = json.load(f)\n® Note\nJSON files must be encoded in UTF-8. Use encoding=""utf-8"" when opening JSON file as a text file for both\nof reading and writing. This simple serialization technique can handle lists and dictionaries, but serializing arbitrary class instances in JSON\nrequires a bit of extra effort.')",1.3625528817675528e-155,0.045513654096228866,0.164842598684674,0.5276677012443542,0.6112385
How can I import a module dynamically given the full path?,"Let's have 
MyClass
 in 
module.name
 module defined at 
/path/to/file.py
. Below is how we import 
MyClass
 from this module


For Python 3.5+ use (
docs
):


import importlib.util
import sys
spec = importlib.util.spec_from_file_location(""module.name"", ""/path/to/file.py"")
foo = importlib.util.module_from_spec(spec)
sys.modules[""module.name""] = foo
spec.loader.exec_module(foo)
foo.MyClass()



For Python 3.3 and 3.4 use:


from importlib.machinery import SourceFileLoader

foo = SourceFileLoader(""module.name"", ""/path/to/file.py"").load_module()
foo.MyClass()



(Although this has been deprecated in Python 3.4.)


For Python 2 use:


import imp

foo = imp.load_source('module.name', '/path/to/file.py')
foo.MyClass()



There are equivalent convenience functions for compiled Python files and DLLs.


See also 
http://bugs.python.org/issue21436
.

","('Answer: You can import a module dynamically using the `import_from_path` function, which takes the module name and file path as arguments. This function uses `importlib.util.spec_from_file_location` to create a module specification, then creates the module with `importlib.util.module_from_spec`, adds it to `sys.modules`, and executes the module using `spec.loader.exec_module`.\n\nReferences: [2]\n', '[1] For those same reasons, the loader’s create_module() method must return None\nor a type for which its __class__ attribute can be mutated along with not using slots. Finally, modules which\nsubstitute the object placed into sys.modules will not work as there is no way to properly replace the module\nreferences throughout the interpreter safely; ValueError is raised if such a substitution is detected. ® Note\nFor projects where startup time is critical, this class allows for potentially minimizing the cost of loading\na module if it is never used. For projects where startup time is not essential then use of this class is\nheavily discouraged due to error messages created during loading being postponed and thus occurring out\nof context. 2052\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\nAdded in version 3.5. Changed in version 3.6:\nBegan calling create_module(), removing the compatibility warning for\nimportlib.machinery.BuiltinImporter and importlib.machinery.ExtensionFileLoader. classmethod factory(loader)\nA class method which returns a callable that creates a lazy loader. This is meant to be used in situations\nwhere the loader is passed by class instead of by instance. suffixes = importlib.machinery.SOURCE_SUFFIXES\nloader = importlib.machinery.SourceFileLoader\nlazy_loader = importlib.util.LazyLoader.factory(loader)\nfinder = importlib.machinery.FileFinder(path, (lazy_loader, suffixes))\n32.5.6 Examples\nImporting programmatically\nTo programmatically import a module, use importlib.import_module(). import importlib\nitertools = importlib.import_module(\'itertools\')\nChecking if a module can be imported\nIf you need to find out if a module can be imported without actually doing the import, then you should use\nimportlib.util.find_spec(). Note that if name is a submodule (contains a dot), importlib.util.find_spec() will import the parent module. import importlib.util\nimport sys\n# For illustrative purposes. name = \'itertools\'\nif name in sys.modules:\nprint(f""{name!r} already in sys.modules"")\nelif (spec := importlib.util.find_spec(name)) is not None:\n# If you chose to perform the actual import ...\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[name] = module\nspec.loader.exec_module(module)\nprint(f""{name!r} has been imported"")\nelse:\nprint(f""can\'t find the {name!r} module"")\nImporting a source file directly\nThis recipe should be used with caution: it is an approximation of an import statement where the file path is specified\ndirectly, rather than sys.path being searched. Alternatives should first be considered first, such as modifying sys. path when a proper module is required, or using runpy.run_path() when the global namespace resulting from\nrunning a Python file is appropriate. To import a Python source file directly from a path, use the following recipe:\nimport importlib.util\nimport sys\n(continues on next page)\n32.5. importlib — The implementation of import\n2053\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\ndef import_from_path(module_name, file_path):\nspec = importlib.util.spec_from_file_location(module_name, file_path)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[module_name] = module\nspec.loader.exec_module(module)\nreturn module\n# For illustrative purposes only (use of `json` is arbitrary). import json\nfile_path = json.__file__\nmodule_name = json.__name__\n# Similar outcome as `import json`. json = import_from_path(module_name, file_path)\nImplementing lazy imports\nThe example below shows how to implement lazy imports:\n>>> import importlib.util\n>>> import sys\n>>> def lazy_import(name):\n...\nspec = importlib.util.find_spec(name)\n...\nloader = importlib.util.LazyLoader(spec.loader)\n...\nspec.loader = loader\n...\nmodule = importlib.util.module_from_spec(spec)\n...\nsys.modules[name] = module\n...\nloader.exec_module(module)\n...\nreturn module\n...\n>>> lazy_typing = lazy_import(""typing"")\n>>> #lazy_typing is a real module object,\n>>> #but it is not loaded in memory yet. >>> lazy_typing.TYPE_CHECKING\nFalse\nSetting up an importer\nFor deep customizations of import, you typically want to implement an importer. This means managing both the\nfinder and loader side of things. For finders there are two flavours to choose from depending on your needs: a meta\npath finder or a path entry finder. The former is what you would put on sys.meta_path while the latter is what\nyou create using a path entry hook on sys.path_hooks which works with sys.path entries to potentially create\na finder. This example will show you how to register your own importers so that import will use them (for creating\nan importer for yourself, read the documentation for the appropriate classes defined within this package):\nimport importlib.machinery\nimport sys\n# For illustrative purposes only. SpamMetaPathFinder = importlib.machinery.PathFinder\nSpamPathEntryFinder = importlib.machinery.FileFinder\nloader_details = (importlib.machinery.SourceFileLoader,\nimportlib.machinery.SOURCE_SUFFIXES)\n(continues on next page)\n2054\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n# Setting up a meta path finder. # Make sure to put the finder in the proper location in the list in terms of\n# priority. sys.meta_path.append(SpamMetaPathFinder)\n# Setting up a path entry finder. # Make sure to put the path hook in the proper location in the list in terms\n# of priority. sys.path_hooks.append(SpamPathEntryFinder.path_hook(loader_details))\nApproximating importlib.import_module()\nImport itself is implemented in Python code, making it possible to expose most of the import machinery through\nimportlib. The following helps illustrate the various APIs that importlib exposes by providing an approximate im-\nplementation of importlib.import_module():\nimport importlib.util\nimport sys\ndef import_module(name, package=None):\n""""""An approximate implementation of import."""""" absolute_name = importlib.util.resolve_name(name, package)\ntry:\nreturn sys.modules[absolute_name]\nexcept KeyError:\npass\npath = None\nif \'.\' in absolute_name:\nparent_name, _, child_name = absolute_name.rpartition(\'.\') parent_module = import_module(parent_name)\npath = parent_module.__spec__.submodule_search_locations\nfor finder in sys.meta_path:\nspec = finder.find_spec(absolute_name, path)\nif spec is not None:\nbreak\nelse:\nmsg = f\'No module named {absolute_name!r}\'\nraise ModuleNotFoundError(msg, name=absolute_name)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[absolute_name] = module\nspec.loader.exec_module(module)\nif path is not None:\nsetattr(parent_module, child_name, module)\nreturn module\n32.6 importlib.resources – Package resource reading, opening\nand access\nSource code: Lib/importlib/resources/__init__.py\nAdded in version 3.7. This module leverages Python’s import system to provide access to resources within packages. 32.6. importlib.resources – Package resource reading, opening and access\n2055\n\nThe Python Library Reference, Release 3.13.2\n“Resources” are file-like resources associated with a module or package in Python. The resources may be contained\ndirectly in a package, within a subdirectory contained in that package, or adjacent to modules outside a package. Resources may be text or binary. As a result, Python module sources (.py) of a package and compilation artifacts\n(pycache) are technically de-facto resources of that package. In practice, however, resources are primarily those\nnon-Python artifacts exposed specifically by the package author. Resources can be opened or read in either binary or text mode. Resources are roughly akin to files inside directories, though it’s important to keep in mind that this is just a metaphor. Resources and packages do not have to exist as physical files and directories on the file system: for example, a package\nand its resources can be imported from a zip file using zipimport. ® Note\nThis module provides functionality similar to pkg_resources Basic Resource Access without the performance\noverhead of that package. This makes reading resources included in packages easier, with more stable and con-\nsistent semantics. The standalone backport of this module provides more information on using importlib.resources and migrating\nfrom pkg_resources to importlib.resources. Loaders that wish to support resource reading should implement a get_resource_reader(fullname) method\nas specified by importlib.resources.abc.ResourceReader. class importlib.resources.Anchor\nRepresents an anchor for resources, either a module object or a module name as a string. Defined as\nUnion[str, ModuleType]. importlib.resources.files(anchor: Anchor | None = None)\nReturns a Traversable object representing the resource container (think directory) and its resources (think\nfiles). A Traversable may contain other containers (think subdirectories).\n\n[2] Finally, modules which\nsubstitute the object placed into sys.modules will not work as there is no way to properly replace the module\nreferences throughout the interpreter safely; ValueError is raised if such a substitution is detected. ® Note\nFor projects where startup time is critical, this class allows for potentially minimizing the cost of loading\na module if it is never used. For projects where startup time is not essential then use of this class is\nheavily discouraged due to error messages created during loading being postponed and thus occurring out\nof context. 2052\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\nAdded in version 3.5. Changed in version 3.6:\nBegan calling create_module(), removing the compatibility warning for\nimportlib.machinery.BuiltinImporter and importlib.machinery.ExtensionFileLoader. classmethod factory(loader)\nA class method which returns a callable that creates a lazy loader. This is meant to be used in situations\nwhere the loader is passed by class instead of by instance. suffixes = importlib.machinery.SOURCE_SUFFIXES\nloader = importlib.machinery.SourceFileLoader\nlazy_loader = importlib.util.LazyLoader.factory(loader)\nfinder = importlib.machinery.FileFinder(path, (lazy_loader, suffixes))\n32.5.6 Examples\nImporting programmatically\nTo programmatically import a module, use importlib.import_module(). import importlib\nitertools = importlib.import_module(\'itertools\')\nChecking if a module can be imported\nIf you need to find out if a module can be imported without actually doing the import, then you should use\nimportlib.util.find_spec(). Note that if name is a submodule (contains a dot), importlib.util.find_spec() will import the parent module. import importlib.util\nimport sys\n# For illustrative purposes. name = \'itertools\'\nif name in sys.modules:\nprint(f""{name!r} already in sys.modules"")\nelif (spec := importlib.util.find_spec(name)) is not None:\n# If you chose to perform the actual import ...\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[name] = module\nspec.loader.exec_module(module)\nprint(f""{name!r} has been imported"")\nelse:\nprint(f""can\'t find the {name!r} module"")\nImporting a source file directly\nThis recipe should be used with caution: it is an approximation of an import statement where the file path is specified\ndirectly, rather than sys.path being searched. Alternatives should first be considered first, such as modifying sys. path when a proper module is required, or using runpy.run_path() when the global namespace resulting from\nrunning a Python file is appropriate. To import a Python source file directly from a path, use the following recipe:\nimport importlib.util\nimport sys\n(continues on next page)\n32.5. importlib — The implementation of import\n2053\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\ndef import_from_path(module_name, file_path):\nspec = importlib.util.spec_from_file_location(module_name, file_path)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[module_name] = module\nspec.loader.exec_module(module)\nreturn module\n# For illustrative purposes only (use of `json` is arbitrary). import json\nfile_path = json.__file__\nmodule_name = json.__name__\n# Similar outcome as `import json`. json = import_from_path(module_name, file_path)\nImplementing lazy imports\nThe example below shows how to implement lazy imports:\n>>> import importlib.util\n>>> import sys\n>>> def lazy_import(name):\n...\nspec = importlib.util.find_spec(name)\n...\nloader = importlib.util.LazyLoader(spec.loader)\n...\nspec.loader = loader\n...\nmodule = importlib.util.module_from_spec(spec)\n...\nsys.modules[name] = module\n...\nloader.exec_module(module)\n...\nreturn module\n...\n>>> lazy_typing = lazy_import(""typing"")\n>>> #lazy_typing is a real module object,\n>>> #but it is not loaded in memory yet. >>> lazy_typing.TYPE_CHECKING\nFalse\nSetting up an importer\nFor deep customizations of import, you typically want to implement an importer. This means managing both the\nfinder and loader side of things. For finders there are two flavours to choose from depending on your needs: a meta\npath finder or a path entry finder. The former is what you would put on sys.meta_path while the latter is what\nyou create using a path entry hook on sys.path_hooks which works with sys.path entries to potentially create\na finder. This example will show you how to register your own importers so that import will use them (for creating\nan importer for yourself, read the documentation for the appropriate classes defined within this package):\nimport importlib.machinery\nimport sys\n# For illustrative purposes only. SpamMetaPathFinder = importlib.machinery.PathFinder\nSpamPathEntryFinder = importlib.machinery.FileFinder\nloader_details = (importlib.machinery.SourceFileLoader,\nimportlib.machinery.SOURCE_SUFFIXES)\n(continues on next page)\n2054\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n# Setting up a meta path finder. # Make sure to put the finder in the proper location in the list in terms of\n# priority. sys.meta_path.append(SpamMetaPathFinder)\n# Setting up a path entry finder. # Make sure to put the path hook in the proper location in the list in terms\n# of priority. sys.path_hooks.append(SpamPathEntryFinder.path_hook(loader_details))\nApproximating importlib.import_module()\nImport itself is implemented in Python code, making it possible to expose most of the import machinery through\nimportlib. The following helps illustrate the various APIs that importlib exposes by providing an approximate im-\nplementation of importlib.import_module():\nimport importlib.util\nimport sys\ndef import_module(name, package=None):\n""""""An approximate implementation of import."""""" absolute_name = importlib.util.resolve_name(name, package)\ntry:\nreturn sys.modules[absolute_name]\nexcept KeyError:\npass\npath = None\nif \'.\' in absolute_name:\nparent_name, _, child_name = absolute_name.rpartition(\'.\') parent_module = import_module(parent_name)\npath = parent_module.__spec__.submodule_search_locations\nfor finder in sys.meta_path:\nspec = finder.find_spec(absolute_name, path)\nif spec is not None:\nbreak\nelse:\nmsg = f\'No module named {absolute_name!r}\'\nraise ModuleNotFoundError(msg, name=absolute_name)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[absolute_name] = module\nspec.loader.exec_module(module)\nif path is not None:\nsetattr(parent_module, child_name, module)\nreturn module\n32.6 importlib.resources – Package resource reading, opening\nand access\nSource code: Lib/importlib/resources/__init__.py\nAdded in version 3.7. This module leverages Python’s import system to provide access to resources within packages. 32.6. importlib.resources – Package resource reading, opening and access\n2055\n\nThe Python Library Reference, Release 3.13.2\n“Resources” are file-like resources associated with a module or package in Python. The resources may be contained\ndirectly in a package, within a subdirectory contained in that package, or adjacent to modules outside a package. Resources may be text or binary. As a result, Python module sources (.py) of a package and compilation artifacts\n(pycache) are technically de-facto resources of that package. In practice, however, resources are primarily those\nnon-Python artifacts exposed specifically by the package author. Resources can be opened or read in either binary or text mode. Resources are roughly akin to files inside directories, though it’s important to keep in mind that this is just a metaphor. Resources and packages do not have to exist as physical files and directories on the file system: for example, a package\nand its resources can be imported from a zip file using zipimport. ® Note\nThis module provides functionality similar to pkg_resources Basic Resource Access without the performance\noverhead of that package. This makes reading resources included in packages easier, with more stable and con-\nsistent semantics. The standalone backport of this module provides more information on using importlib.resources and migrating\nfrom pkg_resources to importlib.resources. Loaders that wish to support resource reading should implement a get_resource_reader(fullname) method\nas specified by importlib.resources.abc.ResourceReader. class importlib.resources.Anchor\nRepresents an anchor for resources, either a module object or a module name as a string. Defined as\nUnion[str, ModuleType]. importlib.resources.files(anchor: Anchor | None = None)\nReturns a Traversable object representing the resource container (think directory) and its resources (think\nfiles). A Traversable may contain other containers (think subdirectories). anchor is an optional Anchor.\n\n[3] This class only works with loaders that define exec_module() as control over what module type is used for\nthe module is required. For those same reasons, the loader’s create_module() method must return None\nor a type for which its __class__ attribute can be mutated along with not using slots. Finally, modules which\nsubstitute the object placed into sys.modules will not work as there is no way to properly replace the module\nreferences throughout the interpreter safely; ValueError is raised if such a substitution is detected. ® Note\nFor projects where startup time is critical, this class allows for potentially minimizing the cost of loading\na module if it is never used. For projects where startup time is not essential then use of this class is\nheavily discouraged due to error messages created during loading being postponed and thus occurring out\nof context. 2052\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\nAdded in version 3.5. Changed in version 3.6:\nBegan calling create_module(), removing the compatibility warning for\nimportlib.machinery.BuiltinImporter and importlib.machinery.ExtensionFileLoader. classmethod factory(loader)\nA class method which returns a callable that creates a lazy loader. This is meant to be used in situations\nwhere the loader is passed by class instead of by instance. suffixes = importlib.machinery.SOURCE_SUFFIXES\nloader = importlib.machinery.SourceFileLoader\nlazy_loader = importlib.util.LazyLoader.factory(loader)\nfinder = importlib.machinery.FileFinder(path, (lazy_loader, suffixes))\n32.5.6 Examples\nImporting programmatically\nTo programmatically import a module, use importlib.import_module(). import importlib\nitertools = importlib.import_module(\'itertools\')\nChecking if a module can be imported\nIf you need to find out if a module can be imported without actually doing the import, then you should use\nimportlib.util.find_spec(). Note that if name is a submodule (contains a dot), importlib.util.find_spec() will import the parent module. import importlib.util\nimport sys\n# For illustrative purposes. name = \'itertools\'\nif name in sys.modules:\nprint(f""{name!r} already in sys.modules"")\nelif (spec := importlib.util.find_spec(name)) is not None:\n# If you chose to perform the actual import ...\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[name] = module\nspec.loader.exec_module(module)\nprint(f""{name!r} has been imported"")\nelse:\nprint(f""can\'t find the {name!r} module"")\nImporting a source file directly\nThis recipe should be used with caution: it is an approximation of an import statement where the file path is specified\ndirectly, rather than sys.path being searched. Alternatives should first be considered first, such as modifying sys. path when a proper module is required, or using runpy.run_path() when the global namespace resulting from\nrunning a Python file is appropriate. To import a Python source file directly from a path, use the following recipe:\nimport importlib.util\nimport sys\n(continues on next page)\n32.5. importlib — The implementation of import\n2053\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\ndef import_from_path(module_name, file_path):\nspec = importlib.util.spec_from_file_location(module_name, file_path)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[module_name] = module\nspec.loader.exec_module(module)\nreturn module\n# For illustrative purposes only (use of `json` is arbitrary). import json\nfile_path = json.__file__\nmodule_name = json.__name__\n# Similar outcome as `import json`. json = import_from_path(module_name, file_path)\nImplementing lazy imports\nThe example below shows how to implement lazy imports:\n>>> import importlib.util\n>>> import sys\n>>> def lazy_import(name):\n...\nspec = importlib.util.find_spec(name)\n...\nloader = importlib.util.LazyLoader(spec.loader)\n...\nspec.loader = loader\n...\nmodule = importlib.util.module_from_spec(spec)\n...\nsys.modules[name] = module\n...\nloader.exec_module(module)\n...\nreturn module\n...\n>>> lazy_typing = lazy_import(""typing"")\n>>> #lazy_typing is a real module object,\n>>> #but it is not loaded in memory yet. >>> lazy_typing.TYPE_CHECKING\nFalse\nSetting up an importer\nFor deep customizations of import, you typically want to implement an importer. This means managing both the\nfinder and loader side of things. For finders there are two flavours to choose from depending on your needs: a meta\npath finder or a path entry finder. The former is what you would put on sys.meta_path while the latter is what\nyou create using a path entry hook on sys.path_hooks which works with sys.path entries to potentially create\na finder. This example will show you how to register your own importers so that import will use them (for creating\nan importer for yourself, read the documentation for the appropriate classes defined within this package):\nimport importlib.machinery\nimport sys\n# For illustrative purposes only. SpamMetaPathFinder = importlib.machinery.PathFinder\nSpamPathEntryFinder = importlib.machinery.FileFinder\nloader_details = (importlib.machinery.SourceFileLoader,\nimportlib.machinery.SOURCE_SUFFIXES)\n(continues on next page)\n2054\nChapter 32. Importing Modules\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n# Setting up a meta path finder. # Make sure to put the finder in the proper location in the list in terms of\n# priority. sys.meta_path.append(SpamMetaPathFinder)\n# Setting up a path entry finder. # Make sure to put the path hook in the proper location in the list in terms\n# of priority. sys.path_hooks.append(SpamPathEntryFinder.path_hook(loader_details))\nApproximating importlib.import_module()\nImport itself is implemented in Python code, making it possible to expose most of the import machinery through\nimportlib. The following helps illustrate the various APIs that importlib exposes by providing an approximate im-\nplementation of importlib.import_module():\nimport importlib.util\nimport sys\ndef import_module(name, package=None):\n""""""An approximate implementation of import."""""" absolute_name = importlib.util.resolve_name(name, package)\ntry:\nreturn sys.modules[absolute_name]\nexcept KeyError:\npass\npath = None\nif \'.\' in absolute_name:\nparent_name, _, child_name = absolute_name.rpartition(\'.\') parent_module = import_module(parent_name)\npath = parent_module.__spec__.submodule_search_locations\nfor finder in sys.meta_path:\nspec = finder.find_spec(absolute_name, path)\nif spec is not None:\nbreak\nelse:\nmsg = f\'No module named {absolute_name!r}\'\nraise ModuleNotFoundError(msg, name=absolute_name)\nmodule = importlib.util.module_from_spec(spec)\nsys.modules[absolute_name] = module\nspec.loader.exec_module(module)\nif path is not None:\nsetattr(parent_module, child_name, module)\nreturn module\n32.6 importlib.resources – Package resource reading, opening\nand access\nSource code: Lib/importlib/resources/__init__.py\nAdded in version 3.7. This module leverages Python’s import system to provide access to resources within packages. 32.6. importlib.resources – Package resource reading, opening and access\n2055\n\nThe Python Library Reference, Release 3.13.2\n“Resources” are file-like resources associated with a module or package in Python. The resources may be contained\ndirectly in a package, within a subdirectory contained in that package, or adjacent to modules outside a package. Resources may be text or binary. As a result, Python module sources (.py) of a package and compilation artifacts\n(pycache) are technically de-facto resources of that package. In practice, however, resources are primarily those\nnon-Python artifacts exposed specifically by the package author. Resources can be opened or read in either binary or text mode. Resources are roughly akin to files inside directories, though it’s important to keep in mind that this is just a metaphor. Resources and packages do not have to exist as physical files and directories on the file system: for example, a package\nand its resources can be imported from a zip file using zipimport. ® Note\nThis module provides functionality similar to pkg_resources Basic Resource Access without the performance\noverhead of that package. This makes reading resources included in packages easier, with more stable and con-\nsistent semantics. The standalone backport of this module provides more information on using importlib.resources and migrating\nfrom pkg_resources to importlib.resources. Loaders that wish to support resource reading should implement a get_resource_reader(fullname) method\nas specified by importlib.resources.abc.ResourceReader. class importlib.resources.Anchor\nRepresents an anchor for resources, either a module object or a module name as a string. Defined as\nUnion[str, ModuleType]. importlib.resources.files(anchor: Anchor | None = None)\nReturns a Traversable object representing the resource container (think directory) and its resources (think\nfiles).')",9.50131658758248e-156,0.03853211009174312,0.09385783895121917,0.6211016774177551,0.7757801
Relative imports in Python 3,"

unfortunately, this module needs to be inside the package, and it also
needs to be runnable as a script, sometimes. Any idea how I could
achieve that?




It's quite common to have a layout like this...


main.py
mypackage/
    __init__.py
    mymodule.py
    myothermodule.py



...with a 
mymodule.py
 like this...


#!/usr/bin/env python3

# Exported function
def as_int(a):
    return int(a)

# Test function for module  
def _test():
    assert as_int('1') == 1

if __name__ == '__main__':
    _test()



...a 
myothermodule.py
 like this...


#!/usr/bin/env python3

from .mymodule import as_int

# Exported function
def add(a, b):
    return as_int(a) + as_int(b)

# Test function for module  
def _test():
    assert add('1', '1') == 2

if __name__ == '__main__':
    _test()



...and a 
main.py
 like this...


#!/usr/bin/env python3

from mypackage.myothermodule import add

def main():
    print(add('1', '1'))

if __name__ == '__main__':
    main()



...which works fine when you run 
main.py
 or 
mypackage/mymodule.py
, but fails with 
mypackage/myothermodule.py
, due to the relative import...


from .mymodule import as_int



The way you're supposed to run it is by using the -m option and giving the path in the Python module system (rather than in the filesystem)...


python3 -m mypackage.myothermodule



...but it's somewhat verbose, and doesn't mix well with a shebang line like 
#!/usr/bin/env python3
.


An alternative is to avoid using relative imports, and just use...


from mypackage.mymodule import as_int



Either way, you'll need to run from the parent of 
mypackage
, or add that directory to 
PYTHONPATH
 (either one will ensure that 
mypackage
 is in the sys.path 
module search path
). Or, if you want it to work ""out of the box"", you can frob the 
PYTHONPATH
 in code first with this...


import sys
import os

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.dirname(SCRIPT_DIR))

from mypackage.mymodule import as_int



It's kind of a pain, but there's a clue as to why in 
an email
 written by a certain Guido van Rossum...




I'm -1 on this and on any other proposed twiddlings of the 
__main__

machinery. The only use case seems to be running scripts that happen
to be living inside a module's directory, which I've always seen as an
antipattern. To make me change my mind you'd have to convince me that
it isn't.




Whether running scripts inside a package is an antipattern or not is subjective, but personally I find it really useful in a package I have which contains some custom wxPython widgets, so I can run the script for any of the source files to display a 
wx.Frame
 containing only that widget for testing purposes.

","('Answer: Relative imports in Python use leading dots. A single dot signifies a relative import starting from the current package. Two or more dots indicate a relative import to the parent(s) of the current package, with each dot after the first representing one level up.\n\nReferences: [2]\n', '[1] . . . . . . . . . . . . . . . . 72\n5.5.2\nPath entry finder protocol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.6\nReplacing the standard import system\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.7\nPackage Relative Imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n5.8\nSpecial considerations for __main__ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n5.8.1\n__main__.__spec__ . . . . .\n\n[2] If the path argument is None, this indicates a top level import and sys.path is used. The path based finder iterates over every entry in the search path, and for each of these, looks for an appropriate\npath entry finder (PathEntryFinder) for the path entry. Because this can be an expensive operation (e.g. there\nmay be stat() call overheads for this search), the path based finder maintains a cache mapping path entries to\npath entry finders. This cache is maintained in sys.path_importer_cache (despite the name, this cache actually\nstores finder objects rather than being limited to importer objects). In this way, the expensive search for a particular\npath entry location’s path entry finder need only be done once. User code is free to remove cache entries from\nsys.path_importer_cache forcing the path based finder to perform the path entry search again. If the path entry is not present in the cache, the path based finder iterates over every callable in sys.path_hooks. Each of the path entry hooks in this list is called with a single argument, the path entry to be searched. This callable\n72\nChapter 5. The import system\n\nThe Python Language Reference, Release 3.13.2\nmay either return a path entry finder that can handle the path entry, or it may raise ImportError. An ImportError\nis used by the path based finder to signal that the hook cannot find a path entry finder for that path entry. The exception\nis ignored and import path iteration continues. The hook should expect either a string or bytes object; the encoding\nof bytes objects is up to the hook (e.g. it may be a file system encoding, UTF-8, or something else), and if the hook\ncannot decode the argument, it should raise ImportError. If sys.path_hooks iteration ends with no path entry finder being returned, then the path based finder’s\nfind_spec() method will store None in sys.path_importer_cache (to indicate that there is no finder for\nthis path entry) and return None, indicating that this meta path finder could not find the module. If a path entry finder is returned by one of the path entry hook callables on sys.path_hooks, then the following\nprotocol is used to ask the finder for a module spec, which is then used when loading the module. The current working directory – denoted by an empty string – is handled slightly differently from other en-\ntries on sys.path. First, if the current working directory is found to not exist, no value is stored in sys. path_importer_cache. Second, the value for the current working directory is looked up fresh for each mod-\nule lookup. Third, the path used for sys.path_importer_cache and returned by importlib.machinery. PathFinder.find_spec() will be the actual current working directory and not the empty string. 5.5.2 Path entry finder protocol\nIn order to support imports of modules and initialized packages and also to contribute portions to namespace packages,\npath entry finders must implement the find_spec() method. find_spec() takes two arguments: the fully qualified name of the module being imported, and the (optional) target\nmodule. find_spec() returns a fully populated spec for the module. This spec will always have “loader” set (with\none exception). To indicate to the import machinery that the spec represents a namespace portion, the path entry finder sets\nsubmodule_search_locations to a list containing the portion. Changed in version 3.4: find_spec() replaced find_loader() and find_module(), both of which are now\ndeprecated, but will be used if find_spec() is not defined. Older path entry finders may implement one of these two deprecated methods instead of find_spec(). The meth-\nods are still respected for the sake of backward compatibility. However, if find_spec() is implemented on the\npath entry finder, the legacy methods are ignored. find_loader() takes one argument, the fully qualified name of the module being imported. find_loader()\nreturns a 2-tuple where the first item is the loader and the second item is a namespace portion. For backwards compatibility with other implementations of the import protocol, many path entry finders also sup-\nport the same, traditional find_module() method that meta path finders support. However path entry finder\nfind_module() methods are never called with a path argument (they are expected to record the appropriate\npath information from the initial call to the path hook). The find_module() method on path entry finders is deprecated, as it does not allow the path entry finder to\ncontribute portions to namespace packages. If both find_loader() and find_module() exist on a path entry\nfinder, the import system will always call find_loader() in preference to find_module(). Changed in version 3.10:\nCalls to find_module() and find_loader() by the import system will raise\nImportWarning. Changed in version 3.12: find_module() and find_loader() have been removed. 5.6 Replacing the standard import system\nThe most reliable mechanism for replacing the entire import system is to delete the default contents of sys. meta_path, replacing them entirely with a custom meta path hook. If it is acceptable to only alter the behaviour of import statements without affecting other APIs that access the import\nsystem, then replacing the builtin __import__() function may be sufficient. This technique may also be employed\nat the module level to only alter the behaviour of import statements within that module. 5.6. Replacing the standard import system\n73\n\nThe Python Language Reference, Release 3.13.2\nTo selectively prevent the import of some modules from a hook early on the meta path (rather than disabling the\nstandard import system entirely), it is sufficient to raise ModuleNotFoundError directly from find_spec() in-\nstead of returning None. The latter indicates that the meta path search should continue, while raising an exception\nterminates it immediately. 5.7 Package Relative Imports\nRelative imports use leading dots. A single leading dot indicates a relative import, starting with the current package. Two or more leading dots indicate a relative import to the parent(s) of the current package, one level per dot after\nthe first. For example, given the following package layout:\npackage/\n__init__.py\nsubpackage1/\n__init__.py\nmoduleX.py\nmoduleY.py\nsubpackage2/\n__init__.py\nmoduleZ.py\nmoduleA.py\nIn either subpackage1/moduleX.py or subpackage1/__init__.py, the following are valid relative imports:\nfrom .moduleY import spam\nfrom .moduleY import spam as ham\nfrom .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n2.7\nModules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.1\nHow do I create a .pyc file? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.2\nHow do I find the current module name? . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.3\nHow can I have modules that mutually import each other? . . . . . . . . . . . . . . . . .')",2.8705994989733243e-155,0.10632014176018902,0.25028148743145356,0.5630710124969482,0.40785873
Use different Python version with virtualenv,"NOTE:
 For 
Python 3.3+
, see The Aelfinn's 
answer
 below.




Use the 
--python
 (or short 
-p
) option when creating a virtualenv instance to specify the Python executable you want to use, e.g.:


virtualenv --python=""/usr/bin/python2.6"" ""/path/to/new/virtualenv/""


","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . . . . . . 39\n3.5.3\nLinker flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n4\nUsing Python on Windows\n43\n4.1\nThe full installer\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.1.1\nInstallation steps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n4.1.2\nRemoving the MAX_PATH Limitation . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.1.3\nInstalling Without UI . .\n\n[2] . . . . 7\n3.2\n… install packages just for the current user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3\n… install scientific Python packages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.4\n… work with multiple versions of Python installed in parallel? . . . . . . . . . . . . . . . . . . . 7\n4\nCommon installation issues\n9\n4.1\nInstalling into the system Python on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2\nPip not installed .\n\n[3] . . . . . . . . 33\n10.5 Deprecated C APIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n11 Build Changes\n38\n12 Porting to Python 3.13\n38\n12.1 Changes in the Python API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n12.2 Changes in the C API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\n13 Regression Test Changes\n41\n14 Notable changes in 3.13.1\n41\n14.1 sys . . . . . . . . . . . . . . .')",9.833817173165367e-156,0.07692307692307693,0.08097165991902834,0.43871304392814636,0.24785061
How do I get time of a Python program's execution?,"The simplest way in Python:


import time
start_time = time.time()
main()
print(""--- %s seconds ---"" % (time.time() - start_time))



This assumes that your program takes at least a tenth of second to run.


Prints:


--- 0.764891862869 seconds ---


","('Answer: You can use the `timeit` module to measure the execution time of small code snippets. It can be used via a Command-Line Interface or a callable one. The `timeit.timeit()` function can be used to time a statement. The default timer is `time.perf_counter()` which returns float seconds.\n\nReferences: [2, 3]\n', '[1] Depending on whether you are using profile.Profile\nor cProfile.Profile, your_time_func’s return value will be interpreted differently:\nprofile.Profile\nyour_time_func should return a single number, or a list of numbers whose sum is the current time (like\nwhat os.times() returns). If the function returns a single time number, or the list of returned numbers has\nlength 2, then you will get an especially fast version of the dispatch routine. Be warned that you should calibrate the profiler class for the timer function that you choose (see Calibration). For most machines, a timer that returns a lone integer value will provide the best results in terms of low\noverhead during profiling. (os.times() is pretty bad, as it returns a tuple of floating-point values). If you\nwant to substitute a better timer in the cleanest fashion, derive a class and hardwire a replacement dispatch\nmethod that best handles your timer call, along with the appropriate calibration constant. cProfile.Profile\nyour_time_func should return a single number. If it returns integers, you can also invoke the class\nconstructor with a second argument specifying the real duration of one unit of time. For example, if\nyour_integer_time_func returns times measured in thousands of seconds, you would construct the\nProfile instance as follows:\npr = cProfile.Profile(your_integer_time_func, 0.001)\nAs the cProfile.Profile class cannot be calibrated, custom timer functions should be used with care and\nshould be as fast as possible. For the best results with a custom timer, it might be necessary to hard-code it in\nthe C source of the internal _lsprof module. Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops).\n\n[2] (os.times() is pretty bad, as it returns a tuple of floating-point values). If you\nwant to substitute a better timer in the cleanest fashion, derive a class and hardwire a replacement dispatch\nmethod that best handles your timer call, along with the appropriate calibration constant. cProfile.Profile\nyour_time_func should return a single number. If it returns integers, you can also invoke the class\nconstructor with a second argument specifying the real duration of one unit of time. For example, if\nyour_integer_time_func returns times measured in thousands of seconds, you would construct the\nProfile instance as follows:\npr = cProfile.Profile(your_integer_time_func, 0.001)\nAs the cProfile.Profile class cannot be calibrated, custom timer functions should be used with care and\nshould be as fast as possible. For the best results with a custom timer, it might be necessary to hard-code it in\nthe C source of the internal _lsprof module. Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops). It calls timeit() with\nincreasing numbers from the sequence 1, 2, 5, 10, 20, 50, … until the time taken is at least 0.2 seconds. If callback is given and is not None, it will be called after each trial with two arguments:\ncallback(number, time_taken). Added in version 3.6.\nrepeat(repeat=5, number=1000000)\nCall timeit() a few times. This is a convenience function that calls the timeit() repeatedly, returning a list of results.\n\n[3] For the best results with a custom timer, it might be necessary to hard-code it in\nthe C source of the internal _lsprof module. Python 3.3 adds several new functions in time that can be used to make precise measurements of process or wall-\nclock time. For example, see time.perf_counter(). 28.6 timeit — Measure execution time of small code snippets\nSource code: Lib/timeit.py\nThis module provides a simple way to time small bits of Python code. It has both a Command-Line Interface as well as\na callable one. It avoids a number of common traps for measuring execution times. See also Tim Peters’ introduction\nto the “Algorithms” chapter in the second edition of Python Cookbook, published by O’Reilly. 28.6.1 Basic Examples\nThe following example shows how the Command-Line Interface can be used to compare three different expressions:\n$ python -m timeit ""\'-\'.join(str(n) for n in range(100))""\n10000 loops, best of 5: 30.2 usec per loop\n$ python -m timeit ""\'-\'.join([str(n) for n in range(100)])""\n10000 loops, best of 5: 27.5 usec per loop\n$ python -m timeit ""\'-\'.join(map(str, range(100)))""\n10000 loops, best of 5: 23.2 usec per loop\nThis can be achieved from the Python Interface with:\n28.6. timeit — Measure execution time of small code snippets\n1871\n\nThe Python Library Reference, Release 3.13.2\n>>> import timeit\n>>> timeit.timeit(\'""-"".join(str(n) for n in range(100))\', number=10000)\n0.3018611848820001\n>>> timeit.timeit(\'""-"".join([str(n) for n in range(100)])\', number=10000)\n0.2727368790656328\n>>> timeit.timeit(\'""-"".join(map(str, range(100)))\', number=10000)\n0.23702679807320237\nA callable can also be passed from the Python Interface:\n>>> timeit.timeit(lambda: ""-"".join(map(str, range(100))), number=10000)\n0.19665591977536678\nNote however that timeit() will automatically determine the number of repetitions only when the command-line\ninterface is used. In the Examples section you can find more advanced examples. 28.6.2 Python Interface\nThe module defines three convenience functions and a public class:\ntimeit.timeit(stmt=’pass’, setup=’pass’, timer=<default timer>, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its timeit() method\nwith number executions. The optional globals argument specifies a namespace in which to execute the code. Changed in version 3.5: The optional globals parameter was added. timeit.repeat(stmt=’pass’, setup=’pass’, timer=<default timer>, repeat=5, number=1000000, globals=None)\nCreate a Timer instance with the given statement, setup code and timer function and run its repeat() method\nwith the given repeat count and number executions. The optional globals argument specifies a namespace in\nwhich to execute the code. Changed in version 3.5: The optional globals parameter was added. Changed in version 3.7: Default value of repeat changed from 3 to 5.\ntimeit.default_timer()\nThe default timer,\nwhich is always time.perf_counter(),\nreturns float seconds. An alternative,\ntime.perf_counter_ns, returns integer nanoseconds. Changed in version 3.3: time.perf_counter() is now the default timer. class timeit.Timer(stmt=’pass’, setup=’pass’, timer=<timer function>, globals=None)\nClass for timing execution speed of small code snippets. The constructor takes a statement to be timed, an additional statement used for setup, and a timer function. Both statements default to \'pass\'; the timer function is platform-dependent (see the module doc string). stmt\nand setup may also contain multiple statements separated by ; or newlines, as long as they don’t contain multi-\nline string literals. The statement will by default be executed within timeit’s namespace; this behavior can be\ncontrolled by passing a namespace to globals. To measure the execution time of the first statement, use the timeit() method. The repeat() and\nautorange() methods are convenience methods to call timeit() multiple times. The execution time of setup is excluded from the overall timed execution run. The stmt and setup parameters can also take objects that are callable without arguments. This will embed calls\nto them in a timer function that will then be executed by timeit(). Note that the timing overhead is a little\nlarger in this case because of the extra function calls. Changed in version 3.5: The optional globals parameter was added. 1872\nChapter 28. Debugging and Profiling\n\nThe Python Library Reference, Release 3.13.2\ntimeit(number=1000000)\nTime number executions of the main statement. This executes the setup statement once, and then returns\nthe time it takes to execute the main statement a number of times. The default timer returns seconds\nas a float. The argument is the number of times through the loop, defaulting to one million. The main\nstatement, the setup statement and the timer function to be used are passed to the constructor. ® Note\nBy default, timeit() temporarily turns off garbage collection during the timing. The advantage of\nthis approach is that it makes independent timings more comparable. The disadvantage is that GC\nmay be an important component of the performance of the function being measured. If so, GC can\nbe re-enabled as the first statement in the setup string. For example:\ntimeit.Timer(\'for i in range(10): oct(i)\', \'gc.enable()\').timeit()\nautorange(callback=None)\nAutomatically determine how many times to call timeit(). This is a convenience function that calls timeit() repeatedly so that the total time >= 0.2 second,\nreturning the eventual (number of loops, time taken for that number of loops). It calls timeit() with\nincreasing numbers from the sequence 1, 2, 5, 10, 20, 50, … until the time taken is at least 0.2 seconds. If callback is given and is not None, it will be called after each trial with two arguments:\ncallback(number, time_taken). Added in version 3.6.\nrepeat(repeat=5, number=1000000)\nCall timeit() a few times. This is a convenience function that calls the timeit() repeatedly, returning a list of results. The first\nargument specifies how many times to call timeit(). The second argument specifies the number argu-\nment for timeit(). ® Note\nIt’s tempting to calculate mean and standard deviation from the result vector and report these. How-\never, this is not very useful. In a typical case, the lowest value gives a lower bound for how fast your\nmachine can run the given code snippet; higher values in the result vector are typically not caused by\nvariability in Python’s speed, but by other processes interfering with your timing accuracy.')",5.665201364701564e-156,0.015397775876817793,0.053509151020742086,0.48981332778930664,0.5937512
Random string generation with upper case letters and digits,"Answer in one line:


''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(N))



or even shorter starting with Python 3.6 using 
random.choices()
:


''.join(random.choices(string.ascii_uppercase + string.digits, k=N))



A cryptographically more secure version:
 
see this post


''.join(random.SystemRandom().choice(string.ascii_uppercase + string.digits) for _ in range(N))



In details, with a clean function for further reuse:


>>> import string
>>> import random
>>> def id_generator(size=6, chars=string.ascii_uppercase + string.digits):
...    return ''.join(random.choice(chars) for _ in range(size))
...
>>> id_generator()
'G5G74W'
>>> id_generator(3, ""6793YUIO"")
'Y3U'



How does it work ?


We import 
string
, a module that contains sequences of common ASCII characters, and 
random
, a module that deals with random generation.


string.ascii_uppercase + string.digits
 just concatenates the list of characters representing uppercase ASCII chars and digits:


>>> string.ascii_uppercase
'ABCDEFGHIJKLMNOPQRSTUVWXYZ'
>>> string.digits
'0123456789'
>>> string.ascii_uppercase + string.digits
'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789'



Then we use a list comprehension to create a list of 'n' elements:


>>> range(4) # range create a list of 'n' numbers
[0, 1, 2, 3]
>>> ['elem' for _ in range(4)] # we use range to create 4 times 'elem'
['elem', 'elem', 'elem', 'elem']



In the example above, we use 
[
 to create the list, but we don't in the 
id_generator
 function so Python doesn't create the list in memory, but generates the elements on the fly, one by one (more about this 
here
).


Instead of asking to create 'n' times the string 
elem
, we will ask Python to create 'n' times a random character, picked from a sequence of characters:


>>> random.choice(""abcde"")
'a'
>>> random.choice(""abcde"")
'd'
>>> random.choice(""abcde"")
'b'



Therefore 
random.choice(chars) for _ in range(size)
 really is creating a sequence of 
size
 characters. Characters that are randomly picked from 
chars
:


>>> [random.choice('abcde') for _ in range(3)]
['a', 'b', 'b']
>>> [random.choice('abcde') for _ in range(3)]
['e', 'b', 'e']
>>> [random.choice('abcde') for _ in range(3)]
['d', 'a', 'c']



Then we just join them with an empty string so the sequence becomes a string:


>>> ''.join(['a', 'b', 'b'])
'abb'
>>> [random.choice('abcde') for _ in range(3)]
['d', 'c', 'b']
>>> ''.join(random.choice('abcde') for _ in range(3))
'dac'


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] String literals that are part of a single expression and have only whitespace between them will be implicitly converted\nto a single string literal. That is, (""spam "" ""eggs"") == ""spam eggs"". See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”)\nprefix that disables most escape sequence processing. Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details.\n\n[2] See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”)\nprefix that disables most escape sequence processing. Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details. For performance reasons, the value of errors is not checked for validity unless an encoding error actually occurs,\nPython Development Mode is enabled or a debug build is used. Changed in version 3.1: Added support for keyword arguments.\n\n[3] That is, (""spam "" ""eggs"") == ""spam eggs"". See strings for more about the various forms of string literal, including supported escape sequences, and the r (“raw”)\nprefix that disables most escape sequence processing. Strings may also be created from other objects using the str constructor. Since there is no separate “character” type, indexing a string produces strings of length 1. That is, for a non-empty\nstring s, s[0] == s[0:1]. There is also no mutable string type, but str.join() or io.StringIO can be used to efficiently construct strings\nfrom multiple fragments. Changed in version 3.3: For backwards compatibility with the Python 2 series, the u prefix is once again permitted\non string literals. It has no effect on the meaning of string literals and cannot be combined with the r prefix. class str(object=”)\nclass str(object=b”, encoding=’utf-8’, errors=’strict’)\nReturn a string version of object. If object is not provided, returns the empty string. Otherwise, the behavior\nof str() depends on whether encoding or errors is given, as follows. If neither encoding nor errors is given, str(object) returns type(object).__str__(object), which\nis the “informal” or nicely printable string representation of object. For string objects, this is the string itself. If object does not have a __str__() method, then str() falls back to returning repr(object). If at least one of encoding or errors is given, object should be a bytes-like object (e.g. bytes or bytearray). In this case, if object is a bytes (or bytearray) object, then str(bytes, encoding, errors) is equiv-\nalent to bytes.decode(encoding, errors). Otherwise, the bytes object underlying the buffer object is\nobtained before calling bytes.decode(). See Binary Sequence Types — bytes, bytearray, memoryview and\nbufferobjects for information on buffer objects. Passing a bytes object to str() without the encoding or errors arguments falls under the first case of returning\nthe informal string representation (see also the -b command-line option to Python). For example:\n>>> str(b\'Zoot!\') ""b\'Zoot!\'"" For more information on the str class and its methods, see Text Sequence Type — str and the String Methods\nsection below. To output formatted strings, see the f-strings and Format String Syntax sections. In addition,\nsee the Text Processing Services section. 4.8.1 String Methods\nStrings implement all of the common sequence operations, along with the additional methods described below. Strings also support two styles of string formatting, one providing a large degree of flexibility and customization\n(see str.format(), Format String Syntax and Custom String Formatting) and the other based on C printf style\nformatting that handles a narrower range of types and is slightly harder to use correctly, but is often faster for the\ncases it can handle (printf-style String Formatting). The Text Processing Services section of the standard library covers a number of other modules that provide various\ntext related utilities (including regular expression support in the re module). str.capitalize()\nReturn a copy of the string with its first character capitalized and the rest lowercased. Changed in version 3.8: The first character is now put into titlecase rather than uppercase. This means that\ncharacters like digraphs will only have their first letter capitalized, instead of the full character. 52\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.casefold()\nReturn a casefolded copy of the string. Casefolded strings may be used for caseless matching. Casefolding is similar to lowercasing but more aggressive because it is intended to remove all case distinctions\nin a string. For example, the German lowercase letter \'ß\' is equivalent to ""ss"". Since it is already lowercase,\nlower() would do nothing to \'ß\'; casefold() converts it to ""ss"". The casefolding algorithm is described in section 3.13 ‘Default Case Folding’ of the Unicode Standard. Added in version 3.3.\nstr.center(width[, fillchar])\nReturn centered in a string of length width. Padding is done using the specified fillchar (default is an ASCII\nspace). The original string is returned if width is less than or equal to len(s). str.count(sub[, start[, end]])\nReturn the number of non-overlapping occurrences of substring sub in the range [start, end]. Optional argu-\nments start and end are interpreted as in slice notation. If sub is empty, returns the number of empty strings between characters which is the length of the string plus\none. str.encode(encoding=’utf-8’, errors=’strict’)\nReturn the string encoded to bytes. encoding defaults to \'utf-8\'; see Standard Encodings for possible values. errors controls how encoding errors are handled. If \'strict\' (the default), a UnicodeError\nexception is raised. Other possible values are \'ignore\', \'replace\', \'xmlcharrefreplace\',\n\'backslashreplace\' and any other name registered via codecs.register_error(). See Error Han-\ndlers for details. For performance reasons, the value of errors is not checked for validity unless an encoding error actually occurs,\nPython Development Mode is enabled or a debug build is used.')",1.4332190481896692e-155,0.0749219562955255,0.22694445596599222,0.5416169166564941,0.40311736
How do I print to stderr in Python?,"I found this to be the only one short, flexible, portable and readable:


import sys

def eprint(*args, **kwargs):
    print(*args, file=sys.stderr, **kwargs)



The optional function 
eprint
 saves some repetition. It can be used in the same way as the standard 
print
 function:


>>> print(""Test"")
Test
>>> eprint(""Test"")
Test
>>> eprint(""foo"", ""bar"", ""baz"", sep=""---"")
foo---bar---baz


","('Answer: To catch output from stderr in Python, define an object with a `write()` method and assign it to `sys.stderr`. The output will then be directed to wherever your `write()` method sends it. The easiest way to do this is with the `io.StringIO` class. You can also create a custom object with a `write()` method that appends the data.\n\nReferences: [2, 3]\n', '[1] 5.9 How do I catch the output from PyErr_Print() (or anything that\nprints to stdout/stderr)? In Python code, define an object that supports the write() method. Assign this object to sys.stdout and sys. stderr. Call print_error, or just allow the standard traceback mechanism to work. Then, the output will go wherever\nyour write() method sends it. The easiest way to do this is to use the io.StringIO class:\n>>> import io, sys\n>>> sys.stdout = io.StringIO()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(sys.stdout.getvalue())\n(continues on next page)\n62\nChapter 5. Extending/Embedding FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfoo\nhello world! A custom object to do the same would look like this:\n>>> import io, sys\n>>> class StdoutCatcher(io.TextIOBase):\n...\ndef __init__(self):\n...\nself.data = []\n...\ndef write(self, stuff):\n...\nself.data.append(stuff)\n...\n>>> import sys\n>>> sys.stdout = StdoutCatcher()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(\'\'.join(sys.stdout.data))\nfoo\nhello world! 5.10 How do I access a module written in Python from C? You can get a pointer to the module object as follows:\nmodule = PyImport_ImportModule(""<modulename>"");\nIf the module hasn’t been imported yet (i.e. it is not yet present in sys.modules), this initializes the module;\notherwise it simply returns the value of sys.modules[""<modulename>""]. Note that it doesn’t enter the module\ninto any namespace – it only ensures it has been initialized and is stored in sys.modules. You can then access the module’s attributes (i.e. any name defined in the module) as follows:\nattr = PyObject_GetAttrString(module, ""<attrname>"");\nCalling PyObject_SetAttrString() to assign to variables in the module also works. 5.11 How do I interface to C++ objects from Python? Depending on your requirements, there are many approaches. To do this manually, begin by reading the “Extending\nand Embedding” document. Realize that for the Python run-time system, there isn’t a whole lot of difference between\nC and C++ – so the strategy of building a new Python type around a C structure (pointer) type will also work for\nC++ objects. For C++ libraries, see Writing C is hard; are there any alternatives?. 5.12 I added a module using the Setup file and the make fails; why? Setup must end in a newline, if there is no newline there, the build process fails. (Fixing this requires some ugly shell\nscript hackery, and this bug is so minor that it doesn’t seem worth the effort.) 5.13 How do I debug an extension? When using GDB with dynamically loaded extensions, you can’t set a breakpoint in your extension until your extension\nis loaded. In your .gdbinit file (or interactively), add the command:\n5.10. How do I access a module written in Python from C? 63\n\nPython Frequently Asked Questions, Release 3.13.2\nbr _PyImport_LoadDynamicModule\nThen, when you run GDB:\n$ gdb /local/bin/python\ngdb) run myscript.py\ngdb) continue # repeat until your extension is loaded\ngdb) finish\n# so that your extension is loaded\ngdb) br myfunction.c:50\ngdb) continue\n5.14 I want to compile a Python module on my Linux system, but\nsome files are missing. Why? Most packaged versions of Python omit some files required for compiling Python extensions. For Red Hat, install the python3-devel RPM to get the necessary files. For Debian, run apt-get install python3-dev. 5.15 How do I tell “incomplete input” from “invalid input”? Sometimes you want to emulate the Python interactive interpreter’s behavior, where it gives you a continuation prompt\nwhen the input is incomplete (e.g. you typed the start of an “if” statement or you didn’t close your parentheses or\ntriple string quotes), but it gives you a syntax error message immediately when the input is invalid. In Python you can use the codeop module, which approximates the parser’s behavior sufficiently. IDLE uses this,\nfor example. The easiest way to do it in C is to call PyRun_InteractiveLoop() (perhaps in a separate thread) and let the\nPython interpreter handle the input for you. You can also set the PyOS_ReadlineFunctionPointer() to point\nat your custom input function. See Modules/readline.c and Parser/myreadline.c for more hints. 5.16 How do I find undefined g++ symbols __builtin_new or\n__pure_virtual? To dynamically load g++ extension modules, you must recompile Python, relink it using g++ (change LINKCC in\nthe Python Modules Makefile), and link your extension module using g++ (e.g., g++ -shared -o mymodule.so\nmymodule.o). 5.17 Can I create an object class with some methods implemented\nin C and others in Python (e.g. through inheritance)? Yes, you can inherit from built-in classes such as int, list, dict, etc. The Boost Python Library (BPL, https://www.boost.org/libs/python/doc/index.html) provides a way of doing this\nfrom C++ (i.e. you can inherit from an extension class written in C++ using the BPL). 64\nChapter 5. Extending/Embedding FAQ\n\nCHAPTER\nSIX\nPYTHON ON WINDOWS FAQ\n6.1 How do I run a Python program under Windows?\n\n[2] “(i)”. 5.9 How do I catch the output from PyErr_Print() (or anything that\nprints to stdout/stderr)? In Python code, define an object that supports the write() method. Assign this object to sys.stdout and sys. stderr. Call print_error, or just allow the standard traceback mechanism to work. Then, the output will go wherever\nyour write() method sends it. The easiest way to do this is to use the io.StringIO class:\n>>> import io, sys\n>>> sys.stdout = io.StringIO()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(sys.stdout.getvalue())\n(continues on next page)\n62\nChapter 5. Extending/Embedding FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfoo\nhello world! A custom object to do the same would look like this:\n>>> import io, sys\n>>> class StdoutCatcher(io.TextIOBase):\n...\ndef __init__(self):\n...\nself.data = []\n...\ndef write(self, stuff):\n...\nself.data.append(stuff)\n...\n>>> import sys\n>>> sys.stdout = StdoutCatcher()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(\'\'.join(sys.stdout.data))\nfoo\nhello world! 5.10 How do I access a module written in Python from C? You can get a pointer to the module object as follows:\nmodule = PyImport_ImportModule(""<modulename>"");\nIf the module hasn’t been imported yet (i.e. it is not yet present in sys.modules), this initializes the module;\notherwise it simply returns the value of sys.modules[""<modulename>""]. Note that it doesn’t enter the module\ninto any namespace – it only ensures it has been initialized and is stored in sys.modules. You can then access the module’s attributes (i.e. any name defined in the module) as follows:\nattr = PyObject_GetAttrString(module, ""<attrname>"");\nCalling PyObject_SetAttrString() to assign to variables in the module also works. 5.11 How do I interface to C++ objects from Python? Depending on your requirements, there are many approaches. To do this manually, begin by reading the “Extending\nand Embedding” document. Realize that for the Python run-time system, there isn’t a whole lot of difference between\nC and C++ – so the strategy of building a new Python type around a C structure (pointer) type will also work for\nC++ objects. For C++ libraries, see Writing C is hard; are there any alternatives?. 5.12 I added a module using the Setup file and the make fails; why? Setup must end in a newline, if there is no newline there, the build process fails. (Fixing this requires some ugly shell\nscript hackery, and this bug is so minor that it doesn’t seem worth the effort.) 5.13 How do I debug an extension? When using GDB with dynamically loaded extensions, you can’t set a breakpoint in your extension until your extension\nis loaded. In your .gdbinit file (or interactively), add the command:\n5.10. How do I access a module written in Python from C? 63\n\nPython Frequently Asked Questions, Release 3.13.2\nbr _PyImport_LoadDynamicModule\nThen, when you run GDB:\n$ gdb /local/bin/python\ngdb) run myscript.py\ngdb) continue # repeat until your extension is loaded\ngdb) finish\n# so that your extension is loaded\ngdb) br myfunction.c:50\ngdb) continue\n5.14 I want to compile a Python module on my Linux system, but\nsome files are missing. Why? Most packaged versions of Python omit some files required for compiling Python extensions. For Red Hat, install the python3-devel RPM to get the necessary files. For Debian, run apt-get install python3-dev. 5.15 How do I tell “incomplete input” from “invalid input”? Sometimes you want to emulate the Python interactive interpreter’s behavior, where it gives you a continuation prompt\nwhen the input is incomplete (e.g. you typed the start of an “if” statement or you didn’t close your parentheses or\ntriple string quotes), but it gives you a syntax error message immediately when the input is invalid. In Python you can use the codeop module, which approximates the parser’s behavior sufficiently. IDLE uses this,\nfor example. The easiest way to do it in C is to call PyRun_InteractiveLoop() (perhaps in a separate thread) and let the\nPython interpreter handle the input for you. You can also set the PyOS_ReadlineFunctionPointer() to point\nat your custom input function. See Modules/readline.c and Parser/myreadline.c for more hints. 5.16 How do I find undefined g++ symbols __builtin_new or\n__pure_virtual? To dynamically load g++ extension modules, you must recompile Python, relink it using g++ (change LINKCC in\nthe Python Modules Makefile), and link your extension module using g++ (e.g., g++ -shared -o mymodule.so\nmymodule.o). 5.17 Can I create an object class with some methods implemented\nin C and others in Python (e.g. through inheritance)? Yes, you can inherit from built-in classes such as int, list, dict, etc. The Boost Python Library (BPL, https://www.boost.org/libs/python/doc/index.html) provides a way of doing this\nfrom C++ (i.e. you can inherit from an extension class written in C++ using the BPL). 64\nChapter 5.\n\n[3] stderr. Call print_error, or just allow the standard traceback mechanism to work. Then, the output will go wherever\nyour write() method sends it. The easiest way to do this is to use the io.StringIO class:\n>>> import io, sys\n>>> sys.stdout = io.StringIO()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(sys.stdout.getvalue())\n(continues on next page)\n62\nChapter 5. Extending/Embedding FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfoo\nhello world! A custom object to do the same would look like this:\n>>> import io, sys\n>>> class StdoutCatcher(io.TextIOBase):\n...\ndef __init__(self):\n...\nself.data = []\n...\ndef write(self, stuff):\n...\nself.data.append(stuff)\n...\n>>> import sys\n>>> sys.stdout = StdoutCatcher()\n>>> print(\'foo\')\n>>> print(\'hello world!\') >>> sys.stderr.write(\'\'.join(sys.stdout.data))\nfoo\nhello world! 5.10 How do I access a module written in Python from C? You can get a pointer to the module object as follows:\nmodule = PyImport_ImportModule(""<modulename>"");\nIf the module hasn’t been imported yet (i.e. it is not yet present in sys.modules), this initializes the module;\notherwise it simply returns the value of sys.modules[""<modulename>""]. Note that it doesn’t enter the module\ninto any namespace – it only ensures it has been initialized and is stored in sys.modules. You can then access the module’s attributes (i.e. any name defined in the module) as follows:\nattr = PyObject_GetAttrString(module, ""<attrname>"");\nCalling PyObject_SetAttrString() to assign to variables in the module also works. 5.11 How do I interface to C++ objects from Python? Depending on your requirements, there are many approaches. To do this manually, begin by reading the “Extending\nand Embedding” document. Realize that for the Python run-time system, there isn’t a whole lot of difference between\nC and C++ – so the strategy of building a new Python type around a C structure (pointer) type will also work for\nC++ objects. For C++ libraries, see Writing C is hard; are there any alternatives?. 5.12 I added a module using the Setup file and the make fails; why? Setup must end in a newline, if there is no newline there, the build process fails. (Fixing this requires some ugly shell\nscript hackery, and this bug is so minor that it doesn’t seem worth the effort.) 5.13 How do I debug an extension? When using GDB with dynamically loaded extensions, you can’t set a breakpoint in your extension until your extension\nis loaded. In your .gdbinit file (or interactively), add the command:\n5.10. How do I access a module written in Python from C? 63\n\nPython Frequently Asked Questions, Release 3.13.2\nbr _PyImport_LoadDynamicModule\nThen, when you run GDB:\n$ gdb /local/bin/python\ngdb) run myscript.py\ngdb) continue # repeat until your extension is loaded\ngdb) finish\n# so that your extension is loaded\ngdb) br myfunction.c:50\ngdb) continue\n5.14 I want to compile a Python module on my Linux system, but\nsome files are missing. Why? Most packaged versions of Python omit some files required for compiling Python extensions. For Red Hat, install the python3-devel RPM to get the necessary files. For Debian, run apt-get install python3-dev. 5.15 How do I tell “incomplete input” from “invalid input”? Sometimes you want to emulate the Python interactive interpreter’s behavior, where it gives you a continuation prompt\nwhen the input is incomplete (e.g. you typed the start of an “if” statement or you didn’t close your parentheses or\ntriple string quotes), but it gives you a syntax error message immediately when the input is invalid. In Python you can use the codeop module, which approximates the parser’s behavior sufficiently. IDLE uses this,\nfor example. The easiest way to do it in C is to call PyRun_InteractiveLoop() (perhaps in a separate thread) and let the\nPython interpreter handle the input for you. You can also set the PyOS_ReadlineFunctionPointer() to point\nat your custom input function. See Modules/readline.c and Parser/myreadline.c for more hints. 5.16 How do I find undefined g++ symbols __builtin_new or\n__pure_virtual? To dynamically load g++ extension modules, you must recompile Python, relink it using g++ (change LINKCC in\nthe Python Modules Makefile), and link your extension module using g++ (e.g., g++ -shared -o mymodule.so\nmymodule.o). 5.17 Can I create an object class with some methods implemented\nin C and others in Python (e.g. through inheritance)? Yes, you can inherit from built-in classes such as int, list, dict, etc. The Boost Python Library (BPL, https://www.boost.org/libs/python/doc/index.html) provides a way of doing this\nfrom C++ (i.e. you can inherit from an extension class written in C++ using the BPL). 64\nChapter 5. Extending/Embedding FAQ\n\nCHAPTER\nSIX\nPYTHON ON WINDOWS FAQ\n6.1 How do I run a Python program under Windows? This is not necessarily a straightforward question. If you are already familiar with running programs from the Win-\ndows command line then everything will seem obvious; otherwise, you might need a little more guidance. Unless you use some sort of integrated development environment, you will end up typing Windows commands into\nwhat is referred to as a “Command prompt window”.')",8.872465545556696e-156,0.01714898177920686,0.1066510295770849,0.5643939971923828,0.48813426
Save plot to image file instead of displaying it,"When using 
matplotlib.pyplot.savefig
, the file format can be specified by the extension:


from matplotlib import pyplot as plt

plt.savefig('foo.png')
plt.savefig('foo.pdf')



That gives a rasterized or vectorized output respectively.
In addition, there is sometimes undesirable whitespace around the image, which can be removed with:


plt.savefig('foo.png', bbox_inches='tight')



Note that if showing the plot, 
plt.show()
 should follow 
plt.savefig()
; otherwise, the file image will be blank.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . 3\n1.3\nLogging to a file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.4\nLogging variable data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.5\nChanging the format of displayed messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.6\nDisplaying the date/time in messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.7\nNext Steps . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.41 tempfile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.42 time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.43 tkinter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.44 traceback\n. . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . 1624\n26.8.6\nNotebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1625\n26.8.7\nProgressbar . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1627\n26.8.8\nSeparator\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1627\n26.8.9\nSizegrip . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1628\n26.8.10 Treeview . . . . . . . . . . . . . . . . . . . . . . .')",5.698089296870598e-232,0.05649717514124294,0.05490734385724092,0.42935872077941895,0.030165046
Selecting multiple columns in a Pandas dataframe,"The column names (which are strings) cannot be sliced in the manner you tried.


Here you have a couple of options. If you know from context which variables you want to slice out, you can just return a view of only those columns by passing a list into the 
__getitem__
 syntax
 (the []'s).


df1 = df[['a', 'b']]



Alternatively, if it matters to index them numerically and not by their name (say your code should automatically do this without knowing the names of the first two columns) then you can do this instead:


df1 = df.iloc[:, 0:2] # Remember that Python does not slice inclusive of the ending index.



Additionally, you should familiarize yourself with the idea of a view into a Pandas object vs. a copy of that object. The first of the above methods will return a new copy in memory of the desired sub-object (the desired slices).


Sometimes, however, there are indexing conventions in Pandas that don't do this and instead give you a new variable that just refers to the same chunk of memory as the sub-object or slice in the original object. This will happen with the second way of indexing, so you can modify it with the 
.copy()
 method to get a regular copy. When this happens, changing what you think is the sliced object can sometimes alter the original object. Always good to be on the look out for this.


df1 = df.iloc[0, 0:2].copy() # To avoid the case where changing df1 also changes df



To use 
iloc
, you need to know the column positions (or indices). As the column positions may change, instead of hard-coding indices, you can use 
iloc
 along with 
get_loc
 function of 
columns
 method of dataframe object to obtain column indices.


{df.columns.get_loc(c): c for idx, c in enumerate(df.columns)}



Now you can use this dictionary to access columns through names and using 
iloc
.

","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.1\nHow do I convert between tuples and lists? . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] Some examples\nare operator.add(a, b) (adds two values), operator.ne(a, b) (same as a != b), and operator. attrgetter(\'id\') (returns a callable that fetches the .id attribute). itertools.starmap(func, iter) assumes that the iterable will return a stream of tuples, and calls func using\nthese tuples as the arguments:\nitertools.starmap(os.path.join,\n[(\'/bin\', \'python\'), (\'/usr\', \'bin\', \'java\'),\n(\'/usr\', \'bin\', \'perl\'), (\'/usr\', \'bin\', \'ruby\')])\n=>\n/bin/python, /usr/bin/java, /usr/bin/perl, /usr/bin/ruby\n6.3 Selecting elements\nAnother group of functions chooses a subset of an iterator’s elements based on a predicate. itertools.filterfalse(predicate, iter) is the opposite of filter(), returning all elements for which\nthe predicate returns false:\nitertools.filterfalse(is_even, itertools.count()) =>\n1, 3, 5, 7, 9, 11, 13, 15, ...\nitertools.takewhile(predicate, iter) returns elements for as long as the predicate returns true. Once the\npredicate returns false, the iterator will signal the end of its results. def less_than_10(x):\nreturn x < 10\nitertools.takewhile(less_than_10, itertools.count()) =>\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9\nitertools.takewhile(is_even, itertools.count()) =>\n0\nitertools.dropwhile(predicate, iter) discards elements while the predicate returns true, and then returns\nthe rest of the iterable’s results. itertools.dropwhile(less_than_10, itertools.count()) =>\n10, 11, 12, 13, 14, 15, 16, 17, 18, 19, ...\nitertools.dropwhile(is_even, itertools.count()) =>\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, ...\nitertools.compress(data, selectors) takes two iterators and returns only those elements of data for which\nthe corresponding element of selectors is true, stopping whenever either one is exhausted:\nitertools.compress([1, 2, 3, 4, 5], [True, True, False, False, True]) =>\n1, 2, 5\n6.4 Combinatoric functions\nThe itertools.combinations(iterable, r) returns an iterator giving all possible r-tuple combinations of\nthe elements contained in iterable. itertools.combinations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(continues on next page)\n13\n\n(continued from previous page)\n(2, 3), (2, 4), (2, 5),\n(3, 4), (3, 5),\n(4, 5)\nitertools.combinations([1, 2, 3, 4, 5], 3) =>\n(1, 2, 3), (1, 2, 4), (1, 2, 5), (1, 3, 4), (1, 3, 5), (1, 4, 5),\n(2, 3, 4), (2, 3, 5), (2, 4, 5),\n(3, 4, 5)\nThe elements within each tuple remain in the same order as iterable returned them. For example, the number 1 is\nalways before 2, 3, 4, or 5 in the examples above. A similar function, itertools.permutations(iterable,\nr=None), removes this constraint on the order, returning all possible arrangements of length r:\nitertools.permutations([1, 2, 3, 4, 5], 2) =>\n(1, 2), (1, 3), (1, 4), (1, 5),\n(2, 1), (2, 3), (2, 4), (2, 5),\n(3, 1), (3, 2), (3, 4), (3, 5),\n(4, 1), (4, 2), (4, 3), (4, 5),\n(5, 1), (5, 2), (5, 3), (5, 4)\nitertools.permutations([1, 2, 3, 4, 5]) =>\n(1, 2, 3, 4, 5), (1, 2, 3, 5, 4), (1, 2, 4, 3, 5),\n...\n(5, 4, 3, 2, 1)\nIf you don’t supply a value for r the length of the iterable is used, meaning that all the elements are permuted. Note that these functions produce all of the possible combinations by position and don’t require that the contents of\niterable are unique:\nitertools.permutations(\'aba\', 3) =>\n(\'a\', \'b\', \'a\'), (\'a\', \'a\', \'b\'), (\'b\', \'a\', \'a\'),\n(\'b\', \'a\', \'a\'), (\'a\', \'a\', \'b\'), (\'a\', \'b\', \'a\')\nThe identical tuple (\'a\', \'a\', \'b\') occurs twice, but the two ‘a’ strings came from different positions. The itertools.combinations_with_replacement(iterable, r) function relaxes a different constraint:\nelements can be repeated within a single tuple. Conceptually an element is selected for the first position of each tuple\nand then is replaced before the second element is selected. itertools.combinations_with_replacement([1, 2, 3, 4, 5], 2) =>\n(1, 1), (1, 2), (1, 3), (1, 4), (1, 5),\n(2, 2), (2, 3), (2, 4), (2, 5),\n(3, 3), (3, 4), (3, 5),\n(4, 4), (4, 5),\n(5, 5)\n6.5 Grouping elements\nThe last function I’ll discuss, itertools.groupby(iter, key_func=None), is the most complicated. key_func(elem) is a function that can compute a key value for each element returned by the iterable. If you\ndon’t supply a key function, the key is simply each element itself. groupby() collects all the consecutive elements from the underlying iterable that have the same key value, and\nreturns a stream of 2-tuples containing a key value and an iterator for the elements with that key. city_list = [(\'Decatur\', \'AL\'), (\'Huntsville\', \'AL\'), (\'Selma\', \'AL\'),\n(\'Anchorage\', \'AK\'), (\'Nome\', \'AK\'),\n(continues on next page)\n14\n\n(continued from previous page)\n(\'Flagstaff\', \'AZ\'), (\'Phoenix\', \'AZ\'), (\'Tucson\', \'AZ\'),\n...\n]\ndef get_state(city_state):\nreturn city_state[1]\nitertools.groupby(city_list, get_state) =>\n(\'AL\', iterator-1),\n(\'AK\', iterator-2),\n(\'AZ\', iterator-3), ...\nwhere\niterator-1 =>\n(\'Decatur\', \'AL\'), (\'Huntsville\', \'AL\'), (\'Selma\', \'AL\')\niterator-2 =>\n(\'Anchorage\', \'AK\'), (\'Nome\', \'AK\')\niterator-3 =>\n(\'Flagstaff\', \'AZ\'), (\'Phoenix\', \'AZ\'), (\'Tucson\', \'AZ\')\ngroupby() assumes that the underlying iterable’s contents will already be sorted based on the key. Note that the\nreturned iterators also use the underlying iterable, so you have to consume the results of iterator-1 before requesting\niterator-2 and its corresponding key. 7 The functools module\nThe functools module contains some higher-order functions. A higher-order function takes one or more func-\ntions as input and returns a new function. The most useful tool in this module is the functools.partial()\nfunction. For programs written in a functional style, you’ll sometimes want to construct variants of existing functions that have\nsome of the parameters filled in. Consider a Python function f(a, b, c); you may wish to create a new function\ng(b, c) that’s equivalent to f(1, b, c); you’re filling in a value for one of f()’s parameters. This is called\n“partial function application”. The constructor for partial() takes the arguments (function, arg1, arg2, ..., kwarg1=value1,\nkwarg2=value2). The resulting object is callable, so you can just call it to invoke function with the filled-in\narguments. Here’s a small but realistic example:\nimport functools\ndef log(message, subsystem):\n""""""Write the contents of \'message\' to the specified subsystem."""""" print(\'%s: %s\' % (subsystem, message))\n...\nserver_log = functools.partial(log, subsystem=\'server\')\nserver_log(\'Unable to open socket\')\nfunctools.reduce(func, iter, [initial_value]) cumulatively performs an operation on all the iter-\nable’s elements and, therefore, can’t be applied to infinite iterables. func must be a function that takes two elements\nand returns a single value. functools.reduce() takes the first two elements A and B returned by the iterator\nand calculates func(A, B). It then requests the third element, C, calculates func(func(A, B), C), combines\nthis result with the fourth element returned, and continues until the iterable is exhausted. If the iterable returns\nno values at all, a TypeError exception is raised. If the initial value is supplied, it’s used as a starting point and\nfunc(initial_value, A) is the first calculation. 15\n\n>>> import operator, functools\n>>> functools.reduce(operator.concat, [\'A\', \'BB\', \'C\'])\n\'ABBC\'\n>>> functools.reduce(operator.concat, [])\nTraceback (most recent call last):\n...\nTypeError: reduce() of empty sequence with no initial value\n>>> functools.reduce(operator.mul, [1, 2, 3], 1)\n6\n>>> functools.reduce(operator.mul, [], 1)\n1\nIf you use operator.add() with functools.reduce(), you’ll add up all the elements of the iterable. This case\nis so common that there’s a special built-in called sum() to compute it:\n>>> import functools, operator\n>>> functools.reduce(operator.add, [1, 2, 3, 4], 0)\n10\n>>> sum([1, 2, 3, 4])\n10\n>>> sum([])\n0\nFor many uses of functools.reduce(), though, it can be clearer to just write the obvious for loop:\nimport functools\n# Instead of:\nproduct = functools.reduce(operator.mul, [1, 2, 3], 1)\n# You can write:\nproduct = 1\nfor i in [1, 2, 3]:\nproduct *= i\nA related function is itertools.accumulate(iterable, func=operator.add). It performs the same cal-\nculation, but instead of returning only the final result, accumulate() returns an iterator that also yields each partial\nresult:\nitertools.accumulate([1, 2, 3, 4, 5]) =>\n1, 3, 6, 10, 15\nitertools.accumulate([1, 2, 3, 4, 5], operator.mul) =>\n1, 2, 6, 24, 120\n7.1 The operator module\nThe operator module was mentioned earlier. It contains a set of functions corresponding to Python’s operators. These functions are often useful in functional-style code because they save you from writing trivial functions that\nperform a single operation. Some of the functions in this module are:\n• Math operations: add(), sub(), mul(), floordiv(), abs(), …\n• Logical operations: not_(), truth(). • Bitwise operations: and_(), or_(), invert(). • Comparisons: eq(), ne(), lt(), le(), gt(), and ge(). • Object identity: is_(), is_not(). 16\n\nConsult the operator module’s documentation for a complete list. 8 Small functions and the lambda expression\nWhen writing functional-style programs, you’ll often need little functions that act as predicates or that combine\nelements in some way. If there’s a Python built-in or a module function that’s suitable, you don’t need to define a new function at all:\nstripped_lines = [line.strip() for line in lines]\nexisting_files = filter(os.path.exists, file_list)\nIf the function you need doesn’t exist, you need to write it. One way to write small functions is to use the lambda\nexpression. lambda takes a number of parameters and an expression combining these parameters, and creates an\nanonymous function that returns the value of the expression:\nadder = lambda x, y: x+y\nprint_assign = lambda name, value: name + \'=\' + str(value)\nAn alternative is to just use the def statement and define a function in the usual way:\ndef adder(x, y):\nreturn x + y\ndef print_assign(name, value):\nreturn name + \'=\' + str(value)\nWhich alternative is preferable? That’s a style question; my usual course is to avoid using lambda. One reason for my preference is that lambda is quite limited in the functions it can define. The result has to be\ncomputable as a single expression, which means you can’t have multiway if... elif... else comparisons or\ntry... except statements.')",5.561437070424197e-79,0.0756075607560756,0.2032852120214696,0.5097753405570984,0.3637057
Make a dictionary (dict) from separate lists of keys and values,"Like this:


keys = ['a', 'b', 'c']
values = [1, 2, 3]
dictionary = dict(zip(keys, values))
print(dictionary) # {'a': 1, 'b': 2, 'c': 3}



Voila :-)  The pairwise 
dict
 constructor and 
zip
 function are awesomely useful.

","('Answer: You can use the `dict()` constructor with a list of key-value pairs to build dictionaries from sequences. You can also use dict comprehensions.\n\nReferences: [1]\n', ""[1] Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one. Lexicographical ordering for\nstrings uses the Unicode code point number to order individual characters.\n\n[2] Curly braces or the set() function can be used to create sets. Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal.\n\n[3] Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one."")",4.394519091366494e-232,0.011777535441657577,0.05381825971521659,0.5918039083480835,0.56386477
What does __all__ mean in Python?,"It's a list of public objects of that module, as interpreted by 
import *
. It overrides the default of hiding everything that begins with an underscore.

","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . 8\n2.2.2\nWhat are the rules for local and global variables in Python? . . . . . . . . . . . . . . . . 9\n2.2.3\nWhy do lambdas defined in a loop with different values all return the same result? . . . . . 9\n2.2.4\nHow do I share global variables across modules? . . . . . . . . . . . . . . . . . . . . . . 10\n2.2.5\nWhat are the “best practices” for using import in a module? . . . . . . . . . . . . . . . . 10\n2.2.6\nWhy are default values shared between objects? . . . . . . . . . . . . . . . . .\n\n[2] 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it? Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a num-\nber of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, .. . )), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or\nisinstance(obj, (int, float, complex)). Note that isinstance() also checks for virtual inheritance from an abstract base class. So, the test will return\nTrue for a registered class even if hasn’t directly or indirectly inherited from it. To test for “true inheritance”, scan\nthe MRO of the class:\nfrom collections.abc import Mapping\nclass P:\npass\nclass C(P):\npass\nMapping.register(P)\n>>> c = C()\n>>> isinstance(c, C)\n# direct\nTrue\n>>> isinstance(c, P)\n# indirect\nTrue\n>>> isinstance(c, Mapping)\n# virtual\nTrue\n# Actual inheritance chain\n>>> type(c).__mro__\n(<class \'C\'>, <class \'P\'>, <class \'object\'>)\n# Test for ""true inheritance""\n>>> Mapping in type(c).__mro__\nFalse\nNote that most programs do not use isinstance() on user-defined classes very often. If you are developing the\nclasses yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular\nbehaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if\nyou have a function that does something:\n2.6. Objects\n27\n\nPython Frequently Asked Questions, Release 3.13.2\ndef search(obj):\nif isinstance(obj, Mailbox):\n...\n# code to search a mailbox\nelif isinstance(obj, Document):\n...\n# code to search a document\nelif ...\nA better approach is to define a search() method on all the classes and just call it:\nclass Mailbox:\ndef search(self):\n...\n# code to search a mailbox\nclass Document:\ndef search(self):\n...\n# code to search a document\nobj.search()\n2.6.5 What is delegation? Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to\nchange the behaviour of just one of its methods. You can create a new class that provides a new implementation of\nthe method you’re interested in changing and delegates all other methods to the corresponding method of x.\nPython programmers can easily implement delegation. For example, the following class implements a class that\nbehaves like a file but converts all written data to uppercase:\nclass UpperOut:\ndef __init__(self, outfile):\nself._outfile = outfile\ndef write(self, s):\nself._outfile.write(s.upper())\ndef __getattr__(self, name):\nreturn getattr(self._outfile, name)\nHere the UpperOut class redefines the write() method to convert the argument string to uppercase before call-\ning the underlying self._outfile.write() method. All other methods are delegated to the underlying self. _outfile object. The delegation is accomplished via the __getattr__() method; consult the language reference\nfor more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved,\nthe class must define a __setattr__() method too, and it must do so carefully. The basic implementation of\n__setattr__() is roughly equivalent to the following:\nclass X:\n...\ndef __setattr__(self, name, value):\nself.__dict__[name] = value\n... Many __setattr__() implementations call object.__setattr__() to set an attribute on self without causing\ninfinite recursion:\n28\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nclass X:\ndef __setattr__(self, name, value):\n# Custom logic here...\nobject.__setattr__(self, name, value)\nAlternatively, it is possible to set attributes by inserting entries into self.__dict__ directly. 2.6.6 How do I call a method defined in a base class from a derived class that\nextends it? Use the built-in super() function:\nclass Derived(Base):\ndef meth(self):\nsuper().meth()\n# calls Base.meth\nIn the example, super() will automatically determine the instance from which it was called (the self value), look\nup the method resolution order (MRO) with type(self).__mro__, and return the next in line after Derived in\nthe MRO: Base. 2.6.7 How can I organize my code to make it easier to change the base class? You could assign the base class to an alias and derive from the alias. Then all you have to change is the value assigned\nto the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of\nresources) which base class to use. Example:\nclass Base:\n...\nBaseAlias = Base\nclass Derived(BaseAlias):\n...\n2.6.8 How do I create static class data and static class methods? Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the\nclass name in the assignment:\nclass C:\ncount = 0\n# number of times C.__init__ called\ndef __init__(self):\nC.count = C.count + 1\ndef getcount(self):\nreturn C.count\n# or return self.count\nc.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by\nsome class on the base-class search path from c.__class__ back to C.\nCaution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named\n“count” in self’s own dict. Rebinding of a class-static data name must always specify the class whether inside a\nmethod or not:\nC.count = 314\n2.6. Objects\n29\n\nPython Frequently Asked Questions, Release 3.13.2\nStatic methods are possible:\nclass C:\n@staticmethod\ndef static(arg1, arg2, arg3):\n# No \'self\' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function:\ndef getcount():\nreturn C.count\nIf your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the\ndesired encapsulation. 2.6.9 How can I overload constructors (or methods) in Python? This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write\nclass C {\nC() { cout << ""No arguments\\n""; }\nC(int i) { cout << ""Argument is "" << i << ""\\n""; }\n}\nIn Python you have to write a single constructor that catches all cases using default arguments. For example:\nclass C:\ndef __init__(self, i=None):\nif i is None:\nprint(""No arguments"")\nelse:\nprint(""Argument is"", i)\nThis is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args):\n... The same approach works for all method definitions. 2.6.10 I try to use __spam and I get an error about _SomeClassName__spam. Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class\nprivate variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing under-\nscore) is textually replaced with _classname__spam, where classname is the current class name with any leading\nunderscores stripped. The identifier can be used unchanged within the class, but to access it outside the class, the mangled name must be\nused:\nclass A:\ndef __one(self):\nreturn 1\ndef two(self):\nreturn 2 * self.__one()\n(continues on next page)\n30\nChapter 2.\n\n[3] The global scope associated with a\nmethod is the module containing its definition. (A class is never used as a global scope.) While one rarely encounters\na good reason for using global data in a method, there are many legitimate uses of the global scope: for one thing,\nfunctions and modules imported into the global scope can be used by methods, as well as functions and classes defined\nin it. Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find\nsome good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as object.__class__. 9.5 Inheritance\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax\nfor a derived class definition looks like this:\nclass DerivedClassName(BaseClassName):\n<statement-1>\n. . . <statement-N>\nThe name BaseClassName must be defined in a namespace accessible from the scope containing the derived class\ndefinition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example,\nwhen the base class is defined in another module:\nclass DerivedClassName(modname.BaseClassName):\nExecution of a derived class definition proceeds the same as for a base class. When the class object is constructed,\nthe base class is remembered. This is used for resolving attribute references: if a requested attribute is not found\nin the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is\nderived from some other class. There’s nothing special about instantiation of derived classes: DerivedClassName() creates a new instance of the\nclass. Method references are resolved as follows: the corresponding class attribute is searched, descending down the\nchain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling\nother methods of the same object, a method of a base class that calls another method defined in the same base class\nmay end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are\neffectively virtual.) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method\nof the same name. There is a simple way to call the base class method directly: just call BaseClassName. 80\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\nmethodname(self, arguments). This is occasionally useful to clients as well. (Note that this only works if\nthe base class is accessible as BaseClassName in the global scope.) Python has two built-in functions that work with inheritance:\n• Use isinstance() to check an instance’s type: isinstance(obj, int) will be True only if obj. __class__ is int or some class derived from int. • Use issubclass() to check class inheritance: issubclass(bool, int) is True since bool is a subclass\nof int. However, issubclass(float, int) is False since float is not a subclass of int. 9.5.1 Multiple Inheritance\nPython supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this:\nclass DerivedClassName(Base1, Base2, Base3):\n<statement-1>\n. . . <statement-N>\nFor most purposes, in the simplest cases, you can think of the search for attributes inherited from a parent class as\ndepth-first, left-to-right, not searching twice in the same class where there is an overlap in the hierarchy. Thus, if an\nattribute is not found in DerivedClassName, it is searched for in Base1, then (recursively) in the base classes of\nBase1, and if it was not found there, it was searched for in Base2, and so on. In fact, it is slightly more complex than that; the method resolution order changes dynamically to support cooperative\ncalls to super(). This approach is known in some other multiple-inheritance languages as call-next-method and is\nmore powerful than the super call found in single-inheritance languages. Dynamic ordering is necessary because all cases of multiple inheritance exhibit one or more diamond relationships\n(where at least one of the parent classes can be accessed through multiple paths from the bottommost class). For\nexample, all classes inherit from object, so any case of multiple inheritance provides more than one path to reach\nobject. To keep the base classes from being accessed more than once, the dynamic algorithm linearizes the search\norder in a way that preserves the left-to-right ordering specified in each class, that calls each parent only once, and that\nis monotonic (meaning that a class can be subclassed without affecting the precedence order of its parents). Taken\ntogether, these properties make it possible to design reliable and extensible classes with multiple inheritance. For\nmore detail, see python_2.3_mro. 9.6 Private Variables\n“Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there\nis a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be\ntreated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered\nan implementation detail and subject to change without notice. Since there is a valid use-case for class-private members (namely to avoid name clashes of names with names\ndefined by subclasses), there is limited support for such a mechanism, called name mangling. Any identifier of\nthe form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with\n_classname__spam, where classname is the current class name with leading underscore(s) stripped. This man-\ngling is done without regard to the syntactic position of the identifier, as long as it occurs within the definition of a\nclass.')",6.71833125977898e-156,0.014900662251655629,0.04168002564924656,0.42499780654907227,0.3517267
What is the best way of implementing a singleton in Python?,"You just need a decorator, different depending on the python version.


Notice how 
foo
 gets printed only once.




Python 3.2+


Implementation
:


from functools import lru_cache

@lru_cache(maxsize=None)
class CustomClass(object):

    def __init__(self, arg):
        print(f""CustomClass initialised with {arg}"")
        self.arg = arg



Usage


c1 = CustomClass(""foo"")
c2 = CustomClass(""foo"")
c3 = CustomClass(""bar"")

print(c1 == c2)
print(c1 == c3)



Output


>>> CustomClass initialised with foo
>>> CustomClass initialised with bar
>>> True
>>> False





Python 3.9+


Implementation
:


from functools import cache

@cache
class CustomClass(object):
    ...


","('Answer: An object is a singleton if only one instance of that object can exist.\n\nReferences: [2, 3]\n', '[1] After the list assign-\nment s[0] = x, it is guaranteed that s[0] is x. 3) If an object is a singleton, it means that only one instance of that object can exist. After the assignments a =\nNone and b = None, it is guaranteed that a is b because None is a singleton. In most other circumstances, identity tests are inadvisable and equality tests are preferred. In particular, identity tests\nshould not be used to check constants such as int and str which aren’t guaranteed to be singletons:\n>>> a = 1000\n>>> b = 500\n>>> c = b + 500\n>>> a is c\nFalse\n>>> a = \'Python\'\n>>> b = \'Py\'\n>>> c = b + \'thon\'\n>>> a is c\nFalse\nLikewise, new instances of mutable containers are never identical:\n>>> a = []\n>>> b = []\n>>> a is b\nFalse\nIn the standard library code, you will see several common patterns for correctly using identity tests:\n1) As recommended by PEP 8, an identity test is the preferred way to check for None. This reads like plain\nEnglish in code and avoids confusion with other objects that may have boolean values that evaluate to false. 2) Detecting optional arguments can be tricky when None is a valid input value. In those situations, you can\ncreate a singleton sentinel object guaranteed to be distinct from other objects. For example, here is how to\nimplement a method that behaves like dict.pop():\n_sentinel = object()\ndef pop(self, key, default=_sentinel):\nif key in self:\n(continues on next page)\n32\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nvalue = self[key]\ndel self[key]\nreturn value\nif default is _sentinel:\nraise KeyError(key)\nreturn default\n3) Container implementations sometimes need to augment equality tests with identity tests. This prevents the\ncode from being confused by objects such as float(\'NaN\') that are not equal to themselves. For example, here is the implementation of collections.abc.Sequence.__contains__():\ndef __contains__(self, value):\nfor v in self:\nif v is value or v == value:\nreturn True\nreturn False\n2.6.15 How can a subclass control what data is stored in an immutable instance? When subclassing an immutable type, override the __new__() method instead of the __init__() method. The\nlatter only runs after an instance is created, which is too late to alter data in an immutable instance. All of these immutable classes have a different signature than their parent class:\nfrom datetime import date\nclass FirstOfMonthDate(date):\n""Always choose the first day of the month""\ndef __new__(cls, year, month, day):\nreturn super().__new__(cls, year, month, 1)\nclass NamedInt(int):\n""Allow text names for some numbers""\nxlat = {\'zero\': 0, \'one\': 1, \'ten\': 10}\ndef __new__(cls, value):\nvalue = cls.xlat.get(value, value)\nreturn super().__new__(cls, value)\nclass TitleStr(str):\n""Convert str to name suitable for a URL path""\ndef __new__(cls, s):\ns = s.lower().replace(\' \', \'-\')\ns = \'\'.join([c for c in s if c.isalnum() or c == \'-\'])\nreturn super().__new__(cls, s)\nThe classes can be used like this:\n>>> FirstOfMonthDate(2012, 2, 14)\nFirstOfMonthDate(2012, 2, 1)\n>>> NamedInt(\'ten\')\n10\n>>> NamedInt(20)\n20\n>>> TitleStr(\'Blog: Why Python Rocks\')\n\'blog-why-python-rocks\'\n2.6. Objects\n33\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.16 How do I cache method calls? The two principal tools for caching methods are functools.cached_property() and functools. lru_cache(). The former stores results at the instance level and the latter at the class level. The cached_property approach only works with methods that do not take any arguments. It does not create a reference\nto the instance. The cached method result will be kept only as long as the instance is alive. The advantage is that when an instance is no longer used, the cached method result will be released right away. The\ndisadvantage is that if instances accumulate, so too will the accumulated method results. They can grow without\nbound. The lru_cache approach works with methods that have hashable arguments. It creates a reference to the instance\nunless special efforts are made to pass in weak references. The advantage of the least recently used algorithm is that the cache is bounded by the specified maxsize. The disad-\nvantage is that instances are kept alive until they age out of the cache or until the cache is cleared. This example shows the various techniques:\nclass Weather:\n""Lookup weather information on a government website""\ndef __init__(self, station_id):\nself._station_id = station_id\n# The _station_id is private and immutable\ndef current_temperature(self):\n""Latest hourly observation""\n# Do not cache this because old results\n# can be out of date. @cached_property\ndef location(self):\n""Return the longitude/latitude coordinates of the station""\n# Result only depends on the station_id\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'mm\'):\n""Rainfall on a given date""\n# Depends on the station_id, date, and units. The above example assumes that the station_id never changes. If the relevant instance attributes are mutable, the\ncached_property approach can’t be made to work because it cannot detect changes to the attributes. To make the lru_cache approach work when the station_id is mutable, the class needs to define the __eq__() and\n__hash__() methods so that the cache can detect relevant attribute updates:\nclass Weather:\n""Example with a mutable station identifier""\ndef __init__(self, station_id):\nself.station_id = station_id\ndef change_station(self, station_id):\nself.station_id = station_id\ndef __eq__(self, other):\nreturn self.station_id == other.station_id\ndef __hash__(self):\n(continues on next page)\n34\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nreturn hash(self.station_id)\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'cm\'):\n\'Rainfall on a given date\'\n# Depends on the station_id, date, and units. 2.7 Modules\n2.7.1 How do I create a .pyc file? When a module is imported for the first time (or when the source file has changed since the current compiled file was\ncreated) a .pyc file containing the compiled code should be created in a __pycache__ subdirectory of the directory\ncontaining the .py file. The .pyc file will have a filename that starts with the same name as the .py file, and ends\nwith .pyc, with a middle component that depends on the particular python binary that created it. (See PEP 3147\nfor details.) One reason that a .pyc file may not be created is a permissions problem with the directory containing the source\nfile, meaning that the __pycache__ subdirectory cannot be created. This can happen, for example, if you develop\nas one user but run as another, such as if you are testing with a web server. Unless the PYTHONDONTWRITEBYTECODE environment variable is set, creation of a .pyc file is automatic if you’re\nimporting a module and Python has the ability (permissions, free space, etc…) to create a __pycache__ subdirectory\nand write the compiled module to that subdirectory. Running Python on a top level script is not considered an import and no .pyc will be created. For example, if you\nhave a top-level module foo.py that imports another module xyz.py, when you run foo (by typing python foo. py as a shell command), a .pyc will be created for xyz because xyz is imported, but no .pyc file will be created\nfor foo since foo.py isn’t being imported. If you need to create a .pyc file for foo – that is, to create a .pyc file for a module that is not imported – you can,\nusing the py_compile and compileall modules. The py_compile module can manually compile any module. One way is to use the compile() function in that\nmodule interactively:\n>>> import py_compile\n>>> py_compile.compile(\'foo.py\')\nThis will write the .pyc to a __pycache__ subdirectory in the same location as foo.py (or you can override that\nwith the optional parameter cfile). You can also automatically compile all files in a directory or directories using the compileall module. You can do\nit from the shell prompt by running compileall.py and providing the path of a directory containing Python files\nto compile:\npython -m compileall . 2.7.2 How do I find the current module name?\n\n[2] 3) If an object is a singleton, it means that only one instance of that object can exist. After the assignments a =\nNone and b = None, it is guaranteed that a is b because None is a singleton. In most other circumstances, identity tests are inadvisable and equality tests are preferred. In particular, identity tests\nshould not be used to check constants such as int and str which aren’t guaranteed to be singletons:\n>>> a = 1000\n>>> b = 500\n>>> c = b + 500\n>>> a is c\nFalse\n>>> a = \'Python\'\n>>> b = \'Py\'\n>>> c = b + \'thon\'\n>>> a is c\nFalse\nLikewise, new instances of mutable containers are never identical:\n>>> a = []\n>>> b = []\n>>> a is b\nFalse\nIn the standard library code, you will see several common patterns for correctly using identity tests:\n1) As recommended by PEP 8, an identity test is the preferred way to check for None. This reads like plain\nEnglish in code and avoids confusion with other objects that may have boolean values that evaluate to false. 2) Detecting optional arguments can be tricky when None is a valid input value. In those situations, you can\ncreate a singleton sentinel object guaranteed to be distinct from other objects. For example, here is how to\nimplement a method that behaves like dict.pop():\n_sentinel = object()\ndef pop(self, key, default=_sentinel):\nif key in self:\n(continues on next page)\n32\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nvalue = self[key]\ndel self[key]\nreturn value\nif default is _sentinel:\nraise KeyError(key)\nreturn default\n3) Container implementations sometimes need to augment equality tests with identity tests. This prevents the\ncode from being confused by objects such as float(\'NaN\') that are not equal to themselves. For example, here is the implementation of collections.abc.Sequence.__contains__():\ndef __contains__(self, value):\nfor v in self:\nif v is value or v == value:\nreturn True\nreturn False\n2.6.15 How can a subclass control what data is stored in an immutable instance? When subclassing an immutable type, override the __new__() method instead of the __init__() method. The\nlatter only runs after an instance is created, which is too late to alter data in an immutable instance. All of these immutable classes have a different signature than their parent class:\nfrom datetime import date\nclass FirstOfMonthDate(date):\n""Always choose the first day of the month""\ndef __new__(cls, year, month, day):\nreturn super().__new__(cls, year, month, 1)\nclass NamedInt(int):\n""Allow text names for some numbers""\nxlat = {\'zero\': 0, \'one\': 1, \'ten\': 10}\ndef __new__(cls, value):\nvalue = cls.xlat.get(value, value)\nreturn super().__new__(cls, value)\nclass TitleStr(str):\n""Convert str to name suitable for a URL path""\ndef __new__(cls, s):\ns = s.lower().replace(\' \', \'-\')\ns = \'\'.join([c for c in s if c.isalnum() or c == \'-\'])\nreturn super().__new__(cls, s)\nThe classes can be used like this:\n>>> FirstOfMonthDate(2012, 2, 14)\nFirstOfMonthDate(2012, 2, 1)\n>>> NamedInt(\'ten\')\n10\n>>> NamedInt(20)\n20\n>>> TitleStr(\'Blog: Why Python Rocks\')\n\'blog-why-python-rocks\'\n2.6. Objects\n33\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.16 How do I cache method calls? The two principal tools for caching methods are functools.cached_property() and functools. lru_cache(). The former stores results at the instance level and the latter at the class level. The cached_property approach only works with methods that do not take any arguments. It does not create a reference\nto the instance. The cached method result will be kept only as long as the instance is alive. The advantage is that when an instance is no longer used, the cached method result will be released right away. The\ndisadvantage is that if instances accumulate, so too will the accumulated method results. They can grow without\nbound. The lru_cache approach works with methods that have hashable arguments. It creates a reference to the instance\nunless special efforts are made to pass in weak references. The advantage of the least recently used algorithm is that the cache is bounded by the specified maxsize. The disad-\nvantage is that instances are kept alive until they age out of the cache or until the cache is cleared. This example shows the various techniques:\nclass Weather:\n""Lookup weather information on a government website""\ndef __init__(self, station_id):\nself._station_id = station_id\n# The _station_id is private and immutable\ndef current_temperature(self):\n""Latest hourly observation""\n# Do not cache this because old results\n# can be out of date. @cached_property\ndef location(self):\n""Return the longitude/latitude coordinates of the station""\n# Result only depends on the station_id\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'mm\'):\n""Rainfall on a given date""\n# Depends on the station_id, date, and units. The above example assumes that the station_id never changes. If the relevant instance attributes are mutable, the\ncached_property approach can’t be made to work because it cannot detect changes to the attributes. To make the lru_cache approach work when the station_id is mutable, the class needs to define the __eq__() and\n__hash__() methods so that the cache can detect relevant attribute updates:\nclass Weather:\n""Example with a mutable station identifier""\ndef __init__(self, station_id):\nself.station_id = station_id\ndef change_station(self, station_id):\nself.station_id = station_id\ndef __eq__(self, other):\nreturn self.station_id == other.station_id\ndef __hash__(self):\n(continues on next page)\n34\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nreturn hash(self.station_id)\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'cm\'):\n\'Rainfall on a given date\'\n# Depends on the station_id, date, and units. 2.7 Modules\n2.7.1 How do I create a .pyc file? When a module is imported for the first time (or when the source file has changed since the current compiled file was\ncreated) a .pyc file containing the compiled code should be created in a __pycache__ subdirectory of the directory\ncontaining the .py file. The .pyc file will have a filename that starts with the same name as the .py file, and ends\nwith .pyc, with a middle component that depends on the particular python binary that created it. (See PEP 3147\nfor details.) One reason that a .pyc file may not be created is a permissions problem with the directory containing the source\nfile, meaning that the __pycache__ subdirectory cannot be created. This can happen, for example, if you develop\nas one user but run as another, such as if you are testing with a web server. Unless the PYTHONDONTWRITEBYTECODE environment variable is set, creation of a .pyc file is automatic if you’re\nimporting a module and Python has the ability (permissions, free space, etc…) to create a __pycache__ subdirectory\nand write the compiled module to that subdirectory. Running Python on a top level script is not considered an import and no .pyc will be created. For example, if you\nhave a top-level module foo.py that imports another module xyz.py, when you run foo (by typing python foo. py as a shell command), a .pyc will be created for xyz because xyz is imported, but no .pyc file will be created\nfor foo since foo.py isn’t being imported. If you need to create a .pyc file for foo – that is, to create a .pyc file for a module that is not imported – you can,\nusing the py_compile and compileall modules. The py_compile module can manually compile any module. One way is to use the compile() function in that\nmodule interactively:\n>>> import py_compile\n>>> py_compile.compile(\'foo.py\')\nThis will write the .pyc to a __pycache__ subdirectory in the same location as foo.py (or you can override that\nwith the optional parameter cfile). You can also automatically compile all files in a directory or directories using the compileall module. You can do\nit from the shell prompt by running compileall.py and providing the path of a directory containing Python files\nto compile:\npython -m compileall . 2.7.2 How do I find the current module name? A module can find out its own module name by looking at the predefined global variable __name__.\n\n[3] Generally, there are\nthree circumstances where identity is guaranteed:\n1) Assignments create new names but do not change object identity. After the assignment new = old, it is guaran-\nteed that new is old. 2) Putting an object in a container that stores object references does not change object identity. After the list assign-\nment s[0] = x, it is guaranteed that s[0] is x. 3) If an object is a singleton, it means that only one instance of that object can exist. After the assignments a =\nNone and b = None, it is guaranteed that a is b because None is a singleton. In most other circumstances, identity tests are inadvisable and equality tests are preferred. In particular, identity tests\nshould not be used to check constants such as int and str which aren’t guaranteed to be singletons:\n>>> a = 1000\n>>> b = 500\n>>> c = b + 500\n>>> a is c\nFalse\n>>> a = \'Python\'\n>>> b = \'Py\'\n>>> c = b + \'thon\'\n>>> a is c\nFalse\nLikewise, new instances of mutable containers are never identical:\n>>> a = []\n>>> b = []\n>>> a is b\nFalse\nIn the standard library code, you will see several common patterns for correctly using identity tests:\n1) As recommended by PEP 8, an identity test is the preferred way to check for None. This reads like plain\nEnglish in code and avoids confusion with other objects that may have boolean values that evaluate to false. 2) Detecting optional arguments can be tricky when None is a valid input value. In those situations, you can\ncreate a singleton sentinel object guaranteed to be distinct from other objects. For example, here is how to\nimplement a method that behaves like dict.pop():\n_sentinel = object()\ndef pop(self, key, default=_sentinel):\nif key in self:\n(continues on next page)\n32\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nvalue = self[key]\ndel self[key]\nreturn value\nif default is _sentinel:\nraise KeyError(key)\nreturn default\n3) Container implementations sometimes need to augment equality tests with identity tests. This prevents the\ncode from being confused by objects such as float(\'NaN\') that are not equal to themselves. For example, here is the implementation of collections.abc.Sequence.__contains__():\ndef __contains__(self, value):\nfor v in self:\nif v is value or v == value:\nreturn True\nreturn False\n2.6.15 How can a subclass control what data is stored in an immutable instance? When subclassing an immutable type, override the __new__() method instead of the __init__() method. The\nlatter only runs after an instance is created, which is too late to alter data in an immutable instance. All of these immutable classes have a different signature than their parent class:\nfrom datetime import date\nclass FirstOfMonthDate(date):\n""Always choose the first day of the month""\ndef __new__(cls, year, month, day):\nreturn super().__new__(cls, year, month, 1)\nclass NamedInt(int):\n""Allow text names for some numbers""\nxlat = {\'zero\': 0, \'one\': 1, \'ten\': 10}\ndef __new__(cls, value):\nvalue = cls.xlat.get(value, value)\nreturn super().__new__(cls, value)\nclass TitleStr(str):\n""Convert str to name suitable for a URL path""\ndef __new__(cls, s):\ns = s.lower().replace(\' \', \'-\')\ns = \'\'.join([c for c in s if c.isalnum() or c == \'-\'])\nreturn super().__new__(cls, s)\nThe classes can be used like this:\n>>> FirstOfMonthDate(2012, 2, 14)\nFirstOfMonthDate(2012, 2, 1)\n>>> NamedInt(\'ten\')\n10\n>>> NamedInt(20)\n20\n>>> TitleStr(\'Blog: Why Python Rocks\')\n\'blog-why-python-rocks\'\n2.6. Objects\n33\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.16 How do I cache method calls? The two principal tools for caching methods are functools.cached_property() and functools. lru_cache(). The former stores results at the instance level and the latter at the class level. The cached_property approach only works with methods that do not take any arguments. It does not create a reference\nto the instance. The cached method result will be kept only as long as the instance is alive. The advantage is that when an instance is no longer used, the cached method result will be released right away. The\ndisadvantage is that if instances accumulate, so too will the accumulated method results. They can grow without\nbound. The lru_cache approach works with methods that have hashable arguments. It creates a reference to the instance\nunless special efforts are made to pass in weak references. The advantage of the least recently used algorithm is that the cache is bounded by the specified maxsize. The disad-\nvantage is that instances are kept alive until they age out of the cache or until the cache is cleared. This example shows the various techniques:\nclass Weather:\n""Lookup weather information on a government website""\ndef __init__(self, station_id):\nself._station_id = station_id\n# The _station_id is private and immutable\ndef current_temperature(self):\n""Latest hourly observation""\n# Do not cache this because old results\n# can be out of date. @cached_property\ndef location(self):\n""Return the longitude/latitude coordinates of the station""\n# Result only depends on the station_id\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'mm\'):\n""Rainfall on a given date""\n# Depends on the station_id, date, and units. The above example assumes that the station_id never changes. If the relevant instance attributes are mutable, the\ncached_property approach can’t be made to work because it cannot detect changes to the attributes. To make the lru_cache approach work when the station_id is mutable, the class needs to define the __eq__() and\n__hash__() methods so that the cache can detect relevant attribute updates:\nclass Weather:\n""Example with a mutable station identifier""\ndef __init__(self, station_id):\nself.station_id = station_id\ndef change_station(self, station_id):\nself.station_id = station_id\ndef __eq__(self, other):\nreturn self.station_id == other.station_id\ndef __hash__(self):\n(continues on next page)\n34\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nreturn hash(self.station_id)\n@lru_cache(maxsize=20)\ndef historic_rainfall(self, date, units=\'cm\'):\n\'Rainfall on a given date\'\n# Depends on the station_id, date, and units. 2.7 Modules\n2.7.1 How do I create a .pyc file? When a module is imported for the first time (or when the source file has changed since the current compiled file was\ncreated) a .pyc file containing the compiled code should be created in a __pycache__ subdirectory of the directory\ncontaining the .py file. The .pyc file will have a filename that starts with the same name as the .py file, and ends\nwith .pyc, with a middle component that depends on the particular python binary that created it. (See PEP 3147\nfor details.) One reason that a .pyc file may not be created is a permissions problem with the directory containing the source\nfile, meaning that the __pycache__ subdirectory cannot be created. This can happen, for example, if you develop\nas one user but run as another, such as if you are testing with a web server. Unless the PYTHONDONTWRITEBYTECODE environment variable is set, creation of a .pyc file is automatic if you’re\nimporting a module and Python has the ability (permissions, free space, etc…) to create a __pycache__ subdirectory\nand write the compiled module to that subdirectory. Running Python on a top level script is not considered an import and no .pyc will be created. For example, if you\nhave a top-level module foo.py that imports another module xyz.py, when you run foo (by typing python foo. py as a shell command), a .pyc will be created for xyz because xyz is imported, but no .pyc file will be created\nfor foo since foo.py isn’t being imported. If you need to create a .pyc file for foo – that is, to create a .pyc file for a module that is not imported – you can,\nusing the py_compile and compileall modules. The py_compile module can manually compile any module. One way is to use the compile() function in that\nmodule interactively:\n>>> import py_compile\n>>> py_compile.compile(\'foo.py\')\nThis will write the .pyc to a __pycache__ subdirectory in the same location as foo.py (or you can override that\nwith the optional parameter cfile).')",5.905349393702067e-156,0.01679909194097616,0.094577005776322,0.5249489545822144,0.30990833
How do I get the filename without the extension from a path in Python?,"Python 3.4+


Use 
pathlib.Path.stem


>>> from pathlib import Path
>>> Path(""/path/to/file.txt"").stem
'file'
>>> Path(""/path/to/file.tar.gz"").stem
'file.tar'



Python < 3.4


Use 
os.path.splitext
 in combination with 
os.path.basename
:


>>> os.path.splitext(os.path.basename(""/path/to/file.txt""))[0]
'file'
>>> os.path.splitext(os.path.basename(""/path/to/file.tar.gz""))[0]
'file.tar'


","('Answer: To get the filename without the extension from a path in Python, you can use the `stem` attribute of the `PurePath` class.\n\nReferences: [1]\n', '[1] PurePath.name\nA string representing the final path component, excluding the drive and root, if any:\n>>> PurePosixPath(\'my/library/setup.py\').name\n\'setup.py\'\nUNC drive names are not considered:\n11.1. pathlib — Object-oriented filesystem paths\n445\n\nThe Python Library Reference, Release 3.13.2\n>>> PureWindowsPath(\'//some/share/setup.py\').name\n\'setup.py\'\n>>> PureWindowsPath(\'//some/share\').name\n\'\'\nPurePath.suffix\nThe last dot-separated portion of the final component, if any:\n>>> PurePosixPath(\'my/library/setup.py\').suffix\n\'.py\'\n>>> PurePosixPath(\'my/library.tar.gz\').suffix\n\'.gz\'\n>>> PurePosixPath(\'my/library\').suffix\n\'\'\nThis is commonly called the file extension. PurePath.suffixes\nA list of the path’s suffixes, often called file extensions:\n>>> PurePosixPath(\'my/library.tar.gar\').suffixes\n[\'.tar\', \'.gar\']\n>>> PurePosixPath(\'my/library.tar.gz\').suffixes\n[\'.tar\', \'.gz\']\n>>> PurePosixPath(\'my/library\').suffixes\n[]\nPurePath.stem\nThe final path component, without its suffix:\n>>> PurePosixPath(\'my/library.tar.gz\').stem\n\'library.tar\'\n>>> PurePosixPath(\'my/library.tar\').stem\n\'library\'\n>>> PurePosixPath(\'my/library\').stem\n\'library\'\nPurePath.as_posix()\nReturn a string representation of the path with forward slashes (/):\n>>> p = PureWindowsPath(\'c:\\\\windows\')\n>>> str(p)\n\'c:\\\\windows\'\n>>> p.as_posix()\n\'c:/windows\'\nPurePath.is_absolute()\nReturn whether the path is absolute or not. A path is considered absolute if it has both a root and (if the flavour\nallows) a drive:\n>>> PurePosixPath(\'/a/b\').is_absolute()\nTrue\n>>> PurePosixPath(\'a/b\').is_absolute()\nFalse\n>>> PureWindowsPath(\'c:/a/b\').is_absolute()\nTrue\n(continues on next page)\n446\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> PureWindowsPath(\'/a/b\').is_absolute()\nFalse\n>>> PureWindowsPath(\'c:\').is_absolute()\nFalse\n>>> PureWindowsPath(\'//some/share\').is_absolute()\nTrue\nPurePath.is_relative_to(other)\nReturn whether or not this path is relative to the other path. >>> p = PurePath(\'/etc/passwd\')\n>>> p.is_relative_to(\'/etc\')\nTrue\n>>> p.is_relative_to(\'/usr\')\nFalse\nThis method is string-based; it neither accesses the filesystem nor treats “..” segments specially. The following\ncode is equivalent:\n>>> u = PurePath(\'/usr\')\n>>> u == p or u in p.parents\nFalse\nAdded in version 3.9. Deprecated since version 3.12, will be removed in version 3.14: Passing additional arguments is deprecated;\nif supplied, they are joined with other. PurePath.is_reserved()\nWith PureWindowsPath, return True if the path is considered reserved under Windows, False otherwise. With PurePosixPath, False is always returned. Changed in version 3.13: Windows path names that contain a colon, or end with a dot or a space, are considered\nreserved. UNC paths may be reserved. Deprecated since version 3.13, will be removed in version 3.15: This method is deprecated; use os.path. isreserved() to detect reserved paths on Windows. PurePath.joinpath(*pathsegments)\nCalling this method is equivalent to combining the path with each of the given pathsegments in turn:\n>>> PurePosixPath(\'/etc\').joinpath(\'passwd\')\nPurePosixPath(\'/etc/passwd\')\n>>> PurePosixPath(\'/etc\').joinpath(PurePosixPath(\'passwd\'))\nPurePosixPath(\'/etc/passwd\')\n>>> PurePosixPath(\'/etc\').joinpath(\'init.d\', \'apache2\')\nPurePosixPath(\'/etc/init.d/apache2\')\n>>> PureWindowsPath(\'c:\').joinpath(\'/Program Files\')\nPureWindowsPath(\'c:/Program Files\')\nPurePath.full_match(pattern, *, case_sensitive=None)\nMatch this path against the provided glob-style pattern. Return True if matching is successful, False other-\nwise. For example:\n>>> PurePath(\'a/b.py\').full_match(\'a/*.py\')\nTrue\n>>> PurePath(\'a/b.py\').full_match(\'*.py\')\nFalse\n(continues on next page)\n11.1. pathlib — Object-oriented filesystem paths\n447\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> PurePath(\'/a/b/c.py\').full_match(\'/a/**\')\nTrue\n>>> PurePath(\'/a/b/c.py\').full_match(\'**/*.py\')\nTrue\nµ See also\nPattern language documentation. As with other methods, case-sensitivity follows platform defaults:\n>>> PurePosixPath(\'b.py\').full_match(\'*.PY\')\nFalse\n>>> PureWindowsPath(\'b.py\').full_match(\'*.PY\')\nTrue\nSet case_sensitive to True or False to override this behaviour. Added in version 3.13. PurePath.match(pattern, *, case_sensitive=None)\nMatch this path against the provided non-recursive glob-style pattern. Return True if matching is successful,\nFalse otherwise. This method is similar to full_match(), but empty patterns aren’t allowed (ValueError is raised), the\nrecursive wildcard “**” isn’t supported (it acts like non-recursive “*”), and if a relative pattern is provided,\nthen matching is done from the right:\n>>> PurePath(\'a/b.py\').match(\'*.py\')\nTrue\n>>> PurePath(\'/a/b/c.py\').match(\'b/*.py\')\nTrue\n>>> PurePath(\'/a/b/c.py\').match(\'a/*.py\')\nFalse\nChanged in version 3.12: The pattern parameter accepts a path-like object. Changed in version 3.12: The case_sensitive parameter was added. PurePath.relative_to(other, walk_up=False)\nCompute a version of this path relative to the path represented by other. If it’s impossible, ValueError is\nraised:\n>>> p = PurePosixPath(\'/etc/passwd\')\n>>> p.relative_to(\'/\')\nPurePosixPath(\'etc/passwd\')\n>>> p.relative_to(\'/etc\')\nPurePosixPath(\'passwd\')\n>>> p.relative_to(\'/usr\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""pathlib.py"", line 941, in relative_to\nraise ValueError(error_message.format(str(self), str(formatted)))\nValueError: \'/etc/passwd\' is not in the subpath of \'/usr\' OR one path is␣\n,→relative and the other is absolute. When walk_up is false (the default), the path must start with other. When the argument is true, .. entries\nmay be added to form the relative path. In all other cases, such as the paths referencing different drives,\n448\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nValueError is raised. :\n>>> p.relative_to(\'/usr\', walk_up=True)\nPurePosixPath(\'../etc/passwd\')\n>>> p.relative_to(\'foo\', walk_up=True)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""pathlib.py"", line 941, in relative_to\nraise ValueError(error_message.format(str(self), str(formatted)))\nValueError: \'/etc/passwd\' is not on the same drive as \'foo\' OR one path is␣\n,→relative and the other is absolute. Á Warning\nThis function is part of PurePath and works with strings. It does not check or access the underlying file\nstructure. This can impact the walk_up option as it assumes that no symlinks are present in the path; call\nresolve() first if necessary to resolve symlinks. Changed in version 3.12: The walk_up parameter was added (old behavior is the same as walk_up=False). Deprecated since version 3.12, will be removed in version 3.14: Passing additional positional arguments is\ndeprecated; if supplied, they are joined with other. PurePath.with_name(name)\nReturn a new path with the name changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_name(\'setup.py\')\nPureWindowsPath(\'c:/Downloads/setup.py\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_name(\'setup.py\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 751, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nPurePath.with_stem(stem)\nReturn a new path with the stem changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/draft.txt\')\n>>> p.with_stem(\'final\')\nPureWindowsPath(\'c:/Downloads/final.txt\')\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_stem(\'lib\')\nPureWindowsPath(\'c:/Downloads/lib.gz\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_stem(\'\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 861, in with_stem\nreturn self.with_name(stem + self.suffix)\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 851, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nAdded in version 3.9. 11.1. pathlib — Object-oriented filesystem paths\n449\n\nThe Python Library Reference, Release 3.13.2\nPurePath.with_suffix(suffix)\nReturn a new path with the suffix changed. If the original path doesn’t have a suffix, the new suffix is\nappended instead. If the suffix is an empty string, the original suffix is removed:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_suffix(\'.bz2\')\nPureWindowsPath(\'c:/Downloads/pathlib.tar.bz2\')\n>>> p = PureWindowsPath(\'README\')\n>>> p.with_suffix(\'.txt\')\nPureWindowsPath(\'README.txt\')\n>>> p = PureWindowsPath(\'README.txt\')\n>>> p.with_suffix(\'\')\nPureWindowsPath(\'README\')\nPurePath.with_segments(*pathsegments)\nCreate a new path object of the same type by combining the given pathsegments. This method is called when-\never a derivative path is created, such as from parent and relative_to(). Subclasses may override this\nmethod to pass information to derivative paths, for example:\nfrom pathlib import PurePosixPath\nclass MyPath(PurePosixPath):\ndef __init__(self, *pathsegments, session_id):\nsuper().__init__(*pathsegments)\nself.session_id = session_id\ndef with_segments(self, *pathsegments):\nreturn type(self)(*pathsegments, session_id=self.session_id)\netc = MyPath(\'/etc\', session_id=42)\nhosts = etc / \'hosts\'\nprint(hosts.session_id)\n# 42\nAdded in version 3.12. 11.1.4 Concrete paths\nConcrete paths are subclasses of the pure path classes. In addition to operations provided by the latter, they also\nprovide methods to do system calls on path objects. There are three ways to instantiate concrete paths:\nclass pathlib.Path(*pathsegments)\nA subclass of PurePath, this class represents concrete paths of the system’s path flavour (instantiating it\ncreates either a PosixPath or a WindowsPath):\n>>> Path(\'setup.py\')\nPosixPath(\'setup.py\')\npathsegments is specified similarly to PurePath. class pathlib.PosixPath(*pathsegments)\nA subclass of Path and PurePosixPath, this class represents concrete non-Windows filesystem paths:\n>>> PosixPath(\'/etc/hosts\')\nPosixPath(\'/etc/hosts\')\npathsegments is specified similarly to PurePath. Changed in version 3.13:\nRaises UnsupportedOperation on Windows. In previous versions,\nNotImplementedError was raised instead. 450\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nclass pathlib.WindowsPath(*pathsegments)\nA subclass of Path and PureWindowsPath, this class represents concrete Windows filesystem paths:\n>>> WindowsPath(\'c:/\', \'Users\', \'Ximénez\')\nWindowsPath(\'c:/Users/Ximénez\')\npathsegments is specified similarly to PurePath. Changed in version 3.13: Raises UnsupportedOperation on non-Windows platforms.\n\n[2] Á Warning\nThis function is part of PurePath and works with strings. It does not check or access the underlying file\nstructure. This can impact the walk_up option as it assumes that no symlinks are present in the path; call\nresolve() first if necessary to resolve symlinks. Changed in version 3.12: The walk_up parameter was added (old behavior is the same as walk_up=False). Deprecated since version 3.12, will be removed in version 3.14: Passing additional positional arguments is\ndeprecated; if supplied, they are joined with other. PurePath.with_name(name)\nReturn a new path with the name changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_name(\'setup.py\')\nPureWindowsPath(\'c:/Downloads/setup.py\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_name(\'setup.py\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 751, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nPurePath.with_stem(stem)\nReturn a new path with the stem changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/draft.txt\')\n>>> p.with_stem(\'final\')\nPureWindowsPath(\'c:/Downloads/final.txt\')\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_stem(\'lib\')\nPureWindowsPath(\'c:/Downloads/lib.gz\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_stem(\'\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 861, in with_stem\nreturn self.with_name(stem + self.suffix)\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 851, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nAdded in version 3.9. 11.1. pathlib — Object-oriented filesystem paths\n449\n\nThe Python Library Reference, Release 3.13.2\nPurePath.with_suffix(suffix)\nReturn a new path with the suffix changed. If the original path doesn’t have a suffix, the new suffix is\nappended instead. If the suffix is an empty string, the original suffix is removed:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_suffix(\'.bz2\')\nPureWindowsPath(\'c:/Downloads/pathlib.tar.bz2\')\n>>> p = PureWindowsPath(\'README\')\n>>> p.with_suffix(\'.txt\')\nPureWindowsPath(\'README.txt\')\n>>> p = PureWindowsPath(\'README.txt\')\n>>> p.with_suffix(\'\')\nPureWindowsPath(\'README\')\nPurePath.with_segments(*pathsegments)\nCreate a new path object of the same type by combining the given pathsegments. This method is called when-\never a derivative path is created, such as from parent and relative_to(). Subclasses may override this\nmethod to pass information to derivative paths, for example:\nfrom pathlib import PurePosixPath\nclass MyPath(PurePosixPath):\ndef __init__(self, *pathsegments, session_id):\nsuper().__init__(*pathsegments)\nself.session_id = session_id\ndef with_segments(self, *pathsegments):\nreturn type(self)(*pathsegments, session_id=self.session_id)\netc = MyPath(\'/etc\', session_id=42)\nhosts = etc / \'hosts\'\nprint(hosts.session_id)\n# 42\nAdded in version 3.12. 11.1.4 Concrete paths\nConcrete paths are subclasses of the pure path classes. In addition to operations provided by the latter, they also\nprovide methods to do system calls on path objects. There are three ways to instantiate concrete paths:\nclass pathlib.Path(*pathsegments)\nA subclass of PurePath, this class represents concrete paths of the system’s path flavour (instantiating it\ncreates either a PosixPath or a WindowsPath):\n>>> Path(\'setup.py\')\nPosixPath(\'setup.py\')\npathsegments is specified similarly to PurePath. class pathlib.PosixPath(*pathsegments)\nA subclass of Path and PurePosixPath, this class represents concrete non-Windows filesystem paths:\n>>> PosixPath(\'/etc/hosts\')\nPosixPath(\'/etc/hosts\')\npathsegments is specified similarly to PurePath. Changed in version 3.13:\nRaises UnsupportedOperation on Windows. In previous versions,\nNotImplementedError was raised instead. 450\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nclass pathlib.WindowsPath(*pathsegments)\nA subclass of Path and PureWindowsPath, this class represents concrete Windows filesystem paths:\n>>> WindowsPath(\'c:/\', \'Users\', \'Ximénez\')\nWindowsPath(\'c:/Users/Ximénez\')\npathsegments is specified similarly to PurePath. Changed in version 3.13: Raises UnsupportedOperation on non-Windows platforms. In previous versions,\nNotImplementedError was raised instead. You can only instantiate the class flavour that corresponds to your system (allowing system calls on non-compatible\npath flavours could lead to bugs or failures in your application):\n>>> import os\n>>> os.name\n\'posix\'\n>>> Path(\'setup.py\')\nPosixPath(\'setup.py\')\n>>> PosixPath(\'setup.py\')\nPosixPath(\'setup.py\')\n>>> WindowsPath(\'setup.py\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""pathlib.py"", line 798, in __new__\n% (cls.__name__,))\nUnsupportedOperation: cannot instantiate \'WindowsPath\' on your system\nSome concrete path methods can raise an OSError if a system call fails (for example because the path doesn’t exist). Parsing and generating URIs\nConcrete path objects can be created from, and represented as, ‘file’ URIs conforming to RFC 8089. ® Note\nFile URIs are not portable across machines with different filesystem encodings. classmethod Path.from_uri(uri)\nReturn a new path object from parsing a ‘file’ URI. For example:\n>>> p = Path.from_uri(\'file:///etc/hosts\')\nPosixPath(\'/etc/hosts\')\nOn Windows, DOS device and UNC paths may be parsed from URIs:\n>>> p = Path.from_uri(\'file:///c:/windows\')\nWindowsPath(\'c:/windows\')\n>>> p = Path.from_uri(\'file://server/share\')\nWindowsPath(\'//server/share\')\nSeveral variant forms are supported:\n>>> p = Path.from_uri(\'file:////server/share\')\nWindowsPath(\'//server/share\')\n>>> p = Path.from_uri(\'file://///server/share\')\nWindowsPath(\'//server/share\')\n>>> p = Path.from_uri(\'file:c:/windows\')\n(continues on next page)\n11.1. pathlib — Object-oriented filesystem paths\n451\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nWindowsPath(\'c:/windows\')\n>>> p = Path.from_uri(\'file:/c|/windows\')\nWindowsPath(\'c:/windows\')\nValueError is raised if the URI does not start with file:, or the parsed path isn’t absolute. Added in version 3.13. Path.as_uri()\nRepresent the path as a ‘file’ URI. ValueError is raised if the path isn’t absolute. >>> p = PosixPath(\'/etc/passwd\')\n>>> p.as_uri()\n\'file:///etc/passwd\'\n>>> p = WindowsPath(\'c:/Windows\')\n>>> p.as_uri()\n\'file:///c:/Windows\'\nFor historical reasons, this method is also available from PurePath objects. However, its use of os. fsencode() makes it strictly impure. Expanding and resolving paths\nclassmethod Path.home()\nReturn a new path object representing the user’s home directory (as returned by os.path.expanduser()\nwith ~ construct). If the home directory can’t be resolved, RuntimeError is raised. >>> Path.home()\nPosixPath(\'/home/antoine\')\nAdded in version 3.5. Path.expanduser()\nReturn a new path with expanded ~ and ~user constructs, as returned by os.path.expanduser(). If a\nhome directory can’t be resolved, RuntimeError is raised. >>> p = PosixPath(\'~/films/Monty Python\')\n>>> p.expanduser()\nPosixPath(\'/home/eric/films/Monty Python\')\nAdded in version 3.5.\nclassmethod Path.cwd()\nReturn a new path object representing the current directory (as returned by os.getcwd()):\n>>> Path.cwd()\nPosixPath(\'/home/antoine/pathlib\')\nPath.absolute()\nMake the path absolute, without normalization or resolving symlinks. Returns a new path object:\n>>> p = Path(\'tests\')\n>>> p\nPosixPath(\'tests\')\n>>> p.absolute()\nPosixPath(\'/home/antoine/pathlib/tests\')\n452\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.resolve(strict=False)\nMake the path absolute, resolving any symlinks. A new path object is returned:\n>>> p = Path()\n>>> p\nPosixPath(\'.\') >>> p.resolve()\nPosixPath(\'/home/antoine/pathlib\')\n“..” components are also eliminated (this is the only method to do so):\n>>> p = Path(\'docs/../setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\nIf a path doesn’t exist or a symlink loop is encountered, and strict is True, OSError is raised. If strict is False,\nthe path is resolved as far as possible and any remainder is appended without checking whether it exists. Changed in version 3.6: The strict parameter was added (pre-3.6 behavior is strict). Changed in version 3.13: Symlink loops are treated like other errors: OSError is raised in strict mode, and\nno exception is raised in non-strict mode. In previous versions, RuntimeError is raised no matter the value\nof strict. Path.readlink()\nReturn the path to which the symbolic link points (as returned by os.readlink()):\n>>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.readlink()\nPosixPath(\'setup.py\')\nAdded in version 3.9. Changed in version 3.13: Raises UnsupportedOperation if os.readlink() is not available. In previous\nversions, NotImplementedError was raised.\n\n[3] PurePath.with_name(name)\nReturn a new path with the name changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_name(\'setup.py\')\nPureWindowsPath(\'c:/Downloads/setup.py\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_name(\'setup.py\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 751, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nPurePath.with_stem(stem)\nReturn a new path with the stem changed. If the original path doesn’t have a name, ValueError is raised:\n>>> p = PureWindowsPath(\'c:/Downloads/draft.txt\')\n>>> p.with_stem(\'final\')\nPureWindowsPath(\'c:/Downloads/final.txt\')\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_stem(\'lib\')\nPureWindowsPath(\'c:/Downloads/lib.gz\')\n>>> p = PureWindowsPath(\'c:/\')\n>>> p.with_stem(\'\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 861, in with_stem\nreturn self.with_name(stem + self.suffix)\nFile ""/home/antoine/cpython/default/Lib/pathlib.py"", line 851, in with_name\nraise ValueError(""%r has an empty name"" % (self,))\nValueError: PureWindowsPath(\'c:/\') has an empty name\nAdded in version 3.9. 11.1. pathlib — Object-oriented filesystem paths\n449\n\nThe Python Library Reference, Release 3.13.2\nPurePath.with_suffix(suffix)\nReturn a new path with the suffix changed. If the original path doesn’t have a suffix, the new suffix is\nappended instead. If the suffix is an empty string, the original suffix is removed:\n>>> p = PureWindowsPath(\'c:/Downloads/pathlib.tar.gz\')\n>>> p.with_suffix(\'.bz2\')\nPureWindowsPath(\'c:/Downloads/pathlib.tar.bz2\')\n>>> p = PureWindowsPath(\'README\')\n>>> p.with_suffix(\'.txt\')\nPureWindowsPath(\'README.txt\')\n>>> p = PureWindowsPath(\'README.txt\')\n>>> p.with_suffix(\'\')\nPureWindowsPath(\'README\')\nPurePath.with_segments(*pathsegments)\nCreate a new path object of the same type by combining the given pathsegments. This method is called when-\never a derivative path is created, such as from parent and relative_to(). Subclasses may override this\nmethod to pass information to derivative paths, for example:\nfrom pathlib import PurePosixPath\nclass MyPath(PurePosixPath):\ndef __init__(self, *pathsegments, session_id):\nsuper().__init__(*pathsegments)\nself.session_id = session_id\ndef with_segments(self, *pathsegments):\nreturn type(self)(*pathsegments, session_id=self.session_id)\netc = MyPath(\'/etc\', session_id=42)\nhosts = etc / \'hosts\'\nprint(hosts.session_id)\n# 42\nAdded in version 3.12. 11.1.4 Concrete paths\nConcrete paths are subclasses of the pure path classes. In addition to operations provided by the latter, they also\nprovide methods to do system calls on path objects. There are three ways to instantiate concrete paths:\nclass pathlib.Path(*pathsegments)\nA subclass of PurePath, this class represents concrete paths of the system’s path flavour (instantiating it\ncreates either a PosixPath or a WindowsPath):\n>>> Path(\'setup.py\')\nPosixPath(\'setup.py\')\npathsegments is specified similarly to PurePath. class pathlib.PosixPath(*pathsegments)\nA subclass of Path and PurePosixPath, this class represents concrete non-Windows filesystem paths:\n>>> PosixPath(\'/etc/hosts\')\nPosixPath(\'/etc/hosts\')\npathsegments is specified similarly to PurePath. Changed in version 3.13:\nRaises UnsupportedOperation on Windows. In previous versions,\nNotImplementedError was raised instead. 450\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nclass pathlib.WindowsPath(*pathsegments)\nA subclass of Path and PureWindowsPath, this class represents concrete Windows filesystem paths:\n>>> WindowsPath(\'c:/\', \'Users\', \'Ximénez\')\nWindowsPath(\'c:/Users/Ximénez\')\npathsegments is specified similarly to PurePath. Changed in version 3.13: Raises UnsupportedOperation on non-Windows platforms. In previous versions,\nNotImplementedError was raised instead. You can only instantiate the class flavour that corresponds to your system (allowing system calls on non-compatible\npath flavours could lead to bugs or failures in your application):\n>>> import os\n>>> os.name\n\'posix\'\n>>> Path(\'setup.py\')\nPosixPath(\'setup.py\')\n>>> PosixPath(\'setup.py\')\nPosixPath(\'setup.py\')\n>>> WindowsPath(\'setup.py\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nFile ""pathlib.py"", line 798, in __new__\n% (cls.__name__,))\nUnsupportedOperation: cannot instantiate \'WindowsPath\' on your system\nSome concrete path methods can raise an OSError if a system call fails (for example because the path doesn’t exist). Parsing and generating URIs\nConcrete path objects can be created from, and represented as, ‘file’ URIs conforming to RFC 8089. ® Note\nFile URIs are not portable across machines with different filesystem encodings. classmethod Path.from_uri(uri)\nReturn a new path object from parsing a ‘file’ URI. For example:\n>>> p = Path.from_uri(\'file:///etc/hosts\')\nPosixPath(\'/etc/hosts\')\nOn Windows, DOS device and UNC paths may be parsed from URIs:\n>>> p = Path.from_uri(\'file:///c:/windows\')\nWindowsPath(\'c:/windows\')\n>>> p = Path.from_uri(\'file://server/share\')\nWindowsPath(\'//server/share\')\nSeveral variant forms are supported:\n>>> p = Path.from_uri(\'file:////server/share\')\nWindowsPath(\'//server/share\')\n>>> p = Path.from_uri(\'file://///server/share\')\nWindowsPath(\'//server/share\')\n>>> p = Path.from_uri(\'file:c:/windows\')\n(continues on next page)\n11.1. pathlib — Object-oriented filesystem paths\n451\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\nWindowsPath(\'c:/windows\')\n>>> p = Path.from_uri(\'file:/c|/windows\')\nWindowsPath(\'c:/windows\')\nValueError is raised if the URI does not start with file:, or the parsed path isn’t absolute. Added in version 3.13. Path.as_uri()\nRepresent the path as a ‘file’ URI. ValueError is raised if the path isn’t absolute. >>> p = PosixPath(\'/etc/passwd\')\n>>> p.as_uri()\n\'file:///etc/passwd\'\n>>> p = WindowsPath(\'c:/Windows\')\n>>> p.as_uri()\n\'file:///c:/Windows\'\nFor historical reasons, this method is also available from PurePath objects. However, its use of os. fsencode() makes it strictly impure. Expanding and resolving paths\nclassmethod Path.home()\nReturn a new path object representing the user’s home directory (as returned by os.path.expanduser()\nwith ~ construct). If the home directory can’t be resolved, RuntimeError is raised. >>> Path.home()\nPosixPath(\'/home/antoine\')\nAdded in version 3.5. Path.expanduser()\nReturn a new path with expanded ~ and ~user constructs, as returned by os.path.expanduser(). If a\nhome directory can’t be resolved, RuntimeError is raised. >>> p = PosixPath(\'~/films/Monty Python\')\n>>> p.expanduser()\nPosixPath(\'/home/eric/films/Monty Python\')\nAdded in version 3.5.\nclassmethod Path.cwd()\nReturn a new path object representing the current directory (as returned by os.getcwd()):\n>>> Path.cwd()\nPosixPath(\'/home/antoine/pathlib\')\nPath.absolute()\nMake the path absolute, without normalization or resolving symlinks. Returns a new path object:\n>>> p = Path(\'tests\')\n>>> p\nPosixPath(\'tests\')\n>>> p.absolute()\nPosixPath(\'/home/antoine/pathlib/tests\')\n452\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nPath.resolve(strict=False)\nMake the path absolute, resolving any symlinks. A new path object is returned:\n>>> p = Path()\n>>> p\nPosixPath(\'.\') >>> p.resolve()\nPosixPath(\'/home/antoine/pathlib\')\n“..” components are also eliminated (this is the only method to do so):\n>>> p = Path(\'docs/../setup.py\')\n>>> p.resolve()\nPosixPath(\'/home/antoine/pathlib/setup.py\')\nIf a path doesn’t exist or a symlink loop is encountered, and strict is True, OSError is raised. If strict is False,\nthe path is resolved as far as possible and any remainder is appended without checking whether it exists. Changed in version 3.6: The strict parameter was added (pre-3.6 behavior is strict). Changed in version 3.13: Symlink loops are treated like other errors: OSError is raised in strict mode, and\nno exception is raised in non-strict mode. In previous versions, RuntimeError is raised no matter the value\nof strict. Path.readlink()\nReturn the path to which the symbolic link points (as returned by os.readlink()):\n>>> p = Path(\'mylink\')\n>>> p.symlink_to(\'setup.py\')\n>>> p.readlink()\nPosixPath(\'setup.py\')\nAdded in version 3.9. Changed in version 3.13: Raises UnsupportedOperation if os.readlink() is not available. In previous\nversions, NotImplementedError was raised. Querying file type and status\nChanged\nin\nversion\n3.8:\nexists(),\nis_dir(),\nis_file(),\nis_mount(),\nis_symlink(),\nis_block_device(),\nis_char_device(),\nis_fifo(),\nis_socket() now return False instead of\nraising an exception for paths that contain characters unrepresentable at the OS level. Path.stat(*, follow_symlinks=True)\nReturn an os.stat_result object containing information about this path, like os.stat(). The result is\nlooked up at each call to this method. This method normally follows symlinks; to stat a symlink add the argument follow_symlinks=False, or\nuse lstat(). >>> p = Path(\'setup.py\')\n>>> p.stat().st_size\n956\n>>> p.stat().st_mtime\n1327883547.852554\nChanged in version 3.10: The follow_symlinks parameter was added.')",5.175155393902142e-156,0.02056231640788922,0.058513903538941106,0.602631688117981,0.44873548
How do I profile a Python script?,"Python includes a profiler called 
cProfile
.
 It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.


You can call it from within your code, or from the interpreter, like this:


import cProfile
cProfile.run('foo()')



Even more usefully, you can invoke cProfile when running a script:


python -m cProfile myscript.py



Or when running a module:


python -m cProfile -m mymodule



To make it even easier, I made a little batch file called 'profile.bat':


python -m cProfile %1



So all I have to do is run:


profile euler048.py



And I get this:


1007 function calls in 0.061 CPU seconds

Ordered by: standard name
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    1    0.000    0.000    0.061    0.061 
:1(
)
 1000    0.051    0.000    0.051    0.000 euler048.py:2(
)
    1    0.005    0.005    0.061    0.061 euler048.py:2(
)
    1    0.000    0.000    0.061    0.061 {execfile}
    1    0.002    0.002    0.053    0.053 {map}
    1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}
    1    0.000    0.000    0.000    0.000 {range}
    1    0.003    0.003    0.003    0.003 {sum}



For more information, check out this tutorial from PyCon 2013 titled

Python Profiling


Also via YouTube
.

","('Answer: To profile a Python script, you can use the Linux `perf` profiler. First, run `perf record -F 9999 -g -o perf.data python your_script.py` to sample CPU stack traces. Then, use `perf report --stdio -n -g` to analyze the data. Note that for Python functions to appear in the output, you need to run Python 3.12 or newer, which has a special mode that allows Python functions to appear in the perf profiler output. To check if your system is supported, check the output of `python -m sysconfig | grep HAVE_PERF_TRAMPOLINE`.\n\nReferences: [1, 3]\n', '[1] Python support for the Linux perf\nprofiler\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nHow to enable perf profiling support\n4\n2\nHow to obtain the best results\n4\n3\nHow to work without frame pointers\n5\nIndex\n6\nauthor\nPablo Galindo\nThe Linux perf profiler is a very powerful tool that allows you to profile and obtain information about the performance\nof your application. perf also has a very vibrant ecosystem of tools that aid with the analysis of the data that it\nproduces. The main problem with using the perf profiler with Python applications is that perf only gets information about\nnative symbols, that is, the names of functions and procedures written in C. This means that the names and file names\nof Python functions in your code will not appear in the output of perf. Since Python 3.12, the interpreter can run in a special mode that allows Python functions to appear in the output of\nthe perf profiler. When this mode is enabled, the interpreter will interpose a small piece of code compiled on the\nfly before the execution of every Python function and it will teach perf the relationship between this piece of code\nand the associated Python function using perf map files. ® Note\nSupport for the perf profiler is currently only available for Linux on select architectures. Check the output of the\nconfigure build step or check the output of python -m sysconfig | grep HAVE_PERF_TRAMPOLINE\nto see if your system is supported. For example, consider the following script:\ndef foo(n):\nresult = 0\n(continues on next page)\n1\n\n(continued from previous page)\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == ""__main__"":\nbaz(1000000)\nWe can run perf to sample CPU stack traces at 9999 hertz:\n$ perf record -F 9999 -g -o perf.data python my_script.py\nThen we can use perf report to analyze the data:\n$ perf report --stdio -n -g\n# Children\nSelf\nSamples\nCommand\nShared Object\nSymbol\n# ........\n........\n............\n..........\n..................\n...............\n,→...........................\n#\n91.08%\n0.00%\n0\npython.exe\npython.exe\n[.] _start\n|\n---_start\n|\n--90.71%--__libc_start_main\nPy_BytesMain\n|\n|--56.88%--pymain_run_python.constprop.0\n|\n|\n|\n|--56.13%--_PyRun_AnyFileObject\n|\n|\n_PyRun_SimpleFileObject\n|\n|\n|\n|\n|\n|--55.02%--run_mod\n|\n|\n|\n|\n|\n|\n|\n--54.65%--PyEval_EvalCode\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n|\n|\n|\n|\n|--51.67%--_\n(continues on next page)\n2\n\n(continued from previous page)\n,→PyEval_EvalFrameDefault\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|--\n,→11.52%--_PyLong_Add\n|\n|\n|\n|\n|\n␣\n,→\n|\n|\n|\n|\n|\n|\n␣\n,→\n|--2.97%--_PyObject_Malloc\n...\nAs you can see, the Python functions are not shown in the output, only _PyEval_EvalFrameDefault (the function\nthat evaluates the Python bytecode) shows up.\n\n[2] Python support for the Linux perf\nprofiler\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nHow to enable perf profiling support\n4\n2\nHow to obtain the best results\n4\n3\nHow to work without frame pointers\n5\nIndex\n6\nauthor\nPablo Galindo\nThe Linux perf profiler is a very powerful tool that allows you to profile and obtain information about the performance\nof your application. perf also has a very vibrant ecosystem of tools that aid with the analysis of the data that it\nproduces. The main problem with using the perf profiler with Python applications is that perf only gets information about\nnative symbols, that is, the names of functions and procedures written in C. This means that the names and file names\nof Python functions in your code will not appear in the output of perf. Since Python 3.12, the interpreter can run in a special mode that allows Python functions to appear in the output of\nthe perf profiler. When this mode is enabled, the interpreter will interpose a small piece of code compiled on the\nfly before the execution of every Python function and it will teach perf the relationship between this piece of code\nand the associated Python function using perf map files. ® Note\nSupport for the perf profiler is currently only available for Linux on select architectures. Check the output of the\nconfigure build step or check the output of python -m sysconfig | grep HAVE_PERF_TRAMPOLINE\nto see if your system is supported. For example, consider the following script:\ndef foo(n):\nresult = 0\n(continues on next page)\n1\n\n(continued from previous page)\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == ""__main__"":\nbaz(1000000)\nWe can run perf to sample CPU stack traces at 9999 hertz:\n$ perf record -F 9999 -g -o perf.data python my_script.py\nThen we can use perf report to analyze the data:\n$ perf report --stdio -n -g\n# Children\nSelf\nSamples\nCommand\nShared Object\nSymbol\n# ........\n........\n............\n..........\n..................\n...............\n,→...........................\n#\n91.08%\n0.00%\n0\npython.exe\npython.exe\n[.] _start\n|\n---_start\n|\n--90.71%--__libc_start_main\nPy_BytesMain\n|\n|--56.88%--pymain_run_python.constprop.0\n|\n|\n|\n|--56.13%--_PyRun_AnyFileObject\n|\n|\n_PyRun_SimpleFileObject\n|\n|\n|\n|\n|\n|--55.02%--run_mod\n|\n|\n|\n|\n|\n|\n|\n--54.65%--PyEval_EvalCode\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n|\n|\n|\n|\n|--51.67%--_\n(continues on next page)\n2\n\n(continued from previous page)\n,→PyEval_EvalFrameDefault\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|--\n,→11.52%--_PyLong_Add\n|\n|\n|\n|\n|\n␣\n,→\n|\n|\n|\n|\n|\n|\n␣\n,→\n|--2.97%--_PyObject_Malloc\n...\nAs you can see, the Python functions are not shown in the output, only _PyEval_EvalFrameDefault (the function\nthat evaluates the Python bytecode) shows up. Unfortunately that’s not very useful because all Python functions use\nthe same C function to evaluate bytecode so we cannot know which Python function corresponds to which bytecode-\nevaluating function.\n\n[3] Python support for the Linux perf\nprofiler\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nHow to enable perf profiling support\n4\n2\nHow to obtain the best results\n4\n3\nHow to work without frame pointers\n5\nIndex\n6\nauthor\nPablo Galindo\nThe Linux perf profiler is a very powerful tool that allows you to profile and obtain information about the performance\nof your application. perf also has a very vibrant ecosystem of tools that aid with the analysis of the data that it\nproduces. The main problem with using the perf profiler with Python applications is that perf only gets information about\nnative symbols, that is, the names of functions and procedures written in C. This means that the names and file names\nof Python functions in your code will not appear in the output of perf. Since Python 3.12, the interpreter can run in a special mode that allows Python functions to appear in the output of\nthe perf profiler. When this mode is enabled, the interpreter will interpose a small piece of code compiled on the\nfly before the execution of every Python function and it will teach perf the relationship between this piece of code\nand the associated Python function using perf map files. ® Note\nSupport for the perf profiler is currently only available for Linux on select architectures. Check the output of the\nconfigure build step or check the output of python -m sysconfig | grep HAVE_PERF_TRAMPOLINE\nto see if your system is supported. For example, consider the following script:\ndef foo(n):\nresult = 0\n(continues on next page)\n1\n\n(continued from previous page)\nfor _ in range(n):\nresult += 1\nreturn result\ndef bar(n):\nfoo(n)\ndef baz(n):\nbar(n)\nif __name__ == ""__main__"":\nbaz(1000000)\nWe can run perf to sample CPU stack traces at 9999 hertz:\n$ perf record -F 9999 -g -o perf.data python my_script.py\nThen we can use perf report to analyze the data:\n$ perf report --stdio -n -g\n# Children\nSelf\nSamples\nCommand\nShared Object\nSymbol\n# ........\n........\n............\n..........\n..................\n...............\n,→...........................\n#\n91.08%\n0.00%\n0\npython.exe\npython.exe\n[.] _start\n|\n---_start\n|\n--90.71%--__libc_start_main\nPy_BytesMain\n|\n|--56.88%--pymain_run_python.constprop.0\n|\n|\n|\n|--56.13%--_PyRun_AnyFileObject\n|\n|\n_PyRun_SimpleFileObject\n|\n|\n|\n|\n|\n|--55.02%--run_mod\n|\n|\n|\n|\n|\n|\n|\n--54.65%--PyEval_EvalCode\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n_PyEval_\n,→EvalFrameDefault\n|\n|\n|\nPyObject_\n,→Vectorcall\n|\n|\n|\n_PyEval_Vector\n|\n|\n|\n|\n|\n|\n|\n|--51.67%--_\n(continues on next page)\n2\n\n(continued from previous page)\n,→PyEval_EvalFrameDefault\n|\n|\n|\n|\n|\n|\n|\n|\n|\n|--\n,→11.52%--_PyLong_Add\n|\n|\n|\n|\n|\n␣\n,→\n|\n|\n|\n|\n|\n|\n␣\n,→\n|--2.97%--_PyObject_Malloc\n...\nAs you can see, the Python functions are not shown in the output, only _PyEval_EvalFrameDefault (the function\nthat evaluates the Python bytecode) shows up. Unfortunately that’s not very useful because all Python functions use\nthe same C function to evaluate bytecode so we cannot know which Python function corresponds to which bytecode-\nevaluating function. Instead, if we run the same experiment with perf support enabled we get:\n$ perf report --stdio -n -g\n# Children\nSelf\nSamples\nCommand\nShared Object\nSymbol\n# ........\n........\n............\n..........\n..................\n...............\n,→......................................................\n#\n90.58%\n0.36%\n1\npython.exe\npython.exe\n[.]')",1.6512322035766201e-155,0.04452521581099501,0.15443037974683546,0.552583634853363,0.61304563
if/else in a list comprehension,"You can totally do that. It's just an ordering issue:


[f(x) if x is not None else '' for x in xs]



In general,


[f(x) if condition else g(x) for x in sequence]



And, for list comprehensions with 
if
 conditions only,


[f(x) for x in sequence if condition]



Note that this actually uses a different language construct, a 
conditional expression
, which itself is not part of the 
comprehension syntax
, while the 
if
 after the 
for…in
 is part of list comprehensions and used to 
filter
 elements from the source iterable.




Conditional expressions can be used in all kinds of situations where you want to choose between two expression values based on some condition. This does the same as the 
ternary operator 
?:
 that exists in other languages
. For example:


value = 123
print(value, 'is', 'even' if value % 2 == 0 else 'odd')


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 32\n5\nData Structures\n33\n5.1\nMore on Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.1.1\nUsing Lists as Stacks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.1.2\nUsing Lists as Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.3\nList Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.4\nNested List Comprehensions\n. . . . . . . .\n\n[2] . . . . . . 35\n5.1.3\nList Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.4\nNested List Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n5.2\nThe del statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5.3\nTuples and Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n5.4\nSets . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . 9\n3.1.3\nLists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n3.2\nFirst Steps Towards Programming . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\n4\nMore Control Flow Tools\n17\n4.1\nif Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function .')",5.820234933757166e-232,0.058823529411764705,0.07347278050717086,0.42373955249786377,0.18205318
Replacements for switch statement in Python?,"Python 3.10 (2021) introduced the 
match
-
case
 statement, which provides a first-class implementation of a ""switch"" for Python. For example:


def f(x):
    match x:
        case 'a':
            return 1
        case 'b':
            return 2
        case _:
            return 0   # 0 is the default case if x is not found



The 
match
-
case
 statement is considerably more powerful than this simple example.


Documentation:




match
 statements
 (under the ""More Control Flow Tools"" page)


The 
match
 statement
 (under ""Compound statements"" page)


PEP 634 – Structural Pattern Matching: Specification


PEP 636 – Structural Pattern Matching: Tutorial






If you need to support Python ≤ 3.9, use a dictionary instead:


def f(x):
    return {
        'a': 1,
        'b': 2,
    }.get(x, 0)  # default case


","('Answer: In Python, the `if...elif...elif...else` sequence can act as a substitute for switch statements. As of Python 3.10, you can use the `match...case` statement to match literal values or constants. You can also use a dictionary to map case values to functions for a large number of possibilities or use `getattr()` to retrieve methods with a particular name.\n\nReferences: [1, 3]\n', '[1] An if … elif … elif … sequence is a substitute for the switch or case\nstatements found in other languages. If you’re comparing the same value to several constants, or checking for specific types or attributes, you may also\nfind the match statement useful. For more details see match Statements. 4.2 for Statements\nThe for statement in Python differs a bit from what you may be used to in C or Pascal. Rather than always iterating\nover an arithmetic progression of numbers (like in Pascal), or giving the user the ability to define both the iteration\nstep and halting condition (as C), Python’s for statement iterates over the items of any sequence (a list or a string),\nin the order that they appear in the sequence. For example (no pun intended):\n>>> # Measure some strings:\n>>> words = [\'cat\', \'window\', \'defenestrate\']\n>>> for w in words:\n...\nprint(w, len(w))\n...\ncat 3\nwindow 6\ndefenestrate 12\nCode that modifies a collection while iterating over that same collection can be tricky to get right. Instead, it is usually\nmore straight-forward to loop over a copy of the collection or to create a new collection:\n17\n\nPython Tutorial, Release 3.13.2\n# Create a sample collection\nusers = {\'Hans\': \'active\', \'Éléonore\': \'inactive\', \'\x00\x00\x00\': \'active\'}\n# Strategy:\nIterate over a copy\nfor user, status in users.copy().items():\nif status == \'inactive\':\ndel users[user]\n# Strategy:\nCreate a new collection\nactive_users = {}\nfor user, status in users.items():\nif status == \'active\':\nactive_users[user] = status\n4.3 The range() Function\nIf you do need to iterate over a sequence of numbers, the built-in function range() comes in handy. It generates\narithmetic progressions:\n>>> for i in range(5):\n...\nprint(i)\n...\n0\n1\n2\n3\n4\nThe given end point is never part of the generated sequence; range(10) generates 10 values, the legal indices for\nitems of a sequence of length 10. It is possible to let the range start at another number, or to specify a different\nincrement (even negative; sometimes this is called the ‘step’):\n>>> list(range(5, 10))\n[5, 6, 7, 8, 9]\n>>> list(range(0, 10, 3))\n[0, 3, 6, 9]\n>>> list(range(-10, -100, -30))\n[-10, -40, -70]\nTo iterate over the indices of a sequence, you can combine range() and len() as follows:\n>>> a = [\'Mary\', \'had\', \'a\', \'little\', \'lamb\']\n>>> for i in range(len(a)):\n...\nprint(i, a[i])\n...\n0 Mary\n1 had\n2 a\n3 little\n4 lamb\nIn most such cases, however, it is convenient to use the enumerate() function, see Looping Techniques. A strange thing happens if you just print a range:\n18\nChapter 4. More Control Flow Tools\n\nPython Tutorial, Release 3.13.2\n>>> range(10)\nrange(0, 10)\nIn many ways the object returned by range() behaves as if it is a list, but in fact it isn’t. It is an object which returns\nthe successive items of the desired sequence when you iterate over it, but it doesn’t really make the list, thus saving\nspace. We say such an object is iterable, that is, suitable as a target for functions and constructs that expect something from\nwhich they can obtain successive items until the supply is exhausted. We have seen that the for statement is such a\nconstruct, while an example of a function that takes an iterable is sum():\n>>> sum(range(4))\n# 0 + 1 + 2 + 3\n6\nLater we will see more functions that return iterables and take iterables as arguments. In chapter Data Structures, we\nwill discuss in more detail about list(). 4.4 break and continue Statements\nThe break statement breaks out of the innermost enclosing for or while loop:\n>>> for n in range(2, 10):\n...\nfor x in range(2, n):\n...\nif n % x == 0:\n...\nprint(f""{n} equals {x} * {n//x}"")\n...\nbreak\n...\n4 equals 2 * 2\n6 equals 2 * 3\n8 equals 2 * 4\n9 equals 3 * 3\nThe continue statement continues with the next iteration of the loop:\n>>> for num in range(2, 10):\n...\nif num % 2 == 0:\n...\nprint(f""Found an even number {num}"")\n...\ncontinue\n...\nprint(f""Found an odd number {num}"")\n...\nFound an even number 2\nFound an odd number 3\nFound an even number 4\nFound an odd number 5\nFound an even number 6\nFound an odd number 7\nFound an even number 8\nFound an odd number 9\n4.5 else Clauses on Loops\nIn a for or while loop the break statement may be paired with an else clause. If the loop finishes without\nexecuting the break, the else clause executes. In a for loop, the else clause is executed after the loop finishes its final iteration, that is, if no break occurred. In a while loop, it’s executed after the loop’s condition becomes false. 4.4. break and continue Statements\n19\n\nPython Tutorial, Release 3.13.2\nIn either kind of loop, the else clause is not executed if the loop was terminated by a break. Of course, other ways\nof ending the loop early, such as a return or a raised exception, will also skip execution of the else clause. This is exemplified in the following for loop, which searches for prime numbers:\n>>> for n in range(2, 10):\n...\nfor x in range(2, n):\n...\nif n % x == 0:\n...\nprint(n, \'equals\', x, \'*\', n//x)\n...\nbreak\n...\nelse:\n...\n# loop fell through without finding a factor\n...\nprint(n, \'is a prime number\')\n...\n2 is a prime number\n3 is a prime number\n4 equals 2 * 2\n5 is a prime number\n6 equals 2 * 3\n7 is a prime number\n8 equals 2 * 4\n9 equals 3 * 3\n(Yes, this is the correct code. Look closely: the else clause belongs to the for loop, not the if statement.) One way to think of the else clause is to imagine it paired with the if inside the loop. As the loop executes, it will\nrun a sequence like if/if/if/else. The if is inside the loop, encountered a number of times. If the condition is ever\ntrue, a break will happen. If the condition is never true, the else clause outside the loop will execute. When used with a loop, the else clause has more in common with the else clause of a try statement than it does\nwith that of if statements: a try statement’s else clause runs when no exception occurs, and a loop’s else clause\nruns when no break occurs. For more on the try statement and exceptions, see Handling Exceptions. 4.6 pass Statements\nThe pass statement does nothing. It can be used when a statement is required syntactically but the program requires\nno action. For example:\n>>> while True:\n...\npass\n# Busy-wait for keyboard interrupt (Ctrl+C)\n... This is commonly used for creating minimal classes:\n>>> class MyEmptyClass:\n...\npass\n...\nAnother place pass can be used is as a place-holder for a function or conditional body when you are working on new\ncode, allowing you to keep thinking at a more abstract level. The pass is silently ignored:\n>>> def initlog(*args):\n...\npass\n# Remember to implement this! ...\n20\nChapter 4. More Control Flow Tools\n\nPython Tutorial, Release 3.13.2\n4.7 match Statements\nA match statement takes an expression and compares its value to successive patterns given as one or more case\nblocks. This is superficially similar to a switch statement in C, Java or JavaScript (and many other languages), but it’s\nmore similar to pattern matching in languages like Rust or Haskell. Only the first pattern that matches gets executed\nand it can also extract components (sequence elements or object attributes) from the value into variables. The simplest form compares a subject value against one or more literals:\ndef http_error(status):\nmatch status:\ncase 400:\nreturn ""Bad request""\ncase 404:\nreturn ""Not found""\ncase 418:\nreturn ""I\'m a teapot""\ncase _:\nreturn ""Something\'s wrong with the internet""\nNote the last block: the “variable name” _ acts as a wildcard and never fails to match. If no case matches, none of\nthe branches is executed. You can combine several literals in a single pattern using | (“or”):\ncase 401 | 403 | 404:\nreturn ""Not allowed""\nPatterns can look like unpacking assignments, and can be used to bind variables:\n# point is an (x, y) tuple\nmatch point:\ncase (0, 0):\nprint(""Origin"")\ncase (0, y):\nprint(f""Y={y}"")\ncase (x, 0):\nprint(f""X={x}"")\ncase (x, y):\nprint(f""X={x}, Y={y}"")\ncase _:\nraise ValueError(""Not a point"")\nStudy that one carefully! The first pattern has two literals, and can be thought of as an extension of the literal pattern\nshown above. But the next two patterns combine a literal and a variable, and the variable binds a value from the subject\n(point). The fourth pattern captures two values, which makes it conceptually similar to the unpacking assignment\n(x, y) = point. If you are using classes to structure your data you can use the class name followed by an argument list resembling a\nconstructor, but with the ability to capture attributes into variables:\nclass Point:\ndef __init__(self, x, y):\nself.x = x\nself.y = y\ndef where_is(point):\nmatch point:\ncase Point(x=0, y=0):\n(continues on next page)\n4.7. match Statements\n21\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nprint(""Origin"")\ncase Point(x=0, y=y):\nprint(f""Y={y}"")\ncase Point(x=x, y=0):\nprint(f""X={x}"")\ncase Point():\nprint(""Somewhere else"")\ncase _:\nprint(""Not a point"")\nYou can use positional parameters with some builtin classes that provide an ordering for their attributes (e.g. data-\nclasses). You can also define a specific position for attributes in patterns by setting the __match_args__ special\nattribute in your classes. If it’s set to (“x”, “y”), the following patterns are all equivalent (and all bind the y attribute\nto the var variable):\nPoint(1, var)\nPoint(1, y=var)\nPoint(x=1, y=var)\nPoint(y=var, x=1)\nA recommended way to read patterns is to look at them as an extended form of what you would put on the left of\nan assignment, to understand which variables would be set to what. Only the standalone names (like var above) are\nassigned to by a match statement. Dotted names (like foo.bar), attribute names (the x= and y= above) or class\nnames (recognized by the “(…)” next to them like Point above) are never assigned to.\n\n[2] 3.10 Why isn’t there a switch or case statement in Python? In general, structured switch statements execute one block of code when an expression has a particular value or set of\nvalues. Since Python 3.10 one can easily match literal values, or constants within a namespace, with a match ...\ncase statement. An older alternative is a sequence of if... elif... elif... else. For cases where you need to choose from a very large number of possibilities, you can create a dictionary mapping\ncase values to functions to call. For example:\nfunctions = {\'a\': function_1,\n\'b\': function_2,\n\'c\': self.method_1}\nfunc = functions[value]\nfunc()\nFor calling methods on objects, you can simplify yet further by using the getattr() built-in to retrieve methods\nwith a particular name:\nclass MyVisitor:\ndef visit_a(self):\n...\ndef dispatch(self, value):\nmethod_name = \'visit_\' + str(value)\nmethod = getattr(self, method_name)\nmethod()\nIt’s suggested that you use a prefix for the method names, such as visit_ in this example. Without such a prefix, if\nvalues are coming from an untrusted source, an attacker would be able to call any method on your object. Imitating switch with fallthrough, as with C’s switch-case-default, is possible, much harder, and less needed. 42\nChapter 3. Design and History FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n3.11 Can’t you emulate threads in the interpreter instead of relying\non an OS-specific thread implementation? Answer 1: Unfortunately, the interpreter pushes at least one C stack frame for each Python stack frame. Also,\nextensions can call back into Python at almost random moments. Therefore, a complete threads implementation\nrequires thread support for C.\nAnswer 2: Fortunately, there is Stackless Python, which has a completely redesigned interpreter loop that avoids the\nC stack. 3.12 Why can’t lambda expressions contain statements? Python lambda expressions cannot contain statements because Python’s syntactic framework can’t handle statements\nnested inside expressions. However, in Python, this is not a serious problem. Unlike lambda forms in other languages,\nwhere they add functionality, Python lambdas are only a shorthand notation if you’re too lazy to define a function. Functions are already first class objects in Python, and can be declared in a local scope. Therefore the only advantage\nof using a lambda instead of a locally defined function is that you don’t need to invent a name for the function –\nbut that’s just a local variable to which the function object (which is exactly the same type of object that a lambda\nexpression yields) is assigned! 3.13 Can Python be compiled to machine code, C or some other\nlanguage? Cython compiles a modified version of Python with optional annotations into C extensions. Nuitka is an up-and-\ncoming compiler of Python into C++ code, aiming to support the full Python language. 3.14 How does Python manage memory? The details of Python memory management depend on the implementation. The standard implementation of Python,\nCPython, uses reference counting to detect inaccessible objects, and another mechanism to collect reference cycles,\nperiodically executing a cycle detection algorithm which looks for inaccessible cycles and deletes the objects involved. The gc module provides functions to perform a garbage collection, obtain debugging statistics, and tune the collector’s\nparameters. Other implementations (such as Jython or PyPy), however, can rely on a different mechanism such as a full-blown\ngarbage collector. This difference can cause some subtle porting problems if your Python code depends on the\nbehavior of the reference counting implementation. In some Python implementations, the following code (which is fine in CPython) will probably run out of file descrip-\ntors:\nfor file in very_long_list_of_files:\nf = open(file)\nc = f.read(1)\nIndeed, using CPython’s reference counting and destructor scheme, each new assignment to f closes the previous file. With a traditional GC, however, those file objects will only get collected (and closed) at varying and possibly long\nintervals. If you want to write code that will work with any Python implementation, you should explicitly close the file or use\nthe with statement; this will work regardless of memory management scheme:\nfor file in very_long_list_of_files:\nwith open(file) as f:\nc = f.read(1)\n3.11. Can’t you emulate threads in the interpreter instead of relying on an OS-specific thread\nimplementation? 43\n\nPython Frequently Asked Questions, Release 3.13.2\n3.15 Why doesn’t CPython use a more traditional garbage collec-\ntion scheme? For one thing, this is not a C standard feature and hence it’s not portable. (Yes, we know about the Boehm GC library. It has bits of assembler code for most common platforms, not for all of them, and although it is mostly transparent,\nit isn’t completely transparent; patches are required to get Python to work with it.) Traditional GC also becomes a problem when Python is embedded into other applications. While in a standalone\nPython it’s fine to replace the standard malloc() and free() with versions provided by the GC library, an applica-\ntion embedding Python may want to have its own substitute for malloc() and free(), and may not want Python’s. Right now, CPython works with anything that implements malloc() and free() properly. 3.16 Why isn’t all memory freed when CPython exits? Objects referenced from the global namespaces of Python modules are not always deallocated when Python exits. This may happen if there are circular references. There are also certain bits of memory that are allocated by the C\nlibrary that are impossible to free (e.g. a tool like Purify will complain about these). Python is, however, aggressive\nabout cleaning up memory on exit and does try to destroy every single object. If you want to force Python to delete certain things on deallocation use the atexit module to run a function that\nwill force those deletions. 3.17 Why are there separate tuple and list data types? Lists and tuples, while similar in many respects, are generally used in fundamentally different ways. Tuples can be\nthought of as being similar to Pascal records or C structs; they’re small collections of related data which may be\nof different types which are operated on as a group. For example, a Cartesian coordinate is appropriately represented\nas a tuple of two or three numbers. Lists, on the other hand, are more like arrays in other languages.\n\n[3] If that wasn’t the case, you\ncoded it like this:\nif key in mydict:\nvalue = mydict[key]\nelse:\nvalue = mydict[key] = getvalue(key)\nFor this specific case, you could also use value = dict.setdefault(key, getvalue(key)), but only if the\ngetvalue() call is cheap enough because it is evaluated in all cases. 3.10 Why isn’t there a switch or case statement in Python? In general, structured switch statements execute one block of code when an expression has a particular value or set of\nvalues. Since Python 3.10 one can easily match literal values, or constants within a namespace, with a match ...\ncase statement. An older alternative is a sequence of if... elif... elif... else. For cases where you need to choose from a very large number of possibilities, you can create a dictionary mapping\ncase values to functions to call. For example:\nfunctions = {\'a\': function_1,\n\'b\': function_2,\n\'c\': self.method_1}\nfunc = functions[value]\nfunc()\nFor calling methods on objects, you can simplify yet further by using the getattr() built-in to retrieve methods\nwith a particular name:\nclass MyVisitor:\ndef visit_a(self):\n...\ndef dispatch(self, value):\nmethod_name = \'visit_\' + str(value)\nmethod = getattr(self, method_name)\nmethod()\nIt’s suggested that you use a prefix for the method names, such as visit_ in this example. Without such a prefix, if\nvalues are coming from an untrusted source, an attacker would be able to call any method on your object. Imitating switch with fallthrough, as with C’s switch-case-default, is possible, much harder, and less needed. 42\nChapter 3. Design and History FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n3.11 Can’t you emulate threads in the interpreter instead of relying\non an OS-specific thread implementation? Answer 1: Unfortunately, the interpreter pushes at least one C stack frame for each Python stack frame. Also,\nextensions can call back into Python at almost random moments. Therefore, a complete threads implementation\nrequires thread support for C.\nAnswer 2: Fortunately, there is Stackless Python, which has a completely redesigned interpreter loop that avoids the\nC stack. 3.12 Why can’t lambda expressions contain statements? Python lambda expressions cannot contain statements because Python’s syntactic framework can’t handle statements\nnested inside expressions. However, in Python, this is not a serious problem. Unlike lambda forms in other languages,\nwhere they add functionality, Python lambdas are only a shorthand notation if you’re too lazy to define a function. Functions are already first class objects in Python, and can be declared in a local scope. Therefore the only advantage\nof using a lambda instead of a locally defined function is that you don’t need to invent a name for the function –\nbut that’s just a local variable to which the function object (which is exactly the same type of object that a lambda\nexpression yields) is assigned! 3.13 Can Python be compiled to machine code, C or some other\nlanguage? Cython compiles a modified version of Python with optional annotations into C extensions. Nuitka is an up-and-\ncoming compiler of Python into C++ code, aiming to support the full Python language. 3.14 How does Python manage memory? The details of Python memory management depend on the implementation. The standard implementation of Python,\nCPython, uses reference counting to detect inaccessible objects, and another mechanism to collect reference cycles,\nperiodically executing a cycle detection algorithm which looks for inaccessible cycles and deletes the objects involved. The gc module provides functions to perform a garbage collection, obtain debugging statistics, and tune the collector’s\nparameters. Other implementations (such as Jython or PyPy), however, can rely on a different mechanism such as a full-blown\ngarbage collector. This difference can cause some subtle porting problems if your Python code depends on the\nbehavior of the reference counting implementation. In some Python implementations, the following code (which is fine in CPython) will probably run out of file descrip-\ntors:\nfor file in very_long_list_of_files:\nf = open(file)\nc = f.read(1)\nIndeed, using CPython’s reference counting and destructor scheme, each new assignment to f closes the previous file. With a traditional GC, however, those file objects will only get collected (and closed) at varying and possibly long\nintervals. If you want to write code that will work with any Python implementation, you should explicitly close the file or use\nthe with statement; this will work regardless of memory management scheme:\nfor file in very_long_list_of_files:\nwith open(file) as f:\nc = f.read(1)\n3.11. Can’t you emulate threads in the interpreter instead of relying on an OS-specific thread\nimplementation? 43\n\nPython Frequently Asked Questions, Release 3.13.2\n3.15 Why doesn’t CPython use a more traditional garbage collec-\ntion scheme? For one thing, this is not a C standard feature and hence it’s not portable. (Yes, we know about the Boehm GC library. It has bits of assembler code for most common platforms, not for all of them, and although it is mostly transparent,\nit isn’t completely transparent; patches are required to get Python to work with it.) Traditional GC also becomes a problem when Python is embedded into other applications. While in a standalone\nPython it’s fine to replace the standard malloc() and free() with versions provided by the GC library, an applica-\ntion embedding Python may want to have its own substitute for malloc() and free(), and may not want Python’s. Right now, CPython works with anything that implements malloc() and free() properly. 3.16 Why isn’t all memory freed when CPython exits? Objects referenced from the global namespaces of Python modules are not always deallocated when Python exits. This may happen if there are circular references. There are also certain bits of memory that are allocated by the C\nlibrary that are impossible to free (e.g. a tool like Purify will complain about these). Python is, however, aggressive\nabout cleaning up memory on exit and does try to destroy every single object. If you want to force Python to delete certain things on deallocation use the atexit module to run a function that\nwill force those deletions. 3.17 Why are there separate tuple and list data types? Lists and tuples, while similar in many respects, are generally used in fundamentally different ways. Tuples can be\nthought of as being similar to Pascal records or C structs; they’re small collections of related data which may be\nof different types which are operated on as a group. For example, a Cartesian coordinate is appropriately represented\nas a tuple of two or three numbers.')",1.7496784042224223e-79,0.030791094268119375,0.11701675836046348,0.5492807626724243,0.66392636
How to check for NaN values,"Use 
math.isnan
:


>>> import math
>>> x = float('nan')
>>> math.isnan(x)
True


","('Answer: To check for NaN values, you can use the `isnan` function from the `math` module. You can count the number of NaN values in a dataset by using `sum(map(isnan, data))`.\n\nReferences: [2, 3]\n', '[1] Since NaNs have unusual comparison\nsemantics, they cause surprising or undefined behaviors in the statistics functions that sort data or that count occur-\nrences. The functions affected are median(), median_low(), median_high(), median_grouped(), mode(),\nmultimode(), and quantiles(). The NaN values should be stripped before calling these functions:\n>>> from statistics import median\n>>> from math import isnan\n>>> from itertools import filterfalse\n>>> data = [20.7, float(\'NaN\'),19.2, 18.3, float(\'NaN\'), 14.4]\n>>> sorted(data)\n# This has surprising behavior\n[20.7, nan, 14.4, 18.3, 19.2, nan]\n>>> median(data)\n# This result is unexpected\n16.35\n>>> sum(map(isnan, data))\n# Number of missing values\n2\n>>> clean = list(filterfalse(isnan, data))\n# Strip NaN values\n>>> clean\n[20.7, 19.2, 18.3, 14.4]\n>>> sorted(clean)\n# Sorting now works as expected\n[14.4, 18.3, 19.2, 20.7]\n>>> median(clean)\n# This result is now well defined\n18.75\n9.7.1 Averages and measures of central location\nThese functions calculate an average or typical value from a population or sample. mean()\nArithmetic mean (“average”) of data. fmean()\nFast, floating-point arithmetic mean, with optional weighting. geometric_mean()\nGeometric mean of data. harmonic_mean()\nHarmonic mean of data. kde()\nEstimate the probability density distribution of the data. kde_random()\nRandom sampling from the PDF generated by kde(). median()\nMedian (middle value) of data. median_low()\nLow median of data. median_high()\nHigh median of data. median_grouped()\nMedian (50th percentile) of grouped data. mode()\nSingle mode (most common value) of discrete or nominal data. multimode()\nList of modes (most common values) of discrete or nominal data. quantiles()\nDivide data into intervals with equal probability. 9.7.2 Measures of spread\nThese functions calculate a measure of how much the population or sample tends to deviate from the typical or\naverage values. pstdev()\nPopulation standard deviation of data. pvariance()\nPopulation variance of data. stdev()\nSample standard deviation of data. variance()\nSample variance of data. 9.7. statistics — Mathematical statistics functions\n387\n\nThe Python Library Reference, Release 3.13.2\n9.7.3 Statistics for relations between two inputs\nThese functions calculate statistics regarding relations between two inputs. covariance()\nSample covariance for two variables. correlation()\nPearson and Spearman’s correlation coefficients. linear_regression()\nSlope and intercept for simple linear regression. 9.7.4 Function details\nNote: The functions do not require the data given to them to be sorted. However, for reading convenience, most of\nthe examples show sorted sequences. statistics.mean(data)\nReturn the sample arithmetic mean of data which can be a sequence or iterable. The arithmetic mean is the sum of the data divided by the number of data points. It is commonly called “the\naverage”, although it is only one of many different mathematical averages. It is a measure of the central location\nof the data. If data is empty, StatisticsError will be raised. Some examples of use:\n>>> mean([1, 2, 3, 4, 4])\n2.8\n>>> mean([-1.0, 2.5, 3.25, 5.75])\n2.625\n>>> from fractions import Fraction as F\n>>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])\nFraction(13, 21)\n>>> from decimal import Decimal as D\n>>> mean([D(""0.5""), D(""0.75""), D(""0.625""), D(""0.375"")])\nDecimal(\'0.5625\')\n® Note\nThe mean is strongly affected by outliers and is not necessarily a typical example of the data points. For a\nmore robust, although less efficient, measure of central tendency, see median(). The sample mean gives an unbiased estimate of the true population mean, so that when taken on average\nover all the possible samples, mean(sample) converges on the true mean of the entire population. If data\nrepresents the entire population rather than a sample, then mean(data) is equivalent to calculating the\ntrue population mean μ.\nstatistics.fmean(data, weights=None)\nConvert data to floats and compute the arithmetic mean. This runs faster than the mean() function and it always returns a float. The data may be a sequence or\niterable. If the input dataset is empty, raises a StatisticsError. >>> fmean([3.5, 4.0, 5.25])\n4.25\nOptional weighting is supported. For example, a professor assigns a grade for a course by weighting quizzes at\n20%, homework at 20%, a midterm exam at 30%, and a final exam at 30%:\n388\nChapter 9. Numeric and Mathematical Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> grades = [85, 92, 83, 91]\n>>> weights = [0.20, 0.20, 0.30, 0.30]\n>>> fmean(grades, weights)\n87.6\nIf weights is supplied, it must be the same length as the data or a ValueError will be raised. Added in version 3.8. Changed in version 3.11: Added support for weights. statistics.geometric_mean(data)\nConvert data to floats and compute the geometric mean. The geometric mean indicates the central tendency or typical value of the data using the product of the values\n(as opposed to the arithmetic mean which uses their sum). Raises a StatisticsError if the input dataset is empty, if it contains a zero, or if it contains a negative\nvalue. The data may be a sequence or iterable. No special efforts are made to achieve exact results. (However, this may change in the future.) >>> round(geometric_mean([54, 24, 36]), 1)\n36.0\nAdded in version 3.8.\nstatistics.harmonic_mean(data, weights=None)\nReturn the harmonic mean of data, a sequence or iterable of real-valued numbers.\n\n[2] Some datasets use NaN (not a number) values to represent missing data. Since NaNs have unusual comparison\nsemantics, they cause surprising or undefined behaviors in the statistics functions that sort data or that count occur-\nrences. The functions affected are median(), median_low(), median_high(), median_grouped(), mode(),\nmultimode(), and quantiles(). The NaN values should be stripped before calling these functions:\n>>> from statistics import median\n>>> from math import isnan\n>>> from itertools import filterfalse\n>>> data = [20.7, float(\'NaN\'),19.2, 18.3, float(\'NaN\'), 14.4]\n>>> sorted(data)\n# This has surprising behavior\n[20.7, nan, 14.4, 18.3, 19.2, nan]\n>>> median(data)\n# This result is unexpected\n16.35\n>>> sum(map(isnan, data))\n# Number of missing values\n2\n>>> clean = list(filterfalse(isnan, data))\n# Strip NaN values\n>>> clean\n[20.7, 19.2, 18.3, 14.4]\n>>> sorted(clean)\n# Sorting now works as expected\n[14.4, 18.3, 19.2, 20.7]\n>>> median(clean)\n# This result is now well defined\n18.75\n9.7.1 Averages and measures of central location\nThese functions calculate an average or typical value from a population or sample. mean()\nArithmetic mean (“average”) of data. fmean()\nFast, floating-point arithmetic mean, with optional weighting. geometric_mean()\nGeometric mean of data. harmonic_mean()\nHarmonic mean of data. kde()\nEstimate the probability density distribution of the data. kde_random()\nRandom sampling from the PDF generated by kde(). median()\nMedian (middle value) of data. median_low()\nLow median of data. median_high()\nHigh median of data. median_grouped()\nMedian (50th percentile) of grouped data. mode()\nSingle mode (most common value) of discrete or nominal data. multimode()\nList of modes (most common values) of discrete or nominal data. quantiles()\nDivide data into intervals with equal probability. 9.7.2 Measures of spread\nThese functions calculate a measure of how much the population or sample tends to deviate from the typical or\naverage values. pstdev()\nPopulation standard deviation of data. pvariance()\nPopulation variance of data. stdev()\nSample standard deviation of data. variance()\nSample variance of data. 9.7. statistics — Mathematical statistics functions\n387\n\nThe Python Library Reference, Release 3.13.2\n9.7.3 Statistics for relations between two inputs\nThese functions calculate statistics regarding relations between two inputs. covariance()\nSample covariance for two variables. correlation()\nPearson and Spearman’s correlation coefficients. linear_regression()\nSlope and intercept for simple linear regression. 9.7.4 Function details\nNote: The functions do not require the data given to them to be sorted. However, for reading convenience, most of\nthe examples show sorted sequences. statistics.mean(data)\nReturn the sample arithmetic mean of data which can be a sequence or iterable. The arithmetic mean is the sum of the data divided by the number of data points. It is commonly called “the\naverage”, although it is only one of many different mathematical averages. It is a measure of the central location\nof the data. If data is empty, StatisticsError will be raised. Some examples of use:\n>>> mean([1, 2, 3, 4, 4])\n2.8\n>>> mean([-1.0, 2.5, 3.25, 5.75])\n2.625\n>>> from fractions import Fraction as F\n>>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])\nFraction(13, 21)\n>>> from decimal import Decimal as D\n>>> mean([D(""0.5""), D(""0.75""), D(""0.625""), D(""0.375"")])\nDecimal(\'0.5625\')\n® Note\nThe mean is strongly affected by outliers and is not necessarily a typical example of the data points. For a\nmore robust, although less efficient, measure of central tendency, see median(). The sample mean gives an unbiased estimate of the true population mean, so that when taken on average\nover all the possible samples, mean(sample) converges on the true mean of the entire population. If data\nrepresents the entire population rather than a sample, then mean(data) is equivalent to calculating the\ntrue population mean μ.\nstatistics.fmean(data, weights=None)\nConvert data to floats and compute the arithmetic mean. This runs faster than the mean() function and it always returns a float. The data may be a sequence or\niterable. If the input dataset is empty, raises a StatisticsError. >>> fmean([3.5, 4.0, 5.25])\n4.25\nOptional weighting is supported. For example, a professor assigns a grade for a course by weighting quizzes at\n20%, homework at 20%, a midterm exam at 30%, and a final exam at 30%:\n388\nChapter 9. Numeric and Mathematical Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> grades = [85, 92, 83, 91]\n>>> weights = [0.20, 0.20, 0.30, 0.30]\n>>> fmean(grades, weights)\n87.6\nIf weights is supplied, it must be the same length as the data or a ValueError will be raised. Added in version 3.8. Changed in version 3.11: Added support for weights. statistics.geometric_mean(data)\nConvert data to floats and compute the geometric mean. The geometric mean indicates the central tendency or typical value of the data using the product of the values\n(as opposed to the arithmetic mean which uses their sum). Raises a StatisticsError if the input dataset is empty, if it contains a zero, or if it contains a negative\nvalue. The data may be a sequence or iterable. No special efforts are made to achieve exact results. (However, this may change in the future.)\n\n[3] Behaviour with other types\n(whether in the numeric tower or not) is currently unsupported. Collections with a mix of types are also undefined\nand implementation-dependent. If your input data consists of mixed types, you may be able to use map() to ensure\na consistent result, for example: map(float, input_data). Some datasets use NaN (not a number) values to represent missing data. Since NaNs have unusual comparison\nsemantics, they cause surprising or undefined behaviors in the statistics functions that sort data or that count occur-\nrences. The functions affected are median(), median_low(), median_high(), median_grouped(), mode(),\nmultimode(), and quantiles(). The NaN values should be stripped before calling these functions:\n>>> from statistics import median\n>>> from math import isnan\n>>> from itertools import filterfalse\n>>> data = [20.7, float(\'NaN\'),19.2, 18.3, float(\'NaN\'), 14.4]\n>>> sorted(data)\n# This has surprising behavior\n[20.7, nan, 14.4, 18.3, 19.2, nan]\n>>> median(data)\n# This result is unexpected\n16.35\n>>> sum(map(isnan, data))\n# Number of missing values\n2\n>>> clean = list(filterfalse(isnan, data))\n# Strip NaN values\n>>> clean\n[20.7, 19.2, 18.3, 14.4]\n>>> sorted(clean)\n# Sorting now works as expected\n[14.4, 18.3, 19.2, 20.7]\n>>> median(clean)\n# This result is now well defined\n18.75\n9.7.1 Averages and measures of central location\nThese functions calculate an average or typical value from a population or sample. mean()\nArithmetic mean (“average”) of data. fmean()\nFast, floating-point arithmetic mean, with optional weighting. geometric_mean()\nGeometric mean of data. harmonic_mean()\nHarmonic mean of data. kde()\nEstimate the probability density distribution of the data. kde_random()\nRandom sampling from the PDF generated by kde(). median()\nMedian (middle value) of data. median_low()\nLow median of data. median_high()\nHigh median of data. median_grouped()\nMedian (50th percentile) of grouped data. mode()\nSingle mode (most common value) of discrete or nominal data. multimode()\nList of modes (most common values) of discrete or nominal data. quantiles()\nDivide data into intervals with equal probability. 9.7.2 Measures of spread\nThese functions calculate a measure of how much the population or sample tends to deviate from the typical or\naverage values. pstdev()\nPopulation standard deviation of data. pvariance()\nPopulation variance of data. stdev()\nSample standard deviation of data. variance()\nSample variance of data. 9.7. statistics — Mathematical statistics functions\n387\n\nThe Python Library Reference, Release 3.13.2\n9.7.3 Statistics for relations between two inputs\nThese functions calculate statistics regarding relations between two inputs. covariance()\nSample covariance for two variables. correlation()\nPearson and Spearman’s correlation coefficients. linear_regression()\nSlope and intercept for simple linear regression. 9.7.4 Function details\nNote: The functions do not require the data given to them to be sorted. However, for reading convenience, most of\nthe examples show sorted sequences. statistics.mean(data)\nReturn the sample arithmetic mean of data which can be a sequence or iterable. The arithmetic mean is the sum of the data divided by the number of data points. It is commonly called “the\naverage”, although it is only one of many different mathematical averages. It is a measure of the central location\nof the data. If data is empty, StatisticsError will be raised. Some examples of use:\n>>> mean([1, 2, 3, 4, 4])\n2.8\n>>> mean([-1.0, 2.5, 3.25, 5.75])\n2.625\n>>> from fractions import Fraction as F\n>>> mean([F(3, 7), F(1, 21), F(5, 3), F(1, 3)])\nFraction(13, 21)\n>>> from decimal import Decimal as D\n>>> mean([D(""0.5""), D(""0.75""), D(""0.625""), D(""0.375"")])\nDecimal(\'0.5625\')\n® Note\nThe mean is strongly affected by outliers and is not necessarily a typical example of the data points. For a\nmore robust, although less efficient, measure of central tendency, see median(). The sample mean gives an unbiased estimate of the true population mean, so that when taken on average\nover all the possible samples, mean(sample) converges on the true mean of the entire population. If data\nrepresents the entire population rather than a sample, then mean(data) is equivalent to calculating the\ntrue population mean μ.\nstatistics.fmean(data, weights=None)\nConvert data to floats and compute the arithmetic mean. This runs faster than the mean() function and it always returns a float. The data may be a sequence or\niterable. If the input dataset is empty, raises a StatisticsError. >>> fmean([3.5, 4.0, 5.25])\n4.25\nOptional weighting is supported. For example, a professor assigns a grade for a course by weighting quizzes at\n20%, homework at 20%, a midterm exam at 30%, and a final exam at 30%:\n388\nChapter 9. Numeric and Mathematical Modules\n\nThe Python Library Reference, Release 3.13.2\n>>> grades = [85, 92, 83, 91]\n>>> weights = [0.20, 0.20, 0.30, 0.30]\n>>> fmean(grades, weights)\n87.6\nIf weights is supplied, it must be the same length as the data or a ValueError will be raised. Added in version 3.8. Changed in version 3.11: Added support for weights. statistics.geometric_mean(data)\nConvert data to floats and compute the geometric mean. The geometric mean indicates the central tendency or typical value of the data using the product of the values\n(as opposed to the arithmetic mean which uses their sum). Raises a StatisticsError if the input dataset is empty, if it contains a zero, or if it contains a negative\nvalue.')",4.148788003003789e-232,0.007010164738871364,0.04377636856424955,0.519723117351532,0.65015525
Why do Python classes inherit object?,"

Is there any reason for a class declaration to inherit from 
object
?




In Python 3, apart from compatibility between Python 2 and 3, 
no reason
. In Python 2, 
many reasons
. 




Python 2.x story:


In Python 2.x (from 2.2 onwards) there's two styles of classes depending on the presence or absence of 
object
 as a base-class:




""classic"" style
 classes: they don't have 
object
 as a base class:


>>> class ClassicSpam:      # no base class
...     pass
>>> ClassicSpam.__bases__
()



""new"" style
 classes: they have, directly 
or indirectly
 (e.g inherit from a 
built-in type
), 
object
 as a base class:


>>> class NewSpam(object):           # directly inherit from object
...    pass
>>> NewSpam.__bases__
(
,)
>>> class IntSpam(int):              # indirectly inherit from object...
...    pass
>>> IntSpam.__bases__
(
,) 
>>> IntSpam.__bases__[0].__bases__   # ... because int inherits from object  
(
,)





Without a doubt, when writing a class you'll 
always
 want to go for new-style classes. The perks of doing so are numerous, to list some of them:




Support for descriptors
. Specifically, the following constructs are made possible with descriptors: 




classmethod
: A method that receives the class as an implicit argument instead of the instance.


staticmethod
: A method that does not receive the implicit argument 
self
 as a first argument.


properties with 
property
: Create functions for managing the getting, setting and deleting of an attribute. 


__slots__
: Saves memory consumptions of a class and also results in faster attribute access. Of course, it does 
impose limitations
.




The 
__new__
 static method: lets you customize how new class instances are created. 


Method resolution order (MRO)
: in what order the base classes of a class will be searched when trying to resolve which method to call. 


Related to MRO, 
super
 calls
. Also see, 
super()
 considered super.




If you don't inherit from 
object
, forget these. A more exhaustive description of the previous bullet points along with other perks of ""new"" style classes can be found 
here
.


One of the downsides of new-style classes is that the class itself is more memory demanding. Unless you're creating many class objects, though, I doubt this would be an issue and it's a negative sinking in a sea of positives.




Python 3.x story:


In Python 3, things are simplified. Only new-style classes exist (referred to plainly as classes) so, the only difference in adding 
object
 is requiring you to type in 8 more characters. This:


class ClassicSpam:
    pass



is completely equivalent (apart from their name :-) to this:


class NewSpam(object):
     pass



and to this:


class Spam():
    pass



All have 
object
 in their 
__bases__
.


>>> [object in cls.__bases__ for cls in {Spam, NewSpam, ClassicSpam}]
[True, True, True]





So, what should you do?


In Python 2:
 
always inherit from 
object
 explicitly
. Get the perks.


In Python 3:
 inherit from 
object
 if you are writing code that tries to be Python agnostic, that is, it needs to work both in Python 2 and in Python 3. Otherwise don't, it really makes no difference since Python inserts it for you behind the scenes.

","('Answer: All classes inherit from object, so any case of multiple inheritance provides more than one path to reach object.\n\nReferences: [1]\n', ""[1] Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find\nsome good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as object.__class__. 9.5 Inheritance\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax\nfor a derived class definition looks like this:\nclass DerivedClassName(BaseClassName):\n<statement-1>\n. . . <statement-N>\nThe name BaseClassName must be defined in a namespace accessible from the scope containing the derived class\ndefinition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example,\nwhen the base class is defined in another module:\nclass DerivedClassName(modname.BaseClassName):\nExecution of a derived class definition proceeds the same as for a base class. When the class object is constructed,\nthe base class is remembered. This is used for resolving attribute references: if a requested attribute is not found\nin the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is\nderived from some other class. There’s nothing special about instantiation of derived classes: DerivedClassName() creates a new instance of the\nclass. Method references are resolved as follows: the corresponding class attribute is searched, descending down the\nchain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling\nother methods of the same object, a method of a base class that calls another method defined in the same base class\nmay end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are\neffectively virtual.) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method\nof the same name. There is a simple way to call the base class method directly: just call BaseClassName. 80\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\nmethodname(self, arguments). This is occasionally useful to clients as well. (Note that this only works if\nthe base class is accessible as BaseClassName in the global scope.) Python has two built-in functions that work with inheritance:\n• Use isinstance() to check an instance’s type: isinstance(obj, int) will be True only if obj. __class__ is int or some class derived from int. • Use issubclass() to check class inheritance: issubclass(bool, int) is True since bool is a subclass\nof int. However, issubclass(float, int) is False since float is not a subclass of int. 9.5.1 Multiple Inheritance\nPython supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this:\nclass DerivedClassName(Base1, Base2, Base3):\n<statement-1>\n. . . <statement-N>\nFor most purposes, in the simplest cases, you can think of the search for attributes inherited from a parent class as\ndepth-first, left-to-right, not searching twice in the same class where there is an overlap in the hierarchy. Thus, if an\nattribute is not found in DerivedClassName, it is searched for in Base1, then (recursively) in the base classes of\nBase1, and if it was not found there, it was searched for in Base2, and so on. In fact, it is slightly more complex than that; the method resolution order changes dynamically to support cooperative\ncalls to super(). This approach is known in some other multiple-inheritance languages as call-next-method and is\nmore powerful than the super call found in single-inheritance languages. Dynamic ordering is necessary because all cases of multiple inheritance exhibit one or more diamond relationships\n(where at least one of the parent classes can be accessed through multiple paths from the bottommost class). For\nexample, all classes inherit from object, so any case of multiple inheritance provides more than one path to reach\nobject. To keep the base classes from being accessed more than once, the dynamic algorithm linearizes the search\norder in a way that preserves the left-to-right ordering specified in each class, that calls each parent only once, and that\nis monotonic (meaning that a class can be subclassed without affecting the precedence order of its parents). Taken\ntogether, these properties make it possible to design reliable and extensible classes with multiple inheritance. For\nmore detail, see python_2.3_mro. 9.6 Private Variables\n“Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there\nis a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be\ntreated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered\nan implementation detail and subject to change without notice. Since there is a valid use-case for class-private members (namely to avoid name clashes of names with names\ndefined by subclasses), there is limited support for such a mechanism, called name mangling. Any identifier of\nthe form __spam (at least two leading underscores, at most one trailing underscore) is textually replaced with\n_classname__spam, where classname is the current class name with leading underscore(s) stripped. This man-\ngling is done without regard to the syntactic position of the identifier, as long as it occurs within the definition of a\nclass. µ See also\nThe private name mangling specifications for details and special cases. Name mangling is helpful for letting subclasses override methods without breaking intraclass method calls. For\nexample:\n9.6.\n\n[2] Random Remarks\n79\n\nPython Tutorial, Release 3.13.2\nNow f, g and h are all attributes of class C that refer to function objects, and consequently they are all methods of\ninstances of C — h being exactly equivalent to g. Note that this practice usually only serves to confuse the reader of\na program. Methods may call other methods by using method attributes of the self argument:\nclass Bag:\ndef __init__(self):\nself.data = []\ndef add(self, x):\nself.data.append(x)\ndef addtwice(self, x):\nself.add(x)\nself.add(x)\nMethods may reference global names in the same way as ordinary functions. The global scope associated with a\nmethod is the module containing its definition. (A class is never used as a global scope.) While one rarely encounters\na good reason for using global data in a method, there are many legitimate uses of the global scope: for one thing,\nfunctions and modules imported into the global scope can be used by methods, as well as functions and classes defined\nin it. Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find\nsome good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as object.__class__. 9.5 Inheritance\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax\nfor a derived class definition looks like this:\nclass DerivedClassName(BaseClassName):\n<statement-1>\n. . . <statement-N>\nThe name BaseClassName must be defined in a namespace accessible from the scope containing the derived class\ndefinition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example,\nwhen the base class is defined in another module:\nclass DerivedClassName(modname.BaseClassName):\nExecution of a derived class definition proceeds the same as for a base class. When the class object is constructed,\nthe base class is remembered. This is used for resolving attribute references: if a requested attribute is not found\nin the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is\nderived from some other class. There’s nothing special about instantiation of derived classes: DerivedClassName() creates a new instance of the\nclass. Method references are resolved as follows: the corresponding class attribute is searched, descending down the\nchain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling\nother methods of the same object, a method of a base class that calls another method defined in the same base class\nmay end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are\neffectively virtual.) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method\nof the same name. There is a simple way to call the base class method directly: just call BaseClassName. 80\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\nmethodname(self, arguments). This is occasionally useful to clients as well. (Note that this only works if\nthe base class is accessible as BaseClassName in the global scope.) Python has two built-in functions that work with inheritance:\n• Use isinstance() to check an instance’s type: isinstance(obj, int) will be True only if obj. __class__ is int or some class derived from int. • Use issubclass() to check class inheritance: issubclass(bool, int) is True since bool is a subclass\nof int. However, issubclass(float, int) is False since float is not a subclass of int. 9.5.1 Multiple Inheritance\nPython supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this:\nclass DerivedClassName(Base1, Base2, Base3):\n<statement-1>\n. . . <statement-N>\nFor most purposes, in the simplest cases, you can think of the search for attributes inherited from a parent class as\ndepth-first, left-to-right, not searching twice in the same class where there is an overlap in the hierarchy. Thus, if an\nattribute is not found in DerivedClassName, it is searched for in Base1, then (recursively) in the base classes of\nBase1, and if it was not found there, it was searched for in Base2, and so on. In fact, it is slightly more complex than that; the method resolution order changes dynamically to support cooperative\ncalls to super(). This approach is known in some other multiple-inheritance languages as call-next-method and is\nmore powerful than the super call found in single-inheritance languages. Dynamic ordering is necessary because all cases of multiple inheritance exhibit one or more diamond relationships\n(where at least one of the parent classes can be accessed through multiple paths from the bottommost class). For\nexample, all classes inherit from object, so any case of multiple inheritance provides more than one path to reach\nobject. To keep the base classes from being accessed more than once, the dynamic algorithm linearizes the search\norder in a way that preserves the left-to-right ordering specified in each class, that calls each parent only once, and that\nis monotonic (meaning that a class can be subclassed without affecting the precedence order of its parents). Taken\ntogether, these properties make it possible to design reliable and extensible classes with multiple inheritance. For\nmore detail, see python_2.3_mro. 9.6 Private Variables\n“Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there\nis a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be\ntreated as a non-public part of the API (whether it is a function, a method or a data member). It should be considered\nan implementation detail and subject to change without notice. Since there is a valid use-case for class-private members (namely to avoid name clashes of names with names\ndefined by subclasses), there is limited support for such a mechanism, called name mangling.\n\n[3] Any function object that is a class attribute defines a method for instances of that class. It is not necessary that the\nfunction definition is textually enclosed in the class definition: assigning a function object to a local variable in the\nclass is also ok. For example:\n# Function defined outside the class\ndef f1(self, x, y):\nreturn min(x, x+y)\nclass C:\nf = f1\ndef g(self):\nreturn 'hello world'\nh = g\n9.4. Random Remarks\n79\n\nPython Tutorial, Release 3.13.2\nNow f, g and h are all attributes of class C that refer to function objects, and consequently they are all methods of\ninstances of C — h being exactly equivalent to g. Note that this practice usually only serves to confuse the reader of\na program. Methods may call other methods by using method attributes of the self argument:\nclass Bag:\ndef __init__(self):\nself.data = []\ndef add(self, x):\nself.data.append(x)\ndef addtwice(self, x):\nself.add(x)\nself.add(x)\nMethods may reference global names in the same way as ordinary functions. The global scope associated with a\nmethod is the module containing its definition. (A class is never used as a global scope.) While one rarely encounters\na good reason for using global data in a method, there are many legitimate uses of the global scope: for one thing,\nfunctions and modules imported into the global scope can be used by methods, as well as functions and classes defined\nin it. Usually, the class containing the method is itself defined in this global scope, and in the next section we’ll find\nsome good reasons why a method would want to reference its own class. Each value is an object, and therefore has a class (also called its type). It is stored as object.__class__. 9.5 Inheritance\nOf course, a language feature would not be worthy of the name “class” without supporting inheritance. The syntax\nfor a derived class definition looks like this:\nclass DerivedClassName(BaseClassName):\n<statement-1>\n. . . <statement-N>\nThe name BaseClassName must be defined in a namespace accessible from the scope containing the derived class\ndefinition. In place of a base class name, other arbitrary expressions are also allowed. This can be useful, for example,\nwhen the base class is defined in another module:\nclass DerivedClassName(modname.BaseClassName):\nExecution of a derived class definition proceeds the same as for a base class. When the class object is constructed,\nthe base class is remembered. This is used for resolving attribute references: if a requested attribute is not found\nin the class, the search proceeds to look in the base class. This rule is applied recursively if the base class itself is\nderived from some other class. There’s nothing special about instantiation of derived classes: DerivedClassName() creates a new instance of the\nclass. Method references are resolved as follows: the corresponding class attribute is searched, descending down the\nchain of base classes if necessary, and the method reference is valid if this yields a function object. Derived classes may override methods of their base classes. Because methods have no special privileges when calling\nother methods of the same object, a method of a base class that calls another method defined in the same base class\nmay end up calling a method of a derived class that overrides it. (For C++ programmers: all methods in Python are\neffectively virtual.) An overriding method in a derived class may in fact want to extend rather than simply replace the base class method\nof the same name. There is a simple way to call the base class method directly: just call BaseClassName. 80\nChapter 9. Classes\n\nPython Tutorial, Release 3.13.2\nmethodname(self, arguments). This is occasionally useful to clients as well. (Note that this only works if\nthe base class is accessible as BaseClassName in the global scope.) Python has two built-in functions that work with inheritance:\n• Use isinstance() to check an instance’s type: isinstance(obj, int) will be True only if obj. __class__ is int or some class derived from int. • Use issubclass() to check class inheritance: issubclass(bool, int) is True since bool is a subclass\nof int. However, issubclass(float, int) is False since float is not a subclass of int. 9.5.1 Multiple Inheritance\nPython supports a form of multiple inheritance as well. A class definition with multiple base classes looks like this:\nclass DerivedClassName(Base1, Base2, Base3):\n<statement-1>\n. . . <statement-N>\nFor most purposes, in the simplest cases, you can think of the search for attributes inherited from a parent class as\ndepth-first, left-to-right, not searching twice in the same class where there is an overlap in the hierarchy. Thus, if an\nattribute is not found in DerivedClassName, it is searched for in Base1, then (recursively) in the base classes of\nBase1, and if it was not found there, it was searched for in Base2, and so on. In fact, it is slightly more complex than that; the method resolution order changes dynamically to support cooperative\ncalls to super(). This approach is known in some other multiple-inheritance languages as call-next-method and is\nmore powerful than the super call found in single-inheritance languages. Dynamic ordering is necessary because all cases of multiple inheritance exhibit one or more diamond relationships\n(where at least one of the parent classes can be accessed through multiple paths from the bottommost class). For\nexample, all classes inherit from object, so any case of multiple inheritance provides more than one path to reach\nobject. To keep the base classes from being accessed more than once, the dynamic algorithm linearizes the search\norder in a way that preserves the left-to-right ordering specified in each class, that calls each parent only once, and that\nis monotonic (meaning that a class can be subclassed without affecting the precedence order of its parents). Taken\ntogether, these properties make it possible to design reliable and extensible classes with multiple inheritance. For\nmore detail, see python_2.3_mro. 9.6 Private Variables\n“Private” instance variables that cannot be accessed except from inside an object don’t exist in Python. However, there\nis a convention that is followed by most Python code: a name prefixed with an underscore (e.g. _spam) should be\ntreated as a non-public part of the API (whether it is a function, a method or a data member)."")",3.7423969350933616e-79,0.09769484083424808,0.2692595559173996,0.5894196629524231,0.6125155
How to put the legend outside the plot,"

You can make the legend text smaller by specifying 
set_size
 of 
FontProperties
.


Resources:



Legend guide


matplotlib.legend


matplotlib.pyplot.legend


matplotlib.font_manager




set_size(self, size)


Valid font size are 
xx-small
, 
x-small
, 
small
, 
medium
, 
large
, 
x-large
, 
xx-large
, 
larger
, 
smaller
, and 
None
.






Real Python: Python Plotting With Matplotlib (Guide)








import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

fontP = FontProperties()
fontP.set_size('xx-small')

p1, = plt.plot([1, 2, 3], label='Line 1')
p2, = plt.plot([3, 2, 1], label='Line 2')
plt.legend(handles=[p1, p2], title='title', bbox_to_anchor=(1.05, 1), loc='upper left', prop=fontP)







fontsize='xx-small'
 also works, without importing 
FontProperties
.




plt.legend(handles=[p1, p2], title='title', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='xx-small')


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 18\n3.2.1\nNone . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2.2\nNotImplemented\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2.3\nEllipsis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2.4\nnumbers.Number\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2.5\nSequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . 1620\n26.8.3\nWidget . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1621\n26.8.4\nCombobox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1623\n26.8.5\nSpinbox . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1624\n26.8.6\nNotebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1625\n26.8.7\nProgressbar . . . .\n\n[3] . . . . . . . . 1551\n25.1.2\nGet started . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1551\n25.1.3\nTutorial . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1552\n25.1.4\nHow to… . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1553\n25.1.5\nTurtle graphics reference\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",5.216678591959745e-232,0.10256410256410256,0.05489970186571331,0.4567650556564331,0.03334292
How do I reverse a string in Python?,"Using 
slicing
:


>>> 'hello world'[::-1]
'dlrow olleh'





Slice notation takes the form 
[start:stop:step]
. In this case, we omit the 
start
 and 
stop
 positions since we want the whole string. We also use 
step = -1
, which means, ""repeatedly step from right to left by 1 character"".

","('Answer: To iterate over a sequence in reverse order, you can use the `reversed()` built-in function. This function builds a new copy with the reversed order to iterate over without modifying the original sequence.\n\nReferences: [2]\n', '[1] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[2] One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython. • Behaviour can vary across operating systems, especially when talking about I/O or multi-threading. • You should always find the hot spots in your program before attempting to optimize any code (see the profile\nmodule). • Writing benchmark scripts will allow you to iterate quickly when searching for improvements (see the timeit\nmodule). • It is highly recommended to have good code coverage (through unit testing or any other technique) before\npotentially introducing regressions hidden in sophisticated optimizations. That being said, there are many tricks to speed up Python code. Here are some general principles which go a long\nway towards reaching acceptable performance levels:\n2.4. Performance\n21\n\nPython Frequently Asked Questions, Release 3.13.2\n• Making your algorithms faster (or changing to faster ones) can yield much larger benefits than trying to sprinkle\nmicro-optimization tricks all over your code. • Use the right data structures. Study documentation for the bltin-types and the collections module. • When the standard library provides a primitive for doing something, it is likely (although not guaranteed) to\nbe faster than any alternative you may come up with. This is doubly true for primitives written in C, such as\nbuiltins and some extension types. For example, be sure to use either the list.sort() built-in method or\nthe related sorted() function to do sorting (and see the sortinghowto for examples of moderately advanced\nusage). • Abstractions tend to create indirections and force the interpreter to work more. If the levels of indirection\noutweigh the amount of useful work done, your program will be slower. You should avoid excessive abstraction,\nespecially under the form of tiny functions or methods (which are also often detrimental to readability). If you have reached the limit of what pure Python can allow, there are tools to take you further away. For example,\nCython can compile a slightly modified version of Python code into a C extension, and can be used on many different\nplatforms. Cython can take advantage of compilation (and optional type annotations) to make your code significantly\nfaster than when interpreted. If you are confident in your C programming skills, you can also write a C extension\nmodule yourself. µ See also\nThe wiki page devoted to performance tips. 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over. 2.5.4 How do you remove duplicates from a list? See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list.\n\n[3] See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this. One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython. • Behaviour can vary across operating systems, especially when talking about I/O or multi-threading. • You should always find the hot spots in your program before attempting to optimize any code (see the profile\nmodule). • Writing benchmark scripts will allow you to iterate quickly when searching for improvements (see the timeit\nmodule). • It is highly recommended to have good code coverage (through unit testing or any other technique) before\npotentially introducing regressions hidden in sophisticated optimizations. That being said, there are many tricks to speed up Python code. Here are some general principles which go a long\nway towards reaching acceptable performance levels:\n2.4. Performance\n21\n\nPython Frequently Asked Questions, Release 3.13.2\n• Making your algorithms faster (or changing to faster ones) can yield much larger benefits than trying to sprinkle\nmicro-optimization tricks all over your code. • Use the right data structures. Study documentation for the bltin-types and the collections module. • When the standard library provides a primitive for doing something, it is likely (although not guaranteed) to\nbe faster than any alternative you may come up with. This is doubly true for primitives written in C, such as\nbuiltins and some extension types. For example, be sure to use either the list.sort() built-in method or\nthe related sorted() function to do sorting (and see the sortinghowto for examples of moderately advanced\nusage). • Abstractions tend to create indirections and force the interpreter to work more. If the levels of indirection\noutweigh the amount of useful work done, your program will be slower. You should avoid excessive abstraction,\nespecially under the form of tiny functions or methods (which are also often detrimental to readability). If you have reached the limit of what pure Python can allow, there are tools to take you further away. For example,\nCython can compile a slightly modified version of Python code into a C extension, and can be used on many different\nplatforms. Cython can take advantage of compilation (and optional type annotations) to make your code significantly\nfaster than when interpreted. If you are confident in your C programming skills, you can also write a C extension\nmodule yourself. µ See also\nThe wiki page devoted to performance tips. 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index? Python sequences are indexed with positive numbers and negative numbers. For positive numbers 0 is the first index\n1 is the second index and so forth. For negative indices -1 is the last index and -2 is the penultimate (next to last)\nindex and so forth. Think of seq[-n] as the same as seq[len(seq)-n]. Using negative indices can be very convenient. For example S[:-1] is all of the string except for its last character,\nwhich is useful for removing the trailing newline from a string. 2.5.3 How do I iterate over a sequence in reverse order? Use the reversed() built-in function:\nfor x in reversed(sequence):\n...\n# do something with x ... This won’t touch your original sequence, but build a new copy with reversed order to iterate over.')",6.890957792548029e-156,0.0164716081491114,0.08940401187979578,0.4603593647480011,0.32587615
How do I check if a directory exists in Python?,"Use 
os.path.isdir
 for directories only:


>>> import os
>>> os.path.isdir('new_folder')
True



Use 
os.path.exists
 for both files and directories:


>>> import os
>>> os.path.exists(os.path.join(os.getcwd(), 'new_folder', 'file.txt'))
False



Alternatively, you can use 
pathlib
:


 >>> from pathlib import Path
 >>> Path('new_folder').is_dir()
 True
 >>> (Path.cwd() / 'new_folder' / 'file.txt').exists()
 False


","('Answer: To check if a directory exists in Python, you can use the `os.path.isdir(path)` function, which returns `True` if the path is an existing directory. Alternatively, `os.path.exists(path)` will return `True` if the path exists, but it does not specify if the path is a directory.\n\nReferences: [1, 3]\n', '[1] os.path.dirname(path)\nReturn the directory name of pathname path. This is the first element of the pair returned by passing path to\nthe function split(). Changed in version 3.6: Accepts a path-like object. os.path.exists(path)\nReturn True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic\nlinks. On some platforms, this function may return False if permission is not granted to execute os.stat()\non the requested file, even if the path physically exists. Changed in version 3.3: path can now be an integer: True is returned if it is an open file descriptor, False\notherwise. Changed in version 3.6: Accepts a path-like object. os.path.lexists(path)\nReturn True if path refers to an existing path, including broken symbolic links. Equivalent to exists() on\nplatforms lacking os.lstat(). Changed in version 3.6: Accepts a path-like object. os.path.expanduser(path)\nOn Unix and Windows, return the argument with an initial component of ~ or ~user replaced by that user’s\nhome directory. On Unix, an initial ~ is replaced by the environment variable HOME if it is set; otherwise the current user’s\nhome directory is looked up in the password directory through the built-in module pwd. An initial ~user is\nlooked up directly in the password directory. On Windows, USERPROFILE will be used if set, otherwise a combination of HOMEPATH and HOMEDRIVE will\nbe used. An initial ~user is handled by checking that the last directory component of the current user’s home\ndirectory matches USERNAME, and replacing it if so. 11.2. os.path — Common pathname manipulations\n465\n\nThe Python Library Reference, Release 3.13.2\nIf the expansion fails or if the path does not begin with a tilde, the path is returned unchanged. Changed in version 3.6: Accepts a path-like object. Changed in version 3.8: No longer uses HOME on Windows. os.path.expandvars(path)\nReturn the argument with environment variables expanded. Substrings of the form $name or ${name} are\nreplaced by the value of environment variable name. Malformed variable names and references to non-existing\nvariables are left unchanged. On Windows, %name% expansions are supported in addition to $name and ${name}. Changed in version 3.6: Accepts a path-like object. os.path.getatime(path)\nReturn the time of last access of path. The return value is a floating-point number giving the number of seconds\nsince the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. os.path.getmtime(path)\nReturn the time of last modification of path. The return value is a floating-point number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getctime(path)\nReturn the system’s ctime which, on some systems (like Unix) is the time of the last metadata change, and,\non others (like Windows), is the creation time for path. The return value is a number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getsize(path)\nReturn the size, in bytes, of path. Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.isabs(path)\nReturn True if path is an absolute pathname. On Unix, that means it begins with a slash, on Windows that it\nbegins with two (back)slashes, or a drive letter, colon, and (back)slash together. Changed in version 3.6: Accepts a path-like object. Changed in version 3.13: On Windows, returns False if the given path starts with exactly one (back)slash. os.path.isfile(path)\nReturn True if path is an existing regular file. This follows symbolic links, so both islink() and\nisfile() can be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isdir(path)\nReturn True if path is an existing directory. This follows symbolic links, so both islink() and isdir()\ncan be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isjunction(path)\nReturn True if path refers to an existing directory entry that is a junction. Always return False if junctions\nare not supported on the current platform. Added in version 3.12.\nos.path.islink(path)\nReturn True if path refers to an existing directory entry that is a symbolic link.\n\n[2] Returns False for broken symbolic\nlinks. On some platforms, this function may return False if permission is not granted to execute os.stat()\non the requested file, even if the path physically exists. Changed in version 3.3: path can now be an integer: True is returned if it is an open file descriptor, False\notherwise. Changed in version 3.6: Accepts a path-like object. os.path.lexists(path)\nReturn True if path refers to an existing path, including broken symbolic links. Equivalent to exists() on\nplatforms lacking os.lstat(). Changed in version 3.6: Accepts a path-like object. os.path.expanduser(path)\nOn Unix and Windows, return the argument with an initial component of ~ or ~user replaced by that user’s\nhome directory. On Unix, an initial ~ is replaced by the environment variable HOME if it is set; otherwise the current user’s\nhome directory is looked up in the password directory through the built-in module pwd. An initial ~user is\nlooked up directly in the password directory. On Windows, USERPROFILE will be used if set, otherwise a combination of HOMEPATH and HOMEDRIVE will\nbe used. An initial ~user is handled by checking that the last directory component of the current user’s home\ndirectory matches USERNAME, and replacing it if so. 11.2. os.path — Common pathname manipulations\n465\n\nThe Python Library Reference, Release 3.13.2\nIf the expansion fails or if the path does not begin with a tilde, the path is returned unchanged. Changed in version 3.6: Accepts a path-like object. Changed in version 3.8: No longer uses HOME on Windows. os.path.expandvars(path)\nReturn the argument with environment variables expanded. Substrings of the form $name or ${name} are\nreplaced by the value of environment variable name. Malformed variable names and references to non-existing\nvariables are left unchanged. On Windows, %name% expansions are supported in addition to $name and ${name}. Changed in version 3.6: Accepts a path-like object. os.path.getatime(path)\nReturn the time of last access of path. The return value is a floating-point number giving the number of seconds\nsince the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. os.path.getmtime(path)\nReturn the time of last modification of path. The return value is a floating-point number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getctime(path)\nReturn the system’s ctime which, on some systems (like Unix) is the time of the last metadata change, and,\non others (like Windows), is the creation time for path. The return value is a number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getsize(path)\nReturn the size, in bytes, of path. Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.isabs(path)\nReturn True if path is an absolute pathname. On Unix, that means it begins with a slash, on Windows that it\nbegins with two (back)slashes, or a drive letter, colon, and (back)slash together. Changed in version 3.6: Accepts a path-like object. Changed in version 3.13: On Windows, returns False if the given path starts with exactly one (back)slash. os.path.isfile(path)\nReturn True if path is an existing regular file. This follows symbolic links, so both islink() and\nisfile() can be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isdir(path)\nReturn True if path is an existing directory. This follows symbolic links, so both islink() and isdir()\ncan be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isjunction(path)\nReturn True if path refers to an existing directory entry that is a junction. Always return False if junctions\nare not supported on the current platform. Added in version 3.12.\nos.path.islink(path)\nReturn True if path refers to an existing directory entry that is a symbolic link. Always False if symbolic\nlinks are not supported by the Python runtime. Changed in version 3.6: Accepts a path-like object. 466\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nos.path.ismount(path)\nReturn True if pathname path is a mount point: a point in a file system where a different file system has been\nmounted.\n\n[3] os.path.exists(path)\nReturn True if path refers to an existing path or an open file descriptor. Returns False for broken symbolic\nlinks. On some platforms, this function may return False if permission is not granted to execute os.stat()\non the requested file, even if the path physically exists. Changed in version 3.3: path can now be an integer: True is returned if it is an open file descriptor, False\notherwise. Changed in version 3.6: Accepts a path-like object. os.path.lexists(path)\nReturn True if path refers to an existing path, including broken symbolic links. Equivalent to exists() on\nplatforms lacking os.lstat(). Changed in version 3.6: Accepts a path-like object. os.path.expanduser(path)\nOn Unix and Windows, return the argument with an initial component of ~ or ~user replaced by that user’s\nhome directory. On Unix, an initial ~ is replaced by the environment variable HOME if it is set; otherwise the current user’s\nhome directory is looked up in the password directory through the built-in module pwd. An initial ~user is\nlooked up directly in the password directory. On Windows, USERPROFILE will be used if set, otherwise a combination of HOMEPATH and HOMEDRIVE will\nbe used. An initial ~user is handled by checking that the last directory component of the current user’s home\ndirectory matches USERNAME, and replacing it if so. 11.2. os.path — Common pathname manipulations\n465\n\nThe Python Library Reference, Release 3.13.2\nIf the expansion fails or if the path does not begin with a tilde, the path is returned unchanged. Changed in version 3.6: Accepts a path-like object. Changed in version 3.8: No longer uses HOME on Windows. os.path.expandvars(path)\nReturn the argument with environment variables expanded. Substrings of the form $name or ${name} are\nreplaced by the value of environment variable name. Malformed variable names and references to non-existing\nvariables are left unchanged. On Windows, %name% expansions are supported in addition to $name and ${name}. Changed in version 3.6: Accepts a path-like object. os.path.getatime(path)\nReturn the time of last access of path. The return value is a floating-point number giving the number of seconds\nsince the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. os.path.getmtime(path)\nReturn the time of last modification of path. The return value is a floating-point number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getctime(path)\nReturn the system’s ctime which, on some systems (like Unix) is the time of the last metadata change, and,\non others (like Windows), is the creation time for path. The return value is a number giving the number of\nseconds since the epoch (see the time module). Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.getsize(path)\nReturn the size, in bytes, of path. Raise OSError if the file does not exist or is inaccessible. Changed in version 3.6: Accepts a path-like object. os.path.isabs(path)\nReturn True if path is an absolute pathname. On Unix, that means it begins with a slash, on Windows that it\nbegins with two (back)slashes, or a drive letter, colon, and (back)slash together. Changed in version 3.6: Accepts a path-like object. Changed in version 3.13: On Windows, returns False if the given path starts with exactly one (back)slash. os.path.isfile(path)\nReturn True if path is an existing regular file. This follows symbolic links, so both islink() and\nisfile() can be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isdir(path)\nReturn True if path is an existing directory. This follows symbolic links, so both islink() and isdir()\ncan be true for the same path. Changed in version 3.6: Accepts a path-like object. os.path.isjunction(path)\nReturn True if path refers to an existing directory entry that is a junction. Always return False if junctions\nare not supported on the current platform. Added in version 3.12.\nos.path.islink(path)\nReturn True if path refers to an existing directory entry that is a symbolic link. Always False if symbolic\nlinks are not supported by the Python runtime. Changed in version 3.6: Accepts a path-like object. 466\nChapter 11.')",8.876310286787252e-80,0.029718875502008028,0.07030371203599552,0.5611892342567444,0.60635793
"What is the Python 3 equivalent of ""python -m SimpleHTTPServer""","From 
the docs
:




The 
SimpleHTTPServer
 module has been merged into 
http.server
 in Python 3.0. The 2to3 tool will automatically adapt imports when converting your sources to 3.0.




So, your command is 
python -m http.server
, or depending on your installation, it can be:


python3 -m http.server


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] 66\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\nDouble-click on the Install Certificates.command icon or file in the /Applications/Python 3.13/\nwindow to complete the installation. This will open a temporary Terminal shell window that will use the new Python to download and install SSL root\ncertificates for its use. 5.1. Using Python for macOS from python.org\n67\n\nPython Setup and Usage, Release 3.13.2\nIf Successfully installed certifi and update complete appears in the terminal window, the installation\nis complete. Close this terminal window and the installer window. A default install will include:\n• A Python 3.13 folder in your Applications folder. In here you find IDLE, the development environment\nthat is a standard part of official Python distributions; and Python Launcher, which handles double-clicking\nPython scripts from the macOS Finder. • A framework /Library/Frameworks/Python.framework, which includes the Python executable and\nlibraries. The installer adds this location to your shell path. To uninstall Python, you can remove these three\nthings. Symlinks to the Python executable are placed in /usr/local/bin/. ® Note\nRecent versions of macOS include a python3 command in /usr/bin/python3 that links to a usually older\nand incomplete version of Python provided by and for use by the Apple development tools, Xcode or the\nCommand Line Tools for Xcode. You should never modify or attempt to delete this installation, as it is\nApple-controlled and is used by Apple-provided or third-party software. If you choose to install a newer Python\nversion from python.org, you will have two different but functional Python installations on your computer that\ncan co-exist. The default installer options should ensure that its python3 will be used instead of the system\npython3. 68\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\n5.1.2 How to run a Python script\nThere are two ways to invoke the Python interpreter. If you are familiar with using a Unix shell in a terminal window,\nyou can invoke python3.13 or python3 optionally followed by one or more command line options (described in\nCommand line and environment). The Python tutorial also has a useful section on using Python interactively from a\nshell. You can also invoke the interpreter through an integrated development environment. idle is a basic editor and inter-\npreter environment which is included with the standard distribution of Python. IDLE includes a Help menu that allows\nyou to access Python documentation. If you are completely new to Python, you can read the tutorial introduction in\nthat document. There are many other editors and IDEs available, see Editors and IDEs for more information. To run a Python script file from the terminal window, you can invoke the interpreter with the name of the script file:\npython3.13 myscript.py\nTo run your script from the Finder, you can either:\n• Drag it to Python Launcher. • Select Python Launcher as the default application to open your script (or any .py script) through the Finder\nInfo window and double-click it. Python Launcher has various preferences to control how your script is\nlaunched. Option-dragging allows you to change these for one invocation, or use its Preferences menu to\nchange things globally. Be aware that running the script directly from the macOS Finder might produce different results than when running\nfrom a terminal window as the script will not be run in the usual shell environment including any setting of envi-\nronment variables in shell profiles. And, as with any other script or program, be certain of what you are about to\nrun. 5.2 Alternative Distributions\nBesides the standard python.org for macOS installer, there are third-party distributions for macOS that may include\nadditional functionality. Some popular distributions and their key features:\nActivePython\nInstaller with multi-platform compatibility, documentation\nAnaconda\nPopular scientific modules (such as numpy, scipy, and pandas) and the conda package manager. Homebrew\nPackage manager for macOS including multiple versions of Python and many third-party Python-based pack-\nages (including numpy, scipy, and pandas). MacPorts\nAnother package manager for macOS including multiple versions of Python and many third-party Python-\nbased packages. May include pre-built versions of Python and many packages for older versions of macOS. Note that distributions might not include the latest versions of Python or other libraries, and are not maintained or\nsupported by the core Python team. 5.3 Installing Additional Python Packages\nRefer to the Python Packaging User Guide for more information. 5.4 GUI Programming\nThere are several options for building GUI applications on the Mac with Python. 5.2. Alternative Distributions\n69\n\nPython Setup and Usage, Release 3.13.2\nThe standard Python GUI toolkit is tkinter, based on the cross-platform Tk toolkit (https://www.tcl.tk). A macOS-\nnative version of Tk is included with the installer. PyObjC is a Python binding to Apple’s Objective-C/Cocoa framework. Information on PyObjC is available from\npyobjc. A number of alternative macOS GUI toolkits are available including:\n• PySide: Official Python bindings to the Qt GUI toolkit. • PyQt: Alternative Python bindings to Qt. • Kivy: A cross-platform GUI toolkit that supports desktop and mobile platforms. • Toga: Part of the BeeWare Project; supports desktop, mobile, web and console apps. • wxPython: A cross-platform toolkit that supports desktop operating systems. 5.5 Advanced Topics\n5.5.1 Installing Free-threaded Binaries\nAdded in version 3.13: (Experimental)\n® Note\nEverything described in this section is considered experimental, and should be expected to change in future\nreleases. The python.org Python for macOS installer package can optionally install an additional build of Python 3.13 that\nsupports PEP 703, the experimental free-threading feature (running with the global interpreter lock disabled).\n\n[2] ® Note\nRecent versions of macOS include a python3 command in /usr/bin/python3 that links to a usually older\nand incomplete version of Python provided by and for use by the Apple development tools, Xcode or the\nCommand Line Tools for Xcode. You should never modify or attempt to delete this installation, as it is\nApple-controlled and is used by Apple-provided or third-party software. If you choose to install a newer Python\nversion from python.org, you will have two different but functional Python installations on your computer that\ncan co-exist. The default installer options should ensure that its python3 will be used instead of the system\npython3. 68\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\n5.1.2 How to run a Python script\nThere are two ways to invoke the Python interpreter. If you are familiar with using a Unix shell in a terminal window,\nyou can invoke python3.13 or python3 optionally followed by one or more command line options (described in\nCommand line and environment). The Python tutorial also has a useful section on using Python interactively from a\nshell. You can also invoke the interpreter through an integrated development environment. idle is a basic editor and inter-\npreter environment which is included with the standard distribution of Python. IDLE includes a Help menu that allows\nyou to access Python documentation. If you are completely new to Python, you can read the tutorial introduction in\nthat document. There are many other editors and IDEs available, see Editors and IDEs for more information. To run a Python script file from the terminal window, you can invoke the interpreter with the name of the script file:\npython3.13 myscript.py\nTo run your script from the Finder, you can either:\n• Drag it to Python Launcher. • Select Python Launcher as the default application to open your script (or any .py script) through the Finder\nInfo window and double-click it. Python Launcher has various preferences to control how your script is\nlaunched. Option-dragging allows you to change these for one invocation, or use its Preferences menu to\nchange things globally. Be aware that running the script directly from the macOS Finder might produce different results than when running\nfrom a terminal window as the script will not be run in the usual shell environment including any setting of envi-\nronment variables in shell profiles. And, as with any other script or program, be certain of what you are about to\nrun. 5.2 Alternative Distributions\nBesides the standard python.org for macOS installer, there are third-party distributions for macOS that may include\nadditional functionality. Some popular distributions and their key features:\nActivePython\nInstaller with multi-platform compatibility, documentation\nAnaconda\nPopular scientific modules (such as numpy, scipy, and pandas) and the conda package manager. Homebrew\nPackage manager for macOS including multiple versions of Python and many third-party Python-based pack-\nages (including numpy, scipy, and pandas). MacPorts\nAnother package manager for macOS including multiple versions of Python and many third-party Python-\nbased packages. May include pre-built versions of Python and many packages for older versions of macOS. Note that distributions might not include the latest versions of Python or other libraries, and are not maintained or\nsupported by the core Python team. 5.3 Installing Additional Python Packages\nRefer to the Python Packaging User Guide for more information. 5.4 GUI Programming\nThere are several options for building GUI applications on the Mac with Python. 5.2. Alternative Distributions\n69\n\nPython Setup and Usage, Release 3.13.2\nThe standard Python GUI toolkit is tkinter, based on the cross-platform Tk toolkit (https://www.tcl.tk). A macOS-\nnative version of Tk is included with the installer. PyObjC is a Python binding to Apple’s Objective-C/Cocoa framework. Information on PyObjC is available from\npyobjc. A number of alternative macOS GUI toolkits are available including:\n• PySide: Official Python bindings to the Qt GUI toolkit. • PyQt: Alternative Python bindings to Qt. • Kivy: A cross-platform GUI toolkit that supports desktop and mobile platforms. • Toga: Part of the BeeWare Project; supports desktop, mobile, web and console apps. • wxPython: A cross-platform toolkit that supports desktop operating systems. 5.5 Advanced Topics\n5.5.1 Installing Free-threaded Binaries\nAdded in version 3.13: (Experimental)\n® Note\nEverything described in this section is considered experimental, and should be expected to change in future\nreleases. The python.org Python for macOS installer package can optionally install an additional build of Python 3.13 that\nsupports PEP 703, the experimental free-threading feature (running with the global interpreter lock disabled). Check\nthe release page on python.org for possible updated information. Because this feature is still considered experimental, the support for it is not installed by default. It is packaged as a\nseparate install option, available by clicking the Customize button on the Installation Type step of the installer as\ndescribed above. 70\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\nIf the box next to the Free-threaded Python package name is checked, a separate PythonT.framework will also\nbe installed alongside the normal Python.framework in /Library/Frameworks. This configuration allows a\nfree-threaded Python 3.13 build to co-exist on your system with a traditional (GIL only) Python 3.13 build with\nminimal risk while installing or testing. This installation layout is itself experimental and is subject to change in\nfuture releases. Known cautions and limitations:\n• The UNIX command-line tools package, which is selected by default, will install links in /usr/local/bin\nfor python3.13t, the free-threaded interpreter, and python3.13t-config, a configuration utility which\nmay be useful for package builders. Since /usr/local/bin is typically included in your shell PATH, in most\ncases no changes to your PATH environment variables should be needed to use python3.13t. • For this release, the Shell profile updater package and the Update Shell Profile.command in /\nApplications/Python 3.13/ do not support the free-threaded package. • The free-threaded build and the traditional build have separate search paths and separate site-packages\ndirectories so, by default, if you need a package available in both builds, it may need to be installed in both. The free-threaded package will install a separate instance of pip for use with python3.13t.\n\n[3] Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\nDouble-click on the Install Certificates.command icon or file in the /Applications/Python 3.13/\nwindow to complete the installation. This will open a temporary Terminal shell window that will use the new Python to download and install SSL root\ncertificates for its use. 5.1. Using Python for macOS from python.org\n67\n\nPython Setup and Usage, Release 3.13.2\nIf Successfully installed certifi and update complete appears in the terminal window, the installation\nis complete. Close this terminal window and the installer window. A default install will include:\n• A Python 3.13 folder in your Applications folder. In here you find IDLE, the development environment\nthat is a standard part of official Python distributions; and Python Launcher, which handles double-clicking\nPython scripts from the macOS Finder. • A framework /Library/Frameworks/Python.framework, which includes the Python executable and\nlibraries. The installer adds this location to your shell path. To uninstall Python, you can remove these three\nthings. Symlinks to the Python executable are placed in /usr/local/bin/. ® Note\nRecent versions of macOS include a python3 command in /usr/bin/python3 that links to a usually older\nand incomplete version of Python provided by and for use by the Apple development tools, Xcode or the\nCommand Line Tools for Xcode. You should never modify or attempt to delete this installation, as it is\nApple-controlled and is used by Apple-provided or third-party software. If you choose to install a newer Python\nversion from python.org, you will have two different but functional Python installations on your computer that\ncan co-exist. The default installer options should ensure that its python3 will be used instead of the system\npython3. 68\nChapter 5. Using Python on macOS\n\nPython Setup and Usage, Release 3.13.2\n5.1.2 How to run a Python script\nThere are two ways to invoke the Python interpreter. If you are familiar with using a Unix shell in a terminal window,\nyou can invoke python3.13 or python3 optionally followed by one or more command line options (described in\nCommand line and environment). The Python tutorial also has a useful section on using Python interactively from a\nshell. You can also invoke the interpreter through an integrated development environment. idle is a basic editor and inter-\npreter environment which is included with the standard distribution of Python. IDLE includes a Help menu that allows\nyou to access Python documentation. If you are completely new to Python, you can read the tutorial introduction in\nthat document. There are many other editors and IDEs available, see Editors and IDEs for more information. To run a Python script file from the terminal window, you can invoke the interpreter with the name of the script file:\npython3.13 myscript.py\nTo run your script from the Finder, you can either:\n• Drag it to Python Launcher. • Select Python Launcher as the default application to open your script (or any .py script) through the Finder\nInfo window and double-click it. Python Launcher has various preferences to control how your script is\nlaunched. Option-dragging allows you to change these for one invocation, or use its Preferences menu to\nchange things globally. Be aware that running the script directly from the macOS Finder might produce different results than when running\nfrom a terminal window as the script will not be run in the usual shell environment including any setting of envi-\nronment variables in shell profiles. And, as with any other script or program, be certain of what you are about to\nrun. 5.2 Alternative Distributions\nBesides the standard python.org for macOS installer, there are third-party distributions for macOS that may include\nadditional functionality. Some popular distributions and their key features:\nActivePython\nInstaller with multi-platform compatibility, documentation\nAnaconda\nPopular scientific modules (such as numpy, scipy, and pandas) and the conda package manager. Homebrew\nPackage manager for macOS including multiple versions of Python and many third-party Python-based pack-\nages (including numpy, scipy, and pandas). MacPorts\nAnother package manager for macOS including multiple versions of Python and many third-party Python-\nbased packages. May include pre-built versions of Python and many packages for older versions of macOS. Note that distributions might not include the latest versions of Python or other libraries, and are not maintained or\nsupported by the core Python team. 5.3 Installing Additional Python Packages\nRefer to the Python Packaging User Guide for more information. 5.4 GUI Programming\nThere are several options for building GUI applications on the Mac with Python. 5.2. Alternative Distributions\n69\n\nPython Setup and Usage, Release 3.13.2\nThe standard Python GUI toolkit is tkinter, based on the cross-platform Tk toolkit (https://www.tcl.tk). A macOS-\nnative version of Tk is included with the installer. PyObjC is a Python binding to Apple’s Objective-C/Cocoa framework. Information on PyObjC is available from\npyobjc. A number of alternative macOS GUI toolkits are available including:\n• PySide: Official Python bindings to the Qt GUI toolkit. • PyQt: Alternative Python bindings to Qt. • Kivy: A cross-platform GUI toolkit that supports desktop and mobile platforms. • Toga: Part of the BeeWare Project; supports desktop, mobile, web and console apps. • wxPython: A cross-platform toolkit that supports desktop operating systems. 5.5 Advanced Topics\n5.5.1 Installing Free-threaded Binaries\nAdded in version 3.13: (Experimental)\n® Note\nEverything described in this section is considered experimental, and should be expected to change in future\nreleases. The python.org Python for macOS installer package can optionally install an additional build of Python 3.13 that\nsupports PEP 703, the experimental free-threading feature (running with the global interpreter lock disabled). Check\nthe release page on python.org for possible updated information.')",6.10884244743819e-156,0.016704143912624474,0.04683508373545275,0.5224493741989136,0.3702283
What is setup.py?,"setup.py
 is a Python file, the presence of which is an indication that the module/package you are about to install has likely been packaged and distributed with 
Distutils
, which is the standard for distributing Python Modules.


This allows you to easily 
install Python packages
. Often it's enough to write:


$ pip install . 



pip
 will use 
setup.py
 to install your module. Avoid calling 
setup.py
 directly.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . 21\n3\nConfigure Python\n23\n3.1\nBuild Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2\nGenerated files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2.1\nconfigure script . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3\nConfigure Options\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3.1\nGeneral Options . . . .\n\n[2] . . . . . 20\n2.3\nPython-related paths and files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.4\nMiscellaneous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.5\nCustom OpenSSL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3\nConfigure Python\n23\n3.1\nBuild Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2\nGenerated files . .\n\n[3] . . . . . . . . . . . 228\n10.3\nPyStatus\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n10.4\nPyPreConfig\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n10.5\nPreinitialize Python with PyPreConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n10.6\nPyConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",5.830383594671622e-232,0.05780346820809249,0.047999999999999994,0.3940763473510742,0.35387316
How can I flush the output of the print function?,"In Python 3, 
print
 can take an optional 
flush
 argument:


print(""Hello, World!"", flush=True)



In Python 2, after calling 
print
, do:


import sys
sys.stdout.flush()



By default, 
print
 prints to 
sys.stdout
 (see the documentation for more about 
file objects
).

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] In that case, you can try the following hack (due to Alex Rezinsky):\n51\n\nPython Frequently Asked Questions, Release 3.13.2\n#! /bin/sh\n"""""":""\nexec python $0 ${1+""$@""}\n""""""\nThe minor disadvantage is that this defines the script’s __doc__ string. However, you can fix that by adding\n__doc__ = """"""...Whatever...""""""\n4.1.4 Is there a curses/termcap package for Python? For Unix variants: The standard Python source distribution comes with a curses module in the Modules subdirectory,\nthough it’s not compiled by default. (Note that this is not available in the Windows distribution – there is no curses\nmodule for Windows.) The curses module supports basic curses features as well as many additional functions from ncurses and SYSV curses\nsuch as colour, alternative character set support, pads, and mouse support. This means the module isn’t compatible\nwith operating systems that only have BSD curses, but there don’t seem to be any currently maintained OSes that fall\ninto this category. 4.1.5 Is there an equivalent to C’s onexit() in Python? The atexit module provides a register function that is similar to C’s onexit(). 4.1.6 Why don’t my signal handlers work? The most common problem is that the signal handler is declared with the wrong argument list. It is called as\nhandler(signum, frame)\nso it should be declared with two parameters:\ndef handler(signum, frame):\n...\n4.2 Common tasks\n4.2.1 How do I test a Python program or component? Python comes with two testing frameworks. The doctest module finds examples in the docstrings for a module and\nruns them, comparing the output with the expected output given in the docstring. The unittest module is a fancier testing framework modelled on Java and Smalltalk testing frameworks. To make testing easier, you should use good modular design in your program. Your program should have almost all\nfunctionality encapsulated in either functions or class methods – and this sometimes has the surprising and delightful\neffect of making the program run faster (because local variable accesses are faster than global accesses). Furthermore\nthe program should avoid depending on mutating global variables, since this makes testing much more difficult to do. The “global main logic” of your program may be as simple as\nif __name__ == ""__main__"":\nmain_logic()\nat the bottom of the main module of your program. Once your program is organized as a tractable collection of function and class behaviours, you should write test\nfunctions that exercise the behaviours. A test suite that automates a sequence of tests can be associated with each\nmodule. This sounds like a lot of work, but since Python is so terse and flexible it’s surprisingly easy. You can make\n52\nChapter 4. Library and Extension FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\ncoding much more pleasant and fun by writing your test functions in parallel with the “production code”, since this\nmakes it easy to find bugs and even design flaws earlier. “Support modules” that are not intended to be the main module of a program may include a self-test of the module. if __name__ == ""__main__"":\nself_test()\nEven programs that interact with complex external interfaces may be tested when the external interfaces are unavail-\nable by using “fake” interfaces implemented in Python. 4.2.2 How do I create documentation from doc strings? The pydoc module can create HTML from the doc strings in your Python source code. An alternative for creating\nAPI documentation purely from docstrings is epydoc. Sphinx can also include docstring content. 4.2.3 How do I get a single keypress at a time? For Unix variants there are several solutions. It’s straightforward to do this using curses, but curses is a fairly large\nmodule to learn. 4.3 Threads\n4.3.1 How do I program using threads? Be sure to use the threading module and not the _thread module. The threading module builds convenient\nabstractions on top of the low-level primitives provided by the _thread module. 4.3.2 None of my threads seem to run: why? As soon as the main thread exits, all threads are killed. Your main thread is running too quickly, giving the threads\nno time to do any work. A simple fix is to add a sleep to the end of the program that’s long enough for all the threads to finish:\nimport threading, time\ndef thread_task(name, n):\nfor i in range(n):\nprint(name, i)\nfor i in range(10):\nT = threading.Thread(target=thread_task, args=(str(i), i))\nT.start()\ntime.sleep(10)\n# <---------------------------! But now (on many platforms) the threads don’t run in parallel, but appear to run sequentially, one at a time! The\nreason is that the OS thread scheduler doesn’t start a new thread until the previous thread is blocked. A simple fix is to add a tiny sleep to the start of the run function:\ndef thread_task(name, n):\ntime.sleep(0.001)\n# <--------------------! for i in range(n):\nprint(name, i)\nfor i in range(10):\nT = threading.Thread(target=thread_task, args=(str(i), i))\n(continues on next page)\n4.3. Threads\n53\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nT.start()\ntime.sleep(10)\nInstead of trying to guess a good delay value for time.sleep(), it’s better to use some kind of semaphore mech-\nanism. One idea is to use the queue module to create a queue object, let each thread append a token to the queue\nwhen it finishes, and let the main thread read as many tokens from the queue as there are threads. 4.3.3 How do I parcel out work among a bunch of worker threads? The easiest way is to use the concurrent.futures module, especially the ThreadPoolExecutor class. Or, if you want fine control over the dispatching algorithm, you can write your own logic manually. Use the queue\nmodule to create a queue containing a list of jobs. The Queue class maintains a list of objects and has a .put(obj)\nmethod that adds items to the queue and a .get() method to return them.\n\n[2] 53\n4.2.3\nHow do I get a single keypress at a time? . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3\nThreads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3.1\nHow do I program using threads? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3.2\nNone of my threads seem to run: why? . . . . . . . . . . . . . . . . . . . . . . . . . . . 53\n4.3.3\nHow do I parcel out work among a bunch of worker threads? . . . . . . . . .\n\n[3] . . . . . . 57\niii\n\n4.4.5\nHow do I access the serial (RS232) port? . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.4.6\nWhy doesn’t closing sys.stdout (stdin, stderr) really close it? . . . . . . . . . . . . . . . . 57\n4.5\nNetwork/Internet Programming\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.5.1\nWhat WWW tools are there for Python? . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.5.2\nWhat module should I use to help with generating HTML? . . . .')",5.7221977983591546e-232,0.022857142857142854,0.10993483339162802,0.4938354790210724,0.38392133
Create a dictionary with comprehension,"Use a 
dict comprehension
 (Python 2.7 and later):


{key: value for key, value in zip(keys, values)}





Alternatively, use the 
dict
 constructor:


pairs = [('a', 1), ('b', 2)]
dict(pairs)                          # → {'a': 1, 'b': 2}
dict((k, v + 10) for k, v in pairs)  # → {'a': 11, 'b': 12}



Given separate lists of keys and values, use the 
dict
 constructor with 
zip
:


keys = ['a', 'b']
values = [1, 2]
dict(zip(keys, values))              # → {'a': 1, 'b': 2}


","('Answer: Dictionaries can be created from arbitrary key and value expressions using dict comprehensions. For example: `{x: x**2 for x in (2, 4, 6)}` results in `{2: 4, 4: 16, 6: 36}`.\n\nReferences: [2]\n', ""[1] A set is an unordered collection with no duplicate elements. Basic uses\ninclude membership testing and eliminating duplicate entries. Set objects also support mathematical operations like\nunion, intersection, difference, and symmetric difference. Curly braces or the set() function can be used to create sets. Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type.\n\n[2] Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal. If one sequence\nis an initial sub-sequence of the other, the shorter sequence is the smaller (lesser) one.\n\n[3] Curly braces or the set() function can be used to create sets. Note: to create an empty set you have to use set(),\nnot {}; the latter creates an empty dictionary, a data structure that we discuss in the next section. Here is a brief demonstration:\n>>> basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n>>> print(basket)\n# show that duplicates have been removed\n{'orange', 'banana', 'pear', 'apple'}\n>>> 'orange' in basket\n# fast membership testing\nTrue\n>>> 'crabgrass' in basket\nFalse\n>>> # Demonstrate set operations on unique letters from two words\n>>>\n>>> a = set('abracadabra')\n>>> b = set('alacazam')\n>>> a\n# unique letters in a\n{'a', 'r', 'b', 'c', 'd'}\n>>> a - b\n# letters in a but not in b\n{'r', 'd', 'b'}\n>>> a | b\n# letters in a or b or both\n{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}\n>>> a & b\n# letters in both a and b\n{'a', 'c'}\n>>> a ^ b\n# letters in a or b but not both\n{'r', 'd', 'b', 'm', 'z', 'l'}\nSimilarly to list comprehensions, set comprehensions are also supported:\n>>> a = {x for x in 'abracadabra' if x not in 'abc'}\n>>> a\n{'r', 'd'}\n5.5 Dictionaries\nAnother useful data type built into Python is the dictionary (see typesmapping). Dictionaries are sometimes found\nin other languages as “associative memories” or “associative arrays”. Unlike sequences, which are indexed by a range\nof numbers, dictionaries are indexed by keys, which can be any immutable type; strings and numbers can always be\nkeys. Tuples can be used as keys if they contain only strings, numbers, or tuples; if a tuple contains any mutable\nobject either directly or indirectly, it cannot be used as a key. You can’t use lists as keys, since lists can be modified\nin place using index assignments, slice assignments, or methods like append() and extend(). It is best to think of a dictionary as a set of key: value pairs, with the requirement that the keys are unique (within\none dictionary). A pair of braces creates an empty dictionary: {}. Placing a comma-separated list of key:value pairs\nwithin the braces adds initial key:value pairs to the dictionary; this is also the way dictionaries are written on output. The main operations on a dictionary are storing a value with some key and extracting the value given the key. It is also\npossible to delete a key:value pair with del. If you store using a key that is already in use, the old value associated\nwith that key is forgotten. It is an error to extract a value using a non-existent key. Performing list(d) on a dictionary returns a list of all the keys used in the dictionary, in insertion order (if you\nwant it sorted, just use sorted(d) instead). To check whether a single key is in the dictionary, use the in keyword. 5.4. Sets\n39\n\nPython Tutorial, Release 3.13.2\nHere is a small example using a dictionary:\n>>> tel = {'jack': 4098, 'sape': 4139}\n>>> tel['guido'] = 4127\n>>> tel\n{'jack': 4098, 'sape': 4139, 'guido': 4127}\n>>> tel['jack']\n4098\n>>> del tel['sape']\n>>> tel['irv'] = 4127\n>>> tel\n{'jack': 4098, 'guido': 4127, 'irv': 4127}\n>>> list(tel)\n['jack', 'guido', 'irv']\n>>> sorted(tel)\n['guido', 'irv', 'jack']\n>>> 'guido' in tel\nTrue\n>>> 'jack' not in tel\nFalse\nThe dict() constructor builds dictionaries directly from sequences of key-value pairs:\n>>> dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\nIn addition, dict comprehensions can be used to create dictionaries from arbitrary key and value expressions:\n>>> {x: x**2 for x in (2, 4, 6)}\n{2: 4, 4: 16, 6: 36}\nWhen the keys are simple strings, it is sometimes easier to specify pairs using keyword arguments:\n>>> dict(sape=4139, guido=4127, jack=4098)\n{'sape': 4139, 'guido': 4127, 'jack': 4098}\n5.6 Looping Techniques\nWhen looping through dictionaries, the key and corresponding value can be retrieved at the same time using the\nitems() method. >>> knights = {'gallahad': 'the pure', 'robin': 'the brave'}\n>>> for k, v in knights.items():\n...\nprint(k, v)\n...\ngallahad the pure\nrobin the brave\nWhen looping through a sequence, the position index and corresponding value can be retrieved at the same time using\nthe enumerate() function. >>> for i, v in enumerate(['tic', 'tac', 'toe']):\n...\nprint(i, v)\n...\n0 tic\n1 tac\n2 toe\n40\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nTo loop over two or more sequences at the same time, the entries can be paired with the zip() function. >>> questions = ['name', 'quest', 'favorite color']\n>>> answers = ['lancelot', 'the holy grail', 'blue']\n>>> for q, a in zip(questions, answers):\n...\nprint('What is your {0}? It is {1}. '.format(q, a))\n...\nWhat is your name? It is lancelot. What is your quest? It is the holy grail. What is your favorite color? It is blue. To loop over a sequence in reverse, first specify the sequence in a forward direction and then call the reversed()\nfunction. >>> for i in reversed(range(1, 10, 2)):\n...\nprint(i)\n...\n9\n7\n5\n3\n1\nTo loop over a sequence in sorted order, use the sorted() function which returns a new sorted list while leaving\nthe source unaltered. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for i in sorted(basket):\n...\nprint(i)\n...\napple\napple\nbanana\norange\norange\npear\nUsing set() on a sequence eliminates duplicate elements. The use of sorted() in combination with set() over\na sequence is an idiomatic way to loop over unique elements of the sequence in sorted order. >>> basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']\n>>> for f in sorted(set(basket)):\n...\nprint(f)\n...\napple\nbanana\norange\npear\nIt is sometimes tempting to change a list while you are looping over it; however, it is often simpler and safer to create\na new list instead. >>> import math\n>>> raw_data = [56.2, float('NaN'), 51.7, 55.3, 52.5, float('NaN'), 47.8]\n>>> filtered_data = []\n>>> for value in raw_data:\n...\nif not math.isnan(value):\n...\nfiltered_data.append(value)\n(continues on next page)\n5.6. Looping Techniques\n41\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> filtered_data\n[56.2, 51.7, 55.3, 52.5, 47.8]\n5.7 More on Conditions\nThe conditions used in while and if statements can contain any operators, not just comparisons. The comparison operators in and not in are membership tests that determine whether a value is in (or not in) a\ncontainer. The operators is and is not compare whether two objects are really the same object. All comparison\noperators have the same priority, which is lower than that of all numerical operators. Comparisons can be chained. For example, a < b == c tests whether a is less than b and moreover b equals c.\nComparisons may be combined using the Boolean operators and and or, and the outcome of a comparison (or of\nany other Boolean expression) may be negated with not. These have lower priorities than comparison operators;\nbetween them, not has the highest priority and or the lowest, so that A and not B or C is equivalent to (A and\n(not B)) or C. As always, parentheses can be used to express the desired composition. The Boolean operators and and or are so-called short-circuit operators: their arguments are evaluated from left to\nright, and evaluation stops as soon as the outcome is determined. For example, if A and C are true but B is false, A\nand B and C does not evaluate the expression C. When used as a general value and not as a Boolean, the return\nvalue of a short-circuit operator is the last evaluated argument. It is possible to assign the result of a comparison or other Boolean expression to a variable. For example,\n>>> string1, string2, string3 = '', 'Trondheim', 'Hammer Dance'\n>>> non_null = string1 or string2 or string3\n>>> non_null\n'Trondheim'\nNote that in Python, unlike C, assignment inside expressions must be done explicitly with the walrus operator :=. This avoids a common class of problems encountered in C programs: typing = in an expression when == was intended. 5.8 Comparing Sequences and Other Types\nSequence objects typically may be compared to other objects with the same sequence type. The comparison uses\nlexicographical ordering: first the first two items are compared, and if they differ this determines the outcome of\nthe comparison; if they are equal, the next two items are compared, and so on, until either sequence is exhausted. If two items to be compared are themselves sequences of the same type, the lexicographical comparison is carried\nout recursively. If all items of two sequences compare equal, the sequences are considered equal."")",0.0011601960080848694,0.022618529795563287,0.09612919764163037,0.6023209095001221,0.5444118
Convert integer to string in Python,">>> str(42)
'42'

>>> int('42')
42



Links to the documentation:




int()


str()




str(x)
 converts any object 
x
 to a string by calling 
x.
__str__()
, or 
repr(x)
 if 
x
 doesn't have a 
__str__()
 method.

","('Answer: To convert a number to a string, use the built-in type constructor str(). If you want a hexadecimal or octal representation, use the built-in functions hex() or oct().\n\nReferences: [1, 2, 3]\n', '[1] For example, to set\nthe variable “a” to the octal value “10” (8 in decimal), type:\n>>> a = 0o10\n>>> a\n8\nHexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2.\n\n[2] Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task.\n\n[3] To specify an octal digit, precede the octal value with a zero, and then a lower or uppercase “o”. For example, to set\nthe variable “a” to the octal value “10” (8 in decimal), type:\n>>> a = 0o10\n>>> a\n8\nHexadecimal is just as easy. Simply precede the hexadecimal number with a zero, and then a lower or uppercase “x”. Hexadecimal digits can be specified in lower or uppercase. For example, in the Python interpreter:\n>>> a = 0xa5\n>>> a\n165\n>>> b = 0XB2\n>>> b\n178\n2.3.2 Why does -22 // 10 return -3? It’s primarily driven by the desire that i % j have the same sign as j. If you want that, and also want:\ni == (i // j) * j + (i % j)\nthen integer division has to return the floor. C also requires that identity to hold, and then compilers that truncate i\n// j need to make i % j have the same sign as i. There are few real use cases for i % j when j is negative. When j is positive, there are many, and in virtually all of\nthem it’s more useful for i % j to be >= 0. If the clock says 10 now, what did it say 200 hours ago? -190 % 12\n== 2 is useful; -190 % 12 == -10 is a bug waiting to bite. 2.3.3 How do I get int literal attribute instead of SyntaxError? Trying to lookup an int literal attribute in the normal manner gives a SyntaxError because the period is seen as\na decimal point:\n>>> 1.__class__\nFile ""<stdin>"", line 1\n1.__class__\n^\nSyntaxError: invalid decimal literal\nThe solution is to separate the literal from the period with either a space or parentheses. >>> 1 .__class__\n<class \'int\'>\n>>> (1).__class__\n<class \'int\'>\n2.3.4 How do I convert a string to a number? For integers, use the built-in int() type constructor, e.g. int(\'144\') == 144. Similarly, float() converts to\na floating-point number, e.g. float(\'144\') == 144.0. By default, these interpret the number as decimal, so that int(\'0144\') == 144 holds true, and int(\'0x144\')\nraises ValueError. int(string, base) takes the base to convert from as a second optional argument, so int(\n18\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n\'0x144\', 16) == 324. If the base is specified as 0, the number is interpreted using Python’s rules: a leading ‘0o’\nindicates octal, and ‘0x’ indicates a hex number. Do not use the built-in function eval() if all you need is to convert strings to numbers. eval() will be significantly\nslower and it presents a security risk: someone could pass you a Python expression that might have unwanted side\neffects. For example, someone could pass __import__(\'os\').system(""rm -rf $HOME"") which would erase\nyour home directory. eval() also has the effect of interpreting numbers as Python expressions, so that e.g. eval(\'09\') gives a syntax\nerror because Python does not allow leading ‘0’ in a decimal number (except ‘0’). 2.3.5 How do I convert a number to a string? To convert, e.g., the number 144 to the string \'144\', use the built-in type constructor str(). If you want a\nhexadecimal or octal representation, use the built-in functions hex() or oct(). For fancy formatting, see the f-\nstrings and formatstrings sections, e.g. ""{:04d}"".format(144) yields \'0144\' and ""{:.3f}"".format(1.0/\n3.0) yields \'0.333\'. 2.3.6 How do I modify a string in place? You can’t, because strings are immutable. In most situations, you should simply construct a new string from the\nvarious parts you want to assemble it from. However, if you need an object with the ability to modify in-place\nunicode data, try using an io.StringIO object or the array module:\n>>> import io\n>>> s = ""Hello, world""\n>>> sio = io.StringIO(s)\n>>> sio.getvalue()\n\'Hello, world\'\n>>> sio.seek(7)\n7\n>>> sio.write(""there!"") 6\n>>> sio.getvalue()\n\'Hello, there!\' >>> import array\n>>> a = array.array(\'w\', s)\n>>> print(a)\narray(\'w\', \'Hello, world\')\n>>> a[0] = \'y\'\n>>> print(a)\narray(\'w\', \'yello, world\')\n>>> a.tounicode()\n\'yello, world\'\n2.3.7 How do I use strings to call functions/methods? There are various techniques. • The best is to use a dictionary that maps strings to functions. The primary advantage of this technique is that\nthe strings do not need to match the names of the functions. This is also the primary technique used to emulate\na case construct:\ndef a():\npass\ndef b():\npass\n(continues on next page)\n2.3. Numbers and strings\n19\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\ndispatch = {\'go\': a, \'stop\': b}\n# Note lack of parens for funcs\ndispatch[get_input()]()\n# Note trailing parens to call function\n• Use the built-in function getattr():\nimport foo\ngetattr(foo, \'bar\')()\nNote that getattr() works on any object, including classes, class instances, modules, and so on. This is used in several places in the standard library, like this:\nclass Foo:\ndef do_foo(self):\n...\ndef do_bar(self):\n...\nf = getattr(foo_instance, \'do_\' + opname)\nf()\n• Use locals() to resolve the function name:\ndef myFunc():\nprint(""hello"")\nfname = ""myFunc""\nf = locals()[fname]\nf()\n2.3.8 Is there an equivalent to Perl’s chomp() for removing trailing newlines from\nstrings? You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator.')",7.544285389679584e-156,0.012665862484921592,0.06643518868309961,0.5331610441207886,0.6016945
Use of *args and **kwargs,"The syntax is the 
*
 and 
**
.  The names 
*args
 and 
**kwargs
 are only by convention but there's no hard requirement to use them.


You would use 
*args
 when you're not sure how many arguments might be passed to your function, i.e. it allows you pass an arbitrary number of arguments to your function.  For example:


>>> def print_everything(*args):
        for count, thing in enumerate(args):
...         print( '{0}. {1}'.format(count, thing))
...
>>> print_everything('apple', 'banana', 'cabbage')
0. apple
1. banana
2. cabbage



Similarly, 
**kwargs
 allows you to handle named arguments that you have not defined in advance:


>>> def table_things(**kwargs):
...     for name, value in kwargs.items():
...         print( '{0} = {1}'.format(name, value))
...
>>> table_things(apple = 'fruit', cabbage = 'vegetable')
cabbage = vegetable
apple = fruit



You can use these along with named arguments too.  The explicit arguments get values first and then everything else is passed to 
*args
 and 
**kwargs
.  The named arguments come first in the list.  For example:


def table_things(titlestring, **kwargs)



You can also use both in the same function definition but 
*args
 must occur before 
**kwargs
.


You can also use the 
*
 and 
**
 syntax when calling a function.  For example:


>>> def print_three_things(a, b, c):
...     print( 'a = {0}, b = {1}, c = {2}'.format(a,b,c))
...
>>> mylist = ['aardvark', 'baboon', 'cat']
>>> print_three_things(*mylist)
a = aardvark, b = baboon, c = cat



As you can see in this case it takes the list (or tuple) of items and unpacks it. By this it matches them to the arguments in the function.  Of course, you could have a 
*
 both in the function definition and in the function call.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . 836\n17.1.2\nThe add_argument() method\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 843\n17.1.3\nThe parse_args() method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 853\n17.1.4\nOther utilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 856\n17.1.5\nExceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 865\n17.2\noptparse — Parser for command line options .\n\n[2] . . . . 801\n16.9.2\nctypes reference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 819\n17 Command Line Interface Libraries\n835\n17.1\nargparse — Parser for command-line options, arguments and subcommands . . . . . . . . . . . 835\n17.1.1\nArgumentParser objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 836\n17.1.2\nThe add_argument() method\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 843\n17.1.3\nThe parse_args() method . . .\n\n[3] . . . . . . . . . . . . . . . 10\n2.2.5\nWhat are the “best practices” for using import in a module? . . . . . . . . . . . . . . . . 10\n2.2.6\nWhy are default values shared between objects? . . . . . . . . . . . . . . . . . . . . . . 11\n2.2.7\nHow can I pass optional or keyword parameters from one function to another? . . . . . . 12\n2.2.8\nWhat is the difference between arguments and parameters? . . . . . . . . . . . . . . . . 12\n2.2.9\nWhy did changing list ‘y’ also change list ‘x’? . . . . . . . . .')",1.81396060558678e-155,0.10360360360360359,0.07582720588235294,0.5306771993637085,0.24465391
Change column type in pandas,"You have four main options for converting types in pandas:




to_numeric()
 - provides functionality to safely convert non-numeric types (e.g. strings) to a suitable numeric type. (See also 
to_datetime()
 and 
to_timedelta()
.)




astype()
 - convert (almost) any type to (almost) any other type (even if it's not necessarily sensible to do so). Also allows you to convert to 
categorial
 types (very useful).




infer_objects()
 - a utility method to convert object columns holding Python objects to a pandas type if possible.




convert_dtypes()
 - convert DataFrame columns to the ""best possible""  dtype that supports 
pd.NA
 (pandas' object to indicate a missing value).






Read on for more detailed explanations and usage of each of these methods.




1. 
to_numeric()


The best way to convert one or more columns of a DataFrame to numeric values is to use 
pandas.to_numeric()
.


This function will try to change non-numeric objects (such as strings) into integers or floating-point numbers as appropriate.


Basic usage


The input to 
to_numeric()
 is a Series or a single column of a DataFrame.


>>> s = pd.Series([""8"", 6, ""7.5"", 3, ""0.9""]) # mixed string and numeric values
>>> s
0      8
1      6
2    7.5
3      3
4    0.9
dtype: object

>>> pd.to_numeric(s) # convert everything to float values
0    8.0
1    6.0
2    7.5
3    3.0
4    0.9
dtype: float64



As you can see, a new Series is returned. Remember to assign this output to a variable or column name to continue using it:


# convert Series
my_series = pd.to_numeric(my_series)

# convert column ""a"" of a DataFrame
df[""a""] = pd.to_numeric(df[""a""])



You can also use it to convert multiple columns of a DataFrame via the 
apply()
 method:


# convert all columns of DataFrame
df = df.apply(pd.to_numeric) # convert all columns of DataFrame

# convert just columns ""a"" and ""b""
df[[""a"", ""b""]] = df[[""a"", ""b""]].apply(pd.to_numeric)



As long as your values can all be converted, that's probably all you need.


Error handling


But what if some values can't be converted to a numeric type?


to_numeric()
 also takes an 
errors
 keyword argument that allows you to force non-numeric values to be 
NaN
, or simply ignore columns containing these values.


Here's an example using a Series of strings 
s
 which has the object dtype:


>>> s = pd.Series(['1', '2', '4.7', 'pandas', '10'])
>>> s
0         1
1         2
2       4.7
3    pandas
4        10
dtype: object



The default behaviour is to raise if it can't convert a value. In this case, it can't cope with the string 'pandas':


>>> pd.to_numeric(s) # or pd.to_numeric(s, errors='raise')
ValueError: Unable to parse string



Rather than fail, we might want 'pandas' to be considered a missing/bad numeric value. We can coerce invalid values to 
NaN
 as follows using the 
errors
 keyword argument:


>>> pd.to_numeric(s, errors='coerce')
0     1.0
1     2.0
2     4.7
3     NaN
4    10.0
dtype: float64



The third option for 
errors
 is just to ignore the operation if an invalid value is encountered:


>>> pd.to_numeric(s, errors='ignore')
# the original Series is returned untouched



This last option is particularly useful for converting your entire DataFrame, but don't know which of our columns can be converted reliably to a numeric type. In that case, just write:


df.apply(pd.to_numeric, errors='ignore')



The function will be applied to each column of the DataFrame. Columns that can be converted to a numeric type will be converted, while columns that cannot (e.g. they contain non-digit strings or dates) will be left alone.


Downcasting


By default, conversion with 
to_numeric()
 will give you either an 
int64
 or 
float64
 dtype (or whatever integer width is native to your platform).


That's usually what you want, but what if you wanted to save some memory and use a more compact dtype, like 
float32
, or 
int8
?


to_numeric()
 gives you the option to downcast to either 
'integer'
, 
'signed'
, 
'unsigned'
, 
'float'
. Here's an example for a simple series 
s
 of integer type:


>>> s = pd.Series([1, 2, -7])
>>> s
0    1
1    2
2   -7
dtype: int64



Downcasting to 
'integer'
 uses the smallest possible integer that can hold the values:


>>> pd.to_numeric(s, downcast='integer')
0    1
1    2
2   -7
dtype: int8



Downcasting to 
'float'
 similarly picks a smaller than normal floating type:


>>> pd.to_numeric(s, downcast='float')
0    1.0
1    2.0
2   -7.0
dtype: float32





2. 
astype()


The 
astype()
 method enables you to be explicit about the dtype you want your DataFrame or Series to have. It's very versatile in that you can try and go from one type to any other.


Basic usage


Just pick a type: you can use a NumPy dtype (e.g. 
np.int16
), some Python types (e.g. bool), or pandas-specific types (like the categorical dtype).


Call the method on the object you want to convert and 
astype()
 will try and convert it for you:


# convert all DataFrame columns to the int64 dtype
df = df.astype(int)

# convert column ""a"" to int64 dtype and ""b"" to complex type
df = df.astype({""a"": int, ""b"": complex})

# convert Series to float16 type
s = s.astype(np.float16)

# convert Series to Python strings
s = s.astype(str)

# convert Series to categorical type - see docs for more details
s = s.astype('category')



Notice I said ""try"" - if 
astype()
 does not know how to convert a value in the Series or DataFrame, it will raise an error. For example, if you have a 
NaN
 or 
inf
 value you'll get an error trying to convert it to an integer.


As of pandas 0.20.0, this error can be suppressed by passing 
errors='ignore'
. Your original object will be returned untouched.


Be careful


astype()
 is powerful, but it will sometimes convert values ""incorrectly"". For example:


>>> s = pd.Series([1, 2, -7])
>>> s
0    1
1    2
2   -7
dtype: int64



These are small integers, so how about converting to an unsigned 8-bit type to save memory?


>>> s.astype(np.uint8)
0      1
1      2
2    249
dtype: uint8



The conversion worked, but the -7 was wrapped round to become 249 (i.e. 2
8
 - 7)!


Trying to downcast using 
pd.to_numeric(s, downcast='unsigned')
 instead could help prevent this error.




3. 
infer_objects()


Version 0.21.0 of pandas introduced the method 
infer_objects()
 for converting columns of a DataFrame that have an object datatype to a more specific type (soft conversions).


For example, here's a DataFrame with two columns of object type. One holds actual integers and the other holds strings representing integers:


>>> df = pd.DataFrame({'a': [7, 1, 5], 'b': ['3','2','1']}, dtype='object')
>>> df.dtypes
a    object
b    object
dtype: object



Using 
infer_objects()
, you can change the type of column 'a' to int64:


>>> df = df.infer_objects()
>>> df.dtypes
a     int64
b    object
dtype: object



Column 'b' has been left alone since its values were strings, not integers. If you wanted to force both columns to an integer type, you could use 
df.astype(int)
 instead.




4. 
convert_dtypes()


Version 1.0 and above includes a method 
convert_dtypes()
 to convert Series and DataFrame columns to the best possible dtype that supports the 
pd.NA
 missing value.


Here ""best possible"" means the type most suited to hold the values. For example, this a pandas integer type, if all of the values are integers (or missing values): an object column of Python integer objects are converted to 
Int64
, a column of NumPy 
int32
 values, will become the pandas dtype 
Int32
.


With our 
object
 DataFrame 
df
, we get the following result:


>>> df.convert_dtypes().dtypes                                             
a     Int64
b    string
dtype: object



Since column 'a' held integer values, it was converted to the 
Int64
 type (which is capable of holding missing values, unlike 
int64
).


Column 'b' contained string objects, so was changed to pandas' 
string
 dtype.


By default, this method will infer the type from object values in each column. We can change this by passing 
infer_objects=False
:


>>> df.convert_dtypes(infer_objects=False).dtypes                          
a    object
b    string
dtype: object



Now column 'a' remained an object column: pandas knows it can be described as an 'integer' column (internally it ran 
infer_dtype
) but didn't infer exactly what dtype of integer it should have so did not convert it. Column 'b' was again converted to 'string' dtype as it was recognised as holding 'string' values.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] 4.8. Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data.\n\n[2] Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object.\n\n[3] Length modifier (optional). 7. Conversion type. When the right argument is a dictionary (or other mapping type), then the formats in the string must include a\nparenthesised mapping key into that dictionary inserted immediately after the \'%\' character. The mapping key\nselects the value to be formatted from the mapping. For example:\n>>> print(\'%(language)s has %(number)03d quote types.\' %\n...\n{\'language\': ""Python"", ""number"": 2})\nPython has 002 quote types. In this case no * specifiers may occur in a format (since they require a sequential parameter list). The conversion flag characters are:\n5 To format only a tuple you should therefore provide a singleton tuple whose only element is the tuple to be formatted. 4.8. Text Sequence Type — str\n61\n\nThe Python Library Reference, Release 3.13.2\nFlag\nMeaning\n\'#\'\nThe value conversion will use the “alternate form” (where defined below). \'0\'\nThe conversion will be zero padded for numeric values. \'-\'\nThe converted value is left adjusted (overrides the \'0\' conversion if both are given).\n\' \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes.')",4.4819887453208826e-79,0.11046364327337219,0.267437690001575,0.5200167298316956,0.33814862
Catch and print full Python exception traceback without halting/exiting the program,"Some other answer have already pointed out the 
traceback
 module.


Please notice that with 
print_exc
, in some corner cases, you will not obtain what you would expect. In Python 2.x:


import traceback

try:
    raise TypeError(""Oups!"")
except Exception, err:
    try:
        raise TypeError(""Again !?!"")
    except:
        pass

    traceback.print_exc()



...will display the traceback of the 
last
 exception:


Traceback (most recent call last):
  File ""e.py"", line 7, in 

    raise TypeError(""Again !?!"")
TypeError: Again !?!



If you really need to access the original 
traceback
 one solution is to cache the 
exception infos
 as returned from 
exc_info
 in a local variable and display it using 
print_exception
:


import traceback
import sys

try:
    raise TypeError(""Oups!"")
except Exception, err:
    try:
        exc_info = sys.exc_info()

        # do you usefull stuff here
        # (potentially raising an exception)
        try:
            raise TypeError(""Again !?!"")
        except:
            pass
        # end of useful stuff


    finally:
        # Display the *original* exception
        traceback.print_exception(*exc_info)
        del exc_info



Producing:


Traceback (most recent call last):
  File ""t.py"", line 6, in 

    raise TypeError(""Oups!"")
TypeError: Oups!



Few pitfalls with this though:




From the doc of 
sys_info
:




Assigning the traceback return value to a local variable in a function that is handling an exception will cause a 
circular reference
. This will prevent anything referenced by a local variable in the same function or by the traceback from being garbage collected. [...] 
If you do need the traceback, make sure to delete it after use
 (best done with a try ... finally statement)




but, from the same doc:




Beginning with Python 2.2, such cycles are automatically reclaimed
 when garbage collection is enabled and they become unreachable, but it remains more efficient to avoid creating cycles.








On the other hand, by allowing you to access the traceback 
associated with
 an exception, Python 3 produce a less surprising result:


import traceback

try:
    raise TypeError(""Oups!"")
except Exception as err:
    try:
        raise TypeError(""Again !?!"")
    except:
        pass

    traceback.print_tb(err.__traceback__)



... will display:


  File ""e3.py"", line 4, in 

    raise TypeError(""Oups!"")


","('Answer: You can use the `traceback` module to print or retrieve stack traces of Python programs. Specifically, `traceback.print_exc()` is a shorthand for `traceback.print_exception(sys.exception(), limit=limit, file=file, chain=chain)` which prints exception information and stack trace entries to a specified file (or `sys.stderr` if no file is specified).\n\nReferences: [1]\n', '[1] 30.11 traceback — Print or retrieve a stack traceback\nSource code: Lib/traceback.py\nThis module provides a standard interface to extract, format and print stack traces of Python programs. It is more\nflexible than the interpreter’s default traceback display, and therefore makes it possible to configure certain aspects of\nthe output. Finally, it contains a utility for capturing enough information about an exception to print it later, without\nthe need to save a reference to the actual exception. Since exceptions can be the roots of large objects graph, this\nutility can significantly improve memory management. The module uses traceback objects — these are objects of type types.TracebackType, which are assigned to the\n__traceback__ field of BaseException instances. µ See also\nModule faulthandler\nUsed to dump Python tracebacks explicitly, on a fault, after a timeout, or on a user signal. Module pdb\nInteractive source code debugger for Python programs. The module’s API can be divided into two parts:\n• Module-level functions offering basic functionality, which are useful for interactive inspection of exceptions\nand tracebacks. • TracebackException class and its helper classes StackSummary and FrameSummary. These offer both\nmore flexibility in the output generated and the ability to store the information necessary for later formatting\nwithout holding references to actual exception and traceback objects. 30.11.1 Module-Level Functions\ntraceback.print_tb(tb, limit=None, file=None)\nPrint up to limit stack trace entries from traceback object tb (starting from the caller’s frame) if limit is positive. Otherwise, print the last abs(limit) entries. If limit is omitted or None, all entries are printed. If file is\nomitted or None, the output goes to sys.stderr; otherwise it should be an open file or file-like object to\nreceive the output. ® Note\nThe meaning of the limit parameter is different than the meaning of sys.tracebacklimit. A negative\nlimit value corresponds to a positive value of sys.tracebacklimit, whereas the behaviour of a positive\nlimit value cannot be achieved with sys.tracebacklimit. Changed in version 3.5: Added negative limit support. 1986\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\ntraceback.print_exception(exc, /, [value, tb, ]limit=None, file=None, chain=True)\nPrint exception information and stack trace entries from traceback object tb to file. This differs from\nprint_tb() in the following ways:\n• if tb is not None, it prints a header Traceback (most recent call last):\n• it prints the exception type and value after the stack trace\n• if type(value) is SyntaxError and value has the appropriate format, it prints the line where the syntax\nerror occurred with a caret indicating the approximate position of the error. Since Python 3.10, instead of passing value and tb, an exception object can be passed as the first argument. If\nvalue and tb are provided, the first argument is ignored in order to provide backwards compatibility. The optional limit argument has the same meaning as for print_tb(). If chain is true (the default), then\nchained exceptions (the __cause__ or __context__ attributes of the exception) will be printed as well, like\nthe interpreter itself does when printing an unhandled exception. Changed in version 3.5: The etype argument is ignored and inferred from the type of value. Changed in version 3.10: The etype parameter has been renamed to exc and is now positional-only. traceback.print_exc(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.exception(), limit=limit, file=file,\nchain=chain). traceback.print_last(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.last_exc, limit=limit, file=file,\nchain=chain). In general it will work only after an exception has reached an interactive prompt\n(see sys.last_exc). traceback.print_stack(f=None, limit=None, file=None)\nPrint up to limit stack trace entries (starting from the invocation point) if limit is positive. Otherwise, print\nthe last abs(limit) entries. If limit is omitted or None, all entries are printed. The optional f argument can\nbe used to specify an alternate stack frame to start. The optional file argument has the same meaning as for\nprint_tb(). Changed in version 3.5: Added negative limit support. traceback.extract_tb(tb, limit=None)\nReturn a StackSummary object representing a list of “pre-processed” stack trace entries extracted from the\ntraceback object tb. It is useful for alternate formatting of stack traces. The optional limit argument has the\nsame meaning as for print_tb(). A “pre-processed” stack trace entry is a FrameSummary object containing\nattributes filename, lineno, name, and line representing the information that is usually printed for a stack\ntrace. traceback.extract_stack(f=None, limit=None)\nExtract the raw traceback from the current stack frame. The return value has the same format as for\nextract_tb(). The optional f and limit arguments have the same meaning as for print_stack(). traceback.print_list(extracted_list, file=None)\nPrint the list of tuples as returned by extract_tb() or extract_stack() as a formatted stack trace to the\ngiven file. If file is None, the output is written to sys.stderr. traceback.format_list(extracted_list)\nGiven a list of tuples or FrameSummary objects as returned by extract_tb() or extract_stack(), return\na list of strings ready for printing. Each string in the resulting list corresponds to the item with the same index\nin the argument list. Each string ends in a newline; the strings may contain internal newlines as well, for those\nitems whose source text line is not None. 30.11. traceback — Print or retrieve a stack traceback\n1987\n\nThe Python Library Reference, Release 3.13.2\ntraceback.format_exception_only(exc, /, [value, ]*, show_group=False)\nFormat the exception part of a traceback using an exception value such as given by sys.last_value. The\nreturn value is a list of strings, each ending in a newline. The list contains the exception’s message, which is\nnormally a single string; however, for SyntaxError exceptions, it contains several lines that (when printed)\ndisplay detailed information about where the syntax error occurred. Following the message, the list contains\nthe exception’s notes.\n\n[2] This only works with functions that can be called without arguments. 30.11 traceback — Print or retrieve a stack traceback\nSource code: Lib/traceback.py\nThis module provides a standard interface to extract, format and print stack traces of Python programs. It is more\nflexible than the interpreter’s default traceback display, and therefore makes it possible to configure certain aspects of\nthe output. Finally, it contains a utility for capturing enough information about an exception to print it later, without\nthe need to save a reference to the actual exception. Since exceptions can be the roots of large objects graph, this\nutility can significantly improve memory management. The module uses traceback objects — these are objects of type types.TracebackType, which are assigned to the\n__traceback__ field of BaseException instances. µ See also\nModule faulthandler\nUsed to dump Python tracebacks explicitly, on a fault, after a timeout, or on a user signal. Module pdb\nInteractive source code debugger for Python programs. The module’s API can be divided into two parts:\n• Module-level functions offering basic functionality, which are useful for interactive inspection of exceptions\nand tracebacks. • TracebackException class and its helper classes StackSummary and FrameSummary. These offer both\nmore flexibility in the output generated and the ability to store the information necessary for later formatting\nwithout holding references to actual exception and traceback objects. 30.11.1 Module-Level Functions\ntraceback.print_tb(tb, limit=None, file=None)\nPrint up to limit stack trace entries from traceback object tb (starting from the caller’s frame) if limit is positive. Otherwise, print the last abs(limit) entries. If limit is omitted or None, all entries are printed. If file is\nomitted or None, the output goes to sys.stderr; otherwise it should be an open file or file-like object to\nreceive the output. ® Note\nThe meaning of the limit parameter is different than the meaning of sys.tracebacklimit. A negative\nlimit value corresponds to a positive value of sys.tracebacklimit, whereas the behaviour of a positive\nlimit value cannot be achieved with sys.tracebacklimit. Changed in version 3.5: Added negative limit support. 1986\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\ntraceback.print_exception(exc, /, [value, tb, ]limit=None, file=None, chain=True)\nPrint exception information and stack trace entries from traceback object tb to file. This differs from\nprint_tb() in the following ways:\n• if tb is not None, it prints a header Traceback (most recent call last):\n• it prints the exception type and value after the stack trace\n• if type(value) is SyntaxError and value has the appropriate format, it prints the line where the syntax\nerror occurred with a caret indicating the approximate position of the error. Since Python 3.10, instead of passing value and tb, an exception object can be passed as the first argument. If\nvalue and tb are provided, the first argument is ignored in order to provide backwards compatibility. The optional limit argument has the same meaning as for print_tb(). If chain is true (the default), then\nchained exceptions (the __cause__ or __context__ attributes of the exception) will be printed as well, like\nthe interpreter itself does when printing an unhandled exception. Changed in version 3.5: The etype argument is ignored and inferred from the type of value. Changed in version 3.10: The etype parameter has been renamed to exc and is now positional-only. traceback.print_exc(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.exception(), limit=limit, file=file,\nchain=chain). traceback.print_last(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.last_exc, limit=limit, file=file,\nchain=chain). In general it will work only after an exception has reached an interactive prompt\n(see sys.last_exc). traceback.print_stack(f=None, limit=None, file=None)\nPrint up to limit stack trace entries (starting from the invocation point) if limit is positive. Otherwise, print\nthe last abs(limit) entries. If limit is omitted or None, all entries are printed. The optional f argument can\nbe used to specify an alternate stack frame to start. The optional file argument has the same meaning as for\nprint_tb(). Changed in version 3.5: Added negative limit support. traceback.extract_tb(tb, limit=None)\nReturn a StackSummary object representing a list of “pre-processed” stack trace entries extracted from the\ntraceback object tb. It is useful for alternate formatting of stack traces. The optional limit argument has the\nsame meaning as for print_tb(). A “pre-processed” stack trace entry is a FrameSummary object containing\nattributes filename, lineno, name, and line representing the information that is usually printed for a stack\ntrace. traceback.extract_stack(f=None, limit=None)\nExtract the raw traceback from the current stack frame. The return value has the same format as for\nextract_tb(). The optional f and limit arguments have the same meaning as for print_stack(). traceback.print_list(extracted_list, file=None)\nPrint the list of tuples as returned by extract_tb() or extract_stack() as a formatted stack trace to the\ngiven file. If file is None, the output is written to sys.stderr. traceback.format_list(extracted_list)\nGiven a list of tuples or FrameSummary objects as returned by extract_tb() or extract_stack(), return\na list of strings ready for printing. Each string in the resulting list corresponds to the item with the same index\nin the argument list. Each string ends in a newline; the strings may contain internal newlines as well, for those\nitems whose source text line is not None. 30.11. traceback — Print or retrieve a stack traceback\n1987\n\nThe Python Library Reference, Release 3.13.2\ntraceback.format_exception_only(exc, /, [value, ]*, show_group=False)\nFormat the exception part of a traceback using an exception value such as given by sys.last_value. The\nreturn value is a list of strings, each ending in a newline. The list contains the exception’s message, which is\nnormally a single string; however, for SyntaxError exceptions, it contains several lines that (when printed)\ndisplay detailed information about where the syntax error occurred.\n\n[3] It is more\nflexible than the interpreter’s default traceback display, and therefore makes it possible to configure certain aspects of\nthe output. Finally, it contains a utility for capturing enough information about an exception to print it later, without\nthe need to save a reference to the actual exception. Since exceptions can be the roots of large objects graph, this\nutility can significantly improve memory management. The module uses traceback objects — these are objects of type types.TracebackType, which are assigned to the\n__traceback__ field of BaseException instances. µ See also\nModule faulthandler\nUsed to dump Python tracebacks explicitly, on a fault, after a timeout, or on a user signal. Module pdb\nInteractive source code debugger for Python programs. The module’s API can be divided into two parts:\n• Module-level functions offering basic functionality, which are useful for interactive inspection of exceptions\nand tracebacks. • TracebackException class and its helper classes StackSummary and FrameSummary. These offer both\nmore flexibility in the output generated and the ability to store the information necessary for later formatting\nwithout holding references to actual exception and traceback objects. 30.11.1 Module-Level Functions\ntraceback.print_tb(tb, limit=None, file=None)\nPrint up to limit stack trace entries from traceback object tb (starting from the caller’s frame) if limit is positive. Otherwise, print the last abs(limit) entries. If limit is omitted or None, all entries are printed. If file is\nomitted or None, the output goes to sys.stderr; otherwise it should be an open file or file-like object to\nreceive the output. ® Note\nThe meaning of the limit parameter is different than the meaning of sys.tracebacklimit. A negative\nlimit value corresponds to a positive value of sys.tracebacklimit, whereas the behaviour of a positive\nlimit value cannot be achieved with sys.tracebacklimit. Changed in version 3.5: Added negative limit support. 1986\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\ntraceback.print_exception(exc, /, [value, tb, ]limit=None, file=None, chain=True)\nPrint exception information and stack trace entries from traceback object tb to file. This differs from\nprint_tb() in the following ways:\n• if tb is not None, it prints a header Traceback (most recent call last):\n• it prints the exception type and value after the stack trace\n• if type(value) is SyntaxError and value has the appropriate format, it prints the line where the syntax\nerror occurred with a caret indicating the approximate position of the error. Since Python 3.10, instead of passing value and tb, an exception object can be passed as the first argument. If\nvalue and tb are provided, the first argument is ignored in order to provide backwards compatibility. The optional limit argument has the same meaning as for print_tb(). If chain is true (the default), then\nchained exceptions (the __cause__ or __context__ attributes of the exception) will be printed as well, like\nthe interpreter itself does when printing an unhandled exception. Changed in version 3.5: The etype argument is ignored and inferred from the type of value. Changed in version 3.10: The etype parameter has been renamed to exc and is now positional-only. traceback.print_exc(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.exception(), limit=limit, file=file,\nchain=chain). traceback.print_last(limit=None, file=None, chain=True)\nThis\nis\na\nshorthand\nfor\nprint_exception(sys.last_exc, limit=limit, file=file,\nchain=chain). In general it will work only after an exception has reached an interactive prompt\n(see sys.last_exc). traceback.print_stack(f=None, limit=None, file=None)\nPrint up to limit stack trace entries (starting from the invocation point) if limit is positive. Otherwise, print\nthe last abs(limit) entries. If limit is omitted or None, all entries are printed. The optional f argument can\nbe used to specify an alternate stack frame to start. The optional file argument has the same meaning as for\nprint_tb(). Changed in version 3.5: Added negative limit support. traceback.extract_tb(tb, limit=None)\nReturn a StackSummary object representing a list of “pre-processed” stack trace entries extracted from the\ntraceback object tb. It is useful for alternate formatting of stack traces. The optional limit argument has the\nsame meaning as for print_tb(). A “pre-processed” stack trace entry is a FrameSummary object containing\nattributes filename, lineno, name, and line representing the information that is usually printed for a stack\ntrace. traceback.extract_stack(f=None, limit=None)\nExtract the raw traceback from the current stack frame. The return value has the same format as for\nextract_tb(). The optional f and limit arguments have the same meaning as for print_stack(). traceback.print_list(extracted_list, file=None)\nPrint the list of tuples as returned by extract_tb() or extract_stack() as a formatted stack trace to the\ngiven file. If file is None, the output is written to sys.stderr. traceback.format_list(extracted_list)\nGiven a list of tuples or FrameSummary objects as returned by extract_tb() or extract_stack(), return\na list of strings ready for printing. Each string in the resulting list corresponds to the item with the same index\nin the argument list. Each string ends in a newline; the strings may contain internal newlines as well, for those\nitems whose source text line is not None. 30.11. traceback — Print or retrieve a stack traceback\n1987\n\nThe Python Library Reference, Release 3.13.2\ntraceback.format_exception_only(exc, /, [value, ]*, show_group=False)\nFormat the exception part of a traceback using an exception value such as given by sys.last_value. The\nreturn value is a list of strings, each ending in a newline. The list contains the exception’s message, which is\nnormally a single string; however, for SyntaxError exceptions, it contains several lines that (when printed)\ndisplay detailed information about where the syntax error occurred. Following the message, the list contains\nthe exception’s notes. Since Python 3.10, instead of passing value, an exception object can be passed as the first argument.')",0.004634772873953073,0.06721731700370266,0.18096238428507871,0.5746269226074219,0.73320043
What are the differences between type() and isinstance()?,"To summarize the contents of other (already good!) answers, 
isinstance
 caters for inheritance (an instance of a derived class 
is an
 instance of a base class, too), while checking for equality of 
type
 does not (it demands identity of types and rejects instances of subtypes, AKA subclasses).


Normally, in Python, you want your code to support inheritance, of course (since inheritance is so handy, it would be bad to stop code using yours from using it!), so 
isinstance
 is less bad than checking identity of 
type
s because it seamlessly supports inheritance.


It's not that 
isinstance
 is 
good
, mind you—it's just 
less bad
 than checking equality of types.  The normal, Pythonic, preferred solution is almost invariably ""duck typing"": try using the argument 
as if
 it was of a certain desired type, do it in a 
try
/
except
 statement catching all exceptions that could arise if the argument was not in fact of that type (or any other type nicely duck-mimicking it;-), and in the 
except
 clause, try something else (using the argument ""as if"" it was of some other type).


basestring
 
is
, however, quite a special case—a builtin type that exists 
only
 to let you use 
isinstance
 (both 
str
 and 
unicode
 subclass 
basestring
). Strings are sequences (you could loop over them, index them, slice them, ...), but you generally want to treat them as ""scalar"" types—it's somewhat incovenient (but a reasonably frequent use case) to treat all kinds of strings (and maybe other scalar types, i.e., ones you can't loop on) one way, all containers (lists, sets, dicts, ...) in another way, and 
basestring
 plus 
isinstance
 helps you do that—the overall structure of this idiom is something like:


if isinstance(x, basestring)
  return treatasscalar(x)
try:
  return treatasiter(iter(x))
except TypeError:
  return treatasscalar(x)



You could say that 
basestring
 is an 
Abstract Base Class
 (""ABC"")—it offers no concrete functionality to subclasses, but rather exists as a ""marker"", mainly for use with 
isinstance
. The concept is obviously a growing one in Python, since 
PEP 3119
, which introduces a generalization of it, was accepted and has been implemented starting with Python 2.6 and 3.0.


The PEP makes it clear that, while ABCs can often substitute for duck typing, there is generally no big pressure to do that (see 
here
). ABCs as implemented in recent Python versions do however offer extra goodies: 
isinstance
 (and 
issubclass
) can now mean more than just ""[an instance of] a derived class"" (in particular, any class can be ""registered"" with an ABC so that it will show as a subclass, and its instances as instances of the ABC); and ABCs can also offer extra convenience to actual subclasses in a very natural way via Template Method design pattern applications (see 
here
 and 
here
 [[part II]] for more on the TM DP, in general and specifically in Python, independent of ABCs).


For the underlying mechanics of ABC support as offered in Python 2.6, see 
here
; for their 3.1 version, very similar, see 
here
.  In both versions, standard library module 
collections
 (that's the 3.1 version—for the very similar 2.6 version, see 
here
) offers several useful ABCs.


For the purpose of this answer, the key thing to retain about ABCs (beyond an arguably more natural placement for TM DP functionality, compared to the classic Python alternative of mixin classes such as 
UserDict.DictMixin
) is that they make 
isinstance
 (and 
issubclass
) much more attractive and pervasive (in Python 2.6 and going forward) than they used to be (in 2.5 and before), and therefore, by contrast, make checking type equality an even worse practice in recent Python versions than it already used to be.

","(""Answer: The built-in function `type()` accesses an object's type, while `isinstance(obj, cls)` checks if an object is an instance of a given class or a subclass of it. `isinstance()` can also check if an object is an instance of any number of classes by providing a tuple of classes. `isinstance()` also checks for virtual inheritance from an abstract base class.\n\nReferences: [2, 3]\n"", '[1] ""int\n| Foo"". union_object == other\nUnion objects can be tested for equality with other union objects. Details:\n4.13. Type Annotation Types — Generic Alias, Union\n97\n\nThe Python Library Reference, Release 3.13.2\n• Unions of unions are flattened:\n(int | str) | float == int | str | float\n• Redundant types are removed:\nint | str | int == int | str\n• When comparing unions, the order is ignored:\nint | str == str | int\n• It is compatible with typing.Union:\nint | str == typing.Union[int, str]\n• Optional types can be spelled as a union with None:\nstr | None == typing.Optional[str]\nisinstance(obj, union_object)\nissubclass(obj, union_object)\nCalls to isinstance() and issubclass() are also supported with a union object:\n>>> isinstance("""", int | str)\nTrue\nHowever, parameterized generics in union objects cannot be checked:\n>>> isinstance(1, int | list[int])\n# short-circuit evaluation\nTrue\n>>> isinstance([1], int | list[int])\nTraceback (most recent call last):\n...\nTypeError: isinstance() argument 2 cannot be a parameterized generic\nThe user-exposed type for the union object can be accessed from types.UnionType and used for isinstance()\nchecks. An object cannot be instantiated from the type:\n>>> import types\n>>> isinstance(int | str, types.UnionType)\nTrue\n>>> types.UnionType()\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: cannot create \'types.UnionType\' instances\n® Note\nThe __or__() method for type objects was added to support the syntax X | Y. If a metaclass implements\n__or__(), the Union may override it:\n>>> class M(type):\n...\ndef __or__(self, other):\n...\nreturn ""Hello""\n...\n>>> class C(metaclass=M):\n...\npass\n98\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n...\n>>> C | int\n\'Hello\'\n>>> int | C\nint | C\nµ See also\nPEP 604 – PEP proposing the X | Y syntax and the Union type. Added in version 3.10. 4.14 Other Built-in Types\nThe interpreter supports several other kinds of objects. Most of these support only one or two operations. 4.14.1 Modules\nThe only special operation on a module is attribute access: m.name, where m is a module and name accesses a name\ndefined in m’s symbol table. Module attributes can be assigned to. (Note that the import statement is not, strictly\nspeaking, an operation on a module object; import foo does not require a module object named foo to exist, rather\nit requires an (external) definition for a module named foo somewhere.) A special attribute of every module is __dict__. This is the dictionary containing the module’s symbol table. Modifying this dictionary will actually change the module’s symbol table, but direct assignment to the __dict__\nattribute is not possible (you can write m.__dict__[\'a\'] = 1, which defines m.a to be 1, but you can’t write\nm.__dict__ = {}). Modifying __dict__ directly is not recommended. Modules built into the interpreter are written like this: <module \'sys\' (built-in)>. If loaded from a file, they\nare written as <module \'os\' from \'/usr/local/lib/pythonX.Y/os.pyc\'>. 4.14.2 Classes and Class Instances\nSee objects and class for these. 4.14.3 Functions\nFunction objects are created by function definitions. The only operation on a function object is to call it:\nfunc(argument-list). There are really two flavors of function objects: built-in functions and user-defined functions. Both support the same\noperation (to call the function), but the implementation is different, hence the different object types. See function for more information. 4.14.4 Methods\nMethods are functions that are called using the attribute notation. There are two flavors: built-in methods (such as\nappend() on lists) and class instance method. Built-in methods are described with the types that support them. If you access a method (a function defined in a class namespace) through an instance, you get a special object: a\nbound method (also called instance method) object. When called, it will add the self argument to the argument list. Bound methods have two special read-only attributes: m.__self__ is the object on which the method operates, and\nm.__func__ is the function implementing the method. Calling m(arg-1, arg-2, ..., arg-n) is completely\nequivalent to calling m.__func__(m.__self__, arg-1, arg-2, ..., arg-n). Like function objects, bound method objects support getting arbitrary attributes. However, since method attributes are\nactually stored on the underlying function object (method.__func__), setting method attributes on bound methods\n4.14. Other Built-in Types\n99\n\nThe Python Library Reference, Release 3.13.2\nis disallowed. Attempting to set an attribute on a method results in an AttributeError being raised. In order to\nset a method attribute, you need to explicitly set it on the underlying function object:\n>>> class C:\n...\ndef method(self):\n...\npass\n...\n>>> c = C()\n>>> c.method.whoami = \'my name is method\'\n# can\'t set on the method\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nAttributeError: \'method\' object has no attribute \'whoami\'\n>>> c.method.__func__.whoami = \'my name is method\'\n>>> c.method.whoami\n\'my name is method\'\nSee instance-methods for more information. 4.14.5 Code Objects\nCode objects are used by the implementation to represent “pseudo-compiled” executable Python code such as a\nfunction body. They differ from function objects because they don’t contain a reference to their global execution\nenvironment. Code objects are returned by the built-in compile() function and can be extracted from function\nobjects through their __code__ attribute. See also the code module. Accessing __code__ raises an auditing event object.__getattr__ with arguments obj and ""__code__"". A code object can be executed or evaluated by passing it (instead of a source string) to the exec() or eval()\nbuilt-in functions. See types for more information. 4.14.6 Type Objects\nType objects represent the various object types. An object’s type is accessed by the built-in function type(). There\nare no special operations on types. The standard module types defines names for all standard built-in types. Types are written like this: <class \'int\'>. 4.14.7 The Null Object\nThis object is returned by functions that don’t explicitly return a value. It supports no special operations.\n\n[2] 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it? Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a num-\nber of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, .. . )), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or\nisinstance(obj, (int, float, complex)). Note that isinstance() also checks for virtual inheritance from an abstract base class. So, the test will return\nTrue for a registered class even if hasn’t directly or indirectly inherited from it. To test for “true inheritance”, scan\nthe MRO of the class:\nfrom collections.abc import Mapping\nclass P:\npass\nclass C(P):\npass\nMapping.register(P)\n>>> c = C()\n>>> isinstance(c, C)\n# direct\nTrue\n>>> isinstance(c, P)\n# indirect\nTrue\n>>> isinstance(c, Mapping)\n# virtual\nTrue\n# Actual inheritance chain\n>>> type(c).__mro__\n(<class \'C\'>, <class \'P\'>, <class \'object\'>)\n# Test for ""true inheritance""\n>>> Mapping in type(c).__mro__\nFalse\nNote that most programs do not use isinstance() on user-defined classes very often. If you are developing the\nclasses yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular\nbehaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if\nyou have a function that does something:\n2.6. Objects\n27\n\nPython Frequently Asked Questions, Release 3.13.2\ndef search(obj):\nif isinstance(obj, Mailbox):\n...\n# code to search a mailbox\nelif isinstance(obj, Document):\n...\n# code to search a document\nelif ...\nA better approach is to define a search() method on all the classes and just call it:\nclass Mailbox:\ndef search(self):\n...\n# code to search a mailbox\nclass Document:\ndef search(self):\n...\n# code to search a document\nobj.search()\n2.6.5 What is delegation? Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to\nchange the behaviour of just one of its methods. You can create a new class that provides a new implementation of\nthe method you’re interested in changing and delegates all other methods to the corresponding method of x.\nPython programmers can easily implement delegation. For example, the following class implements a class that\nbehaves like a file but converts all written data to uppercase:\nclass UpperOut:\ndef __init__(self, outfile):\nself._outfile = outfile\ndef write(self, s):\nself._outfile.write(s.upper())\ndef __getattr__(self, name):\nreturn getattr(self._outfile, name)\nHere the UpperOut class redefines the write() method to convert the argument string to uppercase before call-\ning the underlying self._outfile.write() method. All other methods are delegated to the underlying self. _outfile object. The delegation is accomplished via the __getattr__() method; consult the language reference\nfor more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved,\nthe class must define a __setattr__() method too, and it must do so carefully. The basic implementation of\n__setattr__() is roughly equivalent to the following:\nclass X:\n...\ndef __setattr__(self, name, value):\nself.__dict__[name] = value\n... Many __setattr__() implementations call object.__setattr__() to set an attribute on self without causing\ninfinite recursion:\n28\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nclass X:\ndef __setattr__(self, name, value):\n# Custom logic here...\nobject.__setattr__(self, name, value)\nAlternatively, it is possible to set attributes by inserting entries into self.__dict__ directly. 2.6.6 How do I call a method defined in a base class from a derived class that\nextends it? Use the built-in super() function:\nclass Derived(Base):\ndef meth(self):\nsuper().meth()\n# calls Base.meth\nIn the example, super() will automatically determine the instance from which it was called (the self value), look\nup the method resolution order (MRO) with type(self).__mro__, and return the next in line after Derived in\nthe MRO: Base. 2.6.7 How can I organize my code to make it easier to change the base class? You could assign the base class to an alias and derive from the alias. Then all you have to change is the value assigned\nto the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of\nresources) which base class to use. Example:\nclass Base:\n...\nBaseAlias = Base\nclass Derived(BaseAlias):\n...\n2.6.8 How do I create static class data and static class methods? Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the\nclass name in the assignment:\nclass C:\ncount = 0\n# number of times C.__init__ called\ndef __init__(self):\nC.count = C.count + 1\ndef getcount(self):\nreturn C.count\n# or return self.count\nc.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by\nsome class on the base-class search path from c.__class__ back to C.\nCaution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named\n“count” in self’s own dict. Rebinding of a class-static data name must always specify the class whether inside a\nmethod or not:\nC.count = 314\n2.6. Objects\n29\n\nPython Frequently Asked Questions, Release 3.13.2\nStatic methods are possible:\nclass C:\n@staticmethod\ndef static(arg1, arg2, arg3):\n# No \'self\' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function:\ndef getcount():\nreturn C.count\nIf your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the\ndesired encapsulation. 2.6.9 How can I overload constructors (or methods) in Python? This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write\nclass C {\nC() { cout << ""No arguments\\n""; }\nC(int i) { cout << ""Argument is "" << i << ""\\n""; }\n}\nIn Python you have to write a single constructor that catches all cases using default arguments. For example:\nclass C:\ndef __init__(self, i=None):\nif i is None:\nprint(""No arguments"")\nelse:\nprint(""Argument is"", i)\nThis is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args):\n... The same approach works for all method definitions. 2.6.10 I try to use __spam and I get an error about _SomeClassName__spam. Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class\nprivate variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing under-\nscore) is textually replaced with _classname__spam, where classname is the current class name with any leading\nunderscores stripped. The identifier can be used unchanged within the class, but to access it outside the class, the mangled name must be\nused:\nclass A:\ndef __one(self):\nreturn 1\ndef two(self):\nreturn 2 * self.__one()\n(continues on next page)\n30\nChapter 2.\n\n[3] You can check if an object is an instance of any of a num-\nber of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, .. . )), and can also check whether an object is one of Python’s built-in types, e.g. isinstance(obj, str) or\nisinstance(obj, (int, float, complex)). Note that isinstance() also checks for virtual inheritance from an abstract base class. So, the test will return\nTrue for a registered class even if hasn’t directly or indirectly inherited from it. To test for “true inheritance”, scan\nthe MRO of the class:\nfrom collections.abc import Mapping\nclass P:\npass\nclass C(P):\npass\nMapping.register(P)\n>>> c = C()\n>>> isinstance(c, C)\n# direct\nTrue\n>>> isinstance(c, P)\n# indirect\nTrue\n>>> isinstance(c, Mapping)\n# virtual\nTrue\n# Actual inheritance chain\n>>> type(c).__mro__\n(<class \'C\'>, <class \'P\'>, <class \'object\'>)\n# Test for ""true inheritance""\n>>> Mapping in type(c).__mro__\nFalse\nNote that most programs do not use isinstance() on user-defined classes very often. If you are developing the\nclasses yourself, a more proper object-oriented style is to define methods on the classes that encapsulate a particular\nbehaviour, instead of checking the object’s class and doing a different thing based on what class it is. For example, if\nyou have a function that does something:\n2.6. Objects\n27\n\nPython Frequently Asked Questions, Release 3.13.2\ndef search(obj):\nif isinstance(obj, Mailbox):\n...\n# code to search a mailbox\nelif isinstance(obj, Document):\n...\n# code to search a document\nelif ...\nA better approach is to define a search() method on all the classes and just call it:\nclass Mailbox:\ndef search(self):\n...\n# code to search a mailbox\nclass Document:\ndef search(self):\n...\n# code to search a document\nobj.search()\n2.6.5 What is delegation? Delegation is an object oriented technique (also called a design pattern). Let’s say you have an object x and want to\nchange the behaviour of just one of its methods. You can create a new class that provides a new implementation of\nthe method you’re interested in changing and delegates all other methods to the corresponding method of x.\nPython programmers can easily implement delegation. For example, the following class implements a class that\nbehaves like a file but converts all written data to uppercase:\nclass UpperOut:\ndef __init__(self, outfile):\nself._outfile = outfile\ndef write(self, s):\nself._outfile.write(s.upper())\ndef __getattr__(self, name):\nreturn getattr(self._outfile, name)\nHere the UpperOut class redefines the write() method to convert the argument string to uppercase before call-\ning the underlying self._outfile.write() method. All other methods are delegated to the underlying self. _outfile object. The delegation is accomplished via the __getattr__() method; consult the language reference\nfor more information about controlling attribute access. Note that for more general cases delegation can get trickier. When attributes must be set as well as retrieved,\nthe class must define a __setattr__() method too, and it must do so carefully. The basic implementation of\n__setattr__() is roughly equivalent to the following:\nclass X:\n...\ndef __setattr__(self, name, value):\nself.__dict__[name] = value\n... Many __setattr__() implementations call object.__setattr__() to set an attribute on self without causing\ninfinite recursion:\n28\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nclass X:\ndef __setattr__(self, name, value):\n# Custom logic here...\nobject.__setattr__(self, name, value)\nAlternatively, it is possible to set attributes by inserting entries into self.__dict__ directly. 2.6.6 How do I call a method defined in a base class from a derived class that\nextends it? Use the built-in super() function:\nclass Derived(Base):\ndef meth(self):\nsuper().meth()\n# calls Base.meth\nIn the example, super() will automatically determine the instance from which it was called (the self value), look\nup the method resolution order (MRO) with type(self).__mro__, and return the next in line after Derived in\nthe MRO: Base. 2.6.7 How can I organize my code to make it easier to change the base class? You could assign the base class to an alias and derive from the alias. Then all you have to change is the value assigned\nto the alias. Incidentally, this trick is also handy if you want to decide dynamically (e.g. depending on availability of\nresources) which base class to use. Example:\nclass Base:\n...\nBaseAlias = Base\nclass Derived(BaseAlias):\n...\n2.6.8 How do I create static class data and static class methods? Both static data and static methods (in the sense of C++ or Java) are supported in Python. For static data, simply define a class attribute. To assign a new value to the attribute, you have to explicitly use the\nclass name in the assignment:\nclass C:\ncount = 0\n# number of times C.__init__ called\ndef __init__(self):\nC.count = C.count + 1\ndef getcount(self):\nreturn C.count\n# or return self.count\nc.count also refers to C.count for any c such that isinstance(c, C) holds, unless overridden by c itself or by\nsome class on the base-class search path from c.__class__ back to C.\nCaution: within a method of C, an assignment like self.count = 42 creates a new and unrelated instance named\n“count” in self’s own dict. Rebinding of a class-static data name must always specify the class whether inside a\nmethod or not:\nC.count = 314\n2.6. Objects\n29\n\nPython Frequently Asked Questions, Release 3.13.2\nStatic methods are possible:\nclass C:\n@staticmethod\ndef static(arg1, arg2, arg3):\n# No \'self\' parameter! ... However, a far more straightforward way to get the effect of a static method is via a simple module-level function:\ndef getcount():\nreturn C.count\nIf your code is structured so as to define one class (or tightly related class hierarchy) per module, this supplies the\ndesired encapsulation. 2.6.9 How can I overload constructors (or methods) in Python? This answer actually applies to all methods, but the question usually comes up first in the context of constructors. In C++ you’d write\nclass C {\nC() { cout << ""No arguments\\n""; }\nC(int i) { cout << ""Argument is "" << i << ""\\n""; }\n}\nIn Python you have to write a single constructor that catches all cases using default arguments. For example:\nclass C:\ndef __init__(self, i=None):\nif i is None:\nprint(""No arguments"")\nelse:\nprint(""Argument is"", i)\nThis is not entirely equivalent, but close enough in practice. You could also try a variable-length argument list, e.g. def __init__(self, *args):\n... The same approach works for all method definitions. 2.6.10 I try to use __spam and I get an error about _SomeClassName__spam. Variable names with double leading underscores are “mangled” to provide a simple but effective way to define class\nprivate variables. Any identifier of the form __spam (at least two leading underscores, at most one trailing under-\nscore) is textually replaced with _classname__spam, where classname is the current class name with any leading\nunderscores stripped. The identifier can be used unchanged within the class, but to access it outside the class, the mangled name must be\nused:\nclass A:\ndef __one(self):\nreturn 1\ndef two(self):\nreturn 2 * self.__one()\n(continues on next page)\n30\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nclass B(A):\ndef three(self):\nreturn 3 * self._A__one()\nfour = 4 * A()._A__one()\nIn particular, this does not guarantee privacy since an outside user can still deliberately access the private attribute;\nmany Python programmers never bother to use private variable names at all. µ See also\nThe private name mangling specifications for details and special cases.')",0.006259447832197743,0.08104395604395605,0.2622313134875539,0.5567682385444641,0.6848788
How do I sort a dictionary by key?,"

Note:
 for Python 3.7+, see 
this answer




Standard Python dictionaries are unordered (until Python 3.7). Even if you sorted the (key,value) pairs, you wouldn't be able to store them in a 
dict
 in a way that would preserve the ordering.


The easiest way is to use 
OrderedDict
, which remembers the order in which the elements have been inserted:


In [1]: import collections

In [2]: d = {2:3, 1:89, 4:5, 3:0}

In [3]: od = collections.OrderedDict(sorted(d.items()))

In [4]: od
Out[4]: OrderedDict([(1, 89), (2, 3), (3, 0), (4, 5)])



Never mind the way 
od
 is printed out; it'll work as expected:


In [11]: od[1]
Out[11]: 89

In [12]: od[3]
Out[12]: 0

In [13]: for k, v in od.iteritems(): print k, v
   ....: 
1 89
2 3
3 0
4 5



Python 3


For Python 3 users, one needs to use the 
.items()
 instead of 
.iteritems()
:


In [13]: for k, v in od.items(): print(k, v)
   ....: 
1 89
2 3
3 0
4 5


","('Answer: You can sort a dictionary by key using the `sorted()` function, which accepts any iterable, including dictionaries.\n\nReferences: [1, 3]\n', '[1] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys. For example:\n>>> student_tuples = [\n...\n(\'john\', \'A\', 15),\n...\n(\'jane\', \'B\', 12),\n...\n(\'dave\', \'B\', 10),\n... ]\n>>> sorted(student_tuples, key=lambda student: student[2])\n# sort by age\n[(\'dave\', \'B\', 10), (\'jane\', \'B\', 12), (\'john\', \'A\', 15)]\nThe same technique works for objects with named attributes.\n\n[2] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord. A common pattern is to sort complex objects using some of the object’s indices as keys.\n\n[3] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion). Usually it’s less convenient than sorted() - but if you don’t need the original list, it’s slightly more efficient. 1\n\n>>> a = [5, 2, 3, 1, 4]\n>>> a.sort()\n>>> a\n[1, 2, 3, 4, 5]\nAnother difference is that the list.sort() method is only defined for lists. In contrast, the sorted() function\naccepts any iterable. >>> sorted({1: \'D\', 2: \'B\', 3: \'B\', 4: \'E\', 5: \'A\'})\n[1, 2, 3, 4, 5]\n2 Key Functions\nBoth list.sort() and sorted() have a key parameter to specify a function (or other callable) to be called on\neach list element prior to making comparisons. For example, here’s a case-insensitive string comparison:\n>>> sorted(""This is a test string from Andrew"".split(), key=str.casefold)\n[\'a\', \'Andrew\', \'from\', \'is\', \'string\', \'test\', \'This\']\nThe value of the key parameter should be a function (or other callable) that takes a single argument and returns a\nkey to use for sorting purposes. This technique is fast because the key function is called exactly once for each input\nrecord.')",1.8908863498399633e-155,0.08992023205221174,0.2347626085376617,0.5630778074264526,0.6286787
Is there a built-in function to print all the current properties and values of an object?,"You are really mixing together two different things.


Use 
dir()
, 
vars()
 or the 
inspect
 module to get what you are interested in (I use 
__builtins__
 as an example; you can use any object instead).


>>> l = dir(__builtins__)
>>> d = __builtins__.__dict__



Print that dictionary however fancy you like:


>>> print l
['ArithmeticError', 'AssertionError', 'AttributeError',...



or


>>> from pprint import pprint
>>> pprint(l)
['ArithmeticError',
 'AssertionError',
 'AttributeError',
 'BaseException',
 'DeprecationWarning',
...

>>> pprint(d, indent=2)
{ 'ArithmeticError': 
,
  'AssertionError': 
,
  'AttributeError': 
,
...
  '_': [ 'ArithmeticError',
         'AssertionError',
         'AttributeError',
         'BaseException',
         'DeprecationWarning',
...



Pretty printing is also available in the interactive debugger as a command:


(Pdb) pp vars()
{'__builtins__': {'ArithmeticError': 
,
                  'AssertionError': 
,
                  'AttributeError': 
,
                  'BaseException': 
,
                  'BufferError': 
,
                  ...
                  'zip': 
},
 '__file__': 'pass.py',
 '__name__': '__main__'}


","(""Answer: I'm sorry, I couldn't find relevant information in the provided context.\n\nReferences: None"", '[1] Example: print all descriptions of arguments:\n30.14. inspect — Inspect live objects\n2009\n\nThe Python Library Reference, Release 3.13.2\n>>> def foo(a, b, *, c, d=10):\n...\npass\n>>> sig = signature(foo)\n>>> for param in sig.parameters.values():\n...\nprint(param.kind.description)\npositional or keyword\npositional or keyword\nkeyword-only\nkeyword-only\nreplace(*[, name][, kind][, default][, annotation])\nCreate a new Parameter instance based on the instance replaced was invoked on. To override a\nParameter attribute, pass the corresponding argument. To remove a default value or/and an annotation\nfrom a Parameter, pass Parameter.empty. >>> from inspect import Parameter\n>>> param = Parameter(\'foo\', Parameter.KEYWORD_ONLY, default=42)\n>>> str(param)\n\'foo=42\'\n>>> str(param.replace()) # Will create a shallow copy of \'param\'\n\'foo=42\'\n>>> str(param.replace(default=Parameter.empty, annotation=\'spam\'))\n""foo: \'spam\'""\nParameter objects are also supported by the generic function copy.replace(). Changed in version 3.4: In Python 3.3 Parameter objects were allowed to have name set to None if their\nkind was set to POSITIONAL_ONLY. This is no longer permitted. class inspect.BoundArguments\nResult of a Signature.bind() or Signature.bind_partial() call. Holds the mapping of arguments\nto the function’s parameters. arguments\nA mutable mapping of parameters’ names to arguments’ values. Contains only explicitly bound argu-\nments. Changes in arguments will reflect in args and kwargs. Should be used in conjunction with Signature.parameters for any argument processing purposes. ® Note\nArguments for which Signature.bind() or Signature.bind_partial() relied on a default\nvalue are skipped. However, if needed, use BoundArguments.apply_defaults() to add them. Changed in version 3.9: arguments is now of type dict. Formerly, it was of type collections. OrderedDict. args\nA tuple of positional arguments values. Dynamically computed from the arguments attribute. kwargs\nA dict of keyword arguments values. Dynamically computed from the arguments attribute. Arguments\nthat can be passed positionally are included in args instead. signature\nA reference to the parent Signature object. 2010\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\napply_defaults()\nSet default values for missing arguments. For variable-positional arguments (*args) the default is an empty tuple. For variable-keyword arguments (**kwargs) the default is an empty dict. >>> def foo(a, b=\'ham\', *args): pass\n>>> ba = inspect.signature(foo).bind(\'spam\')\n>>> ba.apply_defaults()\n>>> ba.arguments\n{\'a\': \'spam\', \'b\': \'ham\', \'args\': ()}\nAdded in version 3.5. The args and kwargs properties can be used to invoke functions:\ndef test(a, *, b):\n...\nsig = signature(test)\nba = sig.bind(10, b=20)\ntest(*ba.args, **ba.kwargs)\nµ See also\nPEP 362 - Function Signature Object. The detailed specification, implementation details and examples. 30.14.4 Classes and functions\ninspect.getclasstree(classes, unique=False)\nArrange the given list of classes into a hierarchy of nested lists. Where a nested list appears, it contains classes\nderived from the class whose entry immediately precedes the list. Each entry is a 2-tuple containing a class and\na tuple of its base classes. If the unique argument is true, exactly one entry appears in the returned structure\nfor each class in the given list. Otherwise, classes using multiple inheritance and their descendants will appear\nmultiple times. inspect.getfullargspec(func)\nGet the names and default values of a Python function’s parameters. A named tuple is returned:\nFullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults,\nannotations)\nargs is a list of the positional parameter names. varargs is the name of the * parameter or None if arbitrary\npositional arguments are not accepted. varkw is the name of the ** parameter or None if arbitrary keyword\narguments are not accepted. defaults is an n-tuple of default argument values corresponding to the last n\npositional parameters, or None if there are no such defaults defined. kwonlyargs is a list of keyword-only pa-\nrameter names in declaration order. kwonlydefaults is a dictionary mapping parameter names from kwonlyargs\nto the default values used if no argument is supplied. annotations is a dictionary mapping parameter names to\nannotations. The special key ""return"" is used to report the function return value annotation (if any). Note that signature() and Signature Object provide the recommended API for callable introspection, and\nsupport additional behaviours (like positional-only arguments) that are sometimes encountered in extension\nmodule APIs. This function is retained primarily for use in code that needs to maintain compatibility with the\nPython 2 inspect module API. Changed in version 3.4: This function is now based on signature(), but still ignores __wrapped__ at-\ntributes and includes the already bound first parameter in the signature output for bound methods. 30.14. inspect — Inspect live objects\n2011\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.6: This method was previously documented as deprecated in favour of signature()\nin Python 3.5, but that decision has been reversed in order to restore a clearly supported standard interface for\nsingle-source Python 2/3 code migrating away from the legacy getargspec() API. Changed in version 3.7: Python only explicitly guaranteed that it preserved the declaration order of keyword-\nonly parameters as of version 3.7, although in practice this order had always been preserved in Python 3.\ninspect.getargvalues(frame)\nGet information about arguments passed into a particular frame. A named tuple ArgInfo(args, varargs,\nkeywords, locals) is returned. args is a list of the argument names.\n\n[2] >>> from inspect import Parameter\n>>> param = Parameter(\'foo\', Parameter.KEYWORD_ONLY, default=42)\n>>> str(param)\n\'foo=42\'\n>>> str(param.replace()) # Will create a shallow copy of \'param\'\n\'foo=42\'\n>>> str(param.replace(default=Parameter.empty, annotation=\'spam\'))\n""foo: \'spam\'""\nParameter objects are also supported by the generic function copy.replace(). Changed in version 3.4: In Python 3.3 Parameter objects were allowed to have name set to None if their\nkind was set to POSITIONAL_ONLY. This is no longer permitted. class inspect.BoundArguments\nResult of a Signature.bind() or Signature.bind_partial() call. Holds the mapping of arguments\nto the function’s parameters. arguments\nA mutable mapping of parameters’ names to arguments’ values. Contains only explicitly bound argu-\nments. Changes in arguments will reflect in args and kwargs. Should be used in conjunction with Signature.parameters for any argument processing purposes. ® Note\nArguments for which Signature.bind() or Signature.bind_partial() relied on a default\nvalue are skipped. However, if needed, use BoundArguments.apply_defaults() to add them. Changed in version 3.9: arguments is now of type dict. Formerly, it was of type collections. OrderedDict. args\nA tuple of positional arguments values. Dynamically computed from the arguments attribute. kwargs\nA dict of keyword arguments values. Dynamically computed from the arguments attribute. Arguments\nthat can be passed positionally are included in args instead. signature\nA reference to the parent Signature object. 2010\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\napply_defaults()\nSet default values for missing arguments. For variable-positional arguments (*args) the default is an empty tuple. For variable-keyword arguments (**kwargs) the default is an empty dict. >>> def foo(a, b=\'ham\', *args): pass\n>>> ba = inspect.signature(foo).bind(\'spam\')\n>>> ba.apply_defaults()\n>>> ba.arguments\n{\'a\': \'spam\', \'b\': \'ham\', \'args\': ()}\nAdded in version 3.5. The args and kwargs properties can be used to invoke functions:\ndef test(a, *, b):\n...\nsig = signature(test)\nba = sig.bind(10, b=20)\ntest(*ba.args, **ba.kwargs)\nµ See also\nPEP 362 - Function Signature Object. The detailed specification, implementation details and examples. 30.14.4 Classes and functions\ninspect.getclasstree(classes, unique=False)\nArrange the given list of classes into a hierarchy of nested lists. Where a nested list appears, it contains classes\nderived from the class whose entry immediately precedes the list. Each entry is a 2-tuple containing a class and\na tuple of its base classes. If the unique argument is true, exactly one entry appears in the returned structure\nfor each class in the given list. Otherwise, classes using multiple inheritance and their descendants will appear\nmultiple times. inspect.getfullargspec(func)\nGet the names and default values of a Python function’s parameters. A named tuple is returned:\nFullArgSpec(args, varargs, varkw, defaults, kwonlyargs, kwonlydefaults,\nannotations)\nargs is a list of the positional parameter names. varargs is the name of the * parameter or None if arbitrary\npositional arguments are not accepted. varkw is the name of the ** parameter or None if arbitrary keyword\narguments are not accepted. defaults is an n-tuple of default argument values corresponding to the last n\npositional parameters, or None if there are no such defaults defined. kwonlyargs is a list of keyword-only pa-\nrameter names in declaration order. kwonlydefaults is a dictionary mapping parameter names from kwonlyargs\nto the default values used if no argument is supplied. annotations is a dictionary mapping parameter names to\nannotations. The special key ""return"" is used to report the function return value annotation (if any). Note that signature() and Signature Object provide the recommended API for callable introspection, and\nsupport additional behaviours (like positional-only arguments) that are sometimes encountered in extension\nmodule APIs. This function is retained primarily for use in code that needs to maintain compatibility with the\nPython 2 inspect module API. Changed in version 3.4: This function is now based on signature(), but still ignores __wrapped__ at-\ntributes and includes the already bound first parameter in the signature output for bound methods. 30.14. inspect — Inspect live objects\n2011\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.6: This method was previously documented as deprecated in favour of signature()\nin Python 3.5, but that decision has been reversed in order to restore a clearly supported standard interface for\nsingle-source Python 2/3 code migrating away from the legacy getargspec() API. Changed in version 3.7: Python only explicitly guaranteed that it preserved the declaration order of keyword-\nonly parameters as of version 3.7, although in practice this order had always been preserved in Python 3.\ninspect.getargvalues(frame)\nGet information about arguments passed into a particular frame. A named tuple ArgInfo(args, varargs,\nkeywords, locals) is returned. args is a list of the argument names. varargs and keywords are the names\nof the * and ** arguments or None. locals is the locals dictionary of the given frame. ® Note\nThis function was inadvertently marked as deprecated in Python 3.5.\ninspect.formatargvalues(args[, varargs, varkw, locals, formatarg, formatvarargs, formatvarkw,\nformatvalue])\nFormat a pretty argument spec from the four values returned by getargvalues().\n\n[3] ® Note\nThis function was inadvertently marked as deprecated in Python 3.5.\ninspect.formatargvalues(args[, varargs, varkw, locals, formatarg, formatvarargs, formatvarkw,\nformatvalue])\nFormat a pretty argument spec from the four values returned by getargvalues(). The format* arguments\nare the corresponding optional formatting functions that are called to turn names and values into strings. ® Note\nThis function was inadvertently marked as deprecated in Python 3.5.\ninspect.getmro(cls)\nReturn a tuple of class cls’s base classes, including cls, in method resolution order. No class appears more\nthan once in this tuple. Note that the method resolution order depends on cls’s type. Unless a very peculiar\nuser-defined metatype is in use, cls will be the first element of the tuple. inspect.getcallargs(func, /, *args, **kwds)\nBind the args and kwds to the argument names of the Python function or method func, as if it was called with\nthem. For bound methods, bind also the first argument (typically named self) to the associated instance. A dict is returned, mapping the argument names (including the names of the * and ** arguments, if any) to\ntheir values from args and kwds. In case of invoking func incorrectly, i.e. whenever func(*args, **kwds)\nwould raise an exception because of incompatible signature, an exception of the same type and the same or\nsimilar message is raised. For example:\n>>> from inspect import getcallargs\n>>> def f(a, b=1, *pos, **named):\n...\npass\n...\n>>> getcallargs(f, 1, 2, 3) == {\'a\': 1, \'named\': {}, \'b\': 2, \'pos\': (3,)}\nTrue\n>>> getcallargs(f, a=2, x=4) == {\'a\': 2, \'named\': {\'x\': 4}, \'b\': 1, \'pos\': ()}\nTrue\n>>> getcallargs(f)\nTraceback (most recent call last):\n...\nTypeError: f() missing 1 required positional argument: \'a\'\nAdded in version 3.2. Deprecated since version 3.5: Use Signature.bind() and Signature.bind_partial() instead. inspect.getclosurevars(func)\nGet the mapping of external name references in a Python function or method func to their current values. A\nnamed tuple ClosureVars(nonlocals, globals, builtins, unbound) is returned. nonlocals maps\n2012\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\nreferenced names to lexical closure variables, globals to the function’s module globals and builtins to the builtins\nvisible from the function body. unbound is the set of names referenced in the function that could not be resolved\nat all given the current module globals and builtins. TypeError is raised if func is not a Python function or method. Added in version 3.3.\ninspect.unwrap(func, *, stop=None)\nGet the object wrapped by func. It follows the chain of __wrapped__ attributes returning the last object in\nthe chain. stop is an optional callback accepting an object in the wrapper chain as its sole argument that allows the\nunwrapping to be terminated early if the callback returns a true value. If the callback never returns a true value,\nthe last object in the chain is returned as usual. For example, signature() uses this to stop unwrapping if\nany object in the chain has a __signature__ attribute defined. ValueError is raised if a cycle is encountered. Added in version 3.4.\ninspect.get_annotations(obj, *, globals=None, locals=None, eval_str=False)\nCompute the annotations dict for an object. obj may be a callable, class, or module. Passing in an object of any other type raises TypeError. Returns a dict. get_annotations() returns a new dict every time it’s called; calling it twice on the same\nobject will return two different but equivalent dicts. This function handles several details for you:\n• If eval_str is true, values of type str will be un-stringized using eval(). This is intended for use\nwith stringized annotations (from __future__ import annotations). • If obj doesn’t have an annotations dict, returns an empty dict. (Functions and methods always have an\nannotations dict; classes, modules, and other types of callables may not.) • Ignores inherited annotations on classes. If a class doesn’t have its own annotations dict, returns an empty\ndict. • All accesses to object members and dict values are done using getattr() and dict.get() for safety. • Always, always, always returns a freshly created dict. eval_str controls whether or not values of type str are replaced with the result of calling eval() on those\nvalues:\n• If eval_str is true, eval() is called on values of type str. (Note that get_annotations doesn’t catch\nexceptions; if eval() raises an exception, it will unwind the stack past the get_annotations call.) • If eval_str is false (the default), values of type str are unchanged. globals and locals are passed in to eval(); see the documentation for eval() for more information. If\nglobals or locals is None, this function may replace that value with a context-specific default, contingent\non type(obj):\n• If obj is a module, globals defaults to obj.__dict__. • If obj is a class, globals defaults to sys.modules[obj.__module__].__dict__ and locals\ndefaults to the obj class namespace. • If obj is a callable, globals defaults to obj.__globals__, although if obj is a wrapped function\n(using functools.update_wrapper()) it is first unwrapped. Calling get_annotations is best practice for accessing the annotations dict of any object. See annotations-\nhowto for more information on annotations best practices. Added in version 3.10. 30.14. inspect — Inspect live objects\n2013\n\nThe Python Library Reference, Release 3.13.2\n30.14.5 The interpreter stack\nSome of the following functions return FrameInfo objects. For backwards compatibility these objects allow tuple-\nlike operations on all attributes except positions. This behavior is considered deprecated and may be removed in\nthe future.')",1.0743062241388499e-155,0.01890094504725236,0.19013175986580017,0.5644128322601318,0.52153265
How to convert string to bytes in Python 3,"If you look at the docs for 
bytes
, it points you to 
bytearray
:




bytearray([source[, encoding[, errors]]])


Return a new array of bytes. The bytearray type is a mutable sequence of integers in the range 0 <= x < 256. It has most of the usual methods of mutable sequences, described in Mutable Sequence Types, as well as most methods that the bytes type has, see Bytes and Byte Array Methods.


The optional source parameter can be used to initialize the array in a few different ways:


If it is a string, you must also give the encoding (and optionally, errors) parameters; bytearray() then converts the string to bytes using str.encode().


If it is an integer, the array will have that size and will be initialized with null bytes.


If it is an object conforming to the buffer interface, a read-only buffer of the object will be used to initialize the bytes array.


If it is an iterable, it must be an iterable of integers in the range 0 <= x < 256, which are used as the initial contents of the array.


Without an argument, an array of size 0 is created.




So 
bytes
 can do much more than just encode a string. It's Pythonic that it would allow you to call the constructor with any type of source parameter that makes sense.


For  encoding a string, I think that 
some_string.encode(encoding)
 is more Pythonic than using the constructor, because it is the most self documenting -- ""take this string and encode it with this encoding"" is clearer than 
bytes(some_string, encoding)
 -- there is no explicit verb when you use the constructor.


I checked the Python source. If you pass a unicode string to 
bytes
 using CPython, it calls 
PyUnicode_AsEncodedString
, which is the implementation of 
encode
; so you're just skipping a level of indirection if you call 
encode
 yourself.


Also, see Serdalis' comment -- 
unicode_string.encode(encoding)
 is also more Pythonic because its inverse is 
byte_string.decode(encoding)
 and symmetry is nice.

","(""Answer:\nIn Python 3, you can convert a string to bytes by using a `b` prefix before the string literal, such as `b'your string'`. You can also create bytes objects using methods like `bytes(10)` for a zero-filled bytes object of length 10, `bytes(range(20))` from an iterable of integers, or `bytes(obj)` by copying existing binary data via the buffer protocol. Additionally, the `bytes.fromhex(string)` class method can decode a string containing two hexadecimal digits per byte into a bytes object, ignoring ASCII whitespace.\n\nReferences: [1]\n"", '[1] (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation. hex([sep[, bytes_per_sep]])\nReturn a string object containing two hexadecimal digits for each byte in the instance. 4.9. Binary Sequence Types — bytes, bytearray, memoryview\n63\n\nThe Python Library Reference, Release 3.13.2\n>>> b\'\\xf0\\xf1\\xf2\'.hex()\n\'f0f1f2\'\nIf you want to make the hex string easier to read, you can specify a single character separator sep param-\neter to include in the output. By default, this separator will be included between each byte. A second\noptional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position\nfrom the right, negative values from the left. >>> value = b\'\\xf0\\xf1\\xf2\'\n>>> value.hex(\'-\')\n\'f0-f1-f2\'\n>>> value.hex(\'_\', 2)\n\'f0_f1f2\'\n>>> b\'UUDDLRLRAB\'.hex(\' \', -4)\n\'55554444 4c524c52 4142\'\nAdded in version 3.5. Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert\nseparators between bytes in the hex output. Since bytes objects are sequences of integers (akin to a tuple), for a bytes object b, b[0] will be an integer, while\nb[0:1] will be a bytes object of length 1. (This contrasts with text strings, where both indexing and slicing will\nproduce a string of length 1)\nThe representation of bytes objects uses the literal format (b\'...\') since it is often more useful than e.g. bytes([46, 46, 46]). You can always convert a bytes object into a list of integers using list(b). 4.9.2 Bytearray Objects\nbytearray objects are a mutable counterpart to bytes objects. class bytearray([source[, encoding[, errors]]])\nThere is no dedicated literal syntax for bytearray objects, instead they are always created by calling the con-\nstructor:\n• Creating an empty instance: bytearray()\n• Creating a zero-filled instance with a given length: bytearray(10)\n• From an iterable of integers: bytearray(range(20))\n• Copying existing binary data via the buffer protocol: bytearray(b\'Hi!\') As bytearray objects are mutable, they support the mutable sequence operations in addition to the common\nbytes and bytearray operations described in Bytes and Bytearray Operations. Also see the bytearray built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytearray type has an additional class method to read data\nin that format:\nclassmethod fromhex(string)\nThis bytearray class method returns bytearray object, decoding the given string object. The string\nmust contain two hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytearray.fromhex(\'2Ef0 F1f2\n\')\nbytearray(b\'.\\xf0\\xf1\\xf2\')\nChanged in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just\nspaces.\n\n[2] (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation. hex([sep[, bytes_per_sep]])\nReturn a string object containing two hexadecimal digits for each byte in the instance. 4.9. Binary Sequence Types — bytes, bytearray, memoryview\n63\n\nThe Python Library Reference, Release 3.13.2\n>>> b\'\\xf0\\xf1\\xf2\'.hex()\n\'f0f1f2\'\nIf you want to make the hex string easier to read, you can specify a single character separator sep param-\neter to include in the output. By default, this separator will be included between each byte. A second\noptional bytes_per_sep parameter controls the spacing. Positive values calculate the separator position\nfrom the right, negative values from the left. >>> value = b\'\\xf0\\xf1\\xf2\'\n>>> value.hex(\'-\')\n\'f0-f1-f2\'\n>>> value.hex(\'_\', 2)\n\'f0_f1f2\'\n>>> b\'UUDDLRLRAB\'.hex(\' \', -4)\n\'55554444 4c524c52 4142\'\nAdded in version 3.5. Changed in version 3.8: bytes.hex() now supports optional sep and bytes_per_sep parameters to insert\nseparators between bytes in the hex output. Since bytes objects are sequences of integers (akin to a tuple), for a bytes object b, b[0] will be an integer, while\nb[0:1] will be a bytes object of length 1. (This contrasts with text strings, where both indexing and slicing will\nproduce a string of length 1)\nThe representation of bytes objects uses the literal format (b\'...\') since it is often more useful than e.g. bytes([46, 46, 46]). You can always convert a bytes object into a list of integers using list(b). 4.9.2 Bytearray Objects\nbytearray objects are a mutable counterpart to bytes objects. class bytearray([source[, encoding[, errors]]])\nThere is no dedicated literal syntax for bytearray objects, instead they are always created by calling the con-\nstructor:\n• Creating an empty instance: bytearray()\n• Creating a zero-filled instance with a given length: bytearray(10)\n• From an iterable of integers: bytearray(range(20))\n• Copying existing binary data via the buffer protocol: bytearray(b\'Hi!\') As bytearray objects are mutable, they support the mutable sequence operations in addition to the common\nbytes and bytearray operations described in Bytes and Bytearray Operations. Also see the bytearray built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytearray type has an additional class method to read data\nin that format:\nclassmethod fromhex(string)\nThis bytearray class method returns bytearray object, decoding the given string object. The string\nmust contain two hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytearray.fromhex(\'2Ef0 F1f2\n\')\nbytearray(b\'.\\xf0\\xf1\\xf2\')\nChanged in version 3.7: bytearray.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytearray object into its hexadecimal representation.\n\n[3] \'\n(a space) A blank should be left before a positive number (or empty string) produced by a signed conver-\nsion. \'+\'\nA sign character (\'+\' or \'-\') will precede the conversion (overrides a “space” flag). A length modifier (h, l, or L) may be present, but is ignored as it is not necessary for Python – so e.g. %ld is identical\nto %d. The conversion types are:\nCon-\nversion\nMeaning\nNotes\n\'d\'\nSigned integer decimal. \'i\'\nSigned integer decimal. \'o\'\nSigned octal value. (1)\n\'u\'\nObsolete type – it is identical to \'d\'. (6)\n\'x\'\nSigned hexadecimal (lowercase). (2)\n\'X\'\nSigned hexadecimal (uppercase). (2)\n\'e\'\nFloating-point exponential format (lowercase). (3)\n\'E\'\nFloating-point exponential format (uppercase). (3)\n\'f\'\nFloating-point decimal format. (3)\n\'F\'\nFloating-point decimal format. (3)\n\'g\'\nFloating-point format. Uses lowercase exponential format if exponent is less than -4 or not less\nthan precision, decimal format otherwise. (4)\n\'G\'\nFloating-point format. Uses uppercase exponential format if exponent is less than -4 or not\nless than precision, decimal format otherwise. (4)\n\'c\'\nSingle character (accepts integer or single character string). \'r\'\nString (converts any Python object using repr()). (5)\n\'s\'\nString (converts any Python object using str()). (5)\n\'a\'\nString (converts any Python object using ascii()). (5)\n\'%\'\nNo argument is converted, results in a \'%\' character in the result. Notes:\n(1) The alternate form causes a leading octal specifier (\'0o\') to be inserted before the first digit. (2) The alternate form causes a leading \'0x\' or \'0X\' (depending on whether the \'x\' or \'X\' format was used)\nto be inserted before the first digit. (3) The alternate form causes the result to always contain a decimal point, even if no digits follow it. The precision determines the number of digits after the decimal point and defaults to 6. (4) The alternate form causes the result to always contain a decimal point, and trailing zeroes are not removed as\nthey would otherwise be. The precision determines the number of significant digits before and after the decimal point and defaults to 6. (5) If precision is N, the output is truncated to N characters. (6) See PEP 237. Since Python strings have an explicit length, %s conversions do not assume that \'\\0\' is the end of the string. Changed in version 3.1: %f conversions for numbers whose absolute value is over 1e50 are no longer replaced by %g\nconversions. 62\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\n4.9 Binary Sequence Types — bytes, bytearray, memoryview\nThe core built-in types for manipulating binary data are bytes and bytearray. They are supported by\nmemoryview which uses the buffer protocol to access the memory of other binary objects without needing to make\na copy. The array module supports efficient storage of basic data types like 32-bit integers and IEEE754 double-precision\nfloating values. 4.9.1 Bytes Objects\nBytes objects are immutable sequences of single bytes. Since many major binary protocols are based on the ASCII\ntext encoding, bytes objects offer several methods that are only valid when working with ASCII compatible data and\nare closely related to string objects in a variety of other ways. class bytes([source[, encoding[, errors]]])\nFirstly, the syntax for bytes literals is largely the same as that for string literals, except that a b prefix is added:\n• Single quotes: b\'still allows embedded ""double"" quotes\'\n• Double quotes: b""still allows embedded \'single\' quotes""\n• Triple quoted: b\'\'\'3 single quotes\'\'\', b""""""3 double quotes""""""\nOnly ASCII characters are permitted in bytes literals (regardless of the declared source code encoding). Any\nbinary values over 127 must be entered into bytes literals using the appropriate escape sequence. As with string literals, bytes literals may also use a r prefix to disable processing of escape sequences. See\nstrings for more about the various forms of bytes literal, including supported escape sequences. While bytes literals and representations are based on ASCII text, bytes objects actually behave like immutable\nsequences of integers, with each value in the sequence restricted such that 0 <= x < 256 (attempts to violate\nthis restriction will trigger ValueError). This is done deliberately to emphasise that while many binary\nformats include ASCII based elements and can be usefully manipulated with some text-oriented algorithms,\nthis is not generally the case for arbitrary binary data (blindly applying text processing algorithms to binary\ndata formats that are not ASCII compatible will usually lead to data corruption). In addition to the literal forms, bytes objects can be created in a number of other ways:\n• A zero-filled bytes object of a specified length: bytes(10)\n• From an iterable of integers: bytes(range(20))\n• Copying existing binary data via the buffer protocol: bytes(obj)\nAlso see the bytes built-in. Since 2 hexadecimal digits correspond precisely to a single byte, hexadecimal numbers are a commonly used\nformat for describing binary data. Accordingly, the bytes type has an additional class method to read data in\nthat format:\nclassmethod fromhex(string)\nThis bytes class method returns a bytes object, decoding the given string object. The string must contain\ntwo hexadecimal digits per byte, with ASCII whitespace being ignored. >>> bytes.fromhex(\'2Ef0 F1f2\n\')\nb\'.\\xf0\\xf1\\xf2\'\nChanged in version 3.7: bytes.fromhex() now skips all ASCII whitespace in the string, not just\nspaces. A reverse conversion function exists to transform a bytes object into its hexadecimal representation.')",0.00651041993374084,0.0721205597416577,0.23957092505666588,0.561777651309967,0.55634636
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128),"Read the Python 
Unicode HOWTO
. This error is the 
very first example
.


Do not use 
str()
 to convert from unicode to encoded text / bytes.


Instead, use 
.encode()
 to encode the string:


p.agent_info = u' '.join((agent_contact, agent_telno)).encode('utf-8').strip()



or work entirely in unicode.

","(""Answer: A `UnicodeEncodeError` occurs when a string object containing code points above U+00FF cannot be encoded with a codec like 'latin-1' or 'ascii'. These encodings can only map 256 of the 1,114,112 code points defined in Unicode.\n\nReferences: [2]\n"", '[1] Doing so will raise a UnicodeEncodeError that looks like the following (although the details of the error mes-\nsage may differ): UnicodeEncodeError: \'latin-1\' codec can\'t encode character \'\\u1234\' in\nposition 3: ordinal not in range(256). There’s another group of encodings (the so called charmap encodings) that choose a different subset of all Unicode\ncode points and how these code points are mapped to the bytes 0x0–0xff. To see how this is done simply open e.g. encodings/cp1252.py (which is an encoding that is used primarily on Windows). There’s a string constant with\n256 characters that shows you which character is mapped to which byte value. All of these encodings can only encode 256 of the 1114112 code points defined in Unicode. A simple and straight-\nforward way that can store each Unicode code point, is to store each code point as four consecutive bytes. There are\ntwo possibilities: store the bytes in big endian or in little endian order. These two encodings are called UTF-32-BE\nand UTF-32-LE respectively. Their disadvantage is that if e.g. you use UTF-32-BE on a little endian machine you\nwill always have to swap bytes on encoding and decoding. UTF-32 avoids this problem: bytes will always be in\nnatural endianness. When these bytes are read by a CPU with a different endianness, then bytes have to be swapped\nthough. To be able to detect the endianness of a UTF-16 or UTF-32 byte sequence, there’s the so called BOM\n(“Byte Order Mark”). This is the Unicode character U+FEFF. This character can be prepended to every UTF-16 or\nUTF-32 byte sequence. The byte swapped version of this character (0xFFFE) is an illegal character that may not\nappear in a Unicode text. So when the first character in a UTF-16 or UTF-32 byte sequence appears to be a U+FFFE\nthe bytes have to be swapped on decoding. Unfortunately the character U+FEFF had a second purpose as a ZERO\nWIDTH NO-BREAK SPACE: a character that has no width and doesn’t allow a word to be split. It can e.g. be used to\ngive hints to a ligature algorithm. With Unicode 4.0 using U+FEFF as a ZERO WIDTH NO-BREAK SPACE has been\ndeprecated (with U+2060 (WORD JOINER) assuming this role). Nevertheless Unicode software still must be able\nto handle U+FEFF in both roles: as a BOM it’s a device to determine the storage layout of the encoded bytes, and\nvanishes once the byte sequence has been decoded into a string; as a ZERO WIDTH NO-BREAK SPACE it’s a normal\ncharacter that will be decoded like any other. There’s another encoding that is able to encode the full range of Unicode characters: UTF-8. UTF-8 is an 8-bit\nencoding, which means there are no issues with byte order in UTF-8. Each byte in a UTF-8 byte sequence consists\nof two parts: marker bits (the most significant bits) and payload bits. The marker bits are a sequence of zero to\nfour 1 bits followed by a 0 bit. Unicode characters are encoded like this (with x being payload bits, which when\nconcatenated give the Unicode character):\nRange\nEncoding\nU-00000000 … U-0000007F\n0xxxxxxx\nU-00000080 … U-000007FF\n110xxxxx 10xxxxxx\nU-00000800 … U-0000FFFF\n1110xxxx 10xxxxxx 10xxxxxx\nU-00010000 … U-0010FFFF\n11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\nThe least significant bit of the Unicode character is the rightmost x bit. As UTF-8 is an 8-bit encoding no BOM is required and any U+FEFF character in the decoded string (even if it’s the\nfirst character) is treated as a ZERO WIDTH NO-BREAK SPACE. Without external information it’s impossible to reliably determine which encoding was used for encoding a string. Each charmap encoding can decode any random byte sequence. However that’s not possible with UTF-8, as UTF-8\nbyte sequences have a structure that doesn’t allow arbitrary byte sequences. To increase the reliability with which a\nUTF-8 encoding can be detected, Microsoft invented a variant of UTF-8 (that Python calls ""utf-8-sig"") for its\nNotepad program: Before any of the Unicode characters is written to the file, a UTF-8 encoded BOM (which looks\nlike this as a byte sequence: 0xef, 0xbb, 0xbf) is written. As it’s rather improbable that any charmap encoded file\nstarts with these byte values (which would e.g. map to\nLATIN SMALL LETTER I WITH DIAERESIS\nRIGHT-POINTING DOUBLE ANGLE QUOTATION MARK\nINVERTED QUESTION MARK\n196\nChapter 7. Binary Data Services\n\nThe Python Library Reference, Release 3.13.2\nin iso-8859-1), this increases the probability that a utf-8-sig encoding can be correctly guessed from the byte\nsequence. So here the BOM is not used to be able to determine the byte order used for generating the byte sequence,\nbut as a signature that helps in guessing the encoding. On encoding the utf-8-sig codec will write 0xef, 0xbb, 0xbf\nas the first three bytes to the file. On decoding utf-8-sig will skip those three bytes if they appear as the first three\nbytes in the file. In UTF-8, the use of the BOM is discouraged and should generally be avoided. 7.2.3 Standard Encodings\nPython comes with a number of codecs built-in, either implemented as C functions or with dictionaries as mapping\ntables. The following table lists the codecs by name, together with a few common aliases, and the languages for which\nthe encoding is likely used. Neither the list of aliases nor the list of languages is meant to be exhaustive. Notice that\nspelling alternatives that only differ in case or use a hyphen instead of an underscore are also valid aliases; therefore,\ne.g. \'utf-8\' is a valid alias for the \'utf_8\' codec. CPython implementation detail: Some common encodings can bypass the codecs lookup machinery to improve\nperformance. These optimization opportunities are only recognized by CPython for a limited set of (case insensitive)\naliases: utf-8, utf8, latin-1, latin1, iso-8859-1, iso8859-1, mbcs (Windows only), ascii, us-ascii, utf-16, utf16, utf-\n32, utf32, and the same using underscores instead of dashes. Using alternative aliases for these encodings may result\nin slower execution. Changed in version 3.6: Optimization opportunity recognized for us-ascii. Many of the character sets support the same languages. They vary in individual characters (e.g.\n\n[2] The simplest text encoding (called \'latin-1\' or \'iso-8859-1\') maps the code points 0–255 to the bytes 0x0–\n0xff, which means that a string object that contains code points above U+00FF can’t be encoded with this codec. Doing so will raise a UnicodeEncodeError that looks like the following (although the details of the error mes-\nsage may differ): UnicodeEncodeError: \'latin-1\' codec can\'t encode character \'\\u1234\' in\nposition 3: ordinal not in range(256). There’s another group of encodings (the so called charmap encodings) that choose a different subset of all Unicode\ncode points and how these code points are mapped to the bytes 0x0–0xff. To see how this is done simply open e.g. encodings/cp1252.py (which is an encoding that is used primarily on Windows). There’s a string constant with\n256 characters that shows you which character is mapped to which byte value. All of these encodings can only encode 256 of the 1114112 code points defined in Unicode. A simple and straight-\nforward way that can store each Unicode code point, is to store each code point as four consecutive bytes. There are\ntwo possibilities: store the bytes in big endian or in little endian order. These two encodings are called UTF-32-BE\nand UTF-32-LE respectively. Their disadvantage is that if e.g. you use UTF-32-BE on a little endian machine you\nwill always have to swap bytes on encoding and decoding. UTF-32 avoids this problem: bytes will always be in\nnatural endianness. When these bytes are read by a CPU with a different endianness, then bytes have to be swapped\nthough. To be able to detect the endianness of a UTF-16 or UTF-32 byte sequence, there’s the so called BOM\n(“Byte Order Mark”). This is the Unicode character U+FEFF. This character can be prepended to every UTF-16 or\nUTF-32 byte sequence. The byte swapped version of this character (0xFFFE) is an illegal character that may not\nappear in a Unicode text. So when the first character in a UTF-16 or UTF-32 byte sequence appears to be a U+FFFE\nthe bytes have to be swapped on decoding. Unfortunately the character U+FEFF had a second purpose as a ZERO\nWIDTH NO-BREAK SPACE: a character that has no width and doesn’t allow a word to be split. It can e.g. be used to\ngive hints to a ligature algorithm. With Unicode 4.0 using U+FEFF as a ZERO WIDTH NO-BREAK SPACE has been\ndeprecated (with U+2060 (WORD JOINER) assuming this role). Nevertheless Unicode software still must be able\nto handle U+FEFF in both roles: as a BOM it’s a device to determine the storage layout of the encoded bytes, and\nvanishes once the byte sequence has been decoded into a string; as a ZERO WIDTH NO-BREAK SPACE it’s a normal\ncharacter that will be decoded like any other. There’s another encoding that is able to encode the full range of Unicode characters: UTF-8. UTF-8 is an 8-bit\nencoding, which means there are no issues with byte order in UTF-8. Each byte in a UTF-8 byte sequence consists\nof two parts: marker bits (the most significant bits) and payload bits. The marker bits are a sequence of zero to\nfour 1 bits followed by a 0 bit. Unicode characters are encoded like this (with x being payload bits, which when\nconcatenated give the Unicode character):\nRange\nEncoding\nU-00000000 … U-0000007F\n0xxxxxxx\nU-00000080 … U-000007FF\n110xxxxx 10xxxxxx\nU-00000800 … U-0000FFFF\n1110xxxx 10xxxxxx 10xxxxxx\nU-00010000 … U-0010FFFF\n11110xxx 10xxxxxx 10xxxxxx 10xxxxxx\nThe least significant bit of the Unicode character is the rightmost x bit. As UTF-8 is an 8-bit encoding no BOM is required and any U+FEFF character in the decoded string (even if it’s the\nfirst character) is treated as a ZERO WIDTH NO-BREAK SPACE. Without external information it’s impossible to reliably determine which encoding was used for encoding a string. Each charmap encoding can decode any random byte sequence. However that’s not possible with UTF-8, as UTF-8\nbyte sequences have a structure that doesn’t allow arbitrary byte sequences. To increase the reliability with which a\nUTF-8 encoding can be detected, Microsoft invented a variant of UTF-8 (that Python calls ""utf-8-sig"") for its\nNotepad program: Before any of the Unicode characters is written to the file, a UTF-8 encoded BOM (which looks\nlike this as a byte sequence: 0xef, 0xbb, 0xbf) is written. As it’s rather improbable that any charmap encoded file\nstarts with these byte values (which would e.g. map to\nLATIN SMALL LETTER I WITH DIAERESIS\nRIGHT-POINTING DOUBLE ANGLE QUOTATION MARK\nINVERTED QUESTION MARK\n196\nChapter 7. Binary Data Services\n\nThe Python Library Reference, Release 3.13.2\nin iso-8859-1), this increases the probability that a utf-8-sig encoding can be correctly guessed from the byte\nsequence. So here the BOM is not used to be able to determine the byte order used for generating the byte sequence,\nbut as a signature that helps in guessing the encoding. On encoding the utf-8-sig codec will write 0xef, 0xbb, 0xbf\nas the first three bytes to the file. On decoding utf-8-sig will skip those three bytes if they appear as the first three\nbytes in the file. In UTF-8, the use of the BOM is discouraged and should generally be avoided. 7.2.3 Standard Encodings\nPython comes with a number of codecs built-in, either implemented as C functions or with dictionaries as mapping\ntables. The following table lists the codecs by name, together with a few common aliases, and the languages for which\nthe encoding is likely used. Neither the list of aliases nor the list of languages is meant to be exhaustive. Notice that\nspelling alternatives that only differ in case or use a hyphen instead of an underscore are also valid aliases; therefore,\ne.g. \'utf-8\' is a valid alias for the \'utf_8\' codec. CPython implementation detail: Some common encodings can bypass the codecs lookup machinery to improve\nperformance. These optimization opportunities are only recognized by CPython for a limited set of (case insensitive)\naliases: utf-8, utf8, latin-1, latin1, iso-8859-1, iso8859-1, mbcs (Windows only), ascii, us-ascii, utf-16, utf16, utf-\n32, utf32, and the same using underscores instead of dashes. Using alternative aliases for these encodings may result\nin slower execution. Changed in version 3.6: Optimization opportunity recognized for us-ascii. Many of the character sets support the same languages.\n\n[3] The errors argument specifies the response when the input string can’t be converted according to the encoding’s\nrules. Legal values for this argument are \'strict\' (raise a UnicodeDecodeError exception), \'replace\'\n(use U+FFFD, REPLACEMENT CHARACTER), \'ignore\' (just leave the character out of the Unicode result), or\n\'backslashreplace\' (inserts a \\xNN escape sequence). The following examples show the differences:\n>>> b\'\\x80abc\'.decode(""utf-8"", ""strict"")\nTraceback (most recent call last):\n...\nUnicodeDecodeError: \'utf-8\' codec can\'t decode byte 0x80 in position 0:\ninvalid start byte\n>>> b\'\\x80abc\'.decode(""utf-8"", ""replace"")\n\'\\ufffdabc\'\n>>> b\'\\x80abc\'.decode(""utf-8"", ""backslashreplace"")\n\'\\\\x80abc\'\n>>> b\'\\x80abc\'.decode(""utf-8"", ""ignore"")\n\'abc\'\nEncodings are specified as strings containing the encoding’s name. Python comes with roughly 100 different encod-\nings; see the Python Library Reference at standard-encodings for a list. Some encodings have multiple names; for\nexample, \'latin-1\', \'iso_8859_1\' and \'8859’ are all synonyms for the same encoding. One-character Unicode strings can also be created with the chr() built-in function, which takes integers and returns\na Unicode string of length 1 that contains the corresponding code point. The reverse operation is the built-in ord()\nfunction that takes a one-character Unicode string and returns the code point value:\n4\n\n>>> chr(57344)\n\'\\ue000\'\n>>> ord(\'\\ue000\')\n57344\n2.2 Converting to Bytes\nThe opposite method of bytes.decode() is str.encode(), which returns a bytes representation of the Unicode\nstring, encoded in the requested encoding. The errors parameter is the same as the parameter of the decode() method but supports a few more possible\nhandlers. As well as \'strict\', \'ignore\', and \'replace\' (which in this case inserts a question mark in-\nstead of the unencodable character), there is also \'xmlcharrefreplace\' (inserts an XML character reference),\nbackslashreplace (inserts a \\uNNNN escape sequence) and namereplace (inserts a \\N{...} escape sequence). The following example shows the different results:\n>>> u = chr(40960) + \'abcd\' + chr(1972)\n>>> u.encode(\'utf-8\')\nb\'\\xea\\x80\\x80abcd\\xde\\xb4\'\n>>> u.encode(\'ascii\')\nTraceback (most recent call last):\n...\nUnicodeEncodeError: \'ascii\' codec can\'t encode character \'\\ua000\' in\nposition 0: ordinal not in range(128)\n>>> u.encode(\'ascii\', \'ignore\')\nb\'abcd\'\n>>> u.encode(\'ascii\', \'replace\')\nb\'?abcd?\' >>> u.encode(\'ascii\', \'xmlcharrefreplace\')\nb\'&#40960;abcd&#1972;\'\n>>> u.encode(\'ascii\', \'backslashreplace\')\nb\'\\\\ua000abcd\\\\u07b4\'\n>>> u.encode(\'ascii\', \'namereplace\')\nb\'\\\\N{YI SYLLABLE IT}abcd\\\\u07b4\'\nThe low-level routines for registering and accessing the available encodings are found in the codecs module. Im-\nplementing new encodings also requires understanding the codecs module. However, the encoding and decoding\nfunctions returned by this module are usually more low-level than is comfortable, and writing new encodings is a\nspecialized task, so the module won’t be covered in this HOWTO. 2.3 Unicode Literals in Python Source Code\nIn Python source code, specific Unicode code points can be written using the \\u escape sequence, which is followed\nby four hex digits giving the code point. The \\U escape sequence is similar, but expects eight hex digits, not four:\n>>> s = ""a\\xac\\u1234\\u20ac\\U00008000""\n... #\n^^^^ two-digit hex escape\n... #\n^^^^^^ four-digit Unicode escape\n... #\n^^^^^^^^^^ eight-digit Unicode escape\n>>> [ord(c) for c in s]\n[97, 172, 4660, 8364, 32768]\nUsing escape sequences for code points greater than 127 is fine in small doses, but becomes an annoyance if you’re\nusing many accented characters, as you would in a program with messages in French or some other accent-using\nlanguage. You can also assemble strings using the chr() built-in function, but this is even more tedious. Ideally, you’d want to be able to write literals in your language’s natural encoding. You could then edit Python source\ncode with your favorite editor which would display the accented characters naturally, and have the right characters\n5\n\nused at runtime. Python supports writing source code in UTF-8 by default, but you can use almost any encoding if you declare the\nencoding being used. This is done by including a special comment as either the first or second line of the source file:\n#!/usr/bin/env python\n# -*- coding: latin-1 -*-\nu = \'abcdé\'\nprint(ord(u[-1]))\nThe syntax is inspired by Emacs’s notation for specifying variables local to a file. Emacs supports many different\nvariables, but Python only supports ‘coding’. The -*- symbols indicate to Emacs that the comment is special; they\nhave no significance to Python but are a convention. Python looks for coding: name or coding=name in the\ncomment. If you don’t include such a comment, the default encoding used will be UTF-8 as already mentioned. See also PEP\n263 for more information. 2.4 Unicode Properties\nThe Unicode specification includes a database of information about code points. For each defined code point, the\ninformation includes the character’s name, its category, the numeric value if applicable (for characters representing\nnumeric concepts such as the Roman numerals, fractions such as one-third and four-fifths, etc.). There are also\ndisplay-related properties, such as how to use the code point in bidirectional text. The following program displays some information about several characters, and prints the numeric value of one\nparticular character:\nimport unicodedata\nu = chr(233) + chr(0x0bf2) + chr(3972) + chr(6000) + chr(13231)\nfor i, c in enumerate(u):\nprint(i, \'%04x\' % ord(c), unicodedata.category(c), end="" "")\nprint(unicodedata.name(c))\n# Get numeric value of second character\nprint(unicodedata.numeric(u[1]))\nWhen run, this prints:\n0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE\n1 0bf2 No TAMIL NUMBER ONE THOUSAND\n2 0f84 Mn TIBETAN MARK HALANTA\n3 1770 Lo TAGBANWA LETTER SA\n4 33af So SQUARE RAD OVER S SQUARED\n1000.0\nThe category codes are abbreviations describing the nature of the character. These are grouped into categories\nsuch as “Letter”, “Number”, “Punctuation”, or “Symbol”, which in turn are broken up into subcategories. To take\nthe codes from the above output, \'Ll\' means ‘Letter, lowercase’, \'No\' means “Number, other”, \'Mn\' is “Mark,\nnonspacing”, and \'So\' is “Symbol, other”. See the General Category Values section of the Unicode Character\nDatabase documentation for a list of category codes. 2.5 Comparing Strings\nUnicode adds some complication to comparing strings, because the same set of characters can be represented by\ndifferent sequences of code points. For example, a letter like ‘ê’ can be represented as a single code point U+00EA,\nor as U+0065 U+0302, which is the code point for ‘e’ followed by a code point for ‘COMBINING CIRCUMFLEX\n6\n\nACCENT’. These will produce the same output when printed, but one is a string of length 1 and the other is of length\n2. One tool for a case-insensitive comparison is the casefold() string method that converts a string to a case-\ninsensitive form following an algorithm described by the Unicode Standard. This algorithm has special handling\nfor characters such as the German letter ‘ß’ (code point U+00DF), which becomes the pair of lowercase letters ‘ss’. >>> street = \'Gürzenichstraße\'\n>>> street.casefold()\n\'gürzenichstrasse\'\nA second tool is the unicodedata module’s normalize() function that converts strings to one of several normal\nforms, where letters followed by a combining character are replaced with single characters. normalize() can\nbe used to perform string comparisons that won’t falsely report inequality if two strings use combining characters\ndifferently:\nimport unicodedata\ndef compare_strs(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize(\'NFD\', s)\nreturn NFD(s1) == NFD(s2)\nsingle_char = \'ê\'\nmultiple_chars = \'\\N{LATIN SMALL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}\'\nprint(\'length of first string=\', len(single_char))\nprint(\'length of second string=\', len(multiple_chars))\nprint(compare_strs(single_char, multiple_chars))\nWhen run, this outputs:\n$ python compare-strs.py\nlength of first string= 1\nlength of second string= 2\nTrue\nThe first argument to the normalize() function is a string giving the desired normalization form, which can be one\nof ‘NFC’, ‘NFKC’, ‘NFD’, and ‘NFKD’. The Unicode Standard also specifies how to do caseless comparisons:\nimport unicodedata\ndef compare_caseless(s1, s2):\ndef NFD(s):\nreturn unicodedata.normalize(\'NFD\', s)\nreturn NFD(NFD(s1).casefold()) == NFD(NFD(s2).casefold())\n# Example usage\nsingle_char = \'ê\'\nmultiple_chars = \'\\N{LATIN CAPITAL LETTER E}\\N{COMBINING CIRCUMFLEX ACCENT}\'\nprint(compare_caseless(single_char, multiple_chars))\nThis will print True. (Why is NFD() invoked twice? Because there are a few characters that make casefold()\nreturn a non-normalized string, so the result needs to be normalized again. See section 3.13 of the Unicode Standard\nfor a discussion and an example.) 7\n\n2.6 Unicode Regular Expressions\nThe regular expressions supported by the re module can be provided either as bytes or strings. Some of the special\ncharacter sequences such as \\d and \\w have different meanings depending on whether the pattern is supplied as bytes\nor a string. For example, \\d will match the characters [0-9] in bytes but in strings will match any character that’s\nin the \'Nd\' category. The string in this example has the number 57 written in both Thai and Arabic numerals:\nimport re\np = re.compile(r\'\\d+\')\ns = ""Over \\u0e55\\u0e57 57 flavours""\nm = p.search(s)\nprint(repr(m.group()))\nWhen executed, \\d+ will match the Thai numerals and print them out. If you supply the re.ASCII flag to\ncompile(), \\d+ will match the substring “57” instead. Similarly, \\w matches a wide variety of Unicode characters but only [a-zA-Z0-9_] in bytes or if re.ASCII is\nsupplied, and \\s will match either Unicode whitespace characters or [ \\t\\n\\r\\f\\v]. 2.7 References\nSome good alternative discussions of Python’s Unicode support are:\n• Processing Text Files in Python 3, by Nick Coghlan. • Pragmatic Unicode, a PyCon 2012 presentation by Ned Batchelder.')",8.814562553642994e-80,0.01547678482276585,0.05807354692720681,0.5236624479293823,0.57615864
How do I move a file in Python?,"os.rename()
, 
os.replace()
, or 
shutil.move()


All employ the same syntax:


import os
import shutil

os.rename(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")
os.replace(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")
shutil.move(""path/to/current/file.foo"", ""path/to/new/destination/for/file.foo"")





The filename (
""file.foo""
) must be included in both the source and destination arguments. If it differs between the two, the file will be renamed as well as moved.


The directory within which the new file is being created must already exist.


On Windows, a file with that name must not exist or an exception will be raised, but 
os.replace()
 will silently replace a file even in that occurrence.


shutil.move
 simply calls 
os.rename
 in most cases. However, if the destination is on a different disk than the source, it will instead copy and then delete the source file.



","('Answer: To move a file or directory in Python, you can use the `shutil.move(src, dst, copy_function=copy2)` function. This function recursively moves a file or directory from the source (`src`) to the destination (`dst`). If the destination is an existing directory, the source is moved inside that directory. If the destination is on the current filesystem, `os.rename()` is used; otherwise, the source is copied to the destination using `copy_function` and then removed.\n\nReferences: [1, 2, 3]\n', '[1] Added in version 3.3.\nshutil.move(src, dst, copy_function=copy2)\nRecursively move a file or directory (src) to another location and return the destination. If dst is an existing directory or a symlink to a directory, then src is moved inside that directory. The destination\npath in that directory must not already exist. If dst already exists but is not a directory, it may be overwritten depending on os.rename() semantics. If the destination is on the current filesystem, then os.rename() is used. Otherwise, src is copied to the\ndestination using copy_function and then removed. In case of symlinks, a new symlink pointing to the target\nof src will be created as the destination and src will be removed. If copy_function is given, it must be a callable that takes two arguments, src and the destination, and will\nbe used to copy src to the destination if os.rename() cannot be used. If the source is a directory,\ncopytree() is called, passing it the copy_function. The default copy_function is copy2(). Using copy() as\nthe copy_function allows the move to succeed when it is not possible to also copy the metadata, at the expense\nof not copying any of the metadata. Raises an auditing event shutil.move with arguments src, dst. Changed in version 3.3: Added explicit symlink handling for foreign filesystems, thus adapting it to the behavior\nof GNU’s mv. Now returns dst. Changed in version 3.5: Added the copy_function keyword argument. Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file\nmore efficiently. See Platform-dependent efficient copy operations section. Changed in version 3.9: Accepts a path-like object for both src and dst. shutil.disk_usage(path)\nReturn disk usage statistics about the given path as a named tuple with the attributes total, used and free, which\nare the amount of total, used and free space, in bytes. path may be a file or a directory. ® Note\nOn Unix filesystems, path must point to a path within a mounted filesystem partition. On those platforms,\nCPython doesn’t attempt to retrieve disk usage information from non-mounted filesystems. Added in version 3.3. Changed in version 3.8: On Windows, path can now be a file or directory. Availability: Unix, Windows. shutil.chown(path, user=None, group=None, *, dir_fd=None, follow_symlinks=True)\nChange owner user and/or group of the given path. user can be a system user name or a uid; the same applies to group. At least one argument is required. See also os.chown(), the underlying function. Raises an auditing event shutil.chown with arguments path, user, group. Availability: Unix. Added in version 3.3. 492\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.13: Added dir_fd and follow_symlinks parameters. shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)\nReturn the path to an executable which would be run if the given cmd was called. If no cmd would be called,\nreturn None. mode is a permission mask passed to os.access(), by default determining if the file exists and is executable. path is a “PATH string” specifying the directories to look in, delimited by os.pathsep. When no path is\nspecified, the PATH environment variable is read from os.environ, falling back to os.defpath if it is not\nset. On Windows, the current directory is prepended to the path if mode does not include os.X_OK. When the\nmode does include os.X_OK, the Windows API NeedCurrentDirectoryForExePathW will be consulted\nto determine if the current directory should be prepended to path. To avoid consulting the current working\ndirectory for executables: set the environment variable NoDefaultCurrentDirectoryInExePath. Also on Windows, the PATHEXT environment variable is used to resolve commands that may not already\ninclude an extension. For example, if you call shutil.which(""python""), which() will search PATHEXT\nto know that it should look for python.exe within the path directories. For example, on Windows:\n>>> shutil.which(""python"")\n\'C:\\\\Python33\\\\python.EXE\'\nThis is also applied when cmd is a path that contains a directory component:\n>> shutil.which(""C:\\\\Python33\\\\python"")\n\'C:\\\\Python33\\\\python.EXE\'\nAdded in version 3.3. Changed in version 3.8: The bytes type is now accepted. If cmd type is bytes, the result type is also bytes. Changed in version 3.12: On Windows, the current directory is no longer prepended to the search path if mode\nincludes os.X_OK and WinAPI NeedCurrentDirectoryForExePathW(cmd) is false, else the current di-\nrectory is prepended even if it is already in the search path; PATHEXT is used now even when cmd includes a\ndirectory component or ends with an extension that is in PATHEXT; and filenames that have no extension can\nnow be found. exception shutil.Error\nThis exception collects exceptions that are raised during a multi-file operation. For copytree(), the exception\nargument is a list of 3-tuples (srcname, dstname, exception). Platform-dependent efficient copy operations\nStarting from Python 3.8, all functions involving a file copy (copyfile(), copy(), copy2(), copytree(), and\nmove()) may use platform-specific “fast-copy” syscalls in order to copy the file more efficiently (see bpo-33671).\n\n[2] If the destination is on the current filesystem, then os.rename() is used. Otherwise, src is copied to the\ndestination using copy_function and then removed. In case of symlinks, a new symlink pointing to the target\nof src will be created as the destination and src will be removed. If copy_function is given, it must be a callable that takes two arguments, src and the destination, and will\nbe used to copy src to the destination if os.rename() cannot be used. If the source is a directory,\ncopytree() is called, passing it the copy_function. The default copy_function is copy2(). Using copy() as\nthe copy_function allows the move to succeed when it is not possible to also copy the metadata, at the expense\nof not copying any of the metadata. Raises an auditing event shutil.move with arguments src, dst. Changed in version 3.3: Added explicit symlink handling for foreign filesystems, thus adapting it to the behavior\nof GNU’s mv. Now returns dst. Changed in version 3.5: Added the copy_function keyword argument. Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file\nmore efficiently. See Platform-dependent efficient copy operations section. Changed in version 3.9: Accepts a path-like object for both src and dst. shutil.disk_usage(path)\nReturn disk usage statistics about the given path as a named tuple with the attributes total, used and free, which\nare the amount of total, used and free space, in bytes. path may be a file or a directory. ® Note\nOn Unix filesystems, path must point to a path within a mounted filesystem partition. On those platforms,\nCPython doesn’t attempt to retrieve disk usage information from non-mounted filesystems. Added in version 3.3. Changed in version 3.8: On Windows, path can now be a file or directory. Availability: Unix, Windows. shutil.chown(path, user=None, group=None, *, dir_fd=None, follow_symlinks=True)\nChange owner user and/or group of the given path. user can be a system user name or a uid; the same applies to group. At least one argument is required. See also os.chown(), the underlying function. Raises an auditing event shutil.chown with arguments path, user, group. Availability: Unix. Added in version 3.3. 492\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.13: Added dir_fd and follow_symlinks parameters. shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)\nReturn the path to an executable which would be run if the given cmd was called. If no cmd would be called,\nreturn None. mode is a permission mask passed to os.access(), by default determining if the file exists and is executable. path is a “PATH string” specifying the directories to look in, delimited by os.pathsep. When no path is\nspecified, the PATH environment variable is read from os.environ, falling back to os.defpath if it is not\nset. On Windows, the current directory is prepended to the path if mode does not include os.X_OK. When the\nmode does include os.X_OK, the Windows API NeedCurrentDirectoryForExePathW will be consulted\nto determine if the current directory should be prepended to path. To avoid consulting the current working\ndirectory for executables: set the environment variable NoDefaultCurrentDirectoryInExePath. Also on Windows, the PATHEXT environment variable is used to resolve commands that may not already\ninclude an extension. For example, if you call shutil.which(""python""), which() will search PATHEXT\nto know that it should look for python.exe within the path directories. For example, on Windows:\n>>> shutil.which(""python"")\n\'C:\\\\Python33\\\\python.EXE\'\nThis is also applied when cmd is a path that contains a directory component:\n>> shutil.which(""C:\\\\Python33\\\\python"")\n\'C:\\\\Python33\\\\python.EXE\'\nAdded in version 3.3. Changed in version 3.8: The bytes type is now accepted. If cmd type is bytes, the result type is also bytes. Changed in version 3.12: On Windows, the current directory is no longer prepended to the search path if mode\nincludes os.X_OK and WinAPI NeedCurrentDirectoryForExePathW(cmd) is false, else the current di-\nrectory is prepended even if it is already in the search path; PATHEXT is used now even when cmd includes a\ndirectory component or ends with an extension that is in PATHEXT; and filenames that have no extension can\nnow be found. exception shutil.Error\nThis exception collects exceptions that are raised during a multi-file operation. For copytree(), the exception\nargument is a list of 3-tuples (srcname, dstname, exception). Platform-dependent efficient copy operations\nStarting from Python 3.8, all functions involving a file copy (copyfile(), copy(), copy2(), copytree(), and\nmove()) may use platform-specific “fast-copy” syscalls in order to copy the file more efficiently (see bpo-33671). “fast-copy” means that the copying operation occurs within the kernel, avoiding the use of userspace buffers in Python\nas in “outfd.write(infd.read())”. On macOS fcopyfile is used to copy the file content (not metadata). On Linux os.sendfile() is used. On Windows shutil.copyfile() uses a bigger default buffer size (1 MiB instead of 64 KiB) and a\nmemoryview()-based variant of shutil.copyfileobj() is used.\n\n[3] If dst already exists but is not a directory, it may be overwritten depending on os.rename() semantics. If the destination is on the current filesystem, then os.rename() is used. Otherwise, src is copied to the\ndestination using copy_function and then removed. In case of symlinks, a new symlink pointing to the target\nof src will be created as the destination and src will be removed. If copy_function is given, it must be a callable that takes two arguments, src and the destination, and will\nbe used to copy src to the destination if os.rename() cannot be used. If the source is a directory,\ncopytree() is called, passing it the copy_function. The default copy_function is copy2(). Using copy() as\nthe copy_function allows the move to succeed when it is not possible to also copy the metadata, at the expense\nof not copying any of the metadata. Raises an auditing event shutil.move with arguments src, dst. Changed in version 3.3: Added explicit symlink handling for foreign filesystems, thus adapting it to the behavior\nof GNU’s mv. Now returns dst. Changed in version 3.5: Added the copy_function keyword argument. Changed in version 3.8: Platform-specific fast-copy syscalls may be used internally in order to copy the file\nmore efficiently. See Platform-dependent efficient copy operations section. Changed in version 3.9: Accepts a path-like object for both src and dst. shutil.disk_usage(path)\nReturn disk usage statistics about the given path as a named tuple with the attributes total, used and free, which\nare the amount of total, used and free space, in bytes. path may be a file or a directory. ® Note\nOn Unix filesystems, path must point to a path within a mounted filesystem partition. On those platforms,\nCPython doesn’t attempt to retrieve disk usage information from non-mounted filesystems. Added in version 3.3. Changed in version 3.8: On Windows, path can now be a file or directory. Availability: Unix, Windows. shutil.chown(path, user=None, group=None, *, dir_fd=None, follow_symlinks=True)\nChange owner user and/or group of the given path. user can be a system user name or a uid; the same applies to group. At least one argument is required. See also os.chown(), the underlying function. Raises an auditing event shutil.chown with arguments path, user, group. Availability: Unix. Added in version 3.3. 492\nChapter 11. File and Directory Access\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.13: Added dir_fd and follow_symlinks parameters. shutil.which(cmd, mode=os.F_OK | os.X_OK, path=None)\nReturn the path to an executable which would be run if the given cmd was called. If no cmd would be called,\nreturn None. mode is a permission mask passed to os.access(), by default determining if the file exists and is executable. path is a “PATH string” specifying the directories to look in, delimited by os.pathsep. When no path is\nspecified, the PATH environment variable is read from os.environ, falling back to os.defpath if it is not\nset. On Windows, the current directory is prepended to the path if mode does not include os.X_OK. When the\nmode does include os.X_OK, the Windows API NeedCurrentDirectoryForExePathW will be consulted\nto determine if the current directory should be prepended to path. To avoid consulting the current working\ndirectory for executables: set the environment variable NoDefaultCurrentDirectoryInExePath. Also on Windows, the PATHEXT environment variable is used to resolve commands that may not already\ninclude an extension. For example, if you call shutil.which(""python""), which() will search PATHEXT\nto know that it should look for python.exe within the path directories. For example, on Windows:\n>>> shutil.which(""python"")\n\'C:\\\\Python33\\\\python.EXE\'\nThis is also applied when cmd is a path that contains a directory component:\n>> shutil.which(""C:\\\\Python33\\\\python"")\n\'C:\\\\Python33\\\\python.EXE\'\nAdded in version 3.3. Changed in version 3.8: The bytes type is now accepted. If cmd type is bytes, the result type is also bytes. Changed in version 3.12: On Windows, the current directory is no longer prepended to the search path if mode\nincludes os.X_OK and WinAPI NeedCurrentDirectoryForExePathW(cmd) is false, else the current di-\nrectory is prepended even if it is already in the search path; PATHEXT is used now even when cmd includes a\ndirectory component or ends with an extension that is in PATHEXT; and filenames that have no extension can\nnow be found. exception shutil.Error\nThis exception collects exceptions that are raised during a multi-file operation. For copytree(), the exception\nargument is a list of 3-tuples (srcname, dstname, exception). Platform-dependent efficient copy operations\nStarting from Python 3.8, all functions involving a file copy (copyfile(), copy(), copy2(), copytree(), and\nmove()) may use platform-specific “fast-copy” syscalls in order to copy the file more efficiently (see bpo-33671). “fast-copy” means that the copying operation occurs within the kernel, avoiding the use of userspace buffers in Python\nas in “outfd.write(infd.read())”. On macOS fcopyfile is used to copy the file content (not metadata). On Linux os.sendfile() is used.')",0.0030500066660754076,0.05534677143833277,0.1515481901439163,0.5995430946350098,0.7514976
How do I get the full path of the current file's directory?,"The special variable 
__file__
 contains the path to the current file. From that we can get the directory using either 
pathlib
 or the 
os.path
 module.


Python 3


For the directory of the script being run:


import pathlib
pathlib.Path(__file__).parent.resolve()



For the current working directory:


import pathlib
pathlib.Path().resolve()



Python 2 and 3


For the directory of the script being run:


import os
os.path.dirname(os.path.abspath(__file__))



If you mean the current working directory:


import os
os.path.abspath(os.getcwd())



Note that before and after 
file
 is two underscores, not just one.


Also note that if you are running interactively or have loaded code from something other than a file (eg: a database or online resource), 
__file__
 may not be set since there is no notion of ""current file"". The above answer assumes the most common scenario of running a python script that is in a file.


References




pathlib
 in the python documentation.


os.path - Python 2.7
, 
os.path - Python 3


os.getcwd - Python 2.7
, 
os.getcwd - Python 3


what does the __file__ variable mean/do?



","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . . 436\n11 File and Directory Access\n439\n11.1\npathlib — Object-oriented filesystem paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439\n11.1.1\nBasic use\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440\n11.1.2\nExceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n11.1.3\nPure paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . 430\n10.3\noperator — Standard operators as functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431\n10.3.1\nMapping Operators to Functions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435\n10.3.2\nIn-place Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436\n11 File and Directory Access\n439\n11.1\npathlib — Object-oriented filesystem paths . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . 477\n11.5\ntempfile — Generate temporary files and directories . . . . . . . . . . . . . . . . . . . . . . . 478\n11.5.1\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482\n11.5.2\nDeprecated functions and variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483\n11.6\nglob — Unix style pathname pattern expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 484\n11.6.1\nExamples\n. . . . . . . . . . . . . . . .')",9.711886143672753e-156,0.08888888888888888,0.06606110652353427,0.45774170756340027,0.31820118
Null object in Python,"In Python, the 'null' object is the singleton 
None
.


To check if something is 
None
, use the 
is
 identity operator:


if foo is None:
    ...


","('Answer: The Python None object denotes a lack of value. It is a singleton, and object identity can be tested using `==` in C. There is no `PyNone_Check()` function. `Py_None` has no methods and is immortal. `Py_RETURN_NONE` can be used to return `Py_None` from a function.\n\nReferences: [2, 3]\n', '[1] 8.1.2 The None Object\nNote that the PyTypeObject for None is not directly exposed in the Python/C API. Since None is a singleton,\ntesting for object identity (using == in C) is sufficient. There is no PyNone_Check() function for the same reason. PyObject *Py_None\nThe Python None object, denoting lack of value. This object has no methods and is immortal. Changed in version 3.12: Py_None is immortal. Py_RETURN_NONE\nReturn Py_None from a function. 8.2 Numeric Objects\n8.2.1 Integer Objects\nAll integers are implemented as “long” integer objects of arbitrary size. On error, most PyLong_As* APIs return (return type)-1 which cannot be distinguished from a number. Use\nPyErr_Occurred() to disambiguate. type PyLongObject\nPart of the Limited API (as an opaque struct). This subtype of PyObject represents a Python integer object. PyTypeObject PyLong_Type\nPart of the Stable ABI. This instance of PyTypeObject represents the Python integer type. This is the same\nobject as int in the Python layer. int PyLong_Check(PyObject *p)\nReturn true if its argument is a PyLongObject or a subtype of PyLongObject. This function always suc-\nceeds. int PyLong_CheckExact(PyObject *p)\nReturn true if its argument is a PyLongObject, but not a subtype of PyLongObject. This function always\nsucceeds. PyObject *PyLong_FromLong(long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from v, or NULL on\nfailure. The current implementation keeps an array of integer objects for all integers between -5 and 256. When you\ncreate an int in that range you actually just get back a reference to the existing object. PyObject *PyLong_FromUnsignedLong(unsigned long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong, or NULL on failure. PyObject *PyLong_FromSsize_t(Py_ssize_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C\nPy_ssize_t, or NULL on failure. 8.2. Numeric Objects\n123\n\nThe Python/C API, Release 3.13.2\nPyObject *PyLong_FromSize_t(size_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C size_t,\nor NULL on failure. PyObject *PyLong_FromLongLong(long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C long\nlong, or NULL on failure. PyObject *PyLong_FromUnsignedLongLong(unsigned long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong long, or NULL on failure. PyObject *PyLong_FromDouble(double v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from the integer\npart of v, or NULL on failure. PyObject *PyLong_FromString(const char *str, char **pend, int base)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject based on the string value\nin str, which is interpreted according to the radix in base, or NULL on failure. If pend is non-NULL, *pend will\npoint to the end of str on success or to the first character that could not be processed on error. If base is 0,\nstr is interpreted using the integers definition; in this case, leading zeros in a non-zero decimal number raises\na ValueError. If base is not 0, it must be between 2 and 36, inclusive. Leading and trailing whitespace\nand single underscores after a base specifier and between digits are ignored. If there are no digits or str is not\nNULL-terminated following the digits and trailing whitespace, ValueError will be raised.\n\n[2] Slots other than Py_tp_doc may not be NULL. 8.1.2 The None Object\nNote that the PyTypeObject for None is not directly exposed in the Python/C API. Since None is a singleton,\ntesting for object identity (using == in C) is sufficient. There is no PyNone_Check() function for the same reason. PyObject *Py_None\nThe Python None object, denoting lack of value. This object has no methods and is immortal. Changed in version 3.12: Py_None is immortal. Py_RETURN_NONE\nReturn Py_None from a function. 8.2 Numeric Objects\n8.2.1 Integer Objects\nAll integers are implemented as “long” integer objects of arbitrary size. On error, most PyLong_As* APIs return (return type)-1 which cannot be distinguished from a number. Use\nPyErr_Occurred() to disambiguate. type PyLongObject\nPart of the Limited API (as an opaque struct). This subtype of PyObject represents a Python integer object. PyTypeObject PyLong_Type\nPart of the Stable ABI. This instance of PyTypeObject represents the Python integer type. This is the same\nobject as int in the Python layer. int PyLong_Check(PyObject *p)\nReturn true if its argument is a PyLongObject or a subtype of PyLongObject. This function always suc-\nceeds. int PyLong_CheckExact(PyObject *p)\nReturn true if its argument is a PyLongObject, but not a subtype of PyLongObject. This function always\nsucceeds. PyObject *PyLong_FromLong(long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from v, or NULL on\nfailure. The current implementation keeps an array of integer objects for all integers between -5 and 256. When you\ncreate an int in that range you actually just get back a reference to the existing object. PyObject *PyLong_FromUnsignedLong(unsigned long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong, or NULL on failure. PyObject *PyLong_FromSsize_t(Py_ssize_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C\nPy_ssize_t, or NULL on failure. 8.2. Numeric Objects\n123\n\nThe Python/C API, Release 3.13.2\nPyObject *PyLong_FromSize_t(size_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C size_t,\nor NULL on failure. PyObject *PyLong_FromLongLong(long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C long\nlong, or NULL on failure. PyObject *PyLong_FromUnsignedLongLong(unsigned long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong long, or NULL on failure. PyObject *PyLong_FromDouble(double v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from the integer\npart of v, or NULL on failure. PyObject *PyLong_FromString(const char *str, char **pend, int base)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject based on the string value\nin str, which is interpreted according to the radix in base, or NULL on failure. If pend is non-NULL, *pend will\npoint to the end of str on success or to the first character that could not be processed on error. If base is 0,\nstr is interpreted using the integers definition; in this case, leading zeros in a non-zero decimal number raises\na ValueError. If base is not 0, it must be between 2 and 36, inclusive. Leading and trailing whitespace\nand single underscores after a base specifier and between digits are ignored.\n\n[3] In most cases, this is a pointer to a function. Slots other than Py_tp_doc may not be NULL. 8.1.2 The None Object\nNote that the PyTypeObject for None is not directly exposed in the Python/C API. Since None is a singleton,\ntesting for object identity (using == in C) is sufficient. There is no PyNone_Check() function for the same reason. PyObject *Py_None\nThe Python None object, denoting lack of value. This object has no methods and is immortal. Changed in version 3.12: Py_None is immortal. Py_RETURN_NONE\nReturn Py_None from a function. 8.2 Numeric Objects\n8.2.1 Integer Objects\nAll integers are implemented as “long” integer objects of arbitrary size. On error, most PyLong_As* APIs return (return type)-1 which cannot be distinguished from a number. Use\nPyErr_Occurred() to disambiguate. type PyLongObject\nPart of the Limited API (as an opaque struct). This subtype of PyObject represents a Python integer object. PyTypeObject PyLong_Type\nPart of the Stable ABI. This instance of PyTypeObject represents the Python integer type. This is the same\nobject as int in the Python layer. int PyLong_Check(PyObject *p)\nReturn true if its argument is a PyLongObject or a subtype of PyLongObject. This function always suc-\nceeds. int PyLong_CheckExact(PyObject *p)\nReturn true if its argument is a PyLongObject, but not a subtype of PyLongObject. This function always\nsucceeds. PyObject *PyLong_FromLong(long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from v, or NULL on\nfailure. The current implementation keeps an array of integer objects for all integers between -5 and 256. When you\ncreate an int in that range you actually just get back a reference to the existing object. PyObject *PyLong_FromUnsignedLong(unsigned long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong, or NULL on failure. PyObject *PyLong_FromSsize_t(Py_ssize_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C\nPy_ssize_t, or NULL on failure. 8.2. Numeric Objects\n123\n\nThe Python/C API, Release 3.13.2\nPyObject *PyLong_FromSize_t(size_t v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C size_t,\nor NULL on failure. PyObject *PyLong_FromLongLong(long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C long\nlong, or NULL on failure. PyObject *PyLong_FromUnsignedLongLong(unsigned long long v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from a C unsigned\nlong long, or NULL on failure. PyObject *PyLong_FromDouble(double v)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject object from the integer\npart of v, or NULL on failure. PyObject *PyLong_FromString(const char *str, char **pend, int base)\nReturn value: New reference. Part of the Stable ABI. Return a new PyLongObject based on the string value\nin str, which is interpreted according to the radix in base, or NULL on failure. If pend is non-NULL, *pend will\npoint to the end of str on success or to the first character that could not be processed on error. If base is 0,\nstr is interpreted using the integers definition; in this case, leading zeros in a non-zero decimal number raises\na ValueError. If base is not 0, it must be between 2 and 36, inclusive.')",7.214597600741337e-156,0.019905709795704562,0.0585747899159664,0.4520314335823059,0.6562103
Why can't Python parse this JSON data?,"Your data is not valid 
JSON
 format. You have 
[]
 when you should have 
{}
 for the 
""masks""
 and 
""parameters""
 elements:




[]
 are for JSON arrays, which are called 
list
 in Python


{}
 are for JSON objects, which are called 
dict
 in Python




Here's how your JSON file should look:


{
    ""maps"": [
        {
            ""id"": ""blabla"",
            ""iscategorical"": ""0""
        },
        {
            ""id"": ""blabla"",
            ""iscategorical"": ""0""
        }
    ],
    ""masks"": {
        ""id"": ""valore""
    },
    ""om_points"": ""value"",
    ""parameters"": {
        ""id"": ""valore""
    }
}



Then you can use your code:


import json
from pprint import pprint

with open('data.json') as f:
    data = json.load(f)

pprint(data)



With data, you can now also find values like so:


data[""maps""][0][""id""]
data[""masks""][""id""]
data[""om_points""]



Try those out and see if it starts to make sense.

","('Answer: If the data being deserialized is not a valid JSON document, a JSONDecodeError will be raised.\n\nReferences: [2, 3]\n', '[1] 20.2 json — JSON encoder and decoder\nSource code: Lib/json/__init__.py\nJSON (JavaScript Object Notation), specified by RFC 7159 (which obsoletes RFC 4627) and by ECMA-404, is a\nlightweight data interchange format inspired by JavaScript object literal syntax (although it is not a strict subset of\nJavaScript1 ). 1 As noted in the errata for RFC 7159, JSON permits literal U+2028 (LINE SEPARATOR) and U+2029 (PARAGRAPH SEPARATOR)\ncharacters in strings, whereas JavaScript (as of ECMAScript Edition 5.1) does not. 20.2. json — JSON encoder and decoder\n1289\n\nThe Python Library Reference, Release 3.13.2\nÁ Warning\nBe cautious when parsing JSON data from untrusted sources. A malicious JSON string may cause the decoder\nto consume considerable CPU and memory resources. Limiting the size of data to be parsed is recommended. json exposes an API familiar to users of the standard library marshal and pickle modules. Encoding basic Python object hierarchies:\n>>> import json\n>>> json.dumps([\'foo\', {\'bar\': (\'baz\', None, 1.0, 2)}])\n\'[""foo"", {""bar"": [""baz"", null, 1.0, 2]}]\'\n>>> print(json.dumps(""\\""foo\\bar""))\n""\\""foo\\bar""\n>>> print(json.dumps(\'\\u1234\'))\n""\\u1234""\n>>> print(json.dumps(\'\\\\\'))\n""\\\\""\n>>> print(json.dumps({""c"": 0, ""b"": 0, ""a"": 0}, sort_keys=True))\n{""a"": 0, ""b"": 0, ""c"": 0}\n>>> from io import StringIO\n>>> io = StringIO()\n>>> json.dump([\'streaming API\'], io)\n>>> io.getvalue()\n\'[""streaming API""]\'\nCompact encoding:\n>>> import json\n>>> json.dumps([1, 2, 3, {\'4\': 5, \'6\': 7}], separators=(\',\', \':\'))\n\'[1,2,3,{""4"":5,""6"":7}]\'\nPretty printing:\n>>> import json\n>>> print(json.dumps({\'6\': 7, \'4\': 5}, sort_keys=True, indent=4))\n{\n""4"": 5,\n""6"": 7\n}\nSpecializing JSON object encoding:\n>>> import json\n>>> def custom_json(obj):\n...\nif isinstance(obj, complex):\n...\nreturn {\'__complex__\': True, \'real\': obj.real, \'imag\': obj.imag}\n...\nraise TypeError(f\'Cannot serialize object of {type(obj)}\')\n...\n>>> json.dumps(1 + 2j, default=custom_json)\n\'{""__complex__"": true, ""real"": 1.0, ""imag"": 2.0}\'\nDecoding JSON:\n>>> import json\n>>> json.loads(\'[""foo"", {""bar"":[""baz"", null, 1.0, 2]}]\')\n[\'foo\', {\'bar\': [\'baz\', None, 1.0, 2]}]\n>>> json.loads(\'""\\\\""foo\\\\bar""\')\n(continues on next page)\n1290\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n\'""foo\\x08ar\'\n>>> from io import StringIO\n>>> io = StringIO(\'[""streaming API""]\')\n>>> json.load(io)\n[\'streaming API\']\nSpecializing JSON object decoding:\n>>> import json\n>>> def as_complex(dct):\n...\nif \'__complex__\' in dct:\n...\nreturn complex(dct[\'real\'], dct[\'imag\'])\n...\nreturn dct\n...\n>>> json.loads(\'{""__complex__"": true, ""real"": 1, ""imag"": 2}\',\n...\nobject_hook=as_complex)\n(1+2j)\n>>> import decimal\n>>> json.loads(\'1.1\', parse_float=decimal.Decimal)\nDecimal(\'1.1\')\nExtending JSONEncoder:\n>>> import json\n>>> class ComplexEncoder(json.JSONEncoder):\n...\ndef default(self, obj):\n...\nif isinstance(obj, complex):\n...\nreturn [obj.real, obj.imag]\n...\n# Let the base class default method raise the TypeError\n...\nreturn super().default(obj)\n...\n>>> json.dumps(2 + 1j, cls=ComplexEncoder)\n\'[2.0, 1.0]\'\n>>> ComplexEncoder().encode(2 + 1j)\n\'[2.0, 1.0]\'\n>>> list(ComplexEncoder().iterencode(2 + 1j))\n[\'[2.0\', \', 1.0\', \']\']\nUsing json.tool from the shell to validate and pretty-print:\n$ echo \'{""json"":""obj""}\' | python -m json.tool\n{\n""json"": ""obj""\n}\n$ echo \'{1.2:3.4}\' | python -m json.tool\nExpecting property name enclosed in double quotes: line 1 column 2 (char 1)\nSee Command Line Interface for detailed documentation. ® Note\nJSON is a subset of YAML 1.2. The JSON produced by this module’s default settings (in particular, the default\nseparators value) is also a subset of YAML 1.0 and 1.1. This module can thus also be used as a YAML serializer. 20.2. json — JSON encoder and decoder\n1291\n\nThe Python Library Reference, Release 3.13.2\n® Note\nThis module’s encoders and decoders preserve input and output order by default. Order is only lost if the under-\nlying containers are unordered. 20.2.1 Basic Usage\njson.dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj as a JSON formatted stream to fp (a .write()-supporting file-like object) using this Python-to-\nJSON conversion table. ® Note\nUnlike pickle and marshal, JSON is not a framed protocol, so trying to serialize multiple objects with\nrepeated calls to dump() using the same fp will result in an invalid JSON file. Parameters\n• obj (object) – The Python object to be serialized. • fp (file-like object) – The file-like object obj will be serialized to. The json module always\nproduces str objects, not bytes objects, therefore fp.write() must support str input. • skipkeys (bool) – If True, keys that are not of a basic type (str, int, float, bool,\nNone) will be skipped instead of raising a TypeError. Default False. • ensure_ascii (bool) – If True (the default), the output is guaranteed to have all in-\ncoming non-ASCII characters escaped. If False, these characters will be outputted as-is. • check_circular (bool) – If False, the circular reference check for container types\nis skipped and a circular reference will result in a RecursionError (or worse). Default\nTrue. • allow_nan (bool) – If False, serialization of out-of-range float values (nan, inf,\n-inf) will result in a ValueError, in strict compliance with the JSON specification. If\nTrue (the default), their JavaScript equivalents (NaN, Infinity, -Infinity) are used. • cls (a JSONEncoder subclass) – If set, a custom JSON encoder with the default()\nmethod overridden, for serializing into custom datatypes. If None (the default),\nJSONEncoder is used. • indent (int | str | None) – If a positive integer or string, JSON array elements and\nobject members will be pretty-printed with that indent level. A positive integer indents\nthat many spaces per level; a string (such as ""\\t"") is used to indent each level. If zero,\nnegative, or """" (the empty string), only newlines are inserted. If None (the default), the\nmost compact representation is used. • separators\n(tuple | None)\n–\nA\ntwo-tuple:\n(item_separator,\nkey_separator). If None (the default), separators defaults to (\', \', \': \')\nif indent is None, and (\',\', \': \') otherwise. For the most compact JSON, specify\n(\',\', \':\') to eliminate whitespace. • default (callable | None) – A function that is called for objects that can’t otherwise be\nserialized. It should return a JSON encodable version of the object or raise a TypeError. If None (the default), TypeError is raised. • sort_keys (bool) – If True, dictionaries will be outputted sorted by key. Default\nFalse. Changed in version 3.2: Allow strings for indent in addition to integers. 1292\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.4: Use (\',\', \': \') as default if indent is not None. Changed in version 3.6: All optional parameters are now keyword-only. json.dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None,\nindent=None, separators=None, default=None, sort_keys=False, **kw)\nSerialize obj to a JSON formatted str using this conversion table. The arguments have the same meaning as\nin dump(). ® Note\nKeys in key/value pairs of JSON are always of the type str. When a dictionary is converted into JSON, all\nthe keys of the dictionary are coerced to strings. As a result of this, if a dictionary is converted into JSON\nand then back into a dictionary, the dictionary may not equal the original one. That is, loads(dumps(x))\n!= x if x has non-string keys. json.load(fp, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nDeserialize fp to a Python object using the JSON-to-Python conversion table.\n\n[2] Raises\n• JSONDecodeError – When the data being deserialized is not a valid JSON document. • UnicodeDecodeError – When the data being deserialized does not contain UTF-8,\nUTF-16 or UTF-32 encoded data. Changed in version 3.1:\n• Added the optional object_pairs_hook parameter. • parse_constant doesn’t get called on ‘null’, ‘true’, ‘false’ anymore. 20.2. json — JSON encoder and decoder\n1293\n\nThe Python Library Reference, Release 3.13.2\nChanged in version 3.6:\n• All optional parameters are now keyword-only. • fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of int() now limits the maximum length of the integer string\nvia the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nIdentical to load(), but instead of a file-like object, deserialize s (a str, bytes or bytearray instance\ncontaining a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type bytes or bytearray. The input encoding should be UTF-8,\nUTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed. 20.2.2 Encoders and Decoders\nclass json.JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nstrict=True, object_pairs_hook=None)\nSimple JSON decoder. Performs the following translations in decoding by default:\nJSON\nPython\nobject\ndict\narray\nlist\nstring\nstr\nnumber (int)\nint\nnumber (real)\nfloat\ntrue\nTrue\nfalse\nFalse\nnull\nNone\nIt also understands NaN, Infinity, and -Infinity as their corresponding float values, which is outside\nthe JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its\nreturn value will be used in place of the given dict. This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with\nan ordered list of pairs. The return value of object_pairs_hook will be used instead of the dict. This feature\ncan be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. Changed in version 3.1: Added support for object_pairs_hook. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By\ndefault, this is equivalent to float(num_str). This can be used to use another datatype or parser for JSON\nfloats (e.g. decimal.Decimal). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default,\nthis is equivalent to int(num_str). This can be used to use another datatype or parser for JSON integers\n(e.g. float). parse_constant is an optional function that will be called with one of the following strings: \'-Infinity\',\n\'Infinity\', \'NaN\'. This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false (True is the default), then control characters will be allowed inside strings. Control characters\nin this context are those with character codes in the 0–31 range, including \'\\t\' (tab), \'\\n\', \'\\r\' and \'\\0\'. 1294\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nIf the data being deserialized is not a valid JSON document, a JSONDecodeError will be raised. Changed in version 3.6: All parameters are now keyword-only. decode(s)\nReturn the Python representation of s (a str instance containing a JSON document). JSONDecodeError will be raised if the given JSON document is not valid. raw_decode(s)\nDecode a JSON document from s (a str beginning with a JSON document) and return a 2-tuple of the\nPython representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. class json.JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True,\nsort_keys=False, indent=None, separators=None, default=None)\nExtensible JSON encoder for Python data structures. Supports the following objects and types by default:\nPython\nJSON\ndict\nobject\nlist, tuple\narray\nstr\nstring\nint, float, int- & float-derived Enums\nnumber\nTrue\ntrue\nFalse\nfalse\nNone\nnull\nChanged in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a default() method with another method\nthat returns a serializable object for o if possible, otherwise it should call the superclass implementation (to\nraise TypeError). If skipkeys is false (the default), a TypeError will be raised when trying to encode keys that are not str, int,\nfloat or None. If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for cir-\ncular references during encoding to prevent an infinite recursion (which would cause a RecursionError). Otherwise, no such check takes place. If allow_nan is true (the default), then NaN, Infinity, and -Infinity will be encoded as such.\n\n[3] • fp can now be a binary file. The input encoding should be UTF-8, UTF-16 or UTF-32. Changed in version 3.11: The default parse_int of int() now limits the maximum length of the integer string\nvia the interpreter’s integer string conversion length limitation to help avoid denial of service attacks. json.loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nobject_pairs_hook=None, **kw)\nIdentical to load(), but instead of a file-like object, deserialize s (a str, bytes or bytearray instance\ncontaining a JSON document) to a Python object using this conversion table. Changed in version 3.6: s can now be of type bytes or bytearray. The input encoding should be UTF-8,\nUTF-16 or UTF-32. Changed in version 3.9: The keyword argument encoding has been removed. 20.2.2 Encoders and Decoders\nclass json.JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None,\nstrict=True, object_pairs_hook=None)\nSimple JSON decoder. Performs the following translations in decoding by default:\nJSON\nPython\nobject\ndict\narray\nlist\nstring\nstr\nnumber (int)\nint\nnumber (real)\nfloat\ntrue\nTrue\nfalse\nFalse\nnull\nNone\nIt also understands NaN, Infinity, and -Infinity as their corresponding float values, which is outside\nthe JSON spec. object_hook is an optional function that will be called with the result of every JSON object decoded and its\nreturn value will be used in place of the given dict. This can be used to provide custom deserializations (e.g. to support JSON-RPC class hinting). object_pairs_hook is an optional function that will be called with the result of every JSON object decoded with\nan ordered list of pairs. The return value of object_pairs_hook will be used instead of the dict. This feature\ncan be used to implement custom decoders. If object_hook is also defined, the object_pairs_hook takes priority. Changed in version 3.1: Added support for object_pairs_hook. parse_float is an optional function that will be called with the string of every JSON float to be decoded. By\ndefault, this is equivalent to float(num_str). This can be used to use another datatype or parser for JSON\nfloats (e.g. decimal.Decimal). parse_int is an optional function that will be called with the string of every JSON int to be decoded. By default,\nthis is equivalent to int(num_str). This can be used to use another datatype or parser for JSON integers\n(e.g. float). parse_constant is an optional function that will be called with one of the following strings: \'-Infinity\',\n\'Infinity\', \'NaN\'. This can be used to raise an exception if invalid JSON numbers are encountered. If strict is false (True is the default), then control characters will be allowed inside strings. Control characters\nin this context are those with character codes in the 0–31 range, including \'\\t\' (tab), \'\\n\', \'\\r\' and \'\\0\'. 1294\nChapter 20. Internet Data Handling\n\nThe Python Library Reference, Release 3.13.2\nIf the data being deserialized is not a valid JSON document, a JSONDecodeError will be raised. Changed in version 3.6: All parameters are now keyword-only. decode(s)\nReturn the Python representation of s (a str instance containing a JSON document). JSONDecodeError will be raised if the given JSON document is not valid. raw_decode(s)\nDecode a JSON document from s (a str beginning with a JSON document) and return a 2-tuple of the\nPython representation and the index in s where the document ended. This can be used to decode a JSON document from a string that may have extraneous data at the end. class json.JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True,\nsort_keys=False, indent=None, separators=None, default=None)\nExtensible JSON encoder for Python data structures. Supports the following objects and types by default:\nPython\nJSON\ndict\nobject\nlist, tuple\narray\nstr\nstring\nint, float, int- & float-derived Enums\nnumber\nTrue\ntrue\nFalse\nfalse\nNone\nnull\nChanged in version 3.4: Added support for int- and float-derived Enum classes. To extend this to recognize other objects, subclass and implement a default() method with another method\nthat returns a serializable object for o if possible, otherwise it should call the superclass implementation (to\nraise TypeError). If skipkeys is false (the default), a TypeError will be raised when trying to encode keys that are not str, int,\nfloat or None. If skipkeys is true, such items are simply skipped. If ensure_ascii is true (the default), the output is guaranteed to have all incoming non-ASCII characters escaped. If ensure_ascii is false, these characters will be output as-is. If check_circular is true (the default), then lists, dicts, and custom encoded objects will be checked for cir-\ncular references during encoding to prevent an infinite recursion (which would cause a RecursionError). Otherwise, no such check takes place. If allow_nan is true (the default), then NaN, Infinity, and -Infinity will be encoded as such. This behav-\nior is not JSON specification compliant, but is consistent with most JavaScript based encoders and decoders. Otherwise, it will be a ValueError to encode such floats. If sort_keys is true (default: False), then the output of dictionaries will be sorted by key; this is useful for\nregression tests to ensure that JSON serializations can be compared on a day-to-day basis. If indent is a non-negative integer or string, then JSON array elements and object members will be pretty-\nprinted with that indent level. An indent level of 0, negative, or """" will only insert newlines.')",1.1828078689478234e-155,0.030231179608772966,0.15956571804573122,0.5709384083747864,0.3491327
"What is the use of ""assert"" in Python?","The 
assert
 statement exists in almost every programming language. It has two main uses:




It helps detect problems early in your program, where the cause is clear, rather than later when some other operation fails. A type error in Python, for example, can go through several layers of code before actually raising an 
Exception
 if not caught early on.




It works as documentation for other developers reading the code, who see the 
assert
 and can confidently say that its condition holds from now on.






When you do...


assert condition



... you're telling the program to test that condition, and immediately trigger an error if the condition is false.


In Python, it's roughly equivalent to this:


if not condition:
    raise AssertionError()



Try it in the Python shell:


>>> assert True # nothing happens
>>> assert False
Traceback (most recent call last):
  File ""
"", line 1, in 

AssertionError



Assertions can include an optional message, and you can disable them when running the interpreter.


To print a message if the assertion fails:


assert False, ""Oh no! This assertion failed!""



Do 
not
 use parenthesis to call 
assert
 like a function. It is a statement. If you do 
assert(condition, message)
 you'll be running the 
assert
 with a 
(condition, message)
 tuple as first parameter.


As for disabling them, when running 
python
 in optimized mode, where 
__debug__
 is 
False
, assert statements will be ignored. Just pass the 
-O
 flag:


python -O script.py



See 
here
 for the relevant documentation.

","('Answer: The TestCase class in Python provides several assert methods to check for and report failures.\n\nReferences: [3]\n', '[1] msg and params are\noptional, arbitrary values which are displayed whenever a subtest fails, allowing you to identify them\nclearly. A test case can contain any number of subtest declarations, and they can be arbitrarily nested. See Distinguishing test iterations using subtests for more information. Added in version 3.4.\ndebug()\nRun the test without collecting the result. This allows exceptions raised by the test to be propagated to\nthe caller, and can be used to support running tests under a debugger. The TestCase class provides several assert methods to check for and report failures. The following table lists\nthe most commonly used methods (see the tables below for more assert methods):\n27.5. unittest — Unit testing framework\n1741\n\nThe Python Library Reference, Release 3.13.2\nMethod\nChecks that\nNew in\nassertEqual(a, b)\na == b\nassertNotEqual(a, b)\na != b\nassertTrue(x)\nbool(x) is True\nassertFalse(x)\nbool(x) is False\nassertIs(a, b)\na is b\n3.1\nassertIsNot(a, b)\na is not b\n3.1\nassertIsNone(x)\nx is None\n3.1\nassertIsNotNone(x)\nx is not None\n3.1\nassertIn(a, b)\na in b\n3.1\nassertNotIn(a, b)\na not in b\n3.1\nassertIsInstance(a, b)\nisinstance(a, b)\n3.2\nassertNotIsInstance(a, b)\nnot isinstance(a, b)\n3.2\nAll the assert methods accept a msg argument that, if specified, is used as the error message on fail-\nure (see also longMessage). Note that the msg keyword argument can be passed to assertRaises(),\nassertRaisesRegex(), assertWarns(), assertWarnsRegex() only when they are used as a context\nmanager. assertEqual(first, second, msg=None)\nTest that first and second are equal. If the values do not compare equal, the test will fail. In addition, if first and second are the exact same type and one of list, tuple, dict, set, frozenset or str\nor any type that a subclass registers with addTypeEqualityFunc() the type-specific equality function\nwill be called in order to generate a more useful default error message (see also the list of type-specific\nmethods). Changed in version 3.1: Added the automatic calling of type-specific equality function. Changed in version 3.2: assertMultiLineEqual() added as the default type equality function for\ncomparing strings. assertNotEqual(first, second, msg=None)\nTest that first and second are not equal. If the values do compare equal, the test will fail. assertTrue(expr, msg=None)\nassertFalse(expr, msg=None)\nTest that expr is true (or false). Note\nthat\nthis\nis\nequivalent\nto\nbool(expr) is True\nand\nnot\nto\nexpr is True\n(use\nassertIs(expr, True) for the latter). This method should also be avoided when more spe-\ncific methods are available (e.g. assertEqual(a, b) instead of assertTrue(a == b)), because\nthey provide a better error message in case of failure. assertIs(first, second, msg=None)\nassertIsNot(first, second, msg=None)\nTest that first and second are (or are not) the same object. Added in version 3.1.\nassertIsNone(expr, msg=None)\nassertIsNotNone(expr, msg=None)\nTest that expr is (or is not) None. Added in version 3.1.\nassertIn(member, container, msg=None)\nassertNotIn(member, container, msg=None)\nTest that member is (or is not) in container. Added in version 3.1. 1742\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nassertIsInstance(obj, cls, msg=None)\nassertNotIsInstance(obj, cls, msg=None)\nTest that obj is (or is not) an instance of cls (which can be a class or a tuple of classes, as supported by\nisinstance()). To check for the exact type, use assertIs(type(obj), cls). Added in version 3.2. It is also possible to check the production of exceptions, warnings, and log messages using the following meth-\nods:\nMethod\nChecks that\nNew in\nassertRaises(exc, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nexc\nassertRaisesRegex(exc,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nexc and the message matches\nregex r\n3.1\nassertWarns(warn, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nwarn\n3.2\nassertWarnsRegex(warn,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nwarn and the message matches\nregex r\n3.2\nassertLogs(logger,\nlevel)\nThe with block logs on logger\nwith minimum level\n3.4\nassertNoLogs(logger,\nlevel)\nThe with block does not log on\nlogger with minimum level\n3.10\nassertRaises(exception, callable, *args, **kwds)\nassertRaises(exception, *, msg=None)\nTest that an exception is raised when callable is called with any positional or keyword arguments that are\nalso passed to assertRaises(). The test passes if exception is raised, is an error if another exception\nis raised, or fails if no exception is raised. To catch any of a group of exceptions, a tuple containing the\nexception classes may be passed as exception. If only the exception and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertRaises(SomeException):\ndo_something()\nWhen used as a context manager, assertRaises() accepts the additional keyword argument msg. The context manager will store the caught exception object in its exception attribute. This can be\nuseful if the intention is to perform additional checks on the exception raised:\nwith self.assertRaises(SomeException) as cm:\ndo_something()\nthe_exception = cm.exception\nself.assertEqual(the_exception.error_code, 3)\nChanged in version 3.1: Added the ability to use assertRaises() as a context manager. Changed in version 3.2: Added the exception attribute. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertRaisesRegex(exception, regex, callable, *args, **kwds)\n27.5. unittest — Unit testing framework\n1743\n\nThe Python Library Reference, Release 3.13.2\nassertRaisesRegex(exception, regex, *, msg=None)\nLike assertRaises() but also tests that regex matches on the string representation of the raised ex-\nception. regex may be a regular expression object or a string containing a regular expression suitable for\nuse by re.search(). Examples:\nself.assertRaisesRegex(ValueError, ""invalid literal for. *XYZ\'$"",\nint, \'XYZ\')\nor:\nwith self.assertRaisesRegex(ValueError, \'literal\'):\nint(\'XYZ\')\nAdded in version 3.1: Added under the name assertRaisesRegexp. Changed in version 3.2: Renamed to assertRaisesRegex(). Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarns(warning, callable, *args, **kwds)\nassertWarns(warning, *, msg=None)\nTest that a warning is triggered when callable is called with any positional or keyword arguments that\nare also passed to assertWarns(). The test passes if warning is triggered and fails if it isn’t. Any\nexception is an error. To catch any of a group of warnings, a tuple containing the warning classes may\nbe passed as warnings. If only the warning and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertWarns(SomeWarning):\ndo_something()\nWhen used as a context manager, assertWarns() accepts the additional keyword argument msg. The context manager will store the caught warning object in its warning attribute, and the source line\nwhich triggered the warnings in the filename and lineno attributes. This can be useful if the intention\nis to perform additional checks on the warning caught:\nwith self.assertWarns(SomeWarning) as cm:\ndo_something()\nself.assertIn(\'myfile.py\', cm.filename)\nself.assertEqual(320, cm.lineno)\nThis method works regardless of the warning filters in place when it is called. Added in version 3.2. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarnsRegex(warning, regex, callable, *args, **kwds)\nassertWarnsRegex(warning, regex, *, msg=None)\nLike assertWarns() but also tests that regex matches on the message of the triggered warning.\n\n[2] The following table lists\nthe most commonly used methods (see the tables below for more assert methods):\n27.5. unittest — Unit testing framework\n1741\n\nThe Python Library Reference, Release 3.13.2\nMethod\nChecks that\nNew in\nassertEqual(a, b)\na == b\nassertNotEqual(a, b)\na != b\nassertTrue(x)\nbool(x) is True\nassertFalse(x)\nbool(x) is False\nassertIs(a, b)\na is b\n3.1\nassertIsNot(a, b)\na is not b\n3.1\nassertIsNone(x)\nx is None\n3.1\nassertIsNotNone(x)\nx is not None\n3.1\nassertIn(a, b)\na in b\n3.1\nassertNotIn(a, b)\na not in b\n3.1\nassertIsInstance(a, b)\nisinstance(a, b)\n3.2\nassertNotIsInstance(a, b)\nnot isinstance(a, b)\n3.2\nAll the assert methods accept a msg argument that, if specified, is used as the error message on fail-\nure (see also longMessage). Note that the msg keyword argument can be passed to assertRaises(),\nassertRaisesRegex(), assertWarns(), assertWarnsRegex() only when they are used as a context\nmanager. assertEqual(first, second, msg=None)\nTest that first and second are equal. If the values do not compare equal, the test will fail. In addition, if first and second are the exact same type and one of list, tuple, dict, set, frozenset or str\nor any type that a subclass registers with addTypeEqualityFunc() the type-specific equality function\nwill be called in order to generate a more useful default error message (see also the list of type-specific\nmethods). Changed in version 3.1: Added the automatic calling of type-specific equality function. Changed in version 3.2: assertMultiLineEqual() added as the default type equality function for\ncomparing strings. assertNotEqual(first, second, msg=None)\nTest that first and second are not equal. If the values do compare equal, the test will fail. assertTrue(expr, msg=None)\nassertFalse(expr, msg=None)\nTest that expr is true (or false). Note\nthat\nthis\nis\nequivalent\nto\nbool(expr) is True\nand\nnot\nto\nexpr is True\n(use\nassertIs(expr, True) for the latter). This method should also be avoided when more spe-\ncific methods are available (e.g. assertEqual(a, b) instead of assertTrue(a == b)), because\nthey provide a better error message in case of failure. assertIs(first, second, msg=None)\nassertIsNot(first, second, msg=None)\nTest that first and second are (or are not) the same object. Added in version 3.1.\nassertIsNone(expr, msg=None)\nassertIsNotNone(expr, msg=None)\nTest that expr is (or is not) None. Added in version 3.1.\nassertIn(member, container, msg=None)\nassertNotIn(member, container, msg=None)\nTest that member is (or is not) in container. Added in version 3.1. 1742\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nassertIsInstance(obj, cls, msg=None)\nassertNotIsInstance(obj, cls, msg=None)\nTest that obj is (or is not) an instance of cls (which can be a class or a tuple of classes, as supported by\nisinstance()). To check for the exact type, use assertIs(type(obj), cls). Added in version 3.2. It is also possible to check the production of exceptions, warnings, and log messages using the following meth-\nods:\nMethod\nChecks that\nNew in\nassertRaises(exc, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nexc\nassertRaisesRegex(exc,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nexc and the message matches\nregex r\n3.1\nassertWarns(warn, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nwarn\n3.2\nassertWarnsRegex(warn,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nwarn and the message matches\nregex r\n3.2\nassertLogs(logger,\nlevel)\nThe with block logs on logger\nwith minimum level\n3.4\nassertNoLogs(logger,\nlevel)\nThe with block does not log on\nlogger with minimum level\n3.10\nassertRaises(exception, callable, *args, **kwds)\nassertRaises(exception, *, msg=None)\nTest that an exception is raised when callable is called with any positional or keyword arguments that are\nalso passed to assertRaises(). The test passes if exception is raised, is an error if another exception\nis raised, or fails if no exception is raised. To catch any of a group of exceptions, a tuple containing the\nexception classes may be passed as exception. If only the exception and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertRaises(SomeException):\ndo_something()\nWhen used as a context manager, assertRaises() accepts the additional keyword argument msg. The context manager will store the caught exception object in its exception attribute. This can be\nuseful if the intention is to perform additional checks on the exception raised:\nwith self.assertRaises(SomeException) as cm:\ndo_something()\nthe_exception = cm.exception\nself.assertEqual(the_exception.error_code, 3)\nChanged in version 3.1: Added the ability to use assertRaises() as a context manager. Changed in version 3.2: Added the exception attribute. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertRaisesRegex(exception, regex, callable, *args, **kwds)\n27.5. unittest — Unit testing framework\n1743\n\nThe Python Library Reference, Release 3.13.2\nassertRaisesRegex(exception, regex, *, msg=None)\nLike assertRaises() but also tests that regex matches on the string representation of the raised ex-\nception. regex may be a regular expression object or a string containing a regular expression suitable for\nuse by re.search(). Examples:\nself.assertRaisesRegex(ValueError, ""invalid literal for. *XYZ\'$"",\nint, \'XYZ\')\nor:\nwith self.assertRaisesRegex(ValueError, \'literal\'):\nint(\'XYZ\')\nAdded in version 3.1: Added under the name assertRaisesRegexp. Changed in version 3.2: Renamed to assertRaisesRegex(). Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarns(warning, callable, *args, **kwds)\nassertWarns(warning, *, msg=None)\nTest that a warning is triggered when callable is called with any positional or keyword arguments that\nare also passed to assertWarns(). The test passes if warning is triggered and fails if it isn’t. Any\nexception is an error. To catch any of a group of warnings, a tuple containing the warning classes may\nbe passed as warnings. If only the warning and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertWarns(SomeWarning):\ndo_something()\nWhen used as a context manager, assertWarns() accepts the additional keyword argument msg. The context manager will store the caught warning object in its warning attribute, and the source line\nwhich triggered the warnings in the filename and lineno attributes. This can be useful if the intention\nis to perform additional checks on the warning caught:\nwith self.assertWarns(SomeWarning) as cm:\ndo_something()\nself.assertIn(\'myfile.py\', cm.filename)\nself.assertEqual(320, cm.lineno)\nThis method works regardless of the warning filters in place when it is called. Added in version 3.2. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarnsRegex(warning, regex, callable, *args, **kwds)\nassertWarnsRegex(warning, regex, *, msg=None)\nLike assertWarns() but also tests that regex matches on the message of the triggered warning. regex\nmay be a regular expression object or a string containing a regular expression suitable for use by re. search(). Example:\nself.assertWarnsRegex(DeprecationWarning,\nr\'legacy_function\\(\\) is deprecated\',\nlegacy_function, \'XYZ\')\nor:\n1744\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nwith self.assertWarnsRegex(RuntimeWarning, \'unsafe frobnicating\'):\nfrobnicate(\'/etc/passwd\')\nAdded in version 3.2. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertLogs(logger=None, level=None)\nA context manager to test that at least one message is logged on the logger or one of its children, with at\nleast the given level.\n\n[3] See Distinguishing test iterations using subtests for more information. Added in version 3.4.\ndebug()\nRun the test without collecting the result. This allows exceptions raised by the test to be propagated to\nthe caller, and can be used to support running tests under a debugger. The TestCase class provides several assert methods to check for and report failures. The following table lists\nthe most commonly used methods (see the tables below for more assert methods):\n27.5. unittest — Unit testing framework\n1741\n\nThe Python Library Reference, Release 3.13.2\nMethod\nChecks that\nNew in\nassertEqual(a, b)\na == b\nassertNotEqual(a, b)\na != b\nassertTrue(x)\nbool(x) is True\nassertFalse(x)\nbool(x) is False\nassertIs(a, b)\na is b\n3.1\nassertIsNot(a, b)\na is not b\n3.1\nassertIsNone(x)\nx is None\n3.1\nassertIsNotNone(x)\nx is not None\n3.1\nassertIn(a, b)\na in b\n3.1\nassertNotIn(a, b)\na not in b\n3.1\nassertIsInstance(a, b)\nisinstance(a, b)\n3.2\nassertNotIsInstance(a, b)\nnot isinstance(a, b)\n3.2\nAll the assert methods accept a msg argument that, if specified, is used as the error message on fail-\nure (see also longMessage). Note that the msg keyword argument can be passed to assertRaises(),\nassertRaisesRegex(), assertWarns(), assertWarnsRegex() only when they are used as a context\nmanager. assertEqual(first, second, msg=None)\nTest that first and second are equal. If the values do not compare equal, the test will fail. In addition, if first and second are the exact same type and one of list, tuple, dict, set, frozenset or str\nor any type that a subclass registers with addTypeEqualityFunc() the type-specific equality function\nwill be called in order to generate a more useful default error message (see also the list of type-specific\nmethods). Changed in version 3.1: Added the automatic calling of type-specific equality function. Changed in version 3.2: assertMultiLineEqual() added as the default type equality function for\ncomparing strings. assertNotEqual(first, second, msg=None)\nTest that first and second are not equal. If the values do compare equal, the test will fail. assertTrue(expr, msg=None)\nassertFalse(expr, msg=None)\nTest that expr is true (or false). Note\nthat\nthis\nis\nequivalent\nto\nbool(expr) is True\nand\nnot\nto\nexpr is True\n(use\nassertIs(expr, True) for the latter). This method should also be avoided when more spe-\ncific methods are available (e.g. assertEqual(a, b) instead of assertTrue(a == b)), because\nthey provide a better error message in case of failure. assertIs(first, second, msg=None)\nassertIsNot(first, second, msg=None)\nTest that first and second are (or are not) the same object. Added in version 3.1.\nassertIsNone(expr, msg=None)\nassertIsNotNone(expr, msg=None)\nTest that expr is (or is not) None. Added in version 3.1.\nassertIn(member, container, msg=None)\nassertNotIn(member, container, msg=None)\nTest that member is (or is not) in container. Added in version 3.1. 1742\nChapter 27. Development Tools\n\nThe Python Library Reference, Release 3.13.2\nassertIsInstance(obj, cls, msg=None)\nassertNotIsInstance(obj, cls, msg=None)\nTest that obj is (or is not) an instance of cls (which can be a class or a tuple of classes, as supported by\nisinstance()). To check for the exact type, use assertIs(type(obj), cls). Added in version 3.2. It is also possible to check the production of exceptions, warnings, and log messages using the following meth-\nods:\nMethod\nChecks that\nNew in\nassertRaises(exc, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nexc\nassertRaisesRegex(exc,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nexc and the message matches\nregex r\n3.1\nassertWarns(warn, fun,\n*args, **kwds)\nfun(*args, **kwds)\nraises\nwarn\n3.2\nassertWarnsRegex(warn,\nr, fun, *args, **kwds)\nfun(*args, **kwds)\nraises\nwarn and the message matches\nregex r\n3.2\nassertLogs(logger,\nlevel)\nThe with block logs on logger\nwith minimum level\n3.4\nassertNoLogs(logger,\nlevel)\nThe with block does not log on\nlogger with minimum level\n3.10\nassertRaises(exception, callable, *args, **kwds)\nassertRaises(exception, *, msg=None)\nTest that an exception is raised when callable is called with any positional or keyword arguments that are\nalso passed to assertRaises(). The test passes if exception is raised, is an error if another exception\nis raised, or fails if no exception is raised. To catch any of a group of exceptions, a tuple containing the\nexception classes may be passed as exception. If only the exception and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertRaises(SomeException):\ndo_something()\nWhen used as a context manager, assertRaises() accepts the additional keyword argument msg. The context manager will store the caught exception object in its exception attribute. This can be\nuseful if the intention is to perform additional checks on the exception raised:\nwith self.assertRaises(SomeException) as cm:\ndo_something()\nthe_exception = cm.exception\nself.assertEqual(the_exception.error_code, 3)\nChanged in version 3.1: Added the ability to use assertRaises() as a context manager. Changed in version 3.2: Added the exception attribute. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertRaisesRegex(exception, regex, callable, *args, **kwds)\n27.5. unittest — Unit testing framework\n1743\n\nThe Python Library Reference, Release 3.13.2\nassertRaisesRegex(exception, regex, *, msg=None)\nLike assertRaises() but also tests that regex matches on the string representation of the raised ex-\nception. regex may be a regular expression object or a string containing a regular expression suitable for\nuse by re.search(). Examples:\nself.assertRaisesRegex(ValueError, ""invalid literal for. *XYZ\'$"",\nint, \'XYZ\')\nor:\nwith self.assertRaisesRegex(ValueError, \'literal\'):\nint(\'XYZ\')\nAdded in version 3.1: Added under the name assertRaisesRegexp. Changed in version 3.2: Renamed to assertRaisesRegex(). Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarns(warning, callable, *args, **kwds)\nassertWarns(warning, *, msg=None)\nTest that a warning is triggered when callable is called with any positional or keyword arguments that\nare also passed to assertWarns(). The test passes if warning is triggered and fails if it isn’t. Any\nexception is an error. To catch any of a group of warnings, a tuple containing the warning classes may\nbe passed as warnings. If only the warning and possibly the msg arguments are given, return a context manager so that the code\nunder test can be written inline rather than as a function:\nwith self.assertWarns(SomeWarning):\ndo_something()\nWhen used as a context manager, assertWarns() accepts the additional keyword argument msg. The context manager will store the caught warning object in its warning attribute, and the source line\nwhich triggered the warnings in the filename and lineno attributes. This can be useful if the intention\nis to perform additional checks on the warning caught:\nwith self.assertWarns(SomeWarning) as cm:\ndo_something()\nself.assertIn(\'myfile.py\', cm.filename)\nself.assertEqual(320, cm.lineno)\nThis method works regardless of the warning filters in place when it is called. Added in version 3.2. Changed in version 3.3: Added the msg keyword argument when used as a context manager. assertWarnsRegex(warning, regex, callable, *args, **kwds)\nassertWarnsRegex(warning, regex, *, msg=None)\nLike assertWarns() but also tests that regex matches on the message of the triggered warning. regex\nmay be a regular expression object or a string containing a regular expression suitable for use by re. search().')",2.1897740409413057e-79,0.04449818621523579,0.14116016672255902,0.5302774310112,0.6594094
Removing duplicates in lists,"The common approach to get a unique collection of items is to use a 
set
. Sets are 
unordered
 collections of 
distinct
 objects. To create a set from any iterable, you can simply pass it to the built-in 
set()
 function. If you later need a real list again, you can similarly pass the set to the 
list()
 function.


The following example should cover whatever you are trying to do:


>>> t = [1, 2, 3, 1, 2, 3, 5, 6, 7, 8]
>>> list(set(t))
[1, 2, 3, 5, 6, 7, 8]
>>> s = [1, 2, 3]
>>> list(set(t) - set(s))
[8, 5, 6, 7]



As you can see from the example result, 
the original order is not maintained
. As mentioned above, sets themselves are unordered collections, so the order is lost. When converting a set back to a list, an arbitrary order is created.


Maintaining order


If order is important to you, then you will have to use a different mechanism. A very common solution for this is to rely on 
OrderedDict
 to keep the order of keys during insertion:


>>> from collections import OrderedDict
>>> list(OrderedDict.fromkeys(t))
[1, 2, 3, 5, 6, 7, 8]



Starting with Python 3.7
, the built-in dictionary is guaranteed to maintain the insertion order as well, so you can also use that directly if you are on Python 3.7 or later (or CPython 3.6):


>>> list(dict.fromkeys(t))
[1, 2, 3, 5, 6, 7, 8]



Note that this may have some overhead of creating a dictionary first, and then creating a list from it. If you don’t actually need to preserve the order, you’re often better off using a set, especially because it gives you a lot more operations to work with. Check out 
this question
 for more details and alternative ways to preserve the order when removing duplicates.




Finally note that both the 
set
 as well as the 
OrderedDict
/
dict
 solutions require your items to be 
hashable
. This usually means that they have to be immutable. If you have to deal with items that are not hashable (e.g. list objects), then you will have to use a slow approach in which you will basically have to compare every item with every other item in a nested loop.

","(""Answer:\nTo remove duplicates from a list, you can convert the list into a set and then back into a list. This method is fast if all elements of the list can be used as set keys (i.e., they are all hashable).\n```python\nmylist = list(set(mylist))\n```\nIf you don't mind reordering the list, you can sort it and then scan from the end, deleting duplicates as you go.\n\nReferences: [1]\n"", '[1] See the Python Cookbook for a long discussion of many ways to do this:\nhttps://code.activestate.com/recipes/52560/\nIf you don’t mind reordering the list, sort it and then scan from the end of the list, deleting duplicates as you go:\nif mylist:\nmylist.sort()\nlast = mylist[-1]\nfor i in range(len(mylist)-2, -1, -1):\nif last == mylist[i]:\ndel mylist[i]\nelse:\nlast = mylist[i]\nIf all elements of the list may be used as set keys (i.e. they are all hashable) this is often faster\nmylist = list(set(mylist))\nThis converts the list into a set, thereby removing duplicates, and then back into a list. 2.5.5 How do you remove multiple items from a list\nAs with removing duplicates, explicitly iterating in reverse with a delete condition is one possibility. However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable. 2.5.10 I want to do a complicated sort: can you do a Schwartzian Transform in\nPython? The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which\nmaps each element to its “sort value”. In Python, use the key argument for the list.sort() method:\nIsorted = L[:]\nIsorted.sort(key=lambda s: int(s[10:15]))\n2.5.11 How can I sort one list by values from another list? Merge them into an iterator of tuples, sort the resulting list, and then pick out the element you want. >>> list1 = [""what"", ""I\'m"", ""sorting"", ""by""]\n>>> list2 = [""something"", ""else"", ""to"", ""sort""]\n>>> pairs = zip(list1, list2)\n>>> pairs = sorted(pairs)\n>>> pairs\n[(""I\'m"", \'else\'), (\'by\', \'sort\'), (\'sorting\', \'to\'), (\'what\', \'something\')]\n>>> result = [x[1] for x in pairs]\n>>> result\n[\'else\', \'sort\', \'to\', \'something\']\n2.6 Objects\n2.6.1 What is a class? A class is the particular object type created by executing a class statement. Class objects are used as templates to\ncreate instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and meth-\nods of its base classes. This allows an object model to be successively refined by inheritance. You might have a\ngeneric Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox,\nMaildirMailbox, OutlookMailbox that handle various specific mailbox formats. 26\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.2 What is a method? A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined\nas functions inside the class definition:\nclass C:\ndef meth(self, arg):\nreturn arg * 2 + self.attribute\n2.6.3 What is self? Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b,\nc) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called\nmethod will think it is called as meth(x, a, b, c). See also Why must ‘self’ be used explicitly in method definitions and calls?. 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it?\n\n[2] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",4.008390682045635e-79,0.10338517840805124,0.3176021822182556,0.5848928093910217,0.61639893
How do I print an exception in Python?,"For Python 2.6 and later and Python 3.x:


except Exception as e: print(e)



For Python 2.5 and earlier, use:


except Exception,e: print str(e)


","('Answer: To print an exception, you can use a `try...except` block. The `except` clause can specify a variable after the exception name, which will be bound to the exception instance. You can then print this variable. Also, built-in exception types define `__str__()` to print all the arguments.\n\nReferences: [1]\n', '[1] Errors detected during execution are called exceptions and are not unconditionally fatal: you will soon learn how\nto handle them in Python programs. Most exceptions are not handled by programs, however, and result in error\nmessages as shown here:\n>>> 10 * (1/0)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n10 * (1/0)\n~^~\nZeroDivisionError: division by zero\n>>> 4 + spam*3\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n4 + spam*3\n^^^^\nNameError: name \'spam\' is not defined\n>>> \'2\' + 2\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n\'2\' + 2\n(continues on next page)\n61\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n~~~~^~~\nTypeError: can only concatenate str (not ""int"") to str\nThe last line of the error message indicates what happened. Exceptions come in different types, and the type is\nprinted as part of the message: the types in the example are ZeroDivisionError, NameError and TypeError. The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in\nexceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception\nnames are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack\ntraceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from\nstandard input. bltin-exceptions lists the built-in exceptions and their meanings. 8.3 Handling Exceptions\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the\nuser for input until a valid integer has been entered, but allows the user to interrupt the program (using Control-\nC or whatever the operating system supports); note that a user-generated interruption is signalled by raising the\nKeyboardInterrupt exception. >>> while True:\n...\ntry:\n...\nx = int(input(""Please enter a number: ""))\n...\nbreak\n...\nexcept ValueError:\n...\nprint(""Oops! That was no valid number. Try again..."")\n... The try statement works as follows. • First, the try clause (the statement(s) between the try and except keywords) is executed. • If no exception occurs, the except clause is skipped and execution of the try statement is finished. • If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\')\n\n[2] In the example, the error is detected at the function\nprint(), since a colon (\':\') is missing just before it. The file name (<stdin> in our example) and line number are printed so you know where to look in case the input\ncame from a file. 8.2 Exceptions\nEven if a statement or expression is syntactically correct, it may cause an error when an attempt is made to execute\nit. Errors detected during execution are called exceptions and are not unconditionally fatal: you will soon learn how\nto handle them in Python programs. Most exceptions are not handled by programs, however, and result in error\nmessages as shown here:\n>>> 10 * (1/0)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n10 * (1/0)\n~^~\nZeroDivisionError: division by zero\n>>> 4 + spam*3\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n4 + spam*3\n^^^^\nNameError: name \'spam\' is not defined\n>>> \'2\' + 2\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\n\'2\' + 2\n(continues on next page)\n61\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n~~~~^~~\nTypeError: can only concatenate str (not ""int"") to str\nThe last line of the error message indicates what happened. Exceptions come in different types, and the type is\nprinted as part of the message: the types in the example are ZeroDivisionError, NameError and TypeError. The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in\nexceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception\nnames are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack\ntraceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from\nstandard input. bltin-exceptions lists the built-in exceptions and their meanings. 8.3 Handling Exceptions\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the\nuser for input until a valid integer has been entered, but allows the user to interrupt the program (using Control-\nC or whatever the operating system supports); note that a user-generated interruption is signalled by raising the\nKeyboardInterrupt exception. >>> while True:\n...\ntry:\n...\nx = int(input(""Please enter a number: ""))\n...\nbreak\n...\nexcept ValueError:\n...\nprint(""Oops! That was no valid number. Try again..."")\n... The try statement works as follows. • First, the try clause (the statement(s) between the try and except keywords) is executed. • If no exception occurs, the except clause is skipped and execution of the try statement is finished. • If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised.\n\n[3] The string printed as the exception type is the name of the built-in exception that occurred. This is true for all built-in\nexceptions, but need not be true for user-defined exceptions (although it is a useful convention). Standard exception\nnames are built-in identifiers (not reserved keywords). The rest of the line provides detail based on the type of exception and what caused it. The preceding part of the error message shows the context where the exception occurred, in the form of a stack\ntraceback. In general it contains a stack traceback listing source lines; however, it will not display lines read from\nstandard input. bltin-exceptions lists the built-in exceptions and their meanings. 8.3 Handling Exceptions\nIt is possible to write programs that handle selected exceptions. Look at the following example, which asks the\nuser for input until a valid integer has been entered, but allows the user to interrupt the program (using Control-\nC or whatever the operating system supports); note that a user-generated interruption is signalled by raising the\nKeyboardInterrupt exception. >>> while True:\n...\ntry:\n...\nx = int(input(""Please enter a number: ""))\n...\nbreak\n...\nexcept ValueError:\n...\nprint(""Oops! That was no valid number. Try again..."")\n... The try statement works as follows. • First, the try clause (the statement(s) between the try and except keywords) is executed. • If no exception occurs, the except clause is skipped and execution of the try statement is finished. • If an exception occurs during execution of the try clause, the rest of the clause is skipped. Then, if its type\nmatches the exception named after the except keyword, the except clause is executed, and then execution\ncontinues after the try/except block. • If an exception occurs which does not match the exception named in the except clause, it is passed on to outer\ntry statements; if no handler is found, it is an unhandled exception and execution stops with an error message. A try statement may have more than one except clause, to specify handlers for different exceptions. At most one\nhandler will be executed. Handlers only handle exceptions that occur in the corresponding try clause, not in other\nhandlers of the same try statement. An except clause may name multiple exceptions as a parenthesized tuple, for\nexample:\n... except (RuntimeError, TypeError, NameError):\n...\npass\nA class in an except clause matches exceptions which are instances of the class itself or one of its derived classes\n(but not the other way around — an except clause listing a derived class does not match instances of its base classes). For example, the following code will print B, C, D in that order:\nclass B(Exception):\npass\n(continues on next page)\n62\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\nclass C(B):\npass\nclass D(C):\npass\nfor cls in [B, C, D]:\ntry:\nraise cls()\nexcept D:\nprint(""D"")\nexcept C:\nprint(""C"")\nexcept B:\nprint(""B"")\nNote that if the except clauses were reversed (with except B first), it would have printed B, B, B — the first matching\nexcept clause is triggered. When an exception occurs, it may have associated values, also known as the exception’s arguments. The presence\nand types of the arguments depend on the exception type. The except clause may specify a variable after the exception name. The variable is bound to the exception instance\nwhich typically has an args attribute that stores the arguments. For convenience, builtin exception types define\n__str__() to print all the arguments without explicitly accessing .args. >>> try:\n...\nraise Exception(\'spam\', \'eggs\')\n... except Exception as inst:\n...\nprint(type(inst))\n# the exception type\n...\nprint(inst.args)\n# arguments stored in .args\n...\nprint(inst)\n# __str__ allows args to be printed directly,\n...\n# but may be overridden in exception subclasses\n...\nx, y = inst.args\n# unpack args\n...\nprint(\'x =\', x)\n...\nprint(\'y =\', y)\n...\n<class \'Exception\'>\n(\'spam\', \'eggs\')\n(\'spam\', \'eggs\')\nx = spam\ny = eggs\nThe exception’s __str__() output is printed as the last part (‘detail’) of the message for unhandled exceptions. BaseException is the common base class of all exceptions. One of its subclasses, Exception, is the base class of\nall the non-fatal exceptions. Exceptions which are not subclasses of Exception are not typically handled, because\nthey are used to indicate that the program should terminate. They include SystemExit which is raised by sys. exit() and KeyboardInterrupt which is raised when a user wishes to interrupt the program. Exception can be used as a wildcard that catches (almost) everything. However, it is good practice to be as specific\nas possible with the types of exceptions that we intend to handle, and to allow any unexpected exceptions to propagate\non. The most common pattern for handling Exception is to print or log the exception and then re-raise it (allowing a\ncaller to handle the exception as well):\nimport sys\n(continues on next page)\n8.3. Handling Exceptions\n63\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\ntry:\nf = open(\'myfile.txt\')\ns = f.readline()\ni = int(s.strip())\nexcept OSError as err:\nprint(""OS error:"", err)\nexcept ValueError:\nprint(""Could not convert data to an integer."") except Exception as err:\nprint(f""Unexpected {err=}, {type(err)=}"")\nraise\nThe try … except statement has an optional else clause, which, when present, must follow all except clauses. It is\nuseful for code that must be executed if the try clause does not raise an exception. For example:\nfor arg in sys.argv[1:]:\ntry:\nf = open(arg, \'r\')\nexcept OSError:\nprint(\'cannot open\', arg)\nelse:\nprint(arg, \'has\', len(f.readlines()), \'lines\')\nf.close()\nThe use of the else clause is better than adding additional code to the try clause because it avoids accidentally\ncatching an exception that wasn’t raised by the code being protected by the try … except statement. Exception handlers do not handle only exceptions that occur immediately in the try clause, but also those that occur\ninside functions that are called (even indirectly) in the try clause. For example:\n>>> def this_fails():\n...\nx = 1/0\n...\n>>> try:\n...\nthis_fails()\n... except ZeroDivisionError as err:\n...\nprint(\'Handling run-time error:\', err)\n...\nHandling run-time error: division by zero\n8.4 Raising Exceptions\nThe raise statement allows the programmer to force a specified exception to occur. For example:\n>>> raise NameError(\'HiThere\')\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\nThe sole argument to raise indicates the exception to be raised. This must be either an exception instance or an\nexception class (a class that derives from BaseException, such as Exception or one of its subclasses). If an\nexception class is passed, it will be implicitly instantiated by calling its constructor with no arguments:\nraise ValueError\n# shorthand for \'raise ValueError()\'\n64\nChapter 8. Errors and Exceptions\n\nPython Tutorial, Release 3.13.2\nIf you need to determine whether an exception was raised but don’t intend to handle it, a simpler form of the raise\nstatement allows you to re-raise the exception:\n>>> try:\n...\nraise NameError(\'HiThere\')\n... except NameError:\n...\nprint(\'An exception flew by!\') ...\nraise\n...\nAn exception flew by! Traceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nraise NameError(\'HiThere\')\nNameError: HiThere\n8.5 Exception Chaining\nIf an unhandled exception occurs inside an except section, it will have the exception being handled attached to it\nand included in the error message:\n>>> try:\n...\nopen(""database.sqlite"")\n... except OSError:\n...\nraise RuntimeError(""unable to handle error"")\n...\nTraceback (most recent call last):\nFile ""<stdin>"", line 2, in <module>\nopen(""database.sqlite"")\n~~~~^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: \'database.sqlite\'\nDuring handling of the above exception, another exception occurred:\nTraceback (most recent call last):\nFile ""<stdin>"", line 4, in <module>\nraise RuntimeError(""unable to handle error"")\nRuntimeError: unable to handle error\nTo indicate that an exception is a direct consequence of another, the raise statement allows an optional from clause:\n# exc must be exception instance or None. raise RuntimeError from exc\nThis can be useful when you are transforming exceptions.')",5.975308601158558e-80,0.008979206049149336,0.023684210526315797,0.4544784724712372,0.620512
How do I check which version of Python is running my script?,"This information is available in the 
sys.version
 string in the 
sys
 module:


>>> import sys



Human readable:


>>> print(sys.version)  # parentheses necessary in python 3.       
2.5.2 (r252:60911, Jul 31 2008, 17:28:52) 
[GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)]



For further processing, use 
sys.version_info
 or 
sys.hexversion
:


>>> sys.version_info
(2, 5, 2, 'final', 0)
# or
>>> sys.hexversion
34014192



To ensure a script runs with a minimal version requirement of the Python interpreter add this to your code:


assert sys.version_info >= (2, 5)



This compares major and minor version information. Add micro (=
0
, 
1
, etc) and even releaselevel (=
'alpha'
,
'final'
, etc) to the tuple as you like. Note however, that it is almost always better to ""duck"" check if a certain feature is there, and if not, workaround (or bail out). Sometimes features go away in newer releases, being replaced by others.

","('Answer: You can check the Python version using `sys.hexversion` or `sys.version_info`. The `platform.python_version()` function returns the Python version as a string, and `platform.python_version_tuple()` returns it as a tuple of strings.\n\nReferences: [1, 3]\n', ""[1] CPython implementation detail: The gettrace() function is intended only for implementing debuggers,\nprofilers, coverage tools and the like. Its behavior is part of the implementation platform, rather than part of\nthe language definition, and thus may not be available in all Python implementations. sys.getwindowsversion()\nReturn a named tuple describing the Windows version currently running. The named elements are major,\nminor, build, platform, service_pack, service_pack_minor, service_pack_major, suite_mask, product_type and\nplatform_version. service_pack contains a string, platform_version a 3-tuple and all other values are inte-\ngers. The components can also be accessed by name, so sys.getwindowsversion()[0] is equivalent to\nsys.getwindowsversion().major. For compatibility with prior versions, only the first 5 elements are\nretrievable by indexing. platform will be 2 (VER_PLATFORM_WIN32_NT). product_type may be one of the following values:\nConstant\nMeaning\n1 (VER_NT_WORKSTATION)\nThe system is a workstation. 2 (VER_NT_DOMAIN_CONTROLLER)\nThe system is a domain controller. 3 (VER_NT_SERVER)\nThe system is a server, but not a domain controller. 30.1. sys — System-specific parameters and functions\n1917\n\nThe Python Library Reference, Release 3.13.2\nThis function wraps the Win32 GetVersionEx() function;\nsee the Microsoft documentation on\nOSVERSIONINFOEX() for more information about these fields. platform_version returns the major version, minor version and build number of the current operating system,\nrather than the version that is being emulated for the process. It is intended for use in logging rather than for\nfeature detection. ® Note\nplatform_version derives the version from kernel32.dll which can be of a different version than the OS\nversion. Please use platform module for achieving accurate OS version. Availability: Windows. Changed in version 3.2: Changed to a named tuple and added service_pack_minor, service_pack_major,\nsuite_mask, and product_type. Changed in version 3.6: Added platform_version\nsys.get_asyncgen_hooks()\nReturns an asyncgen_hooks object, which is similar to a namedtuple of the form (firstiter,\nfinalizer), where firstiter and finalizer are expected to be either None or functions which take an asyn-\nchronous generator iterator as an argument, and are used to schedule finalization of an asynchronous generator\nby an event loop. Added in version 3.6: See PEP 525 for more details. ® Note\nThis function has been added on a provisional basis (see PEP 411 for details.) sys.get_coroutine_origin_tracking_depth()\nGet the current coroutine origin tracking depth, as set by set_coroutine_origin_tracking_depth(). Added in version 3.7. ® Note\nThis function has been added on a provisional basis (see PEP 411 for details.) Use it only for debugging\npurposes. sys.hash_info\nA named tuple giving parameters of the numeric hash implementation. For more details about hashing of\nnumeric types, see Hashing of numeric types. hash_info.width\nThe width in bits used for hash values\nhash_info.modulus\nThe prime modulus P used for numeric hash scheme\nhash_info.inf\nThe hash value returned for a positive infinity\nhash_info.nan\n(This attribute is no longer used)\n1918\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\nhash_info.imag\nThe multiplier used for the imaginary part of a complex number\nhash_info.algorithm\nThe name of the algorithm for hashing of str, bytes, and memoryview\nhash_info.hash_bits\nThe internal output size of the hash algorithm\nhash_info.seed_bits\nThe size of the seed key of the hash algorithm\nAdded in version 3.2. Changed in version 3.4: Added algorithm, hash_bits and seed_bits\nsys.hexversion\nThe version number encoded as a single integer. This is guaranteed to increase with each version, including\nproper support for non-production releases. For example, to test that the Python interpreter is at least version\n1.5.2, use:\nif sys.hexversion >= 0x010502F0:\n# use some advanced feature\n...\nelse:\n# use an alternative implementation or warn the user\n... This is called hexversion since it only really looks meaningful when viewed as the result of passing it to\nthe built-in hex() function. The named tuple sys.version_info may be used for a more human-friendly\nencoding of the same information. More details of hexversion can be found at apiabiversion. sys.implementation\nAn object containing information about the implementation of the currently running Python interpreter. The\nfollowing attributes are required to exist in all Python implementations. name is the implementation’s identifier, e.g. 'cpython'. The actual string is defined by the Python imple-\nmentation, but it is guaranteed to be lower case. version is a named tuple, in the same format as sys.version_info. It represents the version of the Python\nimplementation. This has a distinct meaning from the specific version of the Python language to which\nthe currently running interpreter conforms, which sys.version_info represents. For example, for PyPy\n1.8 sys.implementation.version might be sys.version_info(1, 8, 0, 'final', 0), whereas\nsys.version_info would be sys.version_info(2, 7, 2, 'final', 0). For CPython they are the\nsame value, since it is the reference implementation. hexversion is the implementation version in hexadecimal format, like sys.hexversion. cache_tag is the tag used by the import machinery in the filenames of cached modules. By convention, it\nwould be a composite of the implementation’s name and version, like 'cpython-33'. However, a Python\nimplementation may use some other value if appropriate. If cache_tag is set to None, it indicates that module\ncaching should be disabled. sys.implementation may contain additional attributes specific to the Python implementation.\n\n[2] Its behavior is part of the implementation platform, rather than part of\nthe language definition, and thus may not be available in all Python implementations. sys.getwindowsversion()\nReturn a named tuple describing the Windows version currently running. The named elements are major,\nminor, build, platform, service_pack, service_pack_minor, service_pack_major, suite_mask, product_type and\nplatform_version. service_pack contains a string, platform_version a 3-tuple and all other values are inte-\ngers. The components can also be accessed by name, so sys.getwindowsversion()[0] is equivalent to\nsys.getwindowsversion().major. For compatibility with prior versions, only the first 5 elements are\nretrievable by indexing. platform will be 2 (VER_PLATFORM_WIN32_NT). product_type may be one of the following values:\nConstant\nMeaning\n1 (VER_NT_WORKSTATION)\nThe system is a workstation. 2 (VER_NT_DOMAIN_CONTROLLER)\nThe system is a domain controller. 3 (VER_NT_SERVER)\nThe system is a server, but not a domain controller. 30.1. sys — System-specific parameters and functions\n1917\n\nThe Python Library Reference, Release 3.13.2\nThis function wraps the Win32 GetVersionEx() function;\nsee the Microsoft documentation on\nOSVERSIONINFOEX() for more information about these fields. platform_version returns the major version, minor version and build number of the current operating system,\nrather than the version that is being emulated for the process. It is intended for use in logging rather than for\nfeature detection. ® Note\nplatform_version derives the version from kernel32.dll which can be of a different version than the OS\nversion. Please use platform module for achieving accurate OS version. Availability: Windows. Changed in version 3.2: Changed to a named tuple and added service_pack_minor, service_pack_major,\nsuite_mask, and product_type. Changed in version 3.6: Added platform_version\nsys.get_asyncgen_hooks()\nReturns an asyncgen_hooks object, which is similar to a namedtuple of the form (firstiter,\nfinalizer), where firstiter and finalizer are expected to be either None or functions which take an asyn-\nchronous generator iterator as an argument, and are used to schedule finalization of an asynchronous generator\nby an event loop. Added in version 3.6: See PEP 525 for more details. ® Note\nThis function has been added on a provisional basis (see PEP 411 for details.) sys.get_coroutine_origin_tracking_depth()\nGet the current coroutine origin tracking depth, as set by set_coroutine_origin_tracking_depth(). Added in version 3.7. ® Note\nThis function has been added on a provisional basis (see PEP 411 for details.) Use it only for debugging\npurposes. sys.hash_info\nA named tuple giving parameters of the numeric hash implementation. For more details about hashing of\nnumeric types, see Hashing of numeric types. hash_info.width\nThe width in bits used for hash values\nhash_info.modulus\nThe prime modulus P used for numeric hash scheme\nhash_info.inf\nThe hash value returned for a positive infinity\nhash_info.nan\n(This attribute is no longer used)\n1918\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\nhash_info.imag\nThe multiplier used for the imaginary part of a complex number\nhash_info.algorithm\nThe name of the algorithm for hashing of str, bytes, and memoryview\nhash_info.hash_bits\nThe internal output size of the hash algorithm\nhash_info.seed_bits\nThe size of the seed key of the hash algorithm\nAdded in version 3.2. Changed in version 3.4: Added algorithm, hash_bits and seed_bits\nsys.hexversion\nThe version number encoded as a single integer. This is guaranteed to increase with each version, including\nproper support for non-production releases. For example, to test that the Python interpreter is at least version\n1.5.2, use:\nif sys.hexversion >= 0x010502F0:\n# use some advanced feature\n...\nelse:\n# use an alternative implementation or warn the user\n... This is called hexversion since it only really looks meaningful when viewed as the result of passing it to\nthe built-in hex() function. The named tuple sys.version_info may be used for a more human-friendly\nencoding of the same information. More details of hexversion can be found at apiabiversion. sys.implementation\nAn object containing information about the implementation of the currently running Python interpreter. The\nfollowing attributes are required to exist in all Python implementations. name is the implementation’s identifier, e.g. 'cpython'. The actual string is defined by the Python imple-\nmentation, but it is guaranteed to be lower case. version is a named tuple, in the same format as sys.version_info. It represents the version of the Python\nimplementation. This has a distinct meaning from the specific version of the Python language to which\nthe currently running interpreter conforms, which sys.version_info represents. For example, for PyPy\n1.8 sys.implementation.version might be sys.version_info(1, 8, 0, 'final', 0), whereas\nsys.version_info would be sys.version_info(2, 7, 2, 'final', 0). For CPython they are the\nsame value, since it is the reference implementation. hexversion is the implementation version in hexadecimal format, like sys.hexversion. cache_tag is the tag used by the import machinery in the filenames of cached modules. By convention, it\nwould be a composite of the implementation’s name and version, like 'cpython-33'. However, a Python\nimplementation may use some other value if appropriate. If cache_tag is set to None, it indicates that module\ncaching should be disabled. sys.implementation may contain additional attributes specific to the Python implementation. These non-\nstandard attributes must start with an underscore, and are not described here.\n\n[3] platform.python_version()\nReturns the Python version as string 'major.minor.patchlevel'. Note that unlike the Python sys.version, the returned value will always include the patchlevel (it defaults\nto 0). platform.python_version_tuple()\nReturns the Python version as tuple (major, minor, patchlevel) of strings. Note that unlike the Python sys.version, the returned value will always include the patchlevel (it defaults\nto '0'). platform.release()\nReturns the system’s release, e.g. '2.2.0' or 'NT'. An empty string is returned if the value cannot be\ndetermined. platform.system()\nReturns the system/OS name, such as 'Linux', 'Darwin', 'Java', 'Windows'. An empty string is re-\nturned if the value cannot be determined. On iOS and Android, this returns the user-facing OS name (i.e, 'iOS, 'iPadOS' or 'Android'). To obtain\nthe kernel name ('Darwin' or 'Linux'), use os.uname(). platform.system_alias(system, release, version)\nReturns (system, release, version) aliased to common marketing names used for some systems. It\nalso does some reordering of the information in some cases where it would otherwise cause confusion. 790\nChapter 16. Generic Operating System Services\n\nThe Python Library Reference, Release 3.13.2\nplatform.version()\nReturns the system’s release version, e.g. '#3 on degas'. An empty string is returned if the value cannot\nbe determined. On iOS and Android, this is the user-facing OS version. To obtain the Darwin or Linux kernel version, use\nos.uname(). platform.uname()\nFairly portable uname interface. Returns a namedtuple() containing six attributes:\nsystem, node,\nrelease, version, machine, and processor. processor is resolved late, on demand. Note: the first two attribute names differ from the names presented by os.uname(), where they are named\nsysname and nodename. Entries which cannot be determined are set to ''. Changed in version 3.3: Result changed from a tuple to a namedtuple(). Changed in version 3.9: processor is resolved late instead of immediately. 16.7.2 Java Platform\nplatform.java_ver(release=”, vendor=”, vminfo=(”, ”, ”), osinfo=(”, ”, ”))\nVersion interface for Jython. Returns a tuple (release, vendor, vminfo, osinfo) with vminfo being a tuple (vm_name,\nvm_release, vm_vendor) and osinfo being a tuple (os_name, os_version, os_arch). Values\nwhich cannot be determined are set to the defaults given as parameters (which all default to ''). Deprecated since version 3.13, will be removed in version 3.15: It was largely untested, had a confusing API,\nand was only useful for Jython support. 16.7.3 Windows Platform\nplatform.win32_ver(release=”, version=”, csd=”, ptype=”)\nGet additional version information from the Windows Registry and return a tuple (release, version,\ncsd, ptype) referring to OS release, version number, CSD level (service pack) and OS type (multi/single\nprocessor). Values which cannot be determined are set to the defaults given as parameters (which all default\nto an empty string). As a hint: ptype is 'Uniprocessor Free' on single processor NT machines and 'Multiprocessor\nFree' on multi processor machines. The 'Free' refers to the OS version being free of debugging code. It could also state 'Checked' which means the OS version uses debugging code, i.e. code that checks argu-\nments, ranges, etc. platform.win32_edition()\nReturns a string representing the current Windows edition, or None if the value cannot be determined. Possible values include but are not limited to 'Enterprise', 'IoTUAP', 'ServerStandard', and\n'nanoserver'. Added in version 3.8.\nplatform.win32_is_iot()\nReturn True if the Windows edition returned by win32_edition() is recognized as an IoT edition. Added in version 3.8. 16.7. platform — Access to underlying platform’s identifying data\n791\n\nThe Python Library Reference, Release 3.13.2\n16.7.4 macOS Platform\nplatform.mac_ver(release=”, versioninfo=(”, ”, ”), machine=”)\nGet macOS version information and return it as tuple (release, versioninfo, machine) with version-\ninfo being a tuple (version, dev_stage, non_release_version). Entries which cannot be determined are set to ''. All tuple entries are strings. 16.7.5 iOS Platform\nplatform.ios_ver(system=”, release=”, model=”, is_simulator=False)\nGet iOS version information and return it as a namedtuple() with the following attributes:\n• system is the OS name; either 'iOS' or 'iPadOS'. • release is the iOS version number as a string (e.g., '17.2'). • model is the device model identifier; this will be a string like 'iPhone13,2' for a physical device, or\n'iPhone' on a simulator. • is_simulator is a boolean describing if the app is running on a simulator or a physical device. Entries which cannot be determined are set to the defaults given as parameters. 16.7.6 Unix Platforms\nplatform.libc_ver(executable=sys.executable, lib=”, version=”, chunksize=16384)\nTries to determine the libc version against which the file executable (defaults to the Python interpreter) is\nlinked. Returns a tuple of strings (lib, version) which default to the given parameters in case the lookup\nfails. Note that this function has intimate knowledge of how different libc versions add symbols to the executable is\nprobably only usable for executables compiled using gcc."")",2.2458933741672996e-79,0.04786324786324786,0.15721770680446545,0.5726135969161987,0.7647513
How to make a class JSON serializable,"Do you have an idea about the expected output? For example, will this do?


>>> f  = FileItem(""/foo/bar"")
>>> magic(f)
'{""fname"": ""/foo/bar""}'



In that case you can merely call 
json.dumps(f.__dict__)
. 


If you want more customized output then you will have to subclass 
JSONEncoder
 and implement your own custom serialization. 


For a trivial example, see below.


>>> from json import JSONEncoder
>>> class MyEncoder(JSONEncoder):
        def default(self, o):
            return o.__dict__    

>>> MyEncoder().encode(f)
'{""fname"": ""/foo/bar""}'



Then you pass this class into the 
json.dumps()
 method as 
cls
 kwarg:


json.dumps(cls=MyEncoder)



If you also want to decode then you'll have to supply a custom 
object_hook
 to the 
JSONDecoder
 class. For example:


>>> def from_json(json_object):
        if 'fname' in json_object:
            return FileItem(json_object['fname'])
>>> f = JSONDecoder(object_hook = from_json).decode('{""fname"": ""/foo/bar""}')
>>> f
<__main__.FileItem object at 0x9337fac>
>>> 


","('Answer: Enumerations can be pickled and unpickled, with certain restrictions. Picklable enums must be defined in the top level of a module to be importable. With pickle protocol version 4, enums nested in other classes can be easily pickled. You can modify how enum members are pickled/unpickled by defining __reduce_ex__() in the enumeration class. The default method is by-value, but enums with complicated values may want to use by-name.\n\nReferences: [2]\n', ""[1] 9 Dataclass support\nWhen inheriting from a dataclass, the __repr__() omits the inherited class’ name. For example:\n>>> from dataclasses import dataclass, field\n>>> @dataclass\n... class CreatureDataMixin:\n...\nsize: str\n...\nlegs: int\n...\ntail: bool = field(repr=False, default=True)\n...\n>>> class Creature(CreatureDataMixin, Enum):\n...\nBEETLE = 'small', 6\n...\nDOG = 'medium', 4\n...\n>>> Creature.DOG\n<Creature.DOG: size='medium', legs=4>\n9\n\nUse the dataclass() argument repr=False to use the standard repr(). Changed in version 3.12: Only the dataclass fields are shown in the value area, not the dataclass’ name. ® Note\nAdding dataclass() decorator to Enum and its subclasses is not supported. It will not raise any errors, but it\nwill produce very strange results at runtime, such as members being equal to each other:\n>>> @dataclass\n# don't do this: it does not make any sense\n... class Color(Enum):\n...\nRED = 1\n...\nBLUE = 2\n...\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED == Color.BLUE\n# problem is here: they should not be equal\nTrue\n10 Pickling\nEnumerations can be pickled and unpickled:\n>>> from test.test_enum import Fruit\n>>> from pickle import dumps, loads\n>>> Fruit.TOMATO is loads(dumps(Fruit.TOMATO))\nTrue\nThe usual restrictions for pickling apply: picklable enums must be defined in the top level of a module, since unpick-\nling requires them to be importable from that module. ® Note\nWith pickle protocol version 4 it is possible to easily pickle enums nested in other classes. It is possible to modify how enum members are pickled/unpickled by defining __reduce_ex__() in the enumera-\ntion class. The default method is by-value, but enums with complicated values may want to use by-name:\n>>> import enum\n>>> class MyEnum(enum.Enum):\n...\n__reduce_ex__ = enum.pickle_by_enum_name\n® Note\nUsing by-name for flags is not recommended, as unnamed aliases will not unpickle. 11 Functional API\nThe Enum class is callable, providing the following functional API:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG')\n>>> Animal\n<enum 'Animal'>\n(continues on next page)\n10\n\n(continued from previous page)\n>>> Animal.ANT\n<Animal.ANT: 1>\n>>> list(Animal)\n[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>]\nThe semantics of this API resemble namedtuple. The first argument of the call to Enum is the name of the enu-\nmeration. The second argument is the source of enumeration member names. It can be a whitespace-separated string of names,\na sequence of names, a sequence of 2-tuples with key/value pairs, or a mapping (e.g. dictionary) of names to values. The last two options enable assigning arbitrary values to enumerations; the others auto-assign increasing integers\nstarting with 1 (use the start parameter to specify a different starting value). A new class derived from Enum is\nreturned. In other words, the above assignment to Animal is equivalent to:\n>>> class Animal(Enum):\n...\nANT = 1\n...\nBEE = 2\n...\nCAT = 3\n...\nDOG = 4\n... The reason for defaulting to 1 as the starting number and not 0 is that 0 is False in a boolean sense, but by default\nenum members all evaluate to True. Pickling enums created with the functional API can be tricky as frame stack implementation details are used to try\nand figure out which module the enumeration is being created in (e.g. it will fail if you use a utility function in\na separate module, and also may not work on IronPython or Jython). The solution is to specify the module name\nexplicitly as follows:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__)\nÁ Warning\nIf module is not supplied, and Enum cannot determine what it is, the new Enum members will not be unpicklable;\nto keep errors closer to the source, pickling will be disabled. The new pickle protocol 4 also, in some circumstances, relies on __qualname__ being set to the location where\npickle will be able to find the class. For example, if the class was made available in class SomeData in the global\nscope:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal')\nThe complete signature is:\nEnum(\nvalue='NewEnumName',\nnames=<...>,\n*,\nmodule='...',\nqualname='...',\ntype=<mixed-in class>,\nstart=1,\n)\n• value: What the new enum class will record as its name. • names: The enum members. This can be a whitespace- or comma-separated string (values will start at 1 unless\notherwise specified):\n11\n\n'RED GREEN BLUE' | 'RED,GREEN,BLUE' | 'RED, GREEN, BLUE'\nor an iterator of names:\n['RED', 'GREEN', 'BLUE']\nor an iterator of (name, value) pairs:\n[('CYAN', 4), ('MAGENTA', 5), ('YELLOW', 6)]\nor a mapping:\n{'CHARTREUSE': 7, 'SEA_GREEN': 11, 'ROSEMARY': 42}\n• module: name of module where new enum class can be found. • qualname: where in module new enum class can be found. • type: type to mix in to new enum class. • start: number to start counting at if only names are passed in. Changed in version 3.5: The start parameter was added. 12 Derived Enumerations\n12.1 IntEnum\nThe first variation of Enum that is provided is also a subclass of int. Members of an IntEnum can be compared to\nintegers; by extension, integer enumerations of different types can also be compared to each other:\n>>> from enum import IntEnum\n>>> class Shape(IntEnum):\n...\nCIRCLE = 1\n...\nSQUARE = 2\n...\n>>> class Request(IntEnum):\n...\nPOST = 1\n...\nGET = 2\n...\n>>> Shape == 1\nFalse\n>>> Shape.CIRCLE == 1\nTrue\n>>> Shape.CIRCLE == Request.POST\nTrue\nHowever, they still can’t be compared to standard Enum enumerations:\n>>> class Shape(IntEnum):\n...\nCIRCLE = 1\n...\nSQUARE = 2\n...\n>>> class Color(Enum):\n...\nRED = 1\n...\nGREEN = 2\n...\n>>> Shape.CIRCLE == Color.RED\nFalse\n12\n\nIntEnum values behave like integers in other ways you’d expect:\n>>> int(Shape.CIRCLE)\n1\n>>> ['a', 'b', 'c'][Shape.CIRCLE]\n'b'\n>>> [i for i in range(Shape.SQUARE)]\n[0, 1]\n12.2 StrEnum\nThe second variation of Enum that is provided is also a subclass of str. Members of a StrEnum can be compared\nto strings; by extension, string enumerations of different types can also be compared to each other. Added in version 3.11. 12.3 IntFlag\nThe next variation of Enum provided, IntFlag, is also based on int. The difference being IntFlag members can\nbe combined using the bitwise operators (&, |, ^, ~) and the result is still an IntFlag member, if possible. Like\nIntEnum, IntFlag members are also integers and can be used wherever an int is used. ® Note\nAny operation on an IntFlag member besides the bit-wise operations will lose the IntFlag membership. Bit-wise operations that result in invalid IntFlag values will lose the IntFlag membership. See\nFlagBoundary for details. Added in version 3.6. Changed in version 3.11. Sample IntFlag class:\n>>> from enum import IntFlag\n>>> class Perm(IntFlag):\n...\nR = 4\n...\nW = 2\n...\nX = 1\n...\n>>> Perm.R | Perm.W\n<Perm.R|W: 6>\n>>> Perm.R + Perm.W\n6\n>>> RW = Perm.R | Perm.W\n>>> Perm.R in RW\nTrue\nIt is also possible to name the combinations:\n>>> class Perm(IntFlag):\n...\nR = 4\n...\nW = 2\n...\nX = 1\n...\nRWX = 7\n...\n>>> Perm.RWX\n<Perm.RWX: 7>\n(continues on next page)\n13\n\n(continued from previous page)\n>>> ~Perm.RWX\n<Perm: 0>\n>>> Perm(7)\n<Perm.RWX: 7>\n® Note\nNamed combinations are considered aliases. Aliases do not show up during iteration, but can be returned from\nby-value lookups. Changed in version 3.11. Another important difference between IntFlag and Enum is that if no flags are set (the value is 0), its boolean\nevaluation is False:\n>>> Perm.R & Perm.X\n<Perm: 0>\n>>> bool(Perm.R & Perm.X)\nFalse\nBecause IntFlag members are also subclasses of int they can be combined with them (but may lose IntFlag\nmembership:\n>>> Perm.X | 4\n<Perm.R|X: 5>\n>>> Perm.X + 8\n9\n® Note\nThe negation operator, ~, always returns an IntFlag member with a positive value:\n>>> (~Perm.X).value == (Perm.R|Perm.W).value == 6\nTrue\nIntFlag members can also be iterated over:\n>>> list(RW)\n[<Perm.R: 4>, <Perm.W: 2>]\nAdded in version 3.11. 12.4 Flag\nThe last variation is Flag. Like IntFlag, Flag members can be combined using the bitwise operators (&, |, ^,\n~). Unlike IntFlag, they cannot be combined with, nor compared against, any other Flag enumeration, nor int. While it is possible to specify the values directly it is recommended to use auto as the value and let Flag select an\nappropriate value. Added in version 3.6. Like IntFlag, if a combination of Flag members results in no flags being set, the boolean evaluation is False:\n>>> from enum import Flag, auto\n>>> class Color(Flag):\n(continues on next page)\n14\n\n(continued from previous page)\n...\nRED = auto()\n...\nBLUE = auto()\n...\nGREEN = auto()\n...\n>>> Color.RED & Color.GREEN\n<Color: 0>\n>>> bool(Color.RED & Color.GREEN)\nFalse\nIndividual flags should have values that are powers of two (1, 2, 4, 8, …), while combinations of flags will not:\n>>> class Color(Flag):\n...\nRED = auto()\n...\nBLUE = auto()\n...\nGREEN = auto()\n...\nWHITE = RED | BLUE | GREEN\n...\n>>> Color.WHITE\n<Color.WHITE: 7>\nGiving a name to the “no flags set” condition does not change its boolean value:\n>>> class Color(Flag):\n...\nBLACK = 0\n...\nRED = auto()\n...\nBLUE = auto()\n...\nGREEN = auto()\n...\n>>> Color.BLACK\n<Color.BLACK: 0>\n>>> bool(Color.BLACK)\nFalse\nFlag members can also be iterated over:\n>>> purple = Color.RED | Color.BLUE\n>>> list(purple)\n[<Color.RED: 1>, <Color.BLUE: 2>]\nAdded in version 3.11. ® Note\nFor the majority of new code, Enum and Flag are strongly recommended, since IntEnum and IntFlag break\nsome semantic promises of an enumeration (by being comparable to integers, and thus by transitivity to other\nunrelated enumerations).\n\n[2] SAD = 2\n... Allowing subclassing of enums that define members would lead to a violation of some important invariants of types\nand instances. On the other hand, it makes sense to allow sharing some common behavior between a group of\nenumerations. (See OrderedEnum for an example.) 9 Dataclass support\nWhen inheriting from a dataclass, the __repr__() omits the inherited class’ name. For example:\n>>> from dataclasses import dataclass, field\n>>> @dataclass\n... class CreatureDataMixin:\n...\nsize: str\n...\nlegs: int\n...\ntail: bool = field(repr=False, default=True)\n...\n>>> class Creature(CreatureDataMixin, Enum):\n...\nBEETLE = 'small', 6\n...\nDOG = 'medium', 4\n...\n>>> Creature.DOG\n<Creature.DOG: size='medium', legs=4>\n9\n\nUse the dataclass() argument repr=False to use the standard repr(). Changed in version 3.12: Only the dataclass fields are shown in the value area, not the dataclass’ name. ® Note\nAdding dataclass() decorator to Enum and its subclasses is not supported. It will not raise any errors, but it\nwill produce very strange results at runtime, such as members being equal to each other:\n>>> @dataclass\n# don't do this: it does not make any sense\n... class Color(Enum):\n...\nRED = 1\n...\nBLUE = 2\n...\n>>> Color.RED is Color.BLUE\nFalse\n>>> Color.RED == Color.BLUE\n# problem is here: they should not be equal\nTrue\n10 Pickling\nEnumerations can be pickled and unpickled:\n>>> from test.test_enum import Fruit\n>>> from pickle import dumps, loads\n>>> Fruit.TOMATO is loads(dumps(Fruit.TOMATO))\nTrue\nThe usual restrictions for pickling apply: picklable enums must be defined in the top level of a module, since unpick-\nling requires them to be importable from that module. ® Note\nWith pickle protocol version 4 it is possible to easily pickle enums nested in other classes. It is possible to modify how enum members are pickled/unpickled by defining __reduce_ex__() in the enumera-\ntion class. The default method is by-value, but enums with complicated values may want to use by-name:\n>>> import enum\n>>> class MyEnum(enum.Enum):\n...\n__reduce_ex__ = enum.pickle_by_enum_name\n® Note\nUsing by-name for flags is not recommended, as unnamed aliases will not unpickle. 11 Functional API\nThe Enum class is callable, providing the following functional API:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG')\n>>> Animal\n<enum 'Animal'>\n(continues on next page)\n10\n\n(continued from previous page)\n>>> Animal.ANT\n<Animal.ANT: 1>\n>>> list(Animal)\n[<Animal.ANT: 1>, <Animal.BEE: 2>, <Animal.CAT: 3>, <Animal.DOG: 4>]\nThe semantics of this API resemble namedtuple. The first argument of the call to Enum is the name of the enu-\nmeration. The second argument is the source of enumeration member names. It can be a whitespace-separated string of names,\na sequence of names, a sequence of 2-tuples with key/value pairs, or a mapping (e.g. dictionary) of names to values. The last two options enable assigning arbitrary values to enumerations; the others auto-assign increasing integers\nstarting with 1 (use the start parameter to specify a different starting value). A new class derived from Enum is\nreturned. In other words, the above assignment to Animal is equivalent to:\n>>> class Animal(Enum):\n...\nANT = 1\n...\nBEE = 2\n...\nCAT = 3\n...\nDOG = 4\n... The reason for defaulting to 1 as the starting number and not 0 is that 0 is False in a boolean sense, but by default\nenum members all evaluate to True. Pickling enums created with the functional API can be tricky as frame stack implementation details are used to try\nand figure out which module the enumeration is being created in (e.g. it will fail if you use a utility function in\na separate module, and also may not work on IronPython or Jython). The solution is to specify the module name\nexplicitly as follows:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', module=__name__)\nÁ Warning\nIf module is not supplied, and Enum cannot determine what it is, the new Enum members will not be unpicklable;\nto keep errors closer to the source, pickling will be disabled. The new pickle protocol 4 also, in some circumstances, relies on __qualname__ being set to the location where\npickle will be able to find the class. For example, if the class was made available in class SomeData in the global\nscope:\n>>> Animal = Enum('Animal', 'ANT BEE CAT DOG', qualname='SomeData.Animal')\nThe complete signature is:\nEnum(\nvalue='NewEnumName',\nnames=<...>,\n*,\nmodule='...',\nqualname='...',\ntype=<mixed-in class>,\nstart=1,\n)\n• value: What the new enum class will record as its name. • names: The enum members. This can be a whitespace- or comma-separated string (values will start at 1 unless\notherwise specified):\n11\n\n'RED GREEN BLUE' | 'RED,GREEN,BLUE' | 'RED, GREEN, BLUE'\nor an iterator of names:\n['RED', 'GREEN', 'BLUE']\nor an iterator of (name, value) pairs:\n[('CYAN', 4), ('MAGENTA', 5), ('YELLOW', 6)]\nor a mapping:\n{'CHARTREUSE': 7, 'SEA_GREEN': 11, 'ROSEMARY': 42}\n• module: name of module where new enum class can be found. • qualname: where in module new enum class can be found. • type: type to mix in to new enum class. • start: number to start counting at if only names are passed in. Changed in version 3.5: The start parameter was added. 12 Derived Enumerations\n12.1 IntEnum\nThe first variation of Enum that is provided is also a subclass of int. Members of an IntEnum can be compared to\nintegers; by extension, integer enumerations of different types can also be compared to each other:\n>>> from enum import IntEnum\n>>> class Shape(IntEnum):\n...\nCIRCLE = 1\n...\nSQUARE = 2\n...\n>>> class Request(IntEnum):\n...\nPOST = 1\n...\nGET = 2\n...\n>>> Shape == 1\nFalse\n>>> Shape.CIRCLE == 1\nTrue\n>>> Shape.CIRCLE == Request.POST\nTrue\nHowever, they still can’t be compared to standard Enum enumerations:\n>>> class Shape(IntEnum):\n...\nCIRCLE = 1\n...\nSQUARE = 2\n...\n>>> class Color(Enum):\n...\nRED = 1\n...\nGREEN = 2\n...\n>>> Shape.CIRCLE == Color.RED\nFalse\n12\n\nIntEnum values behave like integers in other ways you’d expect:\n>>> int(Shape.CIRCLE)\n1\n>>> ['a', 'b', 'c'][Shape.CIRCLE]\n'b'\n>>> [i for i in range(Shape.SQUARE)]\n[0, 1]\n12.2 StrEnum\nThe second variation of Enum that is provided is also a subclass of str. Members of a StrEnum can be compared\nto strings; by extension, string enumerations of different types can also be compared to each other. Added in version 3.11. 12.3 IntFlag\nThe next variation of Enum provided, IntFlag, is also based on int. The difference being IntFlag members can\nbe combined using the bitwise operators (&, |, ^, ~) and the result is still an IntFlag member, if possible. Like\nIntEnum, IntFlag members are also integers and can be used wherever an int is used. ® Note\nAny operation on an IntFlag member besides the bit-wise operations will lose the IntFlag membership. Bit-wise operations that result in invalid IntFlag values will lose the IntFlag membership. See\nFlagBoundary for details. Added in version 3.6. Changed in version 3.11. Sample IntFlag class:\n>>> from enum import IntFlag\n>>> class Perm(IntFlag):\n...\nR = 4\n...\nW = 2\n...\nX = 1\n...\n>>> Perm.R | Perm.W\n<Perm.R|W: 6>\n>>> Perm.R + Perm.W\n6\n>>> RW = Perm.R | Perm.W\n>>> Perm.R in RW\nTrue\nIt is also possible to name the combinations:\n>>> class Perm(IntFlag):\n...\nR = 4\n...\nW = 2\n...\nX = 1\n...\nRWX = 7\n...\n>>> Perm.RWX\n<Perm.RWX: 7>\n(continues on next page)\n13\n\n(continued from previous page)\n>>> ~Perm.RWX\n<Perm: 0>\n>>> Perm(7)\n<Perm.RWX: 7>\n® Note\nNamed combinations are considered aliases. Aliases do not show up during iteration, but can be returned from\nby-value lookups. Changed in version 3.11. Another important difference between IntFlag and Enum is that if no flags are set (the value is 0), its boolean\nevaluation is False:\n>>> Perm.R & Perm.X\n<Perm: 0>\n>>> bool(Perm.R & Perm.X)\nFalse\nBecause IntFlag members are also subclasses of int they can be combined with them (but may lose IntFlag\nmembership:\n>>> Perm.X | 4\n<Perm.R|X: 5>\n>>> Perm.X + 8\n9\n® Note\nThe negation operator, ~, always returns an IntFlag member with a positive value:\n>>> (~Perm.X).value == (Perm.R|Perm.W).value == 6\nTrue\nIntFlag members can also be iterated over:\n>>> list(RW)\n[<Perm.R: 4>, <Perm.W: 2>]\nAdded in version 3.11. 12.4 Flag\nThe last variation is Flag. Like IntFlag, Flag members can be combined using the bitwise operators (&, |, ^,\n~). Unlike IntFlag, they cannot be combined with, nor compared against, any other Flag enumeration, nor int.\n\n[3] Enum HOWTO\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nProgrammatic access to enumeration members and their attributes\n5\n2\nDuplicating enum members and values\n5\n3\nEnsuring unique enumeration values\n6\n4\nUsing automatic values\n6\n5\nIteration\n7\n6\nComparisons\n7\n7\nAllowed members and attributes of enumerations\n8\n8\nRestricted Enum subclassing\n9\n9\nDataclass support\n9\n10 Pickling\n10\n11 Functional API\n10\n12 Derived Enumerations\n12\n12.1 IntEnum . . . . ."")",1.0675325957894946e-155,0.0244457077885162,0.13513060505262692,0.5744129419326782,0.28950602
How to deal with SettingWithCopyWarning in Pandas,"The 
SettingWithCopyWarning
 was created to flag potentially confusing ""chained"" assignments, such as the following, which does not always work as expected, particularly when the first selection returns a 
copy
.  [see 
GH5390
 and 
GH5597
 for background discussion.]


df[df['A'] > 2]['B'] = new_val  # new_val not set in df



The warning offers a suggestion to rewrite as follows:


df.loc[df['A'] > 2, 'B'] = new_val



However, this doesn't fit your usage, which is equivalent to:


df = df[df['A'] > 2]
df['B'] = new_val



While it's clear that you don't care about writes making it back to the original frame (since you are overwriting the reference to it), unfortunately this pattern cannot be differentiated from the first chained assignment example. Hence the (false positive) warning. The potential for false positives is addressed in the 
docs on indexing
, if you'd like to read further.  You can safely disable this new warning with the following assignment.


import pandas as pd
pd.options.mode.chained_assignment = None  # default='warn'





Other Resources




pandas User Guide: Indexing and selecting data


Python Data Science Handbook: Data Indexing and Selection


Real Python: SettingWithCopyWarning in Pandas: Views vs Copies


Dataquest: SettingwithCopyWarning: How to Fix This Warning in Pandas


Towards Data Science: Explaining the SettingWithCopyWarning in pandas



","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] However, it is\neasier and faster to use slice replacement with an implicit or explicit forward iteration. Here are three variations. :\nmylist[:] = filter(keep_function, mylist)\nmylist[:] = (x for x in mylist if keep_condition)\nmylist[:] = [x for x in mylist if keep_condition]\nThe list comprehension may be fastest. 2.5.6 How do you make an array in Python? Use a list:\n[""this"", 1, ""is"", ""an"", ""array""]\nLists are equivalent to C or Pascal arrays in their time complexity; the primary difference is that a Python list can\ncontain objects of many different types. 2.5. Sequences (Tuples/Lists)\n23\n\nPython Frequently Asked Questions, Release 3.13.2\nThe array module also provides methods for creating arrays of fixed types with compact representations, but they\nare slower to index than lists. Also note that NumPy and other third party packages define array-like structures with\nvarious characteristics as well. To get Lisp-style linked lists, you can emulate cons cells using tuples:\nlisp_list = (""like"",\n(""this"",\n(""example"", None) ) )\nIf mutability is desired, you could use lists instead of tuples. Here the analogue of a Lisp car is lisp_list[0] and\nthe analogue of cdr is lisp_list[1]. Only do this if you’re sure you really need to, because it’s usually a lot slower\nthan using Python lists. 2.5.7 How do I create a multidimensional list? You probably tried to make a multidimensional array like this:\n>>> A = [[None] * 2] * 3\nThis looks correct if you print it:\n>>> A\n[[None, None], [None, None], [None, None]]\nBut when you assign a value, it shows up in multiple places:\n>>> A[0][0] = 5\n>>> A\n[[5, None], [5, None], [5, None]]\nThe reason is that replicating a list with * doesn’t create copies, it only creates references to the existing objects. The\n*3 creates a list containing 3 references to the same list of length two. Changes to one row will show in all rows,\nwhich is almost certainly not what you want. The suggested approach is to create a list of the desired length first and then fill in each element with a newly created\nlist:\nA = [None] * 3\nfor i in range(3):\nA[i] = [None] * 2\nThis generates a list containing 3 different lists of length two. You can also use a list comprehension:\nw, h = 2, 3\nA = [[None] * w for i in range(h)]\nOr, you can use an extension that provides a matrix datatype; NumPy is the best known. 2.5.8 How do I apply a method or function to a sequence of objects? To call a method or function and accumulate the return values is a list, a list comprehension is an elegant solution:\nresult = [obj.method() for obj in mylist]\nresult = [function(obj) for obj in mylist]\nTo just run the method or function without saving the return values, a plain for loop will suffice:\nfor obj in mylist:\nobj.method()\n(continues on next page)\n24\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n(continued from previous page)\nfor obj in mylist:\nfunction(obj)\n2.5.9 Why does a_tuple[i] += [‘item’] raise an exception when the addition works? This is because of a combination of the fact that augmented assignment operators are assignment operators, and the\ndifference between mutable and immutable objects in Python. This discussion applies in general when augmented assignment operators are applied to elements of a tuple that point\nto mutable objects, but we’ll use a list and += as our exemplar. If you wrote:\n>>> a_tuple = (1, 2)\n>>> a_tuple[0] += 1\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe reason for the exception should be immediately clear: 1 is added to the object a_tuple[0] points to (1),\nproducing the result object, 2, but when we attempt to assign the result of the computation, 2, to element 0 of the\ntuple, we get an error because we can’t change what an element of a tuple points to. Under the covers, what this augmented assignment statement is doing is approximately this:\n>>> result = a_tuple[0] + 1\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nIt is the assignment part of the operation that produces the error, since a tuple is immutable. When you write something like:\n>>> a_tuple = ([\'foo\'], \'bar\')\n>>> a_tuple[0] += [\'item\']\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe exception is a bit more surprising, and even more surprising is the fact that even though there was an error, the\nappend worked:\n>>> a_tuple[0]\n[\'foo\', \'item\']\nTo see why this happens, you need to know that (a) if an object implements an __iadd__() magic method, it\ngets called when the += augmented assignment is executed, and its return value is what gets used in the assignment\nstatement; and (b) for lists, __iadd__() is equivalent to calling extend() on the list and returning the list. That’s\nwhy we say that for lists, += is a “shorthand” for list.extend():\n>>> a_list = []\n>>> a_list += [1]\n>>> a_list\n[1]\nThis is equivalent to:\n2.5. Sequences (Tuples/Lists)\n25\n\nPython Frequently Asked Questions, Release 3.13.2\n>>> result = a_list.__iadd__([1])\n>>> a_list = result\nThe object pointed to by a_list has been mutated, and the pointer to the mutated object is assigned back to a_list. The end result of the assignment is a no-op, since it is a pointer to the same object that a_list was previously\npointing to, but the assignment still happens. Thus, in our tuple example what is happening is equivalent to:\n>>> result = a_tuple[0].__iadd__([\'item\'])\n>>> a_tuple[0] = result\nTraceback (most recent call last):\n...\nTypeError: \'tuple\' object does not support item assignment\nThe __iadd__() succeeds, and thus the list is extended, but even though result points to the same object that\na_tuple[0] already points to, that final assignment still results in an error, because tuples are immutable. 2.5.10 I want to do a complicated sort: can you do a Schwartzian Transform in\nPython? The technique, attributed to Randal Schwartz of the Perl community, sorts the elements of a list by a metric which\nmaps each element to its “sort value”. In Python, use the key argument for the list.sort() method:\nIsorted = L[:]\nIsorted.sort(key=lambda s: int(s[10:15]))\n2.5.11 How can I sort one list by values from another list? Merge them into an iterator of tuples, sort the resulting list, and then pick out the element you want. >>> list1 = [""what"", ""I\'m"", ""sorting"", ""by""]\n>>> list2 = [""something"", ""else"", ""to"", ""sort""]\n>>> pairs = zip(list1, list2)\n>>> pairs = sorted(pairs)\n>>> pairs\n[(""I\'m"", \'else\'), (\'by\', \'sort\'), (\'sorting\', \'to\'), (\'what\', \'something\')]\n>>> result = [x[1] for x in pairs]\n>>> result\n[\'else\', \'sort\', \'to\', \'something\']\n2.6 Objects\n2.6.1 What is a class? A class is the particular object type created by executing a class statement. Class objects are used as templates to\ncreate instance objects, which embody both the data (attributes) and code (methods) specific to a datatype. A class can be based on one or more other classes, called its base class(es). It then inherits the attributes and meth-\nods of its base classes. This allows an object model to be successively refined by inheritance. You might have a\ngeneric Mailbox class that provides basic accessor methods for a mailbox, and subclasses such as MboxMailbox,\nMaildirMailbox, OutlookMailbox that handle various specific mailbox formats. 26\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.6.2 What is a method? A method is a function on some object x that you normally call as x.name(arguments...). Methods are defined\nas functions inside the class definition:\nclass C:\ndef meth(self, arg):\nreturn arg * 2 + self.attribute\n2.6.3 What is self? Self is merely a conventional name for the first argument of a method. A method defined as meth(self, a, b,\nc) should be called as x.meth(a, b, c) for some instance x of the class in which the definition occurs; the called\nmethod will think it is called as meth(x, a, b, c). See also Why must ‘self’ be used explicitly in method definitions and calls?. 2.6.4 How do I check if an object is an instance of a given class or of a subclass\nof it? Use the built-in function isinstance(obj, cls). You can check if an object is an instance of any of a num-\nber of classes by providing a tuple instead of a single class, e.g. isinstance(obj, (class1, class2, ..\n\n[2] . . . . . . . . 1942\n30.5.2\n__main__.py in Python Packages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1944\n30.5.3\nimport __main__ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1945\n30.6\nwarnings — Warning control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1947\n30.6.1\nWarning Categories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1947\n30.6.2\nThe Warnings Filter . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . 228\n10.3\nPyStatus\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n10.4\nPyPreConfig\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230\n10.5\nPreinitialize Python with PyPreConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n10.6\nPyConfig . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",1.9415631044434e-155,0.057874234835837514,0.20469257188613119,0.5378237366676331,0.28162867
How to drop rows of Pandas DataFrame whose value in a certain column is NaN,"Don't drop, just take the rows where EPS is not NA:


df = df[df['EPS'].notna()]


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . 18\n2.3.3\nHow do I get int literal attribute instead of SyntaxError? . . . . . . . . . . . . . . . . . . 18\n2.3.4\nHow do I convert a string to a number? . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n2.3.5\nHow do I convert a number to a string? . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.6\nHow do I modify a string in place? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.7\nHow do I use strings to call functions/methods? . . .\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",3.886167727468338e-232,0.018348623853211007,0.07894736842105265,0.4164314866065979,0.18003556
Running shell command and capturing the output,"In all officially maintained versions of Python, the simplest approach is to use the 
subprocess.check_output
 function:


>>> subprocess.check_output(['ls', '-l'])
b'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



check_output
 runs a single program that takes only arguments as input.
1
 It returns the result exactly as printed to 
stdout
. If you need to write input to 
stdin
, skip ahead to the 
run
 or 
Popen
 sections. If you want to execute complex shell commands, see the note on 
shell=True
 at the end of this answer.


The 
check_output
 function works in all officially maintained versions of Python. But for more recent versions, a more flexible approach is available.


Modern versions of Python (3.5 or higher): 
run


If you're using 
Python 3.5+
, and 
do not need backwards compatibility
, the new 
run
 function is recommended by the official documentation for most tasks. It provides a very general, high-level API for the 
subprocess
 module. To capture the output of a program, pass the 
subprocess.PIPE
 flag to the 
stdout
 keyword argument. Then access the 
stdout
 attribute of the returned 
CompletedProcess
 object:


>>> import subprocess
>>> result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)
>>> result.stdout
b'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



The return value is a 
bytes
 object, so if you want a proper string, you'll need to 
decode
 it. Assuming the called process returns a UTF-8-encoded string:


>>> result.stdout.decode('utf-8')
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



This can all be compressed to a one-liner if desired:


>>> subprocess.run(['ls', '-l'], stdout=subprocess.PIPE).stdout.decode('utf-8')
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



If you want to pass input to the process's 
stdin
, you can pass a 
bytes
 object to the 
input
 keyword argument:


>>> cmd = ['awk', 'length($0) > 5']
>>> ip = 'foo\nfoofoo\n'.encode('utf-8')
>>> result = subprocess.run(cmd, stdout=subprocess.PIPE, input=ip)
>>> result.stdout.decode('utf-8')
'foofoo\n'



You can capture errors by passing 
stderr=subprocess.PIPE
 (capture to 
result.stderr
) or 
stderr=subprocess.STDOUT
 (capture to 
result.stdout
 along with regular output). If you want 
run
 to throw an exception when the process returns a nonzero exit code, you can pass 
check=True
. (Or you can check the 
returncode
 attribute of 
result
 above.) When security is not a concern, you can also run more complex shell commands by passing 
shell=True
 as described at the end of this answer.


Later versions of Python streamline the above further. In Python 3.7+, the above one-liner can be spelled like this:


>>> subprocess.run(['ls', '-l'], capture_output=True, text=True).stdout
'total 0\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\n'



Using 
run
 this way adds just a bit of complexity, compared to the old way of doing things. But now you can do almost anything you need to do with the 
run
 function alone.


Older versions of Python (3-3.4): more about 
check_output


If you are using an older version of Python, or need modest backwards compatibility, you can use the 
check_output
 function as briefly described above. It has been available since Python 2.7.


subprocess.check_output(*popenargs, **kwargs)  



It takes takes the same arguments as 
Popen
 (see below), and returns a string containing the program's output. The beginning of this answer has a more detailed usage example. In Python 3.5+, 
check_output
 is equivalent to executing 
run
 with 
check=True
 and 
stdout=PIPE
, and returning just the 
stdout
 attribute.


You can pass 
stderr=subprocess.STDOUT
 to ensure that error messages are included in the returned output. When security is not a concern, you can also run more complex shell commands by passing 
shell=True
 as described at the end of this answer.


If you need to pipe from 
stderr
 or pass input to the process, 
check_output
 won't be up to the task. See the 
Popen
 examples below in that case.


Complex applications and legacy versions of Python (2.6 and below): 
Popen


If you need deep backwards compatibility, or if you need more sophisticated functionality than 
check_output
 or 
run
 provide, you'll have to work directly with 
Popen
 objects, which encapsulate the low-level API for subprocesses.


The 
Popen
 constructor accepts either 
a single command
 without arguments, or 
a list
 containing a command as its first item, followed by any number of arguments, each as a separate item in the list. 
shlex.split
 can help parse strings into appropriately formatted lists. 
Popen
 objects also accept a 
host of different arguments
 for process IO management and low-level configuration.


To send input and capture output, 
communicate
 is almost always the preferred method. As in:


output = subprocess.Popen([""mycmd"", ""myarg""], 
                          stdout=subprocess.PIPE).communicate()[0]



Or


>>> import subprocess
>>> p = subprocess.Popen(['ls', '-a'], stdout=subprocess.PIPE, 
...                                    stderr=subprocess.PIPE)
>>> out, err = p.communicate()
>>> print out
.
..
foo



If you set 
stdin=PIPE
, 
communicate
 also allows you to pass data to the process via 
stdin
:


>>> cmd = ['awk', 'length($0) > 5']
>>> p = subprocess.Popen(cmd, stdout=subprocess.PIPE,
...                           stderr=subprocess.PIPE,
...                           stdin=subprocess.PIPE)
>>> out, err = p.communicate('foo\nfoofoo\n')
>>> print out
foofoo



Note 
Aaron Hall's answer
, which indicates that on some systems, you may need to set 
stdout
, 
stderr
, and 
stdin
 all to 
PIPE
 (or 
DEVNULL
) to get 
communicate
 to work at all.


In some rare cases, you may need complex, real-time output capturing. 
Vartec
's answer suggests a way forward, but methods other than 
communicate
 are prone to deadlocks if not used carefully.


As with all the above functions, when security is not a concern, you can run more complex shell commands by passing 
shell=True
.


Notes


1. Running shell commands: the 
shell=True
 argument


Normally, each call to 
run
, 
check_output
, or the 
Popen
 constructor executes a 
single program
. That means no fancy bash-style pipes. If you want to run complex shell commands, you can pass 
shell=True
, which all three functions support. For example:


>>> subprocess.check_output('cat books/* | wc', shell=True, text=True)
' 1299377 17005208 101299376\n'



However, doing this raises 
security concerns
. If you're doing anything more than light scripting, you might be better off calling each process separately, and passing the output from each as an input to the next, via


run(cmd, [stdout=etc...], input=other_output)



Or


Popen(cmd, [stdout=etc...]).communicate(other_output)



The temptation to directly connect pipes is strong; resist it. Otherwise, you'll likely see deadlocks or have to do hacky things like 
this
.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . 1871\n28.6.2\nPython Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1872\n28.6.3\nCommand-Line Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1874\n28.6.4\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1874\n28.7\ntrace — Trace or track Python statement execution\n. . . . . . . . . . . . . . . . . . . . . . . . 1876\n28.7.1\nCommand-Line Usage\n. . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . 55\n4.8.3\nArguments in shebang lines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n4.8.4\nCustomization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n4.8.5\nDiagnostics\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.8.6\nDry Run . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n4.8.7\nInstall on demand . . . . . . . . . . . . . .\n\n[3] . . . . . . . 1710\n27.4.3\nCommand-line Usage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1711\n27.4.4\nHow It Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1711\n27.4.5\nBasic API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1718\n27.4.6\nUnittest API . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1720\n27.4.7\nAdvanced API . . . . . . . . . . . . . . . . . . . .')",5.866626428615233e-156,0.04472843450479232,0.031282173121089725,0.47456616163253784,0.34808713
Automatically create file 'requirements.txt',"Use 
Pipenv or other tools
 is recommended for improving your development flow.


pip3 freeze > requirements.txt  # Python3
pip freeze > requirements.txt  # Python2



If you do not use a virtual environment, 
pigar
 will be a good choice for you.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 20\n2.3\nPython-related paths and files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n2.4\nMiscellaneous . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.5\nCustom OpenSSL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3\nConfigure Python\n23\n3.1\nBuild Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2\nGenerated files . .\n\n[2] . . . . . . 21\n3\nConfigure Python\n23\n3.1\nBuild Requirements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2\nGenerated files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.2.1\nconfigure script . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3\nConfigure Options\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.3.1\nGeneral Options . . . .\n\n[3] . . . . . . . . 18\n5.47 unicodedata . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.48 venv . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.49 warnings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.50 xml\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n5.51 zipimport\n. . . . . . . .')",0.0,0.02777777777777778,0.014836795252225523,0.4294261932373047,0.44760036
"How can I overcome ""datetime.datetime not JSON serializable""?","Updated for 2018


The original answer accommodated the way MongoDB ""date"" fields were represented as:


{""$date"": 1506816000000}


If you want a generic Python solution for serializing 
datetime
 to json, check out 
@jjmontes' answer
 for a quick solution which requires no dependencies.




As you are using mongoengine (per comments) and pymongo is a dependency, pymongo has built-in utilities to help with json serialization:


http://api.mongodb.org/python/1.10.1/api/bson/json_util.html


Example usage (serialization):


from bson import json_util
import json

json.dumps(anObject, default=json_util.default)



Example usage (deserialization):


json.loads(aJsonString, object_hook=json_util.object_hook)





Django


Django provides a native 
DjangoJSONEncoder
 serializer that deals with this kind of properly.


See 
https://docs.djangoproject.com/en/dev/topics/serialization/#djangojsonencoder


from django.core.serializers.json import DjangoJSONEncoder

return json.dumps(
  item,
  sort_keys=True,
  indent=1,
  cls=DjangoJSONEncoder
)



One difference I've noticed between 
DjangoJSONEncoder
 and using a custom 
default
 like this:


import datetime
import json

def default(o):
    if isinstance(o, (datetime.date, datetime.datetime)):
        return o.isoformat()

return json.dumps(
  item,
  sort_keys=True,
  indent=1,
  default=default
)



Is that Django strips a bit of the data:


 ""last_login"": ""2018-08-03T10:51:42.990"", # DjangoJSONEncoder 
 ""last_login"": ""2018-08-03T10:51:42.990239"", # default



So, you may need to be careful about that in some cases.

","('Answer: To get an aware datetime object, you can call `datetime.fromtimestamp(timestamp, timezone.utc)`.\n\nReferences: [3]\n', '[1] (The resulting object\nis naive.) This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C\ngmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,\nsecond and microsecond of the result are all 0, and tzinfo is None. classmethod datetime.combine(date, time, tzinfo=time.tzinfo)\nReturn a new datetime object whose date components are equal to the given date object’s, and whose time\ncomponents are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set\nthe tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date\nargument is a datetime object, its time components and tzinfo attributes are ignored. For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo). Changed in version 3.6: Added the tzinfo argument. classmethod datetime.fromisoformat(date_string)\nReturn a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:\n1. Time zone offsets may have fractional seconds. 8.1. datetime — Basic date and time types\n215\n\nThe Python Library Reference, Release 3.13.2\n2. The T separator may be replaced by any single unicode character. 3. Fractional hours and minutes are not supported. 4. Reduced precision dates are not currently supported (YYYY-MM, YYYY). 5. Extended date representations are not currently supported (±YYYYYY-MM-DD). 6. Ordinal dates are not currently supported (YYYY-OOO). Examples:\n>>> from datetime import datetime\n>>> datetime.fromisoformat(\'2011-11-04\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'20111104\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23Z\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'20111104T000523\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-W01-2T00:05:23.283\')\ndatetime.datetime(2011, 1, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283+00:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23+04:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23,\ntzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))\nAdded in version 3.7. Changed in version 3.11: Previously, this method only supported formats that could be emitted by date. isoformat() or datetime.isoformat(). classmethod datetime.fromisocalendar(year, week, day)\nReturn a datetime corresponding to the ISO calendar date specified by year, week and day. The non-date\ncomponents of the datetime are populated with their normal default values. This is the inverse of the function\ndatetime.isocalendar(). Added in version 3.8.\nclassmethod datetime.strptime(date_string, format)\nReturn a datetime corresponding to date_string, parsed according to format. If format does not contain microseconds or time zone information, this is equivalent to:\ndatetime(*(time.strptime(date_string, format)[0:6]))\nValueError is raised if the date_string and format can’t be parsed by time.strptime() or if it returns a\nvalue which isn’t a time tuple. See also strftime() and strptime() Behavior and datetime.fromisoformat(). Changed in version 3.13: If format specifies a day of month without a year a DeprecationWarning is now\nemitted. This is to avoid a quadrennial leap year bug in code seeking to parse only a month and day as the\ndefault year used in absence of one in the format is not a leap year. Such format values may raise an error as\nof Python 3.15. The workaround is to always include a year in your format. If parsing date_string values that\ndo not have a year, explicitly add a year that is a leap year before parsing:\n>>> from datetime import datetime\n>>> date_string = ""02/29""\n(continues on next page)\n216\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> when = datetime.strptime(f""{date_string};1984"", ""%m/%d;%Y"")\n# Avoids leap␣\n,→year bug. >>> when.strftime(""%B %d"")\n\'February 29\'\nClass attributes:\ndatetime.min\nThe earliest representable datetime, datetime(MINYEAR, 1, 1, tzinfo=None). datetime.max\nThe\nlatest\nrepresentable\ndatetime,\ndatetime(MAXYEAR, 12, 31, 23, 59, 59, 999999,\ntzinfo=None). datetime.resolution\nThe smallest possible difference between non-equal datetime objects, timedelta(microseconds=1). Instance attributes (read-only):\ndatetime.year\nBetween MINYEAR and MAXYEAR inclusive. datetime.month\nBetween 1 and 12 inclusive. datetime.day\nBetween 1 and the number of days in the given month of the given year. datetime.hour\nIn range(24).\n\n[2] This may raise OverflowError, if the timestamp is out of the range of values supported by the platform C\ngmtime() function, and OSError on gmtime() failure. It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,\nsecond and microsecond of the result are all 0, and tzinfo is None. classmethod datetime.combine(date, time, tzinfo=time.tzinfo)\nReturn a new datetime object whose date components are equal to the given date object’s, and whose time\ncomponents are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set\nthe tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date\nargument is a datetime object, its time components and tzinfo attributes are ignored. For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo). Changed in version 3.6: Added the tzinfo argument. classmethod datetime.fromisoformat(date_string)\nReturn a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:\n1. Time zone offsets may have fractional seconds. 8.1. datetime — Basic date and time types\n215\n\nThe Python Library Reference, Release 3.13.2\n2. The T separator may be replaced by any single unicode character. 3. Fractional hours and minutes are not supported. 4. Reduced precision dates are not currently supported (YYYY-MM, YYYY). 5. Extended date representations are not currently supported (±YYYYYY-MM-DD). 6. Ordinal dates are not currently supported (YYYY-OOO). Examples:\n>>> from datetime import datetime\n>>> datetime.fromisoformat(\'2011-11-04\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'20111104\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23Z\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'20111104T000523\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-W01-2T00:05:23.283\')\ndatetime.datetime(2011, 1, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283+00:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23+04:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23,\ntzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))\nAdded in version 3.7. Changed in version 3.11: Previously, this method only supported formats that could be emitted by date. isoformat() or datetime.isoformat(). classmethod datetime.fromisocalendar(year, week, day)\nReturn a datetime corresponding to the ISO calendar date specified by year, week and day. The non-date\ncomponents of the datetime are populated with their normal default values. This is the inverse of the function\ndatetime.isocalendar(). Added in version 3.8.\nclassmethod datetime.strptime(date_string, format)\nReturn a datetime corresponding to date_string, parsed according to format. If format does not contain microseconds or time zone information, this is equivalent to:\ndatetime(*(time.strptime(date_string, format)[0:6]))\nValueError is raised if the date_string and format can’t be parsed by time.strptime() or if it returns a\nvalue which isn’t a time tuple. See also strftime() and strptime() Behavior and datetime.fromisoformat(). Changed in version 3.13: If format specifies a day of month without a year a DeprecationWarning is now\nemitted. This is to avoid a quadrennial leap year bug in code seeking to parse only a month and day as the\ndefault year used in absence of one in the format is not a leap year. Such format values may raise an error as\nof Python 3.15. The workaround is to always include a year in your format. If parsing date_string values that\ndo not have a year, explicitly add a year that is a leap year before parsing:\n>>> from datetime import datetime\n>>> date_string = ""02/29""\n(continues on next page)\n216\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> when = datetime.strptime(f""{date_string};1984"", ""%m/%d;%Y"")\n# Avoids leap␣\n,→year bug. >>> when.strftime(""%B %d"")\n\'February 29\'\nClass attributes:\ndatetime.min\nThe earliest representable datetime, datetime(MINYEAR, 1, 1, tzinfo=None). datetime.max\nThe\nlatest\nrepresentable\ndatetime,\ndatetime(MAXYEAR, 12, 31, 23, 59, 59, 999999,\ntzinfo=None). datetime.resolution\nThe smallest possible difference between non-equal datetime objects, timedelta(microseconds=1). Instance attributes (read-only):\ndatetime.year\nBetween MINYEAR and MAXYEAR inclusive. datetime.month\nBetween 1 and 12 inclusive. datetime.day\nBetween 1 and the number of days in the given month of the given year. datetime.hour\nIn range(24). datetime.minute\nIn range(60).\n\n[3] It’s common for this to be restricted to years in 1970\nthrough 2038. To get an aware datetime object, call fromtimestamp():\ndatetime.fromtimestamp(timestamp, timezone.utc)\nOn the POSIX compliant platforms, it is equivalent to the following expression:\ndatetime(1970, 1, 1, tzinfo=timezone.utc) + timedelta(seconds=timestamp)\nexcept the latter formula always supports the full years range: between MINYEAR and MAXYEAR inclusive. Á Warning\nBecause naive datetime objects are treated by many datetime methods as local times, it is preferred\nto use aware datetimes to represent times in UTC. As such, the recommended way to create an ob-\nject representing a specific timestamp in UTC is by calling datetime.fromtimestamp(timestamp,\ntz=timezone.utc). Changed in version 3.3: Raise OverflowError instead of ValueError if the timestamp is out of the range\nof values supported by the platform C gmtime() function. Raise OSError instead of ValueError on\ngmtime() failure. Deprecated since version 3.12: Use datetime.fromtimestamp() with UTC instead. classmethod datetime.fromordinal(ordinal)\nReturn the datetime corresponding to the proleptic Gregorian ordinal, where January 1 of year 1 has ordinal\n1. ValueError is raised unless 1 <= ordinal <= datetime.max.toordinal(). The hour, minute,\nsecond and microsecond of the result are all 0, and tzinfo is None. classmethod datetime.combine(date, time, tzinfo=time.tzinfo)\nReturn a new datetime object whose date components are equal to the given date object’s, and whose time\ncomponents are equal to the given time object’s. If the tzinfo argument is provided, its value is used to set\nthe tzinfo attribute of the result, otherwise the tzinfo attribute of the time argument is used. If the date\nargument is a datetime object, its time components and tzinfo attributes are ignored. For any datetime object d, d == datetime.combine(d.date(), d.time(), d.tzinfo). Changed in version 3.6: Added the tzinfo argument. classmethod datetime.fromisoformat(date_string)\nReturn a datetime corresponding to a date_string in any valid ISO 8601 format, with the following exceptions:\n1. Time zone offsets may have fractional seconds. 8.1. datetime — Basic date and time types\n215\n\nThe Python Library Reference, Release 3.13.2\n2. The T separator may be replaced by any single unicode character. 3. Fractional hours and minutes are not supported. 4. Reduced precision dates are not currently supported (YYYY-MM, YYYY). 5. Extended date representations are not currently supported (±YYYYYY-MM-DD). 6. Ordinal dates are not currently supported (YYYY-OOO). Examples:\n>>> from datetime import datetime\n>>> datetime.fromisoformat(\'2011-11-04\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'20111104\')\ndatetime.datetime(2011, 11, 4, 0, 0)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23Z\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'20111104T000523\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23)\n>>> datetime.fromisoformat(\'2011-W01-2T00:05:23.283\')\ndatetime.datetime(2011, 1, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000)\n>>> datetime.fromisoformat(\'2011-11-04 00:05:23.283+00:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23, 283000, tzinfo=datetime.timezone.utc)\n>>> datetime.fromisoformat(\'2011-11-04T00:05:23+04:00\')\ndatetime.datetime(2011, 11, 4, 0, 5, 23,\ntzinfo=datetime.timezone(datetime.timedelta(seconds=14400)))\nAdded in version 3.7. Changed in version 3.11: Previously, this method only supported formats that could be emitted by date. isoformat() or datetime.isoformat(). classmethod datetime.fromisocalendar(year, week, day)\nReturn a datetime corresponding to the ISO calendar date specified by year, week and day. The non-date\ncomponents of the datetime are populated with their normal default values. This is the inverse of the function\ndatetime.isocalendar(). Added in version 3.8.\nclassmethod datetime.strptime(date_string, format)\nReturn a datetime corresponding to date_string, parsed according to format. If format does not contain microseconds or time zone information, this is equivalent to:\ndatetime(*(time.strptime(date_string, format)[0:6]))\nValueError is raised if the date_string and format can’t be parsed by time.strptime() or if it returns a\nvalue which isn’t a time tuple. See also strftime() and strptime() Behavior and datetime.fromisoformat(). Changed in version 3.13: If format specifies a day of month without a year a DeprecationWarning is now\nemitted. This is to avoid a quadrennial leap year bug in code seeking to parse only a month and day as the\ndefault year used in absence of one in the format is not a leap year. Such format values may raise an error as\nof Python 3.15. The workaround is to always include a year in your format. If parsing date_string values that\ndo not have a year, explicitly add a year that is a leap year before parsing:\n>>> from datetime import datetime\n>>> date_string = ""02/29""\n(continues on next page)\n216\nChapter 8. Data Types\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> when = datetime.strptime(f""{date_string};1984"", ""%m/%d;%Y"")\n# Avoids leap␣\n,→year bug. >>> when.strftime(""%B %d"")\n\'February 29\'\nClass attributes:\ndatetime.min\nThe earliest representable datetime, datetime(MINYEAR, 1, 1, tzinfo=None). datetime.max\nThe\nlatest\nrepresentable\ndatetime,\ndatetime(MAXYEAR, 12, 31, 23, 59, 59, 999999,\ntzinfo=None). datetime.resolution\nThe smallest possible difference between non-equal datetime objects, timedelta(microseconds=1). Instance attributes (read-only):\ndatetime.year\nBetween MINYEAR and MAXYEAR inclusive. datetime.month\nBetween 1 and 12 inclusive. datetime.day\nBetween 1 and the number of days in the given month of the given year. datetime.hour\nIn range(24). datetime.minute\nIn range(60). datetime.second\nIn range(60).')",1.2109025215225426e-155,0.033992583436341164,0.12882635124012104,0.5381816625595093,0.4516505
String formatting: % vs. .format vs. f-string literal,"To answer your first question... 
.format
 just seems more sophisticated in many ways. An annoying thing about 
%
 is also how it can either take a variable or a tuple. You'd think the following would always work:


""Hello %s"" % name



yet, if 
name
 happens to be 
(1, 2, 3)
, it will throw a 
TypeError
. To guarantee that it always prints, you'd need to do


""Hello %s"" % (name,)   # supply the single argument as a single-item tuple



which is just ugly. 
.format
 doesn't have those issues. Also in the second example you gave, the 
.format
 example is much cleaner looking.


Only use it for backwards compatibility with Python 2.5.




To answer your second question, string formatting happens at the same time as any other operation - when the string formatting expression is evaluated. And Python, not being a lazy language, evaluates expressions before calling functions, so the expression 
log.debug(""some debug info: %s"" % some_info)
 will first evaluate the string to, e.g. 
""some debug info: roflcopters are active""
, then that string will be passed to 
log.debug()
.

","('Answer: There are three ways to format output: formatted string literals (f-strings), the str.format() method, and manual string formatting. F-strings allow you to include the value of Python expressions inside a string by prefixing the string with `f` or `F` and writing expressions as `{expression}`. The str.format() method uses `{}` to mark where a variable will be substituted and requires you to provide the information to be formatted. Finally, you can do all the string handling manually using string slicing and concatenation operations.\n\nReferences: [2, 3]\n', '[1] There\nare several ways to format output. • To use formatted string literals, begin a string with f or F before the opening quotation mark or triple quotation\nmark. Inside this string, you can write a Python expression between { and } characters that can refer to\nvariables or literal values. >>> year = 2016\n>>> event = \'Referendum\'\n>>> f\'Results of the {year} {event}\'\n\'Results of the 2016 Referendum\'\n• The str.format() method of strings requires more manual effort. You’ll still use { and } to mark where a\nvariable will be substituted and can provide detailed formatting directives, but you’ll also need to provide the\ninformation to be formatted. In the following code block there are two examples of how to format variables:\n>>> yes_votes = 42_572_654\n>>> total_votes = 85_705_149\n>>> percentage = yes_votes / total_votes\n>>> \'{:-9} YES votes\n{:2.2%}\'.format(yes_votes, percentage)\n\' 42572654 YES votes\n49.67%\'\nNotice how the yes_votes are padded with spaces and a negative sign only for negative numbers. The\nexample also prints percentage multiplied by 100, with 2 decimal places and followed by a percent sign (see\nformatspec for details). • Finally, you can do all the string handling yourself by using string slicing and concatenation operations to create\nany layout you can imagine. The string type has some methods that perform useful operations for padding\nstrings to a given column width. When you don’t need fancy output but just want a quick display of some variables for debugging purposes, you can\nconvert any value to a string with the repr() or str() functions. The str() function is meant to return representations of values which are fairly human-readable, while repr()\nis meant to generate representations which can be read by the interpreter (or will force a SyntaxError if there is\nno equivalent syntax). For objects which don’t have a particular representation for human consumption, str() will\nreturn the same value as repr(). Many values, such as numbers or structures like lists and dictionaries, have the\nsame representation using either function. Strings, in particular, have two distinct representations. 53\n\nPython Tutorial, Release 3.13.2\nSome examples:\n>>> s = \'Hello, world.\' >>> str(s)\n\'Hello, world.\' >>> repr(s)\n""\'Hello, world.\'"" >>> str(1/7)\n\'0.14285714285714285\'\n>>> x = 10 * 3.25\n>>> y = 200 * 200\n>>> s = \'The value of x is \' + repr(x) + \', and y is \' + repr(y) + \'...\'\n>>> print(s)\nThe value of x is 32.5, and y is 40000...\n>>> # The repr() of a string adds string quotes and backslashes:\n>>> hello = \'hello, world\\n\'\n>>> hellos = repr(hello)\n>>> print(hellos)\n\'hello, world\\n\'\n>>> # The argument to repr() may be any Python object:\n>>> repr((x, y, (\'spam\', \'eggs\')))\n""(32.5, 40000, (\'spam\', \'eggs\'))""\nThe string module contains a Template class that offers yet another way to substitute values into strings, using\nplaceholders like $x and replacing them with values from a dictionary, but offers much less control of the formatting. 7.1.1 Formatted String Literals\nFormatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string\nby prefixing the string with f or F and writing expressions as {expression}. An optional format specifier can follow the expression. This allows greater control over how the value is formatted. The following example rounds pi to three places after the decimal:\n>>> import math\n>>> print(f\'The value of pi is approximately {math.pi:.3f}.\') The value of pi is approximately 3.142. Passing an integer after the \':\' will cause that field to be a minimum number of characters wide. This is useful for\nmaking columns line up. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 7678}\n>>> for name, phone in table.items():\n...\nprint(f\'{name:10} ==> {phone:10d}\')\n...\nSjoerd\n==>\n4127\nJack\n==>\n4098\nDcab\n==>\n7678\nOther modifiers can be used to convert the value before it is formatted. \'!a\' applies ascii(), \'!s\' applies str(),\nand \'!r\' applies repr():\n>>> animals = \'eels\'\n>>> print(f\'My hovercraft is full of {animals}.\') My hovercraft is full of eels. >>> print(f\'My hovercraft is full of {animals!r}.\') My hovercraft is full of \'eels\'. The = specifier can be used to expand an expression to the text of the expression, an equal sign, then the representation\nof the evaluated expression:\n54\nChapter 7. Input and Output\n\nPython Tutorial, Release 3.13.2\n>>> bugs = \'roaches\'\n>>> count = 13\n>>> area = \'living room\'\n>>> print(f\'Debugging {bugs=} {count=} {area=}\')\nDebugging bugs=\'roaches\' count=13 area=\'living room\'\nSee self-documenting expressions for more information on the = specifier. For a reference on these format specifi-\ncations, see the reference guide for the formatspec. 7.1.2 The String format() Method\nBasic usage of the str.format() method looks like this:\n>>> print(\'We are the {} who say ""{}! ""\'.format(\'knights\', \'Ni\'))\nWe are the knights who say ""Ni!"" The brackets and characters within them (called format fields) are replaced with the objects passed into the str. format() method. A number in the brackets can be used to refer to the position of the object passed into the\nstr.format() method. >>> print(\'{0} and {1}\'.format(\'spam\', \'eggs\'))\nspam and eggs\n>>> print(\'{1} and {0}\'.format(\'spam\', \'eggs\'))\neggs and spam\nIf keyword arguments are used in the str.format() method, their values are referred to by using the name of the\nargument. >>> print(\'This {food} is {adjective}. \'.format(\n...\nfood=\'spam\', adjective=\'absolutely horrible\'))\nThis spam is absolutely horrible. Positional and keyword arguments can be arbitrarily combined:\n>>> print(\'The story of {0}, {1}, and {other}. \'.format(\'Bill\', \'Manfred\',\n...\nother=\'Georg\'))\nThe story of Bill, Manfred, and Georg. If you have a really long format string that you don’t want to split up, it would be nice if you could reference the\nvariables to be formatted by name instead of by position. This can be done by simply passing the dict and using\nsquare brackets \'[]\' to access the keys. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; \'\n...\n\'Dcab: {0[Dcab]:d}\'.format(table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis could also be done by passing the table dictionary as keyword arguments with the ** notation. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}\'.format(**table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis is particularly useful in combination with the built-in function vars(), which returns a dictionary containing\nall local variables:\n>>> table = {k: str(v) for k, v in vars().items()}\n>>> message = "" "".join([f\'{k}: \' + \'{\' + k +\'};\' for k in table.keys()])\n(continues on next page)\n7.1. Fancier Output Formatting\n55\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n>>> print(message.format(**table))\n__name__: __main__; __doc__: None; __package__: None; __loader__: ...\nAs an example, the following lines produce a tidily aligned set of columns giving integers and their squares and cubes:\n>>> for x in range(1, 11):\n...\nprint(\'{0:2d} {1:3d} {2:4d}\'.format(x, x*x, x*x*x))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\nFor a complete overview of string formatting with str.format(), see formatstrings. 7.1.3 Manual String Formatting\nHere’s the same table of squares and cubes, formatted manually:\n>>> for x in range(1, 11):\n...\nprint(repr(x).rjust(2), repr(x*x).rjust(3), end=\' \')\n...\n# Note use of \'end\' on previous line\n...\nprint(repr(x*x*x).rjust(4))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\n(Note that the one space between each column was added by the way print() works: it always adds spaces between\nits arguments.) The str.rjust() method of string objects right-justifies a string in a field of a given width by padding it with spaces\non the left. There are similar methods str.ljust() and str.center().\n\n[2] See the\nLibrary Reference for more information on this.) Often you’ll want more control over the formatting of your output than simply printing space-separated values. There\nare several ways to format output. • To use formatted string literals, begin a string with f or F before the opening quotation mark or triple quotation\nmark. Inside this string, you can write a Python expression between { and } characters that can refer to\nvariables or literal values. >>> year = 2016\n>>> event = \'Referendum\'\n>>> f\'Results of the {year} {event}\'\n\'Results of the 2016 Referendum\'\n• The str.format() method of strings requires more manual effort. You’ll still use { and } to mark where a\nvariable will be substituted and can provide detailed formatting directives, but you’ll also need to provide the\ninformation to be formatted. In the following code block there are two examples of how to format variables:\n>>> yes_votes = 42_572_654\n>>> total_votes = 85_705_149\n>>> percentage = yes_votes / total_votes\n>>> \'{:-9} YES votes\n{:2.2%}\'.format(yes_votes, percentage)\n\' 42572654 YES votes\n49.67%\'\nNotice how the yes_votes are padded with spaces and a negative sign only for negative numbers. The\nexample also prints percentage multiplied by 100, with 2 decimal places and followed by a percent sign (see\nformatspec for details). • Finally, you can do all the string handling yourself by using string slicing and concatenation operations to create\nany layout you can imagine. The string type has some methods that perform useful operations for padding\nstrings to a given column width. When you don’t need fancy output but just want a quick display of some variables for debugging purposes, you can\nconvert any value to a string with the repr() or str() functions. The str() function is meant to return representations of values which are fairly human-readable, while repr()\nis meant to generate representations which can be read by the interpreter (or will force a SyntaxError if there is\nno equivalent syntax). For objects which don’t have a particular representation for human consumption, str() will\nreturn the same value as repr(). Many values, such as numbers or structures like lists and dictionaries, have the\nsame representation using either function. Strings, in particular, have two distinct representations. 53\n\nPython Tutorial, Release 3.13.2\nSome examples:\n>>> s = \'Hello, world.\' >>> str(s)\n\'Hello, world.\' >>> repr(s)\n""\'Hello, world.\'"" >>> str(1/7)\n\'0.14285714285714285\'\n>>> x = 10 * 3.25\n>>> y = 200 * 200\n>>> s = \'The value of x is \' + repr(x) + \', and y is \' + repr(y) + \'...\'\n>>> print(s)\nThe value of x is 32.5, and y is 40000...\n>>> # The repr() of a string adds string quotes and backslashes:\n>>> hello = \'hello, world\\n\'\n>>> hellos = repr(hello)\n>>> print(hellos)\n\'hello, world\\n\'\n>>> # The argument to repr() may be any Python object:\n>>> repr((x, y, (\'spam\', \'eggs\')))\n""(32.5, 40000, (\'spam\', \'eggs\'))""\nThe string module contains a Template class that offers yet another way to substitute values into strings, using\nplaceholders like $x and replacing them with values from a dictionary, but offers much less control of the formatting. 7.1.1 Formatted String Literals\nFormatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string\nby prefixing the string with f or F and writing expressions as {expression}. An optional format specifier can follow the expression. This allows greater control over how the value is formatted. The following example rounds pi to three places after the decimal:\n>>> import math\n>>> print(f\'The value of pi is approximately {math.pi:.3f}.\') The value of pi is approximately 3.142. Passing an integer after the \':\' will cause that field to be a minimum number of characters wide. This is useful for\nmaking columns line up. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 7678}\n>>> for name, phone in table.items():\n...\nprint(f\'{name:10} ==> {phone:10d}\')\n...\nSjoerd\n==>\n4127\nJack\n==>\n4098\nDcab\n==>\n7678\nOther modifiers can be used to convert the value before it is formatted. \'!a\' applies ascii(), \'!s\' applies str(),\nand \'!r\' applies repr():\n>>> animals = \'eels\'\n>>> print(f\'My hovercraft is full of {animals}.\') My hovercraft is full of eels. >>> print(f\'My hovercraft is full of {animals!r}.\') My hovercraft is full of \'eels\'. The = specifier can be used to expand an expression to the text of the expression, an equal sign, then the representation\nof the evaluated expression:\n54\nChapter 7. Input and Output\n\nPython Tutorial, Release 3.13.2\n>>> bugs = \'roaches\'\n>>> count = 13\n>>> area = \'living room\'\n>>> print(f\'Debugging {bugs=} {count=} {area=}\')\nDebugging bugs=\'roaches\' count=13 area=\'living room\'\nSee self-documenting expressions for more information on the = specifier. For a reference on these format specifi-\ncations, see the reference guide for the formatspec. 7.1.2 The String format() Method\nBasic usage of the str.format() method looks like this:\n>>> print(\'We are the {} who say ""{}! ""\'.format(\'knights\', \'Ni\'))\nWe are the knights who say ""Ni!"" The brackets and characters within them (called format fields) are replaced with the objects passed into the str. format() method. A number in the brackets can be used to refer to the position of the object passed into the\nstr.format() method. >>> print(\'{0} and {1}\'.format(\'spam\', \'eggs\'))\nspam and eggs\n>>> print(\'{1} and {0}\'.format(\'spam\', \'eggs\'))\neggs and spam\nIf keyword arguments are used in the str.format() method, their values are referred to by using the name of the\nargument. >>> print(\'This {food} is {adjective}. \'.format(\n...\nfood=\'spam\', adjective=\'absolutely horrible\'))\nThis spam is absolutely horrible. Positional and keyword arguments can be arbitrarily combined:\n>>> print(\'The story of {0}, {1}, and {other}. \'.format(\'Bill\', \'Manfred\',\n...\nother=\'Georg\'))\nThe story of Bill, Manfred, and Georg. If you have a really long format string that you don’t want to split up, it would be nice if you could reference the\nvariables to be formatted by name instead of by position. This can be done by simply passing the dict and using\nsquare brackets \'[]\' to access the keys. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; \'\n...\n\'Dcab: {0[Dcab]:d}\'.format(table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis could also be done by passing the table dictionary as keyword arguments with the ** notation. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}\'.format(**table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis is particularly useful in combination with the built-in function vars(), which returns a dictionary containing\nall local variables:\n>>> table = {k: str(v) for k, v in vars().items()}\n>>> message = "" "".join([f\'{k}: \' + \'{\' + k +\'};\' for k in table.keys()])\n(continues on next page)\n7.1. Fancier Output Formatting\n55\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n>>> print(message.format(**table))\n__name__: __main__; __doc__: None; __package__: None; __loader__: ...\nAs an example, the following lines produce a tidily aligned set of columns giving integers and their squares and cubes:\n>>> for x in range(1, 11):\n...\nprint(\'{0:2d} {1:3d} {2:4d}\'.format(x, x*x, x*x*x))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\nFor a complete overview of string formatting with str.format(), see formatstrings. 7.1.3 Manual String Formatting\nHere’s the same table of squares and cubes, formatted manually:\n>>> for x in range(1, 11):\n...\nprint(repr(x).rjust(2), repr(x*x).rjust(3), end=\' \')\n...\n# Note use of \'end\' on previous line\n...\nprint(repr(x*x*x).rjust(4))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\n(Note that the one space between each column was added by the way print() works: it always adds spaces between\nits arguments.)\n\n[3] Often you’ll want more control over the formatting of your output than simply printing space-separated values. There\nare several ways to format output. • To use formatted string literals, begin a string with f or F before the opening quotation mark or triple quotation\nmark. Inside this string, you can write a Python expression between { and } characters that can refer to\nvariables or literal values. >>> year = 2016\n>>> event = \'Referendum\'\n>>> f\'Results of the {year} {event}\'\n\'Results of the 2016 Referendum\'\n• The str.format() method of strings requires more manual effort. You’ll still use { and } to mark where a\nvariable will be substituted and can provide detailed formatting directives, but you’ll also need to provide the\ninformation to be formatted. In the following code block there are two examples of how to format variables:\n>>> yes_votes = 42_572_654\n>>> total_votes = 85_705_149\n>>> percentage = yes_votes / total_votes\n>>> \'{:-9} YES votes\n{:2.2%}\'.format(yes_votes, percentage)\n\' 42572654 YES votes\n49.67%\'\nNotice how the yes_votes are padded with spaces and a negative sign only for negative numbers. The\nexample also prints percentage multiplied by 100, with 2 decimal places and followed by a percent sign (see\nformatspec for details). • Finally, you can do all the string handling yourself by using string slicing and concatenation operations to create\nany layout you can imagine. The string type has some methods that perform useful operations for padding\nstrings to a given column width. When you don’t need fancy output but just want a quick display of some variables for debugging purposes, you can\nconvert any value to a string with the repr() or str() functions. The str() function is meant to return representations of values which are fairly human-readable, while repr()\nis meant to generate representations which can be read by the interpreter (or will force a SyntaxError if there is\nno equivalent syntax). For objects which don’t have a particular representation for human consumption, str() will\nreturn the same value as repr(). Many values, such as numbers or structures like lists and dictionaries, have the\nsame representation using either function. Strings, in particular, have two distinct representations. 53\n\nPython Tutorial, Release 3.13.2\nSome examples:\n>>> s = \'Hello, world.\' >>> str(s)\n\'Hello, world.\' >>> repr(s)\n""\'Hello, world.\'"" >>> str(1/7)\n\'0.14285714285714285\'\n>>> x = 10 * 3.25\n>>> y = 200 * 200\n>>> s = \'The value of x is \' + repr(x) + \', and y is \' + repr(y) + \'...\'\n>>> print(s)\nThe value of x is 32.5, and y is 40000...\n>>> # The repr() of a string adds string quotes and backslashes:\n>>> hello = \'hello, world\\n\'\n>>> hellos = repr(hello)\n>>> print(hellos)\n\'hello, world\\n\'\n>>> # The argument to repr() may be any Python object:\n>>> repr((x, y, (\'spam\', \'eggs\')))\n""(32.5, 40000, (\'spam\', \'eggs\'))""\nThe string module contains a Template class that offers yet another way to substitute values into strings, using\nplaceholders like $x and replacing them with values from a dictionary, but offers much less control of the formatting. 7.1.1 Formatted String Literals\nFormatted string literals (also called f-strings for short) let you include the value of Python expressions inside a string\nby prefixing the string with f or F and writing expressions as {expression}. An optional format specifier can follow the expression. This allows greater control over how the value is formatted. The following example rounds pi to three places after the decimal:\n>>> import math\n>>> print(f\'The value of pi is approximately {math.pi:.3f}.\') The value of pi is approximately 3.142. Passing an integer after the \':\' will cause that field to be a minimum number of characters wide. This is useful for\nmaking columns line up. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 7678}\n>>> for name, phone in table.items():\n...\nprint(f\'{name:10} ==> {phone:10d}\')\n...\nSjoerd\n==>\n4127\nJack\n==>\n4098\nDcab\n==>\n7678\nOther modifiers can be used to convert the value before it is formatted. \'!a\' applies ascii(), \'!s\' applies str(),\nand \'!r\' applies repr():\n>>> animals = \'eels\'\n>>> print(f\'My hovercraft is full of {animals}.\') My hovercraft is full of eels. >>> print(f\'My hovercraft is full of {animals!r}.\') My hovercraft is full of \'eels\'. The = specifier can be used to expand an expression to the text of the expression, an equal sign, then the representation\nof the evaluated expression:\n54\nChapter 7. Input and Output\n\nPython Tutorial, Release 3.13.2\n>>> bugs = \'roaches\'\n>>> count = 13\n>>> area = \'living room\'\n>>> print(f\'Debugging {bugs=} {count=} {area=}\')\nDebugging bugs=\'roaches\' count=13 area=\'living room\'\nSee self-documenting expressions for more information on the = specifier. For a reference on these format specifi-\ncations, see the reference guide for the formatspec. 7.1.2 The String format() Method\nBasic usage of the str.format() method looks like this:\n>>> print(\'We are the {} who say ""{}! ""\'.format(\'knights\', \'Ni\'))\nWe are the knights who say ""Ni!"" The brackets and characters within them (called format fields) are replaced with the objects passed into the str. format() method. A number in the brackets can be used to refer to the position of the object passed into the\nstr.format() method. >>> print(\'{0} and {1}\'.format(\'spam\', \'eggs\'))\nspam and eggs\n>>> print(\'{1} and {0}\'.format(\'spam\', \'eggs\'))\neggs and spam\nIf keyword arguments are used in the str.format() method, their values are referred to by using the name of the\nargument. >>> print(\'This {food} is {adjective}. \'.format(\n...\nfood=\'spam\', adjective=\'absolutely horrible\'))\nThis spam is absolutely horrible. Positional and keyword arguments can be arbitrarily combined:\n>>> print(\'The story of {0}, {1}, and {other}. \'.format(\'Bill\', \'Manfred\',\n...\nother=\'Georg\'))\nThe story of Bill, Manfred, and Georg. If you have a really long format string that you don’t want to split up, it would be nice if you could reference the\nvariables to be formatted by name instead of by position. This can be done by simply passing the dict and using\nsquare brackets \'[]\' to access the keys. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {0[Jack]:d}; Sjoerd: {0[Sjoerd]:d}; \'\n...\n\'Dcab: {0[Dcab]:d}\'.format(table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis could also be done by passing the table dictionary as keyword arguments with the ** notation. >>> table = {\'Sjoerd\': 4127, \'Jack\': 4098, \'Dcab\': 8637678}\n>>> print(\'Jack: {Jack:d}; Sjoerd: {Sjoerd:d}; Dcab: {Dcab:d}\'.format(**table))\nJack: 4098; Sjoerd: 4127; Dcab: 8637678\nThis is particularly useful in combination with the built-in function vars(), which returns a dictionary containing\nall local variables:\n>>> table = {k: str(v) for k, v in vars().items()}\n>>> message = "" "".join([f\'{k}: \' + \'{\' + k +\'};\' for k in table.keys()])\n(continues on next page)\n7.1. Fancier Output Formatting\n55\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n>>> print(message.format(**table))\n__name__: __main__; __doc__: None; __package__: None; __loader__: ...\nAs an example, the following lines produce a tidily aligned set of columns giving integers and their squares and cubes:\n>>> for x in range(1, 11):\n...\nprint(\'{0:2d} {1:3d} {2:4d}\'.format(x, x*x, x*x*x))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\nFor a complete overview of string formatting with str.format(), see formatstrings. 7.1.3 Manual String Formatting\nHere’s the same table of squares and cubes, formatted manually:\n>>> for x in range(1, 11):\n...\nprint(repr(x).rjust(2), repr(x*x).rjust(3), end=\' \')\n...\n# Note use of \'end\' on previous line\n...\nprint(repr(x*x*x).rjust(4))\n...\n1\n1\n1\n2\n4\n8\n3\n9\n27\n4\n16\n64\n5\n25\n125\n6\n36\n216\n7\n49\n343\n8\n64\n512\n9\n81\n729\n10 100 1000\n(Note that the one space between each column was added by the way print() works: it always adds spaces between\nits arguments.) The str.rjust() method of string objects right-justifies a string in a field of a given width by padding it with spaces\non the left.')",1.4453860877035087e-155,0.03449820788530466,0.11542714755591361,0.5326122641563416,0.5160637
How do I create multiline comments in Python?,"You can use triple-quoted strings. When they're not a docstring (the first thing in a class/function/module), they are ignored.


'''
This is a multiline
comment.
'''



(Make sure to indent the leading 
'''
 appropriately to avoid an 
IndentationError
.)


Guido van Rossum
 (creator of Python) 
tweeted this
 as a ""pro tip"".


However, Python's style guide, PEP8, 
favors using consecutive single-line comments
, like this:


# This is a multiline
# comment.



...and this is also what you'll find in many projects. Text editors usually have a shortcut to do this easily.

","('Answer: Multiline comments in Python can be created using triple quotes (""""""..."""""" or \'\'\'...\'\'\').\n\nReferences: [1]\n', '[1] Comments\nin Python start with the hash character, #, and extend to the end of the physical line. A comment may appear at the\nstart of a line or following whitespace or code, but not within a string literal. A hash character within a string literal\nis just a hash character. Since comments are to clarify code and are not interpreted by Python, they may be omitted\nwhen typing in examples. Some examples:\n# this is the first comment\nspam = 1\n# and this is the second comment\n# ... and now a third! text = ""# This is not a comment because it\'s inside quotes."" 3.1 Using Python as a Calculator\nLet’s try some simple Python commands. Start the interpreter and wait for the primary prompt, >>>. (It shouldn’t\ntake long.) 3.1.1 Numbers\nThe interpreter acts as a simple calculator: you can type an expression at it and it will write the value. Expression\nsyntax is straightforward: the operators +, -, * and / can be used to perform arithmetic; parentheses (()) can be\nused for grouping. For example:\n>>> 2 + 2\n4\n>>> 50 - 5*6\n20\n>>> (50 - 5*6) / 4\n5.0\n>>> 8 / 5\n# division always returns a floating-point number\n1.6\nThe integer numbers (e.g. 2, 4, 20) have type int, the ones with a fractional part (e.g. 5.0, 1.6) have type float. We will see more about numeric types later in the tutorial. Division (/) always returns a float. To do floor division and get an integer result you can use the // operator; to\ncalculate the remainder you can use %:\n7\n\nPython Tutorial, Release 3.13.2\n>>> 17 / 3\n# classic division returns a float\n5.666666666666667\n>>>\n>>> 17 // 3\n# floor division discards the fractional part\n5\n>>> 17 % 3\n# the % operator returns the remainder of the division\n2\n>>> 5 * 3 + 2\n# floored quotient * divisor + remainder\n17\nWith Python, it is possible to use the ** operator to calculate powers1:\n>>> 5 ** 2\n# 5 squared\n25\n>>> 2 ** 7\n# 2 to the power of 7\n128\nThe equal sign (=) is used to assign a value to a variable. Afterwards, no result is displayed before the next interactive\nprompt:\n>>> width = 20\n>>> height = 5 * 9\n>>> width * height\n900\nIf a variable is not “defined” (assigned a value), trying to use it will give you an error:\n>>> n\n# try to access an undefined variable\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nNameError: name \'n\' is not defined\nThere is full support for floating point; operators with mixed type operands convert the integer operand to floating\npoint:\n>>> 4 * 3.75 - 1\n14.0\nIn interactive mode, the last printed expression is assigned to the variable _. This means that when you are using\nPython as a desk calculator, it is somewhat easier to continue calculations, for example:\n>>> tax = 12.5 / 100\n>>> price = 100.50\n>>> price * tax\n12.5625\n>>> price + _\n113.0625\n>>> round(_, 2)\n113.06\nThis variable should be treated as read-only by the user. Don’t explicitly assign a value to it — you would create an\nindependent local variable with the same name masking the built-in variable with its magic behavior. In addition to int and float, Python supports other types of numbers, such as Decimal and Fraction. Python\nalso has built-in support for complex numbers, and uses the j or J suffix to indicate the imaginary part (e.g. 3+5j). 1 Since ** has higher precedence than -, -3**2 will be interpreted as -(3**2) and thus result in -9. To avoid this and get 9, you can use\n(-3)**2. 8\nChapter 3. An Informal Introduction to Python\n\nPython Tutorial, Release 3.13.2\n3.1.2 Text\nPython can manipulate text (represented by type str, so-called “strings”) as well as numbers. This includes characters\n“!”, words “rabbit”, names “Paris”, sentences “Got your back.”, etc. “Yay! :)”. They can be enclosed in\nsingle quotes (\'...\') or double quotes (""..."") with the same result2. >>> \'spam eggs\'\n# single quotes\n\'spam eggs\'\n>>> ""Paris rabbit got your back :)! Yay!"" # double quotes\n\'Paris rabbit got your back :)! Yay!\' >>> \'1975\'\n# digits and numerals enclosed in quotes are also strings\n\'1975\'\nTo quote a quote, we need to “escape” it, by preceding it with \\. Alternatively, we can use the other type of quotation\nmarks:\n>>> \'doesn\\\'t\'\n# use \\\' to escape the single quote...\n""doesn\'t""\n>>> ""doesn\'t""\n# ...or use double quotes instead\n""doesn\'t""\n>>> \'""Yes,"" they said.\' \'""Yes,"" they said.\' >>> ""\\""Yes,\\"" they said."" \'""Yes,"" they said.\' >>> \'""Isn\\\'t,"" they said.\' \'""Isn\\\'t,"" they said.\' In the Python shell, the string definition and output string can look different. The print() function produces a more\nreadable output, by omitting the enclosing quotes and by printing escaped and special characters:\n>>> s = \'First line.\\nSecond line.\' # \\n means newline\n>>> s\n# without print(), special characters are included in the string\n\'First line.\\nSecond line.\' >>> print(s)\n# with print(), special characters are interpreted, so \\n produces␣\n,→new line\nFirst line. Second line. If you don’t want characters prefaced by \\ to be interpreted as special characters, you can use raw strings by adding\nan r before the first quote:\n>>> print(\'C:\\some\\name\')\n# here \\n means newline! C:\\some\name\n>>> print(r\'C:\\some\\name\')\n# note the r before the quote\nC:\\some\\name\nThere is one subtle aspect to raw strings: a raw string may not end in an odd number of \\ characters; see the FAQ\nentry for more information and workarounds. String literals can span multiple lines. One way is using triple-quotes: """"""..."""""" or \'\'\'...\'\'\'.\n\n[2] If you have the py.exe launcher installed, you can use the py command. See setting-envvars for other\nways to launch Python. Typing an end-of-file character (Control-D on Unix, Control-Z on Windows) at the primary prompt causes the\ninterpreter to exit with a zero exit status. If that doesn’t work, you can exit the interpreter by typing the following\ncommand: quit(). The interpreter’s line-editing features include interactive editing, history substitution and code completion on systems\nthat support the GNU Readline library. Perhaps the quickest check to see whether command line editing is supported\nis typing Control-P to the first Python prompt you get. If it beeps, you have command line editing; see Appendix\nInteractive Input Editing and History Substitution for an introduction to the keys. If nothing appears to happen, or if\n^P is echoed, command line editing isn’t available; you’ll only be able to use backspace to remove characters from\nthe current line. The interpreter operates somewhat like the Unix shell: when called with standard input connected to a tty device, it\nreads and executes commands interactively; when called with a file name argument or with a file as standard input, it\nreads and executes a script from that file. A second way of starting the interpreter is python -c command [arg] ..., which executes the statement(s) in\ncommand, analogous to the shell’s -c option. Since Python statements often contain spaces or other characters that\nare special to the shell, it is usually advised to quote command in its entirety. Some Python modules are also useful as scripts. These can be invoked using python -m module [arg] ...,\nwhich executes the source file for module as if you had spelled out its full name on the command line. When a script file is used, it is sometimes useful to be able to run the script and enter interactive mode afterwards. This can be done by passing -i before the script. All command line options are described in using-on-general. 1 On Unix, the Python 3.x interpreter is by default not installed with the executable named python, so that it does not conflict with a simul-\ntaneously installed Python 2.x executable. 5\n\nPython Tutorial, Release 3.13.2\n2.1.1 Argument Passing\nWhen known to the interpreter, the script name and additional arguments thereafter are turned into a list of strings\nand assigned to the argv variable in the sys module. You can access this list by executing import sys. The length\nof the list is at least one; when no script and no arguments are given, sys.argv[0] is an empty string. When the\nscript name is given as \'-\' (meaning standard input), sys.argv[0] is set to \'-\'. When -c command is used,\nsys.argv[0] is set to \'-c\'. When -m module is used, sys.argv[0] is set to the full name of the located module. Options found after -c command or -m module are not consumed by the Python interpreter’s option processing but\nleft in sys.argv for the command or module to handle. 2.1.2 Interactive Mode\nWhen commands are read from a tty, the interpreter is said to be in interactive mode. In this mode it prompts for\nthe next command with the primary prompt, usually three greater-than signs (>>>); for continuation lines it prompts\nwith the secondary prompt, by default three dots (...). The interpreter prints a welcome message stating its version\nnumber and a copyright notice before printing the first prompt:\n$ python3.13\nPython 3.13 (default, April 4 2023, 09:25:04)\n[GCC 10.2.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>>\nContinuation lines are needed when entering a multi-line construct. As an example, take a look at this if statement:\n>>> the_world_is_flat = True\n>>> if the_world_is_flat:\n...\nprint(""Be careful not to fall off!"") ...\nBe careful not to fall off! For more on interactive mode, see Interactive Mode. 2.2 The Interpreter and Its Environment\n2.2.1 Source Code Encoding\nBy default, Python source files are treated as encoded in UTF-8. In that encoding, characters of most languages in\nthe world can be used simultaneously in string literals, identifiers and comments — although the standard library\nonly uses ASCII characters for identifiers, a convention that any portable code should follow. To display all these\ncharacters properly, your editor must recognize that the file is UTF-8, and it must use a font that supports all the\ncharacters in the file. To declare an encoding other than the default one, a special comment line should be added as the first line of the file. The syntax is as follows:\n# -*- coding: encoding -*-\nwhere encoding is one of the valid codecs supported by Python. For example, to declare that Windows-1252 encoding is to be used, the first line of your source code file should be:\n# -*- coding: cp1252 -*-\nOne exception to the first line rule is when the source code starts with a UNIX “shebang” line. In this case, the encoding\ndeclaration should be added as the second line of the file. For example:\n#!/usr/bin/env python3\n# -*- coding: cp1252 -*-\n6\nChapter 2. Using the Python Interpreter\n\nCHAPTER\nTHREE\nAN INFORMAL INTRODUCTION TO PYTHON\nIn the following examples, input and output are distinguished by the presence or absence of prompts (»> and …):\nto repeat the example, you must type everything after the prompt, when the prompt appears; lines that do not begin\nwith a prompt are output from the interpreter. Note that a secondary prompt on a line by itself in an example means\nyou must type a blank line; this is used to end a multi-line command. Many of the examples in this manual, even those entered at the interactive prompt, include comments. Comments\nin Python start with the hash character, #, and extend to the end of the physical line. A comment may appear at the\nstart of a line or following whitespace or code, but not within a string literal. A hash character within a string literal\nis just a hash character. Since comments are to clarify code and are not interpreted by Python, they may be omitted\nwhen typing in examples. Some examples:\n# this is the first comment\nspam = 1\n# and this is the second comment\n# ... and now a third! text = ""# This is not a comment because it\'s inside quotes."" 3.1 Using Python as a Calculator\nLet’s try some simple Python commands. Start the interpreter and wait for the primary prompt, >>>. (It shouldn’t\ntake long.)\n\n[3] (E.g., /usr/local/python is a popular\nalternative location.) On Windows machines where you have installed Python from the Microsoft Store, the python3.13 command will\nbe available. If you have the py.exe launcher installed, you can use the py command. See setting-envvars for other\nways to launch Python. Typing an end-of-file character (Control-D on Unix, Control-Z on Windows) at the primary prompt causes the\ninterpreter to exit with a zero exit status. If that doesn’t work, you can exit the interpreter by typing the following\ncommand: quit(). The interpreter’s line-editing features include interactive editing, history substitution and code completion on systems\nthat support the GNU Readline library. Perhaps the quickest check to see whether command line editing is supported\nis typing Control-P to the first Python prompt you get. If it beeps, you have command line editing; see Appendix\nInteractive Input Editing and History Substitution for an introduction to the keys. If nothing appears to happen, or if\n^P is echoed, command line editing isn’t available; you’ll only be able to use backspace to remove characters from\nthe current line. The interpreter operates somewhat like the Unix shell: when called with standard input connected to a tty device, it\nreads and executes commands interactively; when called with a file name argument or with a file as standard input, it\nreads and executes a script from that file. A second way of starting the interpreter is python -c command [arg] ..., which executes the statement(s) in\ncommand, analogous to the shell’s -c option. Since Python statements often contain spaces or other characters that\nare special to the shell, it is usually advised to quote command in its entirety. Some Python modules are also useful as scripts. These can be invoked using python -m module [arg] ...,\nwhich executes the source file for module as if you had spelled out its full name on the command line. When a script file is used, it is sometimes useful to be able to run the script and enter interactive mode afterwards. This can be done by passing -i before the script. All command line options are described in using-on-general. 1 On Unix, the Python 3.x interpreter is by default not installed with the executable named python, so that it does not conflict with a simul-\ntaneously installed Python 2.x executable. 5\n\nPython Tutorial, Release 3.13.2\n2.1.1 Argument Passing\nWhen known to the interpreter, the script name and additional arguments thereafter are turned into a list of strings\nand assigned to the argv variable in the sys module. You can access this list by executing import sys. The length\nof the list is at least one; when no script and no arguments are given, sys.argv[0] is an empty string. When the\nscript name is given as \'-\' (meaning standard input), sys.argv[0] is set to \'-\'. When -c command is used,\nsys.argv[0] is set to \'-c\'. When -m module is used, sys.argv[0] is set to the full name of the located module. Options found after -c command or -m module are not consumed by the Python interpreter’s option processing but\nleft in sys.argv for the command or module to handle. 2.1.2 Interactive Mode\nWhen commands are read from a tty, the interpreter is said to be in interactive mode. In this mode it prompts for\nthe next command with the primary prompt, usually three greater-than signs (>>>); for continuation lines it prompts\nwith the secondary prompt, by default three dots (...). The interpreter prints a welcome message stating its version\nnumber and a copyright notice before printing the first prompt:\n$ python3.13\nPython 3.13 (default, April 4 2023, 09:25:04)\n[GCC 10.2.0] on linux\nType ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>>\nContinuation lines are needed when entering a multi-line construct. As an example, take a look at this if statement:\n>>> the_world_is_flat = True\n>>> if the_world_is_flat:\n...\nprint(""Be careful not to fall off!"") ...\nBe careful not to fall off! For more on interactive mode, see Interactive Mode. 2.2 The Interpreter and Its Environment\n2.2.1 Source Code Encoding\nBy default, Python source files are treated as encoded in UTF-8. In that encoding, characters of most languages in\nthe world can be used simultaneously in string literals, identifiers and comments — although the standard library\nonly uses ASCII characters for identifiers, a convention that any portable code should follow. To display all these\ncharacters properly, your editor must recognize that the file is UTF-8, and it must use a font that supports all the\ncharacters in the file. To declare an encoding other than the default one, a special comment line should be added as the first line of the file. The syntax is as follows:\n# -*- coding: encoding -*-\nwhere encoding is one of the valid codecs supported by Python. For example, to declare that Windows-1252 encoding is to be used, the first line of your source code file should be:\n# -*- coding: cp1252 -*-\nOne exception to the first line rule is when the source code starts with a UNIX “shebang” line. In this case, the encoding\ndeclaration should be added as the second line of the file. For example:\n#!/usr/bin/env python3\n# -*- coding: cp1252 -*-\n6\nChapter 2. Using the Python Interpreter\n\nCHAPTER\nTHREE\nAN INFORMAL INTRODUCTION TO PYTHON\nIn the following examples, input and output are distinguished by the presence or absence of prompts (»> and …):\nto repeat the example, you must type everything after the prompt, when the prompt appears; lines that do not begin\nwith a prompt are output from the interpreter. Note that a secondary prompt on a line by itself in an example means\nyou must type a blank line; this is used to end a multi-line command. Many of the examples in this manual, even those entered at the interactive prompt, include comments. Comments\nin Python start with the hash character, #, and extend to the end of the physical line. A comment may appear at the\nstart of a line or following whitespace or code, but not within a string literal. A hash character within a string literal\nis just a hash character. Since comments are to clarify code and are not interpreted by Python, they may be omitted\nwhen typing in examples. Some examples:\n# this is the first comment\nspam = 1\n# and this is the second comment\n# ... and now a third! text = ""# This is not a comment because it\'s inside quotes."" 3.1 Using Python as a Calculator\nLet’s try some simple Python commands.')",1.179923641442077e-155,0.027561414020371478,0.09682198256053692,0.5337628722190857,0.73786956
Display number with leading zeros,"In Python 2 (and Python 3) you can do:


number = 1
print(""%02d"" % (number,))



Basically 
%
 is like 
printf
 or 
sprintf
 (see 
docs
).




For Python 3.+, the same behavior can also be achieved with 
format
:


number = 1
print(""{:02d}"".format(number))





For Python 3.6+ the same behavior can be achieved with 
f-strings
:


number = 1
print(f""{number:02d}"")


","(""Answer: To display a number with leading zeros, precede the width field by a zero ('0') character when no explicit alignment is given. This enables sign-aware zero-padding for numeric types, excluding complex and is equivalent to using a fill character of '0' with alignment type '='.\n\nReferences: [1, 2, 3]\n"", ""[1] When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-\npadding for numeric types, excluding complex. This is equivalent to a fill character of '0' with an alignment type\nof '='. Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings. 6.1. string — Common string operations\n123\n\nThe Python Library Reference, Release 3.13.2\nThe precision is a decimal integer indicating how many digits should be displayed after the decimal point for pre-\nsentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string\npresentation types the field indicates the maximum field size - in other words, how many characters will be used from\nthe field content. The precision is not allowed for integer presentation types. Finally, the type determines how the data should be presented. The available string presentation types are:\nType\nMeaning\n's'\nString format. This is the default type for strings and may be omitted. None\nThe same as 's'. The available integer presentation types are:\nType Meaning\n'b'\nBinary format. Outputs the number in base 2. 'c'\nCharacter. Converts the integer to the corresponding unicode character before printing. 'd'\nDecimal Integer. Outputs the number in base 10. 'o'\nOctal format. Outputs the number in base 8. 'x'\nHex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X'\nHex format. Outputs the number in base 16, using upper-case letters for the digits above 9. In case '#' is specified, the prefix '0x' will be upper-cased to '0X' as well. 'n'\nNumber. This is the same as 'd', except that it uses the current locale setting to insert the\nappropriate number separator characters. None The same as 'd'. In addition to the above presentation types, integers can be formatted with the floating-point presentation types listed\nbelow (except 'n' and None). When doing so, float() is used to convert the integer to a floating-point number\nbefore formatting. The available presentation types for float and Decimal values are:\n124\nChapter 6. Text Processing Services\n\nThe Python Library Reference, Release 3.13.2\nType Meaning\n'e'\nScientific notation. For a given precision p, formats the number in scientific notation with\nthe letter ‘e’ separating the coefficient from the exponent. The coefficient has one digit before\nand p digits after the decimal point, for a total of p + 1 significant digits. With no precision\ngiven, uses a precision of 6 digits after the decimal point for float, and shows all coefficient\ndigits for Decimal. If p=0, the decimal point is omitted unless the # option is used. 'E'\nScientific notation. Same as 'e' except it uses an upper case ‘E’ as the separator character. 'f'\nFixed-point notation. For a given precision p, formats the number as a decimal number with\nexactly p digits following the decimal point. With no precision given, uses a precision of\n6 digits after the decimal point for float, and uses a precision large enough to show all\ncoefficient digits for Decimal. If p=0, the decimal point is omitted unless the # option is\nused. 'F'\nFixed-point notation. Same as 'f', but converts nan to NAN and inf to INF. 'g'\nGeneral format. For a given precision p >= 1, this rounds the number to p significant digits\nand then formats the result in either fixed-point format or in scientific notation, depending on\nits magnitude. A precision of 0 is treated as equivalent to a precision of 1. The precise rules are as follows: suppose that the result formatted with presentation type 'e'\nand precision p-1 would have exponent exp. Then, if m <= exp < p, where m is -4 for\nfloats and -6 for Decimals, the number is formatted with presentation type 'f' and precision\np-1-exp. Otherwise, the number is formatted with presentation type 'e' and precision p-1. In both cases insignificant trailing zeros are removed from the significand, and the decimal\npoint is also removed if there are no remaining digits following it, unless the '#' option is\nused. With no precision given, uses a precision of 6 significant digits for float. For Decimal, the\ncoefficient of the result is formed from the coefficient digits of the value; scientific notation is\nused for values smaller than 1e-6 in absolute value and values where the place value of the\nleast significant digit is larger than 1, and fixed-point notation is used otherwise.\n\n[2] '>'\nForces the field to be right-aligned within the available space (this is the default for numbers). '='\nForces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields\nin the form ‘+000000120’. This alignment option is only valid for numeric types, excluding complex. It\nbecomes the default for numbers when ‘0’ immediately precedes the field width. '^'\nForces the field to be centered within the available space. Note that unless a minimum field width is defined, the field width will always be the same size as the data to fill it, so\nthat the alignment option has no meaning in this case. The sign option is only valid for number types, and can be one of the following:\nOp-\ntion\nMeaning\n'+'\nindicates that a sign should be used for both positive as well as negative numbers. '-'\nindicates that a sign should be used only for negative numbers (this is the default behavior). space\nindicates that a leading space should be used on positive numbers, and a minus sign on negative numbers. The 'z' option coerces negative zero floating-point values to positive zero after rounding to the format precision. This option is only valid for floating-point presentation types. Changed in version 3.11: Added the 'z' option (see also PEP 682). The '#' option causes the “alternate form” to be used for the conversion. The alternate form is defined differently\nfor different types. This option is only valid for integer, float and complex types. For integers, when binary, octal, or\nhexadecimal output is used, this option adds the respective prefix '0b', '0o', '0x', or '0X' to the output value. For\nfloat and complex the alternate form causes the result of the conversion to always contain a decimal-point character,\neven if no digits follow it. Normally, a decimal-point character appears in the result of these conversions only if a\ndigit follows it. In addition, for 'g' and 'G' conversions, trailing zeros are not removed from the result. The ',' option signals the use of a comma for a thousands separator for floating-point presentation types and for\ninteger presentation type 'd'. For other presentation types, this option is an error. For a locale aware separator, use\nthe 'n' integer presentation type instead. Changed in version 3.1: Added the ',' option (see also PEP 378). The '_' option signals the use of an underscore for a thousands separator for floating-point presentation types and for\ninteger presentation type 'd'. For integer presentation types 'b', 'o', 'x', and 'X', underscores will be inserted\nevery 4 digits. For other presentation types, specifying this option is an error. Changed in version 3.6: Added the '_' option (see also PEP 515). width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other for-\nmatting characters. If not specified, then the field width will be determined by the content. When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-\npadding for numeric types, excluding complex. This is equivalent to a fill character of '0' with an alignment type\nof '='. Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings. 6.1. string — Common string operations\n123\n\nThe Python Library Reference, Release 3.13.2\nThe precision is a decimal integer indicating how many digits should be displayed after the decimal point for pre-\nsentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string\npresentation types the field indicates the maximum field size - in other words, how many characters will be used from\nthe field content. The precision is not allowed for integer presentation types. Finally, the type determines how the data should be presented. The available string presentation types are:\nType\nMeaning\n's'\nString format. This is the default type for strings and may be omitted. None\nThe same as 's'. The available integer presentation types are:\nType Meaning\n'b'\nBinary format. Outputs the number in base 2. 'c'\nCharacter. Converts the integer to the corresponding unicode character before printing. 'd'\nDecimal Integer. Outputs the number in base 10. 'o'\nOctal format. Outputs the number in base 8. 'x'\nHex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X'\nHex format.\n\n[3] '='\nForces the padding to be placed after the sign (if any) but before the digits. This is used for printing fields\nin the form ‘+000000120’. This alignment option is only valid for numeric types, excluding complex. It\nbecomes the default for numbers when ‘0’ immediately precedes the field width. '^'\nForces the field to be centered within the available space. Note that unless a minimum field width is defined, the field width will always be the same size as the data to fill it, so\nthat the alignment option has no meaning in this case. The sign option is only valid for number types, and can be one of the following:\nOp-\ntion\nMeaning\n'+'\nindicates that a sign should be used for both positive as well as negative numbers. '-'\nindicates that a sign should be used only for negative numbers (this is the default behavior). space\nindicates that a leading space should be used on positive numbers, and a minus sign on negative numbers. The 'z' option coerces negative zero floating-point values to positive zero after rounding to the format precision. This option is only valid for floating-point presentation types. Changed in version 3.11: Added the 'z' option (see also PEP 682). The '#' option causes the “alternate form” to be used for the conversion. The alternate form is defined differently\nfor different types. This option is only valid for integer, float and complex types. For integers, when binary, octal, or\nhexadecimal output is used, this option adds the respective prefix '0b', '0o', '0x', or '0X' to the output value. For\nfloat and complex the alternate form causes the result of the conversion to always contain a decimal-point character,\neven if no digits follow it. Normally, a decimal-point character appears in the result of these conversions only if a\ndigit follows it. In addition, for 'g' and 'G' conversions, trailing zeros are not removed from the result. The ',' option signals the use of a comma for a thousands separator for floating-point presentation types and for\ninteger presentation type 'd'. For other presentation types, this option is an error. For a locale aware separator, use\nthe 'n' integer presentation type instead. Changed in version 3.1: Added the ',' option (see also PEP 378). The '_' option signals the use of an underscore for a thousands separator for floating-point presentation types and for\ninteger presentation type 'd'. For integer presentation types 'b', 'o', 'x', and 'X', underscores will be inserted\nevery 4 digits. For other presentation types, specifying this option is an error. Changed in version 3.6: Added the '_' option (see also PEP 515). width is a decimal integer defining the minimum total field width, including any prefixes, separators, and other for-\nmatting characters. If not specified, then the field width will be determined by the content. When no explicit alignment is given, preceding the width field by a zero ('0') character enables sign-aware zero-\npadding for numeric types, excluding complex. This is equivalent to a fill character of '0' with an alignment type\nof '='. Changed in version 3.10: Preceding the width field by '0' no longer affects the default alignment for strings. 6.1. string — Common string operations\n123\n\nThe Python Library Reference, Release 3.13.2\nThe precision is a decimal integer indicating how many digits should be displayed after the decimal point for pre-\nsentation types 'f' and 'F', or before and after the decimal point for presentation types 'g' or 'G'. For string\npresentation types the field indicates the maximum field size - in other words, how many characters will be used from\nthe field content. The precision is not allowed for integer presentation types. Finally, the type determines how the data should be presented. The available string presentation types are:\nType\nMeaning\n's'\nString format. This is the default type for strings and may be omitted. None\nThe same as 's'. The available integer presentation types are:\nType Meaning\n'b'\nBinary format. Outputs the number in base 2. 'c'\nCharacter. Converts the integer to the corresponding unicode character before printing. 'd'\nDecimal Integer. Outputs the number in base 10. 'o'\nOctal format. Outputs the number in base 8. 'x'\nHex format. Outputs the number in base 16, using lower-case letters for the digits above 9. 'X'\nHex format. Outputs the number in base 16, using upper-case letters for the digits above 9."")",9.724824375658286e-156,0.030521407376006785,0.10218332173951174,0.5125290751457214,0.6176941
Python: how to determine if an object is iterable?,"

Checking for 
__iter__
 works on sequence types, but it would fail on e.g. strings 
in Python 2
. I would like to know the right answer too, until then, here is one possibility (which would work on strings, too):


try:
    some_object_iterator = iter(some_object)
except TypeError as te:
    print(some_object, 'is not iterable')



The 
iter
 built-in checks for the 
__iter__
 method or in the case of strings the 
__getitem__
 method.




Another general pythonic approach is to assume an iterable, then fail gracefully if it does not work on the given object. The Python glossary:




Pythonic programming style that determines an object's type by inspection of its method or attribute signature rather than by explicit relationship to some type object (""If it looks like a 
duck
 and quacks like a 
duck
, it must be a 
duck
."") By emphasizing interfaces rather than specific types, well-designed code improves its flexibility by allowing polymorphic substitution. Duck-typing avoids tests using type() or isinstance(). 
Instead, it typically employs the EAFP (Easier to Ask Forgiveness than Permission) style of programming.


...


try:
   _ = (e for e in my_object)
except TypeError:
   print(my_object, 'is not iterable')







The 
collections
 module provides some abstract base classes, which allow to ask classes or instances if they provide particular functionality, for example:


from collections.abc import Iterable

if isinstance(e, Iterable):
    # e is iterable



However, this does not check for classes that are iterable through 
__getitem__
.





","(""Answer: An object is iterable if you can get an iterator for it. The built-in `iter()` function attempts to return an iterator for an object. If the object doesn't support iteration, a TypeError is raised.\n\nReferences: [2, 3]\n"", '[1] An object is called iterable if you can get an\niterator for it. You can experiment with the iteration interface manually:\n>>> L = [1, 2, 3]\n>>> it = iter(L)\n>>> it\n<...iterator object at ...>\n>>> it.__next__()\n# same as next(it)\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nStopIteration\n>>>\nPython expects iterable objects in several different contexts, the most important being the for statement. In the\nstatement for X in Y, Y must be an iterator or some object for which iter() can create an iterator. These two\nstatements are equivalent:\nfor i in iter(obj):\nprint(i)\nfor i in obj:\nprint(i)\nIterators can be materialized as lists or tuples by using the list() or tuple() constructor functions:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> t = tuple(iterator)\n>>> t\n(1, 2, 3)\nSequence unpacking also supports iterators: if you know an iterator will return N elements, you can unpack them\ninto an N-tuple:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> a, b, c = iterator\n>>> a, b, c\n(1, 2, 3)\n4\n\nBuilt-in functions such as max() and min() can take a single iterator argument and will return the largest or smallest\nelement. The ""in"" and ""not in"" operators also support iterators: X in iterator is true if X is found in the\nstream returned by the iterator. You’ll run into obvious problems if the iterator is infinite; max(), min() will never\nreturn, and if the element X never appears in the stream, the ""in"" and ""not in"" operators won’t return either. Note that you can only go forward in an iterator; there’s no way to get the previous element, reset the iterator, or\nmake a copy of it. Iterator objects can optionally provide these additional capabilities, but the iterator protocol only\nspecifies the __next__() method. Functions may therefore consume all of the iterator’s output, and if you need to\ndo something different with the same stream, you’ll have to create a new iterator. 2.1 Data Types That Support Iterators\nWe’ve already seen how lists and tuples support iterators. In fact, any Python sequence type, such as strings, will\nautomatically support creation of an iterator. Calling iter() on a dictionary returns an iterator that will loop over the dictionary’s keys:\n>>> m = {\'Jan\': 1, \'Feb\': 2, \'Mar\': 3, \'Apr\': 4, \'May\': 5, \'Jun\': 6,\n...\n\'Jul\': 7, \'Aug\': 8, \'Sep\': 9, \'Oct\': 10, \'Nov\': 11, \'Dec\': 12}\n>>> for key in m:\n...\nprint(key, m[key])\nJan 1\nFeb 2\nMar 3\nApr 4\nMay 5\nJun 6\nJul 7\nAug 8\nSep 9\nOct 10\nNov 11\nDec 12\nNote that starting with Python 3.7, dictionary iteration order is guaranteed to be the same as the insertion order. In\nearlier versions, the behaviour was unspecified and could vary between implementations. Applying iter() to a dictionary always loops over the keys, but dictionaries have methods that return other iterators. If you want to iterate over values or key/value pairs, you can explicitly call the values() or items() methods to\nget an appropriate iterator. The dict() constructor can accept an iterator that returns a finite stream of (key, value) tuples:\n>>> L = [(\'Italy\', \'Rome\'), (\'France\', \'Paris\'), (\'US\', \'Washington DC\')]\n>>> dict(iter(L))\n{\'Italy\': \'Rome\', \'France\': \'Paris\', \'US\': \'Washington DC\'}\nFiles also support iteration by calling the readline() method until there are no more lines in the file. This means\nyou can read each line of a file like this:\nfor line in file:\n# do something for each line\n...\nSets can take their contents from an iterable and let you iterate over the set’s elements:\n>>> S = {2, 3, 5, 7, 11, 13}\n>>> for i in S:\n...\nprint(i)\n2\n(continues on next page)\n5\n\n(continued from previous page)\n3\n5\n7\n11\n13\n3 Generator expressions and list comprehensions\nTwo common operations on an iterator’s output are 1) performing some operation for every element, 2) selecting a\nsubset of elements that meet some condition. For example, given a list of strings, you might want to strip off trailing\nwhitespace from each line or extract all the strings containing a given substring. List comprehensions and generator expressions (short form: “listcomps” and “genexps”) are a concise notation for\nsuch operations, borrowed from the functional programming language Haskell (https://www.haskell.org/). You can\nstrip all the whitespace from a stream of strings with the following code:\n>>> line_list = [\'\nline 1\\n\', \'line 2\n\\n\', \' \\n\', \'\']\n>>> # Generator expression -- returns iterator\n>>> stripped_iter = (line.strip() for line in line_list)\n>>> # List comprehension -- returns list\n>>> stripped_list = [line.strip() for line in line_list]\nYou can select only certain elements by adding an ""if"" condition:\n>>> stripped_list = [line.strip() for line in line_list\n...\nif line != """"]\nWith a list comprehension, you get back a Python list; stripped_list is a list containing the resulting lines, not an\niterator. Generator expressions return an iterator that computes the values as necessary, not needing to materialize\nall the values at once. This means that list comprehensions aren’t useful if you’re working with iterators that return\nan infinite stream or a very large amount of data. Generator expressions are preferable in these situations. Generator expressions are surrounded by parentheses (“()”) and list comprehensions are surrounded by square brack-\nets (“[]”). Generator expressions have the form:\n( expression for expr in sequence1\nif condition1\nfor expr2 in sequence2\nif condition2\nfor expr3 in sequence3\n...\nif condition3\nfor exprN in sequenceN\nif conditionN )\nAgain, for a list comprehension only the outside brackets are different (square brackets instead of parentheses). The elements of the generated output will be the successive values of expression. The if clauses are all optional;\nif present, expression is only evaluated and added to the result when condition is true. Generator expressions always have to be written inside parentheses, but the parentheses signalling a function call also\ncount. If you want to create an iterator that will be immediately passed to a function you can write:\nobj_total = sum(obj.count for obj in list_all_objects())\nThe for...in clauses contain the sequences to be iterated over. The sequences do not have to be the same length,\nbecause they are iterated over from left to right, not in parallel. For each element in sequence1, sequence2 is\n6\n\nlooped over from the beginning. sequence3 is then looped over for each resulting pair of elements from sequence1\nand sequence2. To put it another way, a list comprehension or generator expression is equivalent to the following Python code:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue\n# Skip this element\nfor expr2 in sequence2:\nif not (condition2):\ncontinue\n# Skip this element\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue\n# Skip this element\n# Output the value of\n# the expression. This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing. Here’s a sample usage of the generate_ints() generator:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile ""stdin"", line 1, in <module>\nFile ""stdin"", line 2, in generate_ints\nStopIteration\nYou could equally write for i in generate_ints(5), or a, b, c = generate_ints(3). Inside a generator function, return value causes StopIteration(value) to be raised from the __next__()\nmethod. Once this happens, or the bottom of the function is reached, the procession of values ends and the generator\ncannot yield any further values.\n\n[2] The built-in iter() function takes an arbitrary object and tries to return an iterator that will return the object’s\ncontents or elements, raising TypeError if the object doesn’t support iteration. Several of Python’s built-in data\ntypes support iteration, the most common being lists and dictionaries. An object is called iterable if you can get an\niterator for it. You can experiment with the iteration interface manually:\n>>> L = [1, 2, 3]\n>>> it = iter(L)\n>>> it\n<...iterator object at ...>\n>>> it.__next__()\n# same as next(it)\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nStopIteration\n>>>\nPython expects iterable objects in several different contexts, the most important being the for statement. In the\nstatement for X in Y, Y must be an iterator or some object for which iter() can create an iterator. These two\nstatements are equivalent:\nfor i in iter(obj):\nprint(i)\nfor i in obj:\nprint(i)\nIterators can be materialized as lists or tuples by using the list() or tuple() constructor functions:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> t = tuple(iterator)\n>>> t\n(1, 2, 3)\nSequence unpacking also supports iterators: if you know an iterator will return N elements, you can unpack them\ninto an N-tuple:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> a, b, c = iterator\n>>> a, b, c\n(1, 2, 3)\n4\n\nBuilt-in functions such as max() and min() can take a single iterator argument and will return the largest or smallest\nelement. The ""in"" and ""not in"" operators also support iterators: X in iterator is true if X is found in the\nstream returned by the iterator. You’ll run into obvious problems if the iterator is infinite; max(), min() will never\nreturn, and if the element X never appears in the stream, the ""in"" and ""not in"" operators won’t return either. Note that you can only go forward in an iterator; there’s no way to get the previous element, reset the iterator, or\nmake a copy of it. Iterator objects can optionally provide these additional capabilities, but the iterator protocol only\nspecifies the __next__() method. Functions may therefore consume all of the iterator’s output, and if you need to\ndo something different with the same stream, you’ll have to create a new iterator. 2.1 Data Types That Support Iterators\nWe’ve already seen how lists and tuples support iterators. In fact, any Python sequence type, such as strings, will\nautomatically support creation of an iterator. Calling iter() on a dictionary returns an iterator that will loop over the dictionary’s keys:\n>>> m = {\'Jan\': 1, \'Feb\': 2, \'Mar\': 3, \'Apr\': 4, \'May\': 5, \'Jun\': 6,\n...\n\'Jul\': 7, \'Aug\': 8, \'Sep\': 9, \'Oct\': 10, \'Nov\': 11, \'Dec\': 12}\n>>> for key in m:\n...\nprint(key, m[key])\nJan 1\nFeb 2\nMar 3\nApr 4\nMay 5\nJun 6\nJul 7\nAug 8\nSep 9\nOct 10\nNov 11\nDec 12\nNote that starting with Python 3.7, dictionary iteration order is guaranteed to be the same as the insertion order. In\nearlier versions, the behaviour was unspecified and could vary between implementations. Applying iter() to a dictionary always loops over the keys, but dictionaries have methods that return other iterators. If you want to iterate over values or key/value pairs, you can explicitly call the values() or items() methods to\nget an appropriate iterator. The dict() constructor can accept an iterator that returns a finite stream of (key, value) tuples:\n>>> L = [(\'Italy\', \'Rome\'), (\'France\', \'Paris\'), (\'US\', \'Washington DC\')]\n>>> dict(iter(L))\n{\'Italy\': \'Rome\', \'France\': \'Paris\', \'US\': \'Washington DC\'}\nFiles also support iteration by calling the readline() method until there are no more lines in the file. This means\nyou can read each line of a file like this:\nfor line in file:\n# do something for each line\n...\nSets can take their contents from an iterable and let you iterate over the set’s elements:\n>>> S = {2, 3, 5, 7, 11, 13}\n>>> for i in S:\n...\nprint(i)\n2\n(continues on next page)\n5\n\n(continued from previous page)\n3\n5\n7\n11\n13\n3 Generator expressions and list comprehensions\nTwo common operations on an iterator’s output are 1) performing some operation for every element, 2) selecting a\nsubset of elements that meet some condition. For example, given a list of strings, you might want to strip off trailing\nwhitespace from each line or extract all the strings containing a given substring. List comprehensions and generator expressions (short form: “listcomps” and “genexps”) are a concise notation for\nsuch operations, borrowed from the functional programming language Haskell (https://www.haskell.org/). You can\nstrip all the whitespace from a stream of strings with the following code:\n>>> line_list = [\'\nline 1\\n\', \'line 2\n\\n\', \' \\n\', \'\']\n>>> # Generator expression -- returns iterator\n>>> stripped_iter = (line.strip() for line in line_list)\n>>> # List comprehension -- returns list\n>>> stripped_list = [line.strip() for line in line_list]\nYou can select only certain elements by adding an ""if"" condition:\n>>> stripped_list = [line.strip() for line in line_list\n...\nif line != """"]\nWith a list comprehension, you get back a Python list; stripped_list is a list containing the resulting lines, not an\niterator. Generator expressions return an iterator that computes the values as necessary, not needing to materialize\nall the values at once. This means that list comprehensions aren’t useful if you’re working with iterators that return\nan infinite stream or a very large amount of data. Generator expressions are preferable in these situations. Generator expressions are surrounded by parentheses (“()”) and list comprehensions are surrounded by square brack-\nets (“[]”). Generator expressions have the form:\n( expression for expr in sequence1\nif condition1\nfor expr2 in sequence2\nif condition2\nfor expr3 in sequence3\n...\nif condition3\nfor exprN in sequenceN\nif conditionN )\nAgain, for a list comprehension only the outside brackets are different (square brackets instead of parentheses). The elements of the generated output will be the successive values of expression. The if clauses are all optional;\nif present, expression is only evaluated and added to the result when condition is true. Generator expressions always have to be written inside parentheses, but the parentheses signalling a function call also\ncount. If you want to create an iterator that will be immediately passed to a function you can write:\nobj_total = sum(obj.count for obj in list_all_objects())\nThe for...in clauses contain the sequences to be iterated over. The sequences do not have to be the same length,\nbecause they are iterated over from left to right, not in parallel. For each element in sequence1, sequence2 is\n6\n\nlooped over from the beginning. sequence3 is then looped over for each resulting pair of elements from sequence1\nand sequence2. To put it another way, a list comprehension or generator expression is equivalent to the following Python code:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue\n# Skip this element\nfor expr2 in sequence2:\nif not (condition2):\ncontinue\n# Skip this element\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue\n# Skip this element\n# Output the value of\n# the expression. This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing. Here’s a sample usage of the generate_ints() generator:\n>>> gen = generate_ints(3)\n>>> gen\n<generator object generate_ints at ...>\n>>> next(gen)\n0\n>>> next(gen)\n1\n>>> next(gen)\n2\n>>> next(gen)\nTraceback (most recent call last):\nFile ""stdin"", line 1, in <module>\nFile ""stdin"", line 2, in generate_ints\nStopIteration\nYou could equally write for i in generate_ints(5), or a, b, c = generate_ints(3).\n\n[3] Iterators don’t have to be finite, though; it’s perfectly reasonable to write an iterator that produces an infinite stream\nof data. The built-in iter() function takes an arbitrary object and tries to return an iterator that will return the object’s\ncontents or elements, raising TypeError if the object doesn’t support iteration. Several of Python’s built-in data\ntypes support iteration, the most common being lists and dictionaries. An object is called iterable if you can get an\niterator for it. You can experiment with the iteration interface manually:\n>>> L = [1, 2, 3]\n>>> it = iter(L)\n>>> it\n<...iterator object at ...>\n>>> it.__next__()\n# same as next(it)\n1\n>>> next(it)\n2\n>>> next(it)\n3\n>>> next(it)\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nStopIteration\n>>>\nPython expects iterable objects in several different contexts, the most important being the for statement. In the\nstatement for X in Y, Y must be an iterator or some object for which iter() can create an iterator. These two\nstatements are equivalent:\nfor i in iter(obj):\nprint(i)\nfor i in obj:\nprint(i)\nIterators can be materialized as lists or tuples by using the list() or tuple() constructor functions:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> t = tuple(iterator)\n>>> t\n(1, 2, 3)\nSequence unpacking also supports iterators: if you know an iterator will return N elements, you can unpack them\ninto an N-tuple:\n>>> L = [1, 2, 3]\n>>> iterator = iter(L)\n>>> a, b, c = iterator\n>>> a, b, c\n(1, 2, 3)\n4\n\nBuilt-in functions such as max() and min() can take a single iterator argument and will return the largest or smallest\nelement. The ""in"" and ""not in"" operators also support iterators: X in iterator is true if X is found in the\nstream returned by the iterator. You’ll run into obvious problems if the iterator is infinite; max(), min() will never\nreturn, and if the element X never appears in the stream, the ""in"" and ""not in"" operators won’t return either. Note that you can only go forward in an iterator; there’s no way to get the previous element, reset the iterator, or\nmake a copy of it. Iterator objects can optionally provide these additional capabilities, but the iterator protocol only\nspecifies the __next__() method. Functions may therefore consume all of the iterator’s output, and if you need to\ndo something different with the same stream, you’ll have to create a new iterator. 2.1 Data Types That Support Iterators\nWe’ve already seen how lists and tuples support iterators. In fact, any Python sequence type, such as strings, will\nautomatically support creation of an iterator. Calling iter() on a dictionary returns an iterator that will loop over the dictionary’s keys:\n>>> m = {\'Jan\': 1, \'Feb\': 2, \'Mar\': 3, \'Apr\': 4, \'May\': 5, \'Jun\': 6,\n...\n\'Jul\': 7, \'Aug\': 8, \'Sep\': 9, \'Oct\': 10, \'Nov\': 11, \'Dec\': 12}\n>>> for key in m:\n...\nprint(key, m[key])\nJan 1\nFeb 2\nMar 3\nApr 4\nMay 5\nJun 6\nJul 7\nAug 8\nSep 9\nOct 10\nNov 11\nDec 12\nNote that starting with Python 3.7, dictionary iteration order is guaranteed to be the same as the insertion order. In\nearlier versions, the behaviour was unspecified and could vary between implementations. Applying iter() to a dictionary always loops over the keys, but dictionaries have methods that return other iterators. If you want to iterate over values or key/value pairs, you can explicitly call the values() or items() methods to\nget an appropriate iterator. The dict() constructor can accept an iterator that returns a finite stream of (key, value) tuples:\n>>> L = [(\'Italy\', \'Rome\'), (\'France\', \'Paris\'), (\'US\', \'Washington DC\')]\n>>> dict(iter(L))\n{\'Italy\': \'Rome\', \'France\': \'Paris\', \'US\': \'Washington DC\'}\nFiles also support iteration by calling the readline() method until there are no more lines in the file. This means\nyou can read each line of a file like this:\nfor line in file:\n# do something for each line\n...\nSets can take their contents from an iterable and let you iterate over the set’s elements:\n>>> S = {2, 3, 5, 7, 11, 13}\n>>> for i in S:\n...\nprint(i)\n2\n(continues on next page)\n5\n\n(continued from previous page)\n3\n5\n7\n11\n13\n3 Generator expressions and list comprehensions\nTwo common operations on an iterator’s output are 1) performing some operation for every element, 2) selecting a\nsubset of elements that meet some condition. For example, given a list of strings, you might want to strip off trailing\nwhitespace from each line or extract all the strings containing a given substring. List comprehensions and generator expressions (short form: “listcomps” and “genexps”) are a concise notation for\nsuch operations, borrowed from the functional programming language Haskell (https://www.haskell.org/). You can\nstrip all the whitespace from a stream of strings with the following code:\n>>> line_list = [\'\nline 1\\n\', \'line 2\n\\n\', \' \\n\', \'\']\n>>> # Generator expression -- returns iterator\n>>> stripped_iter = (line.strip() for line in line_list)\n>>> # List comprehension -- returns list\n>>> stripped_list = [line.strip() for line in line_list]\nYou can select only certain elements by adding an ""if"" condition:\n>>> stripped_list = [line.strip() for line in line_list\n...\nif line != """"]\nWith a list comprehension, you get back a Python list; stripped_list is a list containing the resulting lines, not an\niterator. Generator expressions return an iterator that computes the values as necessary, not needing to materialize\nall the values at once. This means that list comprehensions aren’t useful if you’re working with iterators that return\nan infinite stream or a very large amount of data. Generator expressions are preferable in these situations. Generator expressions are surrounded by parentheses (“()”) and list comprehensions are surrounded by square brack-\nets (“[]”). Generator expressions have the form:\n( expression for expr in sequence1\nif condition1\nfor expr2 in sequence2\nif condition2\nfor expr3 in sequence3\n...\nif condition3\nfor exprN in sequenceN\nif conditionN )\nAgain, for a list comprehension only the outside brackets are different (square brackets instead of parentheses). The elements of the generated output will be the successive values of expression. The if clauses are all optional;\nif present, expression is only evaluated and added to the result when condition is true. Generator expressions always have to be written inside parentheses, but the parentheses signalling a function call also\ncount. If you want to create an iterator that will be immediately passed to a function you can write:\nobj_total = sum(obj.count for obj in list_all_objects())\nThe for...in clauses contain the sequences to be iterated over. The sequences do not have to be the same length,\nbecause they are iterated over from left to right, not in parallel. For each element in sequence1, sequence2 is\n6\n\nlooped over from the beginning. sequence3 is then looped over for each resulting pair of elements from sequence1\nand sequence2. To put it another way, a list comprehension or generator expression is equivalent to the following Python code:\nfor expr1 in sequence1:\nif not (condition1):\ncontinue\n# Skip this element\nfor expr2 in sequence2:\nif not (condition2):\ncontinue\n# Skip this element\n...\nfor exprN in sequenceN:\nif not (conditionN):\ncontinue\n# Skip this element\n# Output the value of\n# the expression. This means that when there are multiple for...in clauses but no if clauses, the length of the resulting output will\nbe equal to the product of the lengths of all the sequences. If you have two lists of length 3, the output list is 9\nelements long:\n>>> seq1 = \'abc\'\n>>> seq2 = (1, 2, 3)\n>>> [(x, y) for x in seq1 for y in seq2]\n[(\'a\', 1), (\'a\', 2), (\'a\', 3),\n(\'b\', 1), (\'b\', 2), (\'b\', 3),\n(\'c\', 1), (\'c\', 2), (\'c\', 3)]\nTo avoid introducing an ambiguity into Python’s grammar, if expression is creating a tuple, it must be surrounded\nwith parentheses. The first list comprehension below is a syntax error, while the second one is correct:\n# Syntax error\n[x, y for x in seq1 for y in seq2]\n# Correct\n[(x, y) for x in seq1 for y in seq2]\n4 Generators\nGenerators are a special class of functions that simplify the task of writing iterators. Regular functions compute a\nvalue and return it, but generators return an iterator that returns a stream of values. You’re doubtless familiar with how regular function calls work in Python or C. When you call a function, it gets a\nprivate namespace where its local variables are created. When the function reaches a return statement, the local\nvariables are destroyed and the value is returned to the caller. A later call to the same function creates a new private\nnamespace and a fresh set of local variables. But, what if the local variables weren’t thrown away on exiting a function? What if you could later resume the function where it left off? This is what generators provide; they can be thought\nof as resumable functions. Here’s the simplest example of a generator function:\n>>> def generate_ints(N):\n...\nfor i in range(N):\n...\nyield i\nAny function containing a yield keyword is a generator function; this is detected by Python’s bytecode compiler\nwhich compiles the function specially as a result. 7\n\nWhen you call a generator function, it doesn’t return a single value; instead it returns a generator object that supports\nthe iterator protocol. On executing the yield expression, the generator outputs the value of i, similar to a return\nstatement. The big difference between yield and a return statement is that on reaching a yield the generator’s\nstate of execution is suspended and local variables are preserved. On the next call to the generator’s __next__()\nmethod, the function will resume executing.')",1.1199348488010256e-79,0.03666361136571952,0.11800653250447793,0.5676153898239136,0.49784878
How do I find the location of my Python site-packages directory?,"There are two types of site-packages directories, 
global
 and 
per user
.




Global
 site-packages (""
dist-packages
"") directories are listed in 
sys.path
 when you run:


 python -m site



For a more concise list run 
getsitepackages
 from the 
site module
 in Python code:


 python -c 'import site; print(site.getsitepackages())'



Caution:
 In virtual environments 
getsitepackages is not available
 with 
older versions of 
virtualenv
, 
sys.path
 from above will list the virtualenv's site-packages directory correctly, though. In Python 3, you may use the 
sysconfig module
 instead:


 python3 -c 'import sysconfig; print(sysconfig.get_paths()[""purelib""])'





The 
per user
 site-packages directory (
PEP 370
) is where Python installs your local packages:


 python -m site --user-site



If this points to a non-existing directory check the exit status of Python and see 
python -m site --help
 for explanations.


Hint:
 Running 
pip list --user
 or 
pip freeze --user
 gives you a list of all installed 
per user
 site-packages.








Practical Tips




.__path__
 lets you identify the location(s) of a specific package: (
details
)


  $ python -c ""import setuptools as _; print(_.__path__)""
  ['/usr/lib/python2.7/dist-packages/setuptools']





.__file__
 lets you identify the location of a specific module: (
difference
)


  $ python3 -c ""import os as _; print(_.__file__)""
  /usr/lib/python3.6/os.py





Run 
pip show 
 to show Debian-style package information:


  $ pip show pytest
  Name: pytest
  Version: 3.8.2
  Summary: pytest: simple powerful testing with Python
  Home-page: https://docs.pytest.org/en/latest/
  Author: Holger Krekel, Bruno Oliveira, Ronny Pfannschmidt, Floris Bruynooghe, Brianna Laugher, Florian Bruhin and others
  Author-email: None
  License: MIT license
  Location: /home/peter/.local/lib/python3.4/site-packages
  Requires: more-itertools, atomicwrites, setuptools, attrs, pathlib2, six, py, pluggy






","(""Answer: You can find the user site-packages directory by running `python -m site --user-site` from the command line. The default location varies by operating system: it's typically `~/.local/lib/pythonX.Y[t]/site-packages` on UNIX and non-framework macOS builds, `~/Library/Python/X.Y/lib/python/site-packages` for macOS framework builds, and `%APPDATA%\\Python\\PythonXY\\site-packages` on Windows. You can also use `site.getusersitepackages()` to get the path.\n\nReferences: [1]\n"", ""[1] Assume foo.pth contains the following:\n# foo package configuration\nfoo\nbar\nbletch\nand bar.pth contains:\n2020\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n# bar package configuration\nbar\nThen the following version-specific directories are added to sys.path, in this order:\n/usr/local/lib/pythonX.Y/site-packages/bar\n/usr/local/lib/pythonX.Y/site-packages/foo\nNote that bletch is omitted because it doesn’t exist; the bar directory precedes the foo directory because bar.pth\ncomes alphabetically before foo.pth; and spam is omitted because it is not mentioned in either path configuration\nfile. 30.15.1 sitecustomize\nAfter these path manipulations, an attempt is made to import a module named sitecustomize, which can perform\narbitrary site-specific customizations. It is typically created by a system administrator in the site-packages directory. If this import fails with an ImportError or its subclass exception, and the exception’s name attribute equals to\n'sitecustomize', it is silently ignored. If Python is started without output streams available, as with pythonw. exe on Windows (which is used by default to start IDLE), attempted output from sitecustomize is ignored. Any\nother exception causes a silent and perhaps mysterious failure of the process. 30.15.2 usercustomize\nAfter this, an attempt is made to import a module named usercustomize, which can perform arbitrary user-specific\ncustomizations, if ENABLE_USER_SITE is true. This file is intended to be created in the user site-packages directory\n(see below), which is part of sys.path unless disabled by -s. If this import fails with an ImportError or its\nsubclass exception, and the exception’s name attribute equals to 'usercustomize', it is silently ignored. Note that for some non-Unix systems, sys.prefix and sys.exec_prefix are empty, and the path manipulations\nare skipped; however the import of sitecustomize and usercustomize is still attempted. 30.15.3 Readline configuration\nOn systems that support readline, this module will also import and configure the rlcompleter module, if Python\nis started in interactive mode and without the -S option. The default behavior is enable tab-completion and to use\n~/.python_history as the history save file. To disable it, delete (or override) the sys.__interactivehook__\nattribute in your sitecustomize or usercustomize module or your PYTHONSTARTUP file. Changed in version 3.4: Activation of rlcompleter and history was made automatic. 30.15.4 Module contents\nsite.PREFIXES\nA list of prefixes for site-packages directories. site.ENABLE_USER_SITE\nFlag showing the status of the user site-packages directory. True means that it is enabled and was added to\nsys.path. False means that it was disabled by user request (with -s or PYTHONNOUSERSITE). None means\nit was disabled for security reasons (mismatch between user or group id and effective id) or by an administrator. site.USER_SITE\nPath to the user site-packages for the running Python. Can be None if getusersitepackages() hasn’t\nbeen called yet. Default value is ~/.local/lib/pythonX.Y[t]/site-packages for UNIX and non-\nframework macOS builds, ~/Library/Python/X.Y/lib/python/site-packages for macOS frame-\nwork builds, and %APPDATA%\\Python\\PythonXY\\site-packages on Windows. The optional “t” indi-\ncates the free-threaded build. This directory is a site directory, which means that .pth files in it will be\nprocessed. 30.15. site — Site-specific configuration hook\n2021\n\nThe Python Library Reference, Release 3.13.2\nsite.USER_BASE\nPath to the base directory for the user site-packages. Can be None if getuserbase() hasn’t been called\nyet. Default value is ~/.local for UNIX and macOS non-framework builds, ~/Library/Python/X.Y\nfor macOS framework builds, and %APPDATA%\\Python for Windows. This value is used to compute the\ninstallation directories for scripts, data files, Python modules, etc. for the user installation scheme. See also\nPYTHONUSERBASE. site.main()\nAdds all the standard site-specific directories to the module search path. This function is called automatically\nwhen this module is imported, unless the Python interpreter was started with the -S flag. Changed in version 3.3: This function used to be called unconditionally. site.addsitedir(sitedir, known_paths=None)\nAdd a directory to sys.path and process its .pth files. Typically used in sitecustomize or usercustomize\n(see above). site.getsitepackages()\nReturn a list containing all global site-packages directories. Added in version 3.2.\nsite.getuserbase()\nReturn the path of the user base directory, USER_BASE. If it is not initialized yet, this function will also set it,\nrespecting PYTHONUSERBASE. Added in version 3.2.\nsite.getusersitepackages()\nReturn the path of the user-specific site-packages directory, USER_SITE. If it is not initialized yet, this function\nwill also set it, respecting USER_BASE. To determine if the user-specific site-packages was added to sys.path\nENABLE_USER_SITE should be used. Added in version 3.2. 30.15.5 Command Line Interface\nThe site module also provides a way to get the user directories from the command line:\n$ python -m site --user-site\n/home/user/.local/lib/python3.11/site-packages\nIf it is called without arguments, it will print the contents of sys.path on the standard output, followed by the\nvalue of USER_BASE and whether the directory exists, then the same thing for USER_SITE, and finally the value of\nENABLE_USER_SITE. --user-base\nPrint the path to the user base directory. --user-site\nPrint the path to the user site-packages directory. If both options are given, user base and user site will be printed (always in this order), separated by os.pathsep. If any option is given, the script will exit with one of these values: 0 if the user site-packages directory is enabled, 1\nif it was disabled by the user, 2 if it is disabled for security reasons or by an administrator, and a value greater than\n2 if there is an error. µ See also\n• PEP 370 – Per user site-packages directory\n• The initialization of the sys.path module search path – The initialization of sys.path. 2022\nChapter 30. Python Runtime Services\n\nCHAPTER\nTHIRTYONE\nCUSTOM PYTHON INTERPRETERS\nThe modules described in this chapter allow writing interfaces similar to Python’s interactive interpreter.\n\n[2] Y/site-packages with three subsubdirectories, foo, bar and spam, and two path configuration files, foo.pth\nand bar.pth. Assume foo.pth contains the following:\n# foo package configuration\nfoo\nbar\nbletch\nand bar.pth contains:\n2020\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n# bar package configuration\nbar\nThen the following version-specific directories are added to sys.path, in this order:\n/usr/local/lib/pythonX.Y/site-packages/bar\n/usr/local/lib/pythonX.Y/site-packages/foo\nNote that bletch is omitted because it doesn’t exist; the bar directory precedes the foo directory because bar.pth\ncomes alphabetically before foo.pth; and spam is omitted because it is not mentioned in either path configuration\nfile. 30.15.1 sitecustomize\nAfter these path manipulations, an attempt is made to import a module named sitecustomize, which can perform\narbitrary site-specific customizations. It is typically created by a system administrator in the site-packages directory. If this import fails with an ImportError or its subclass exception, and the exception’s name attribute equals to\n'sitecustomize', it is silently ignored. If Python is started without output streams available, as with pythonw. exe on Windows (which is used by default to start IDLE), attempted output from sitecustomize is ignored. Any\nother exception causes a silent and perhaps mysterious failure of the process. 30.15.2 usercustomize\nAfter this, an attempt is made to import a module named usercustomize, which can perform arbitrary user-specific\ncustomizations, if ENABLE_USER_SITE is true. This file is intended to be created in the user site-packages directory\n(see below), which is part of sys.path unless disabled by -s. If this import fails with an ImportError or its\nsubclass exception, and the exception’s name attribute equals to 'usercustomize', it is silently ignored. Note that for some non-Unix systems, sys.prefix and sys.exec_prefix are empty, and the path manipulations\nare skipped; however the import of sitecustomize and usercustomize is still attempted. 30.15.3 Readline configuration\nOn systems that support readline, this module will also import and configure the rlcompleter module, if Python\nis started in interactive mode and without the -S option. The default behavior is enable tab-completion and to use\n~/.python_history as the history save file. To disable it, delete (or override) the sys.__interactivehook__\nattribute in your sitecustomize or usercustomize module or your PYTHONSTARTUP file. Changed in version 3.4: Activation of rlcompleter and history was made automatic. 30.15.4 Module contents\nsite.PREFIXES\nA list of prefixes for site-packages directories. site.ENABLE_USER_SITE\nFlag showing the status of the user site-packages directory. True means that it is enabled and was added to\nsys.path. False means that it was disabled by user request (with -s or PYTHONNOUSERSITE). None means\nit was disabled for security reasons (mismatch between user or group id and effective id) or by an administrator. site.USER_SITE\nPath to the user site-packages for the running Python. Can be None if getusersitepackages() hasn’t\nbeen called yet. Default value is ~/.local/lib/pythonX.Y[t]/site-packages for UNIX and non-\nframework macOS builds, ~/Library/Python/X.Y/lib/python/site-packages for macOS frame-\nwork builds, and %APPDATA%\\Python\\PythonXY\\site-packages on Windows. The optional “t” indi-\ncates the free-threaded build. This directory is a site directory, which means that .pth files in it will be\nprocessed. 30.15. site — Site-specific configuration hook\n2021\n\nThe Python Library Reference, Release 3.13.2\nsite.USER_BASE\nPath to the base directory for the user site-packages. Can be None if getuserbase() hasn’t been called\nyet. Default value is ~/.local for UNIX and macOS non-framework builds, ~/Library/Python/X.Y\nfor macOS framework builds, and %APPDATA%\\Python for Windows. This value is used to compute the\ninstallation directories for scripts, data files, Python modules, etc. for the user installation scheme. See also\nPYTHONUSERBASE. site.main()\nAdds all the standard site-specific directories to the module search path. This function is called automatically\nwhen this module is imported, unless the Python interpreter was started with the -S flag. Changed in version 3.3: This function used to be called unconditionally. site.addsitedir(sitedir, known_paths=None)\nAdd a directory to sys.path and process its .pth files. Typically used in sitecustomize or usercustomize\n(see above). site.getsitepackages()\nReturn a list containing all global site-packages directories. Added in version 3.2.\nsite.getuserbase()\nReturn the path of the user base directory, USER_BASE. If it is not initialized yet, this function will also set it,\nrespecting PYTHONUSERBASE. Added in version 3.2.\nsite.getusersitepackages()\nReturn the path of the user-specific site-packages directory, USER_SITE. If it is not initialized yet, this function\nwill also set it, respecting USER_BASE. To determine if the user-specific site-packages was added to sys.path\nENABLE_USER_SITE should be used. Added in version 3.2. 30.15.5 Command Line Interface\nThe site module also provides a way to get the user directories from the command line:\n$ python -m site --user-site\n/home/user/.local/lib/python3.11/site-packages\nIf it is called without arguments, it will print the contents of sys.path on the standard output, followed by the\nvalue of USER_BASE and whether the directory exists, then the same thing for USER_SITE, and finally the value of\nENABLE_USER_SITE. --user-base\nPrint the path to the user base directory. --user-site\nPrint the path to the user site-packages directory. If both options are given, user base and user site will be printed (always in this order), separated by os.pathsep. If any option is given, the script will exit with one of these values: 0 if the user site-packages directory is enabled, 1\nif it was disabled by the user, 2 if it is disabled for security reasons or by an administrator, and a value greater than\n2 if there is an error. µ See also\n• PEP 370 – Per user site-packages directory\n• The initialization of the sys.path module search path – The initialization of sys.path. 2022\nChapter 30.\n\n[3] Suppose this has a subdirectory /usr/local/lib/pythonX. Y/site-packages with three subsubdirectories, foo, bar and spam, and two path configuration files, foo.pth\nand bar.pth. Assume foo.pth contains the following:\n# foo package configuration\nfoo\nbar\nbletch\nand bar.pth contains:\n2020\nChapter 30. Python Runtime Services\n\nThe Python Library Reference, Release 3.13.2\n# bar package configuration\nbar\nThen the following version-specific directories are added to sys.path, in this order:\n/usr/local/lib/pythonX.Y/site-packages/bar\n/usr/local/lib/pythonX.Y/site-packages/foo\nNote that bletch is omitted because it doesn’t exist; the bar directory precedes the foo directory because bar.pth\ncomes alphabetically before foo.pth; and spam is omitted because it is not mentioned in either path configuration\nfile. 30.15.1 sitecustomize\nAfter these path manipulations, an attempt is made to import a module named sitecustomize, which can perform\narbitrary site-specific customizations. It is typically created by a system administrator in the site-packages directory. If this import fails with an ImportError or its subclass exception, and the exception’s name attribute equals to\n'sitecustomize', it is silently ignored. If Python is started without output streams available, as with pythonw. exe on Windows (which is used by default to start IDLE), attempted output from sitecustomize is ignored. Any\nother exception causes a silent and perhaps mysterious failure of the process. 30.15.2 usercustomize\nAfter this, an attempt is made to import a module named usercustomize, which can perform arbitrary user-specific\ncustomizations, if ENABLE_USER_SITE is true. This file is intended to be created in the user site-packages directory\n(see below), which is part of sys.path unless disabled by -s. If this import fails with an ImportError or its\nsubclass exception, and the exception’s name attribute equals to 'usercustomize', it is silently ignored. Note that for some non-Unix systems, sys.prefix and sys.exec_prefix are empty, and the path manipulations\nare skipped; however the import of sitecustomize and usercustomize is still attempted. 30.15.3 Readline configuration\nOn systems that support readline, this module will also import and configure the rlcompleter module, if Python\nis started in interactive mode and without the -S option. The default behavior is enable tab-completion and to use\n~/.python_history as the history save file. To disable it, delete (or override) the sys.__interactivehook__\nattribute in your sitecustomize or usercustomize module or your PYTHONSTARTUP file. Changed in version 3.4: Activation of rlcompleter and history was made automatic. 30.15.4 Module contents\nsite.PREFIXES\nA list of prefixes for site-packages directories. site.ENABLE_USER_SITE\nFlag showing the status of the user site-packages directory. True means that it is enabled and was added to\nsys.path. False means that it was disabled by user request (with -s or PYTHONNOUSERSITE). None means\nit was disabled for security reasons (mismatch between user or group id and effective id) or by an administrator. site.USER_SITE\nPath to the user site-packages for the running Python. Can be None if getusersitepackages() hasn’t\nbeen called yet. Default value is ~/.local/lib/pythonX.Y[t]/site-packages for UNIX and non-\nframework macOS builds, ~/Library/Python/X.Y/lib/python/site-packages for macOS frame-\nwork builds, and %APPDATA%\\Python\\PythonXY\\site-packages on Windows. The optional “t” indi-\ncates the free-threaded build. This directory is a site directory, which means that .pth files in it will be\nprocessed. 30.15. site — Site-specific configuration hook\n2021\n\nThe Python Library Reference, Release 3.13.2\nsite.USER_BASE\nPath to the base directory for the user site-packages. Can be None if getuserbase() hasn’t been called\nyet. Default value is ~/.local for UNIX and macOS non-framework builds, ~/Library/Python/X.Y\nfor macOS framework builds, and %APPDATA%\\Python for Windows. This value is used to compute the\ninstallation directories for scripts, data files, Python modules, etc. for the user installation scheme. See also\nPYTHONUSERBASE. site.main()\nAdds all the standard site-specific directories to the module search path. This function is called automatically\nwhen this module is imported, unless the Python interpreter was started with the -S flag. Changed in version 3.3: This function used to be called unconditionally. site.addsitedir(sitedir, known_paths=None)\nAdd a directory to sys.path and process its .pth files. Typically used in sitecustomize or usercustomize\n(see above). site.getsitepackages()\nReturn a list containing all global site-packages directories. Added in version 3.2.\nsite.getuserbase()\nReturn the path of the user base directory, USER_BASE. If it is not initialized yet, this function will also set it,\nrespecting PYTHONUSERBASE. Added in version 3.2.\nsite.getusersitepackages()\nReturn the path of the user-specific site-packages directory, USER_SITE. If it is not initialized yet, this function\nwill also set it, respecting USER_BASE. To determine if the user-specific site-packages was added to sys.path\nENABLE_USER_SITE should be used. Added in version 3.2. 30.15.5 Command Line Interface\nThe site module also provides a way to get the user directories from the command line:\n$ python -m site --user-site\n/home/user/.local/lib/python3.11/site-packages\nIf it is called without arguments, it will print the contents of sys.path on the standard output, followed by the\nvalue of USER_BASE and whether the directory exists, then the same thing for USER_SITE, and finally the value of\nENABLE_USER_SITE. --user-base\nPrint the path to the user base directory. --user-site\nPrint the path to the user site-packages directory. If both options are given, user base and user site will be printed (always in this order), separated by os.pathsep. If any option is given, the script will exit with one of these values: 0 if the user site-packages directory is enabled, 1\nif it was disabled by the user, 2 if it is disabled for security reasons or by an administrator, and a value greater than\n2 if there is an error. µ See also\n• PEP 370 – Per user site-packages directory\n• The initialization of the sys.path module search path – The initialization of sys.path."")",3.075190890613698e-79,0.06281833616298811,0.19618273948553197,0.5863103270530701,0.7584628
Getting key with maximum value in dictionary?,"You can use 
operator.itemgetter
 for that:


import operator
stats = {'a': 1000, 'b': 3000, 'c': 100}
max(stats.iteritems(), key=operator.itemgetter(1))[0]



And instead of building a new list in memory use 
stats.iteritems()
. The 
key
 parameter to the 
max()
 function is a function that computes a key that is used to determine how to rank items.


Please note that if you were to have another key-value pair 'd': 3000 that this method will only return 
one
 of the 
two
 even though they both have the maximum value.


>>> import operator
>>> stats = {'a': 1000, 'b': 3000, 'c': 100, 'd': 3000}
>>> max(stats.iteritems(), key=operator.itemgetter(1))[0]
'b' 



If using Python3:


>>> max(stats.items(), key=operator.itemgetter(1))[0]
'b'


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4.\n\n[2] d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6.\n\n[3] key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nDictionaries and dictionary views are reversible.')",1.7996564065511902e-79,0.04099060631938514,0.17666143986021282,0.5473988056182861,0.40915525
What does the 'b' character do in front of a string literal?,"To quote 
the Python 2.x documentation
:




A prefix of 'b' or 'B' is ignored in
  Python 2; it indicates that the
  literal should become a bytes literal
  in Python 3 (e.g. when code is
  automatically converted with 2to3). A
  'u' or 'b' prefix may be followed by
  an 'r' prefix.




The 
Python 3 documentation
 states:




Bytes literals are always prefixed with 'b' or 'B'; they produce an instance of the bytes type instead of the str type. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with escapes.



","(""Answer: Prefacing a string literal with 'b' or 'B' creates a bytes literal, which is an instance of the bytes type instead of the str type. Bytes literals can only contain ASCII characters, and bytes with a numeric value of 128 or greater must be expressed with escapes.\n\nReferences: [2, 3]\n"", '[1] It can also be used to escape characters that otherwise have a special meaning,\nsuch as newline, backslash itself, or the quote character. See escape sequences below for examples. Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'. Support for the unicode legacy literal (u\'value\') was reintroduced to simplify the maintenance of dual Python 2.x\nand 3.x codebases. See PEP 414 for more information. A string literal with \'f\' or \'F\' in its prefix is a formatted string literal; see f-strings. The \'f\' may be combined\nwith \'r\', but not with \'b\' or \'u\', therefore raw formatted strings are possible, but formatted bytes literals are not. In triple-quoted literals, unescaped newlines and quotes are allowed (and are retained), except that three unescaped\nquotes in a row terminate the literal. (A “quote” is the character used to open the literal, i.e. either \' or "".) Escape sequences\nUnless an \'r\' or \'R\' prefix is present, escape sequences in string and bytes literals are interpreted according to rules\nsimilar to those used by Standard C. The recognized escape sequences are:\n10\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nEscape Sequence\nMeaning\nNotes\n\\<newline>\nBackslash and newline ignored\n(1)\n\\\\\nBackslash (\\)\n\\\'\nSingle quote (\')\n\\""\nDouble quote ("")\n\\a\nASCII Bell (BEL)\n\\b\nASCII Backspace (BS)\n\\f\nASCII Formfeed (FF)\n\\n\nASCII Linefeed (LF)\n\\r\nASCII Carriage Return (CR)\n\\t\nASCII Horizontal Tab (TAB)\n\\v\nASCII Vertical Tab (VT)\n\\ooo\nCharacter with octal value ooo\n(2,4)\n\\xhh\nCharacter with hex value hh\n(3,4)\nEscape sequences only recognized in string literals are:\nEscape Sequence\nMeaning\nNotes\n\\N{name}\nCharacter named name in the Unicode database\n(5)\n\\uxxxx\nCharacter with 16-bit hex value xxxx\n(6)\n\\Uxxxxxxxx\nCharacter with 32-bit hex value xxxxxxxx\n(7)\nNotes:\n(1) A backslash can be added at the end of a line to ignore the newline:\n>>> \'This string will not include \\\n... backslashes or newline characters.\' \'This string will not include backslashes or newline characters.\' The same result can be achieved using triple-quoted strings, or parentheses and string literal concatenation. (2) As in Standard C, up to three octal digits are accepted. Changed in version 3.11: Octal escapes with value larger than 0o377 produce a DeprecationWarning. Changed in version 3.12: Octal escapes with value larger than 0o377 produce a SyntaxWarning. In a future\nPython version they will be eventually a SyntaxError. (3) Unlike in Standard C, exactly two hex digits are required. (4) In a bytes literal, hexadecimal and octal escapes denote the byte with the given value. In a string literal, these\nescapes denote a Unicode character with the given value. (5) Changed in version 3.3: Support for name aliases1 has been added. (6) Exactly four hex digits are required. (7) Any Unicode character can be encoded this way. Exactly eight hex digits are required. Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., the backslash is left in\nthe result. (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more\neasily recognized as broken.) It is also important to note that the escape sequences only recognized in string literals\nfall into the category of unrecognized escapes for bytes literals. Changed in version 3.6: Unrecognized escape sequences produce a DeprecationWarning. Changed in version 3.12: Unrecognized escape sequences produce a SyntaxWarning. In a future Python version\nthey will be eventually a SyntaxError. 1 https://www.unicode.org/Public/15.1.0/ucd/NameAliases.txt\n2.4. Literals\n11\n\nThe Python Language Reference, Release 3.13.2\nEven in a raw literal, quotes can be escaped with a backslash, but the backslash remains in the result; for example,\nr""\\"""" is a valid string literal consisting of two characters: a backslash and a double quote; r""\\"" is not a valid string\nliteral (even a raw string cannot end in an odd number of backslashes). Specifically, a raw literal cannot end in a\nsingle backslash (since the backslash would escape the following quote character). Note also that a single backslash\nfollowed by a newline is interpreted as those two characters as part of the literal, not as a line continuation. 2.4.2 String literal concatenation\nMultiple adjacent string or bytes literals (delimited by whitespace), possibly using different quoting conventions,\nare allowed, and their meaning is the same as their concatenation. Thus, ""hello"" \'world\' is equivalent to\n""helloworld"". This feature can be used to reduce the number of backslashes needed, to split long strings conve-\nniently across long lines, or even to add comments to parts of strings, for example:\nre.compile(""[A-Za-z_]""\n# letter or underscore\n""[A-Za-z0-9_]*""\n# letter, digit or underscore\n)\nNote that this feature is defined at the syntactical level, but implemented at compile time. The ‘+’ operator must\nbe used to concatenate string expressions at run time. Also note that literal concatenation can use different quoting\nstyles for each component (even mixing raw strings and triple quoted strings), and formatted string literals may be\nconcatenated with plain string literals. 2.4.3 f-strings\nAdded in version 3.6. A formatted string literal or f-string is a string literal that is prefixed with \'f\' or \'F\'. These strings may contain\nreplacement fields, which are expressions delimited by curly braces {}. While other string literals always have a\nconstant value, formatted strings are really expressions evaluated at run time. Escape sequences are decoded like in ordinary string literals (except when a literal is also marked as a raw string). After decoding, the grammar for the contents of the string is:\nf_string\n::= (literal_char | ""{{"" | ""}}"" | replacement_field)*\nreplacement_field ::= ""{"" f_expression [""=""] [""!"" conversion] ["":"" format_spec] ""}""\nf_expression\n::= (conditional_expression | ""*"" or_expr)\n("","" conditional_expression | "","" ""*"" or_expr)* ["",""]\n| yield_expression\nconversion\n::= ""s"" | ""r"" | ""a""\nformat_spec\n::= (literal_char | replacement_field)*\nliteral_char\n::= <any code point except ""{"", ""}"" or NULL>\nThe parts of the string outside curly braces are treated literally, except that any doubled curly braces \'{{\' or \'}}\'\nare replaced with the corresponding single curly brace.\n\n[2] Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'. Support for the unicode legacy literal (u\'value\') was reintroduced to simplify the maintenance of dual Python 2.x\nand 3.x codebases. See PEP 414 for more information. A string literal with \'f\' or \'F\' in its prefix is a formatted string literal; see f-strings. The \'f\' may be combined\nwith \'r\', but not with \'b\' or \'u\', therefore raw formatted strings are possible, but formatted bytes literals are not. In triple-quoted literals, unescaped newlines and quotes are allowed (and are retained), except that three unescaped\nquotes in a row terminate the literal. (A “quote” is the character used to open the literal, i.e. either \' or "".) Escape sequences\nUnless an \'r\' or \'R\' prefix is present, escape sequences in string and bytes literals are interpreted according to rules\nsimilar to those used by Standard C. The recognized escape sequences are:\n10\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nEscape Sequence\nMeaning\nNotes\n\\<newline>\nBackslash and newline ignored\n(1)\n\\\\\nBackslash (\\)\n\\\'\nSingle quote (\')\n\\""\nDouble quote ("")\n\\a\nASCII Bell (BEL)\n\\b\nASCII Backspace (BS)\n\\f\nASCII Formfeed (FF)\n\\n\nASCII Linefeed (LF)\n\\r\nASCII Carriage Return (CR)\n\\t\nASCII Horizontal Tab (TAB)\n\\v\nASCII Vertical Tab (VT)\n\\ooo\nCharacter with octal value ooo\n(2,4)\n\\xhh\nCharacter with hex value hh\n(3,4)\nEscape sequences only recognized in string literals are:\nEscape Sequence\nMeaning\nNotes\n\\N{name}\nCharacter named name in the Unicode database\n(5)\n\\uxxxx\nCharacter with 16-bit hex value xxxx\n(6)\n\\Uxxxxxxxx\nCharacter with 32-bit hex value xxxxxxxx\n(7)\nNotes:\n(1) A backslash can be added at the end of a line to ignore the newline:\n>>> \'This string will not include \\\n... backslashes or newline characters.\' \'This string will not include backslashes or newline characters.\' The same result can be achieved using triple-quoted strings, or parentheses and string literal concatenation. (2) As in Standard C, up to three octal digits are accepted. Changed in version 3.11: Octal escapes with value larger than 0o377 produce a DeprecationWarning. Changed in version 3.12: Octal escapes with value larger than 0o377 produce a SyntaxWarning. In a future\nPython version they will be eventually a SyntaxError. (3) Unlike in Standard C, exactly two hex digits are required. (4) In a bytes literal, hexadecimal and octal escapes denote the byte with the given value. In a string literal, these\nescapes denote a Unicode character with the given value. (5) Changed in version 3.3: Support for name aliases1 has been added. (6) Exactly four hex digits are required. (7) Any Unicode character can be encoded this way. Exactly eight hex digits are required. Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., the backslash is left in\nthe result. (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more\neasily recognized as broken.) It is also important to note that the escape sequences only recognized in string literals\nfall into the category of unrecognized escapes for bytes literals. Changed in version 3.6: Unrecognized escape sequences produce a DeprecationWarning. Changed in version 3.12: Unrecognized escape sequences produce a SyntaxWarning. In a future Python version\nthey will be eventually a SyntaxError. 1 https://www.unicode.org/Public/15.1.0/ucd/NameAliases.txt\n2.4. Literals\n11\n\nThe Python Language Reference, Release 3.13.2\nEven in a raw literal, quotes can be escaped with a backslash, but the backslash remains in the result; for example,\nr""\\"""" is a valid string literal consisting of two characters: a backslash and a double quote; r""\\"" is not a valid string\nliteral (even a raw string cannot end in an odd number of backslashes). Specifically, a raw literal cannot end in a\nsingle backslash (since the backslash would escape the following quote character). Note also that a single backslash\nfollowed by a newline is interpreted as those two characters as part of the literal, not as a line continuation. 2.4.2 String literal concatenation\nMultiple adjacent string or bytes literals (delimited by whitespace), possibly using different quoting conventions,\nare allowed, and their meaning is the same as their concatenation. Thus, ""hello"" \'world\' is equivalent to\n""helloworld"". This feature can be used to reduce the number of backslashes needed, to split long strings conve-\nniently across long lines, or even to add comments to parts of strings, for example:\nre.compile(""[A-Za-z_]""\n# letter or underscore\n""[A-Za-z0-9_]*""\n# letter, digit or underscore\n)\nNote that this feature is defined at the syntactical level, but implemented at compile time. The ‘+’ operator must\nbe used to concatenate string expressions at run time. Also note that literal concatenation can use different quoting\nstyles for each component (even mixing raw strings and triple quoted strings), and formatted string literals may be\nconcatenated with plain string literals. 2.4.3 f-strings\nAdded in version 3.6. A formatted string literal or f-string is a string literal that is prefixed with \'f\' or \'F\'. These strings may contain\nreplacement fields, which are expressions delimited by curly braces {}. While other string literals always have a\nconstant value, formatted strings are really expressions evaluated at run time. Escape sequences are decoded like in ordinary string literals (except when a literal is also marked as a raw string). After decoding, the grammar for the contents of the string is:\nf_string\n::= (literal_char | ""{{"" | ""}}"" | replacement_field)*\nreplacement_field ::= ""{"" f_expression [""=""] [""!"" conversion] ["":"" format_spec] ""}""\nf_expression\n::= (conditional_expression | ""*"" or_expr)\n("","" conditional_expression | "","" ""*"" or_expr)* ["",""]\n| yield_expression\nconversion\n::= ""s"" | ""r"" | ""a""\nformat_spec\n::= (literal_char | replacement_field)*\nliteral_char\n::= <any code point except ""{"", ""}"" or NULL>\nThe parts of the string outside curly braces are treated literally, except that any doubled curly braces \'{{\' or \'}}\'\nare replaced with the corresponding single curly brace. A single opening curly bracket \'{\' marks a replacement field,\nwhich starts with a Python expression. To display both the expression text and its value after evaluation, (useful in\ndebugging), an equal sign \'=\' may be added after the expression.\n\n[3] See escape sequences below for examples. Bytes literals are always prefixed with \'b\' or \'B\'; they produce an instance of the bytes type instead of the str\ntype. They may only contain ASCII characters; bytes with a numeric value of 128 or greater must be expressed with\nescapes. Both string and bytes literals may optionally be prefixed with a letter \'r\' or \'R\'; such constructs are called raw string\nliterals and raw bytes literals respectively and treat backslashes as literal characters. As a result, in raw string literals,\n\'\\U\' and \'\\u\' escapes are not treated specially. Added in version 3.3: The \'rb\' prefix of raw bytes literals has been added as a synonym of \'br\'. Support for the unicode legacy literal (u\'value\') was reintroduced to simplify the maintenance of dual Python 2.x\nand 3.x codebases. See PEP 414 for more information. A string literal with \'f\' or \'F\' in its prefix is a formatted string literal; see f-strings. The \'f\' may be combined\nwith \'r\', but not with \'b\' or \'u\', therefore raw formatted strings are possible, but formatted bytes literals are not. In triple-quoted literals, unescaped newlines and quotes are allowed (and are retained), except that three unescaped\nquotes in a row terminate the literal. (A “quote” is the character used to open the literal, i.e. either \' or "".) Escape sequences\nUnless an \'r\' or \'R\' prefix is present, escape sequences in string and bytes literals are interpreted according to rules\nsimilar to those used by Standard C. The recognized escape sequences are:\n10\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nEscape Sequence\nMeaning\nNotes\n\\<newline>\nBackslash and newline ignored\n(1)\n\\\\\nBackslash (\\)\n\\\'\nSingle quote (\')\n\\""\nDouble quote ("")\n\\a\nASCII Bell (BEL)\n\\b\nASCII Backspace (BS)\n\\f\nASCII Formfeed (FF)\n\\n\nASCII Linefeed (LF)\n\\r\nASCII Carriage Return (CR)\n\\t\nASCII Horizontal Tab (TAB)\n\\v\nASCII Vertical Tab (VT)\n\\ooo\nCharacter with octal value ooo\n(2,4)\n\\xhh\nCharacter with hex value hh\n(3,4)\nEscape sequences only recognized in string literals are:\nEscape Sequence\nMeaning\nNotes\n\\N{name}\nCharacter named name in the Unicode database\n(5)\n\\uxxxx\nCharacter with 16-bit hex value xxxx\n(6)\n\\Uxxxxxxxx\nCharacter with 32-bit hex value xxxxxxxx\n(7)\nNotes:\n(1) A backslash can be added at the end of a line to ignore the newline:\n>>> \'This string will not include \\\n... backslashes or newline characters.\' \'This string will not include backslashes or newline characters.\' The same result can be achieved using triple-quoted strings, or parentheses and string literal concatenation. (2) As in Standard C, up to three octal digits are accepted. Changed in version 3.11: Octal escapes with value larger than 0o377 produce a DeprecationWarning. Changed in version 3.12: Octal escapes with value larger than 0o377 produce a SyntaxWarning. In a future\nPython version they will be eventually a SyntaxError. (3) Unlike in Standard C, exactly two hex digits are required. (4) In a bytes literal, hexadecimal and octal escapes denote the byte with the given value. In a string literal, these\nescapes denote a Unicode character with the given value. (5) Changed in version 3.3: Support for name aliases1 has been added. (6) Exactly four hex digits are required. (7) Any Unicode character can be encoded this way. Exactly eight hex digits are required. Unlike Standard C, all unrecognized escape sequences are left in the string unchanged, i.e., the backslash is left in\nthe result. (This behavior is useful when debugging: if an escape sequence is mistyped, the resulting output is more\neasily recognized as broken.) It is also important to note that the escape sequences only recognized in string literals\nfall into the category of unrecognized escapes for bytes literals. Changed in version 3.6: Unrecognized escape sequences produce a DeprecationWarning. Changed in version 3.12: Unrecognized escape sequences produce a SyntaxWarning. In a future Python version\nthey will be eventually a SyntaxError. 1 https://www.unicode.org/Public/15.1.0/ucd/NameAliases.txt\n2.4. Literals\n11\n\nThe Python Language Reference, Release 3.13.2\nEven in a raw literal, quotes can be escaped with a backslash, but the backslash remains in the result; for example,\nr""\\"""" is a valid string literal consisting of two characters: a backslash and a double quote; r""\\"" is not a valid string\nliteral (even a raw string cannot end in an odd number of backslashes). Specifically, a raw literal cannot end in a\nsingle backslash (since the backslash would escape the following quote character). Note also that a single backslash\nfollowed by a newline is interpreted as those two characters as part of the literal, not as a line continuation. 2.4.2 String literal concatenation\nMultiple adjacent string or bytes literals (delimited by whitespace), possibly using different quoting conventions,\nare allowed, and their meaning is the same as their concatenation. Thus, ""hello"" \'world\' is equivalent to\n""helloworld"". This feature can be used to reduce the number of backslashes needed, to split long strings conve-\nniently across long lines, or even to add comments to parts of strings, for example:\nre.compile(""[A-Za-z_]""\n# letter or underscore\n""[A-Za-z0-9_]*""\n# letter, digit or underscore\n)\nNote that this feature is defined at the syntactical level, but implemented at compile time. The ‘+’ operator must\nbe used to concatenate string expressions at run time. Also note that literal concatenation can use different quoting\nstyles for each component (even mixing raw strings and triple quoted strings), and formatted string literals may be\nconcatenated with plain string literals. 2.4.3 f-strings\nAdded in version 3.6. A formatted string literal or f-string is a string literal that is prefixed with \'f\' or \'F\'. These strings may contain\nreplacement fields, which are expressions delimited by curly braces {}. While other string literals always have a\nconstant value, formatted strings are really expressions evaluated at run time. Escape sequences are decoded like in ordinary string literals (except when a literal is also marked as a raw string). After decoding, the grammar for the contents of the string is:\nf_string\n::= (literal_char | ""{{"" | ""}}"" | replacement_field)*\nreplacement_field ::= ""{"" f_expression [""=""] [""!"" conversion] ["":"" format_spec] ""}""\nf_expression\n::= (conditional_expression | ""*"" or_expr)\n("","" conditional_expression | "","" ""*"" or_expr)* ["",""]\n| yield_expression\nconversion\n::= ""s"" | ""r"" | ""a""\nformat_spec\n::= (literal_char | replacement_field)*\nliteral_char\n::= <any code point except ""{"", ""}"" or NULL>\nThe parts of the string outside curly braces are treated literally, except that any doubled curly braces \'{{\' or \'}}\'\nare replaced with the corresponding single curly brace. A single opening curly bracket \'{\' marks a replacement field,\nwhich starts with a Python expression.')",0.013878421973610817,0.04439511653718091,0.11566504175612591,0.6546605825424194,0.60303044
How do I create a constant in Python?,"You cannot declare a variable or value as constant in Python.




To 
indicate
 to programmers that a variable is a constant, one usually writes it in upper case:


CONST_NAME = ""Name""





To raise exceptions when constants are changed, see 
Constants in Python
 by Alex Martelli. Note that this is not commonly used in practice.




As of Python 3.8, there's a 
typing.Final
 variable annotation that will tell static type checkers (like mypy) that your variable shouldn't be reassigned. This is the closest equivalent to Java's 
final
. However, it 
does not actually prevent reassignment
:


from typing import Final

a: Final[int] = 1

# Executes fine, but mypy will report an error if you run mypy on this:
a = 2


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . 59\n4.6.2\nHow do you implement persistent objects in Python? . . . . . . . . . . . . . . . . . . . . 59\n4.7\nMathematics and Numerics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.7.1\nHow do I generate random numbers in Python? . . . . . . . . . . . . . . . . . . . . . . . 59\n5\nExtending/Embedding FAQ\n61\n5.1\nCan I create my own functions in C? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . 28\n2.6.6\nHow do I call a method defined in a base class from a derived class that extends it? . . . . 29\n2.6.7\nHow can I organize my code to make it easier to change the base class? . . . . . . . . . . 29\n2.6.8\nHow do I create static class data and static class methods? . . . . . . . . . . . . . . . . . 29\n2.6.9\nHow can I overload constructors (or methods) in Python? . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n2.7\nModules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.1\nHow do I create a .pyc file? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.2\nHow do I find the current module name? . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n2.7.3\nHow can I have modules that mutually import each other? . . . . . . . . . . . . . . . . .')",8.186537294367414e-232,0.09395973154362418,0.12899607403252947,0.44218865036964417,0.28487676
How do I terminate a script?,"import sys
sys.exit()



details from the 
sys
 module documentation
:




sys.
exit
([
arg
])


Exit from Python. This is implemented by raising the

SystemExit
 exception, so cleanup actions specified by finally clauses
of 
try
 statements are honored, and it is possible to intercept the
exit attempt at an outer level.


The optional argument 
arg
 can be an integer giving the exit status
(defaulting to zero), or another type of object. If it is an integer,
zero is considered “successful termination” and any nonzero value is
considered “abnormal termination” by shells and the like. Most systems
require it to be in the range 0-127, and produce undefined results
otherwise. Some systems have a convention for assigning specific
meanings to specific exit codes, but these are generally
underdeveloped; Unix programs generally use 2 for command line syntax
errors and 1 for all other kind of errors. If another type of object
is passed, None is equivalent to passing zero, and any other object is
printed to 
stderr
 and results in an exit code of 1. In particular,

sys.exit(""some error message"")
 is a quick way to exit a program when
an error occurs.


Since 
exit()
 ultimately “only” raises an exception, it will only exit
the process when called from the main thread, and the exception is not
intercepted.




Note that this is the 'nice' way to exit.  @
glyphtwistedmatrix
 below points out that if you want a 'hard exit', you can use 
os._exit(*errorcode*)
, though it's likely os-specific to some extent (it might not take an errorcode under windows, for example), and it definitely is less friendly since it doesn't let the interpreter do any cleanup before the process dies.  On the other hand, it 
does
 kill the entire process, including all running threads, while 
sys.exit()
 (as it says in the docs) only exits if called from the main thread, with no other threads running.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . 102\n7.9\nThe break statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n7.10\nThe continue statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n7.11\nThe import statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n7.11.1\nFuture statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . 3\n1.3\nLogging to a file . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.4\nLogging variable data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.5\nChanging the format of displayed messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.6\nDisplaying the date/time in messages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.7\nNext Steps . . . . . . . . . . . .\n\n[3] . . . . . . . 15\n5.30 pdb\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n5.31 queue\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\n5.32 random\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5.33 re\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n5.34 shutil . . . . . . . . . . . .')",1.0718135460328898e-155,0.0425531914893617,0.05066732575383094,0.4414510130882263,0.30883503
What is the difference between null=True and blank=True in Django?,"null=True
 sets 
NULL
 (versus 
NOT NULL
) on the column in your DB. Blank values for Django field types such as 
DateTimeField
 or 
ForeignKey
 will be stored as 
NULL
 in the DB.


blank
 determines whether the field will be required in forms. This includes the admin and your custom forms. If 
blank=True
 then the field will not be required, whereas if it's 
False
 the field cannot be blank.


The combo of the two is so frequent because typically if you're going to allow a field to be blank in your form, you're going to also need your database to allow 
NULL
 values for that field. The exception is 
CharField
s and 
TextField
s, which in Django are 
never
 saved as 
NULL
. Blank values are stored in the DB as an empty string (
''
).


A few examples:


models.DateTimeField(blank=True) # raises IntegrityError if blank

models.DateTimeField(null=True) # NULL allowed, but must be filled out in a form



Obviously, Those two options don't make logical sense to use (though there might be a use case for 
null=True, blank=False
 if you want a field to always be required in forms, optional when dealing with an object through something like the shell.)


models.CharField(blank=True) # No problem, blank is stored as ''

models.CharField(null=True) # NULL allowed, but will never be set as NULL



CHAR
 and 
TEXT
 types are never saved as 
NULL
 by Django, so 
null=True
 is unnecessary. However, you can manually set one of these fields to 
None
 to force set it as 
NULL
. If you have a scenario where that might be necessary, you should still include 
null=True
.

","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries\nshould be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The\ndefault false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default),\nerrors are silently ignored. If true, errors raise a ValueError exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode\ncharacters, as accepted by the bytes.decode() method. The optional argument max_num_fields is the maximum number of fields to read. If set, then throws a\nValueError if there are more than max_num_fields fields read. The optional argument separator is the symbol to use for separating the query arguments. It defaults to &. Use the urllib.parse.urlencode() function to convert such lists of pairs into query strings. Changed in version 3.2: Add encoding and errors parameters. Changed in version 3.8: Added max_num_fields parameter. Changed in version 3.10: Added separator parameter with the default value of &. Python versions earlier than\nPython 3.10 allowed using both ; and & as query parameter separator. This has been changed to allow only a\nsingle separator key, with & as the default separator. 22.6. urllib.parse — Parse URLs into components\n1429\n\nThe Python Library Reference, Release 3.13.2\nurllib.parse.urlunparse(parts)\nConstruct a URL from a tuple as returned by urlparse(). The parts argument can be any six-item iter-\nable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had\nunnecessary delimiters (for example, a ? with an empty query; the RFC states that these are equivalent). urllib.parse.urlsplit(urlstring, scheme=”, allow_fragments=True)\nThis is similar to urlparse(), but does not split the params from the URL. This should generally be used\ninstead of urlparse() if the more recent URL syntax allowing parameters to be applied to each segment of\nthe path portion of the URL (see RFC 2396) is wanted. A separate function is needed to separate the path\nsegments and parameters. This function returns a 5-item named tuple:\n(addressing scheme, network location, path, query, fragment identifier). The return value is a named tuple, its items can be accessed by index or as named attributes:\nAttribute\nIndex\nValue\nValue if not present\nscheme\n0\nURL scheme specifier\nscheme parameter\nnetloc\n1\nNetwork location part\nempty string\npath\n2\nHierarchical path\nempty string\nquery\n3\nQuery component\nempty string\nfragment\n4\nFragment identifier\nempty string\nusername\nUser name\nNone\npassword\nPassword\nNone\nhostname\nHost name (lower case)\nNone\nport\nPort number as integer, if present\nNone\nReading the port attribute will raise a ValueError if an invalid port is specified in the URL. See section\nStructured Parse Results for more information on the result object. Unmatched square brackets in the netloc attribute will raise a ValueError. Characters in the netloc attribute that decompose under NFKC normalization (as used by the IDNA encod-\ning) into any of /, ?, #, @, or : will raise a ValueError. If the URL is decomposed before parsing, no error\nwill be raised. Following some of the WHATWG spec that updates RFC 3986, leading C0 control and space characters are\nstripped from the URL. \\n, \\r and tab \\t characters are removed from the URL at any position. Á Warning\nurlsplit() does not perform validation. See URL parsing security for details. Changed in version 3.6: Out-of-range port numbers now raise ValueError, instead of returning None. Changed in version 3.8: Characters that affect netloc parsing under NFKC normalization will now raise\nValueError. Changed in version 3.10: ASCII newline and tab characters are stripped from the URL. Changed in version 3.12: Leading WHATWG C0 control and space characters are stripped from the URL. urllib.parse.urlunsplit(parts)\nCombine the elements of a tuple as returned by urlsplit() into a complete URL as a string. The parts\nargument can be any five-item iterable. This may result in a slightly different, but equivalent URL, if the URL\nthat was parsed originally had unnecessary delimiters (for example, a ? with an empty query; the RFC states\nthat these are equivalent). 1430\nChapter 22. Internet Protocols and Support\n\nThe Python Library Reference, Release 3.13.2\nurllib.parse.urljoin(base, url, allow_fragments=True)\nConstruct a full (“absolute”) URL by combining a “base URL” (base) with another URL (url). Informally, this\nuses components of the base URL, in particular the addressing scheme, the network location and (part of) the\npath, to provide missing components in the relative URL. For example:\n>>> from urllib.parse import urljoin\n>>> urljoin(\'http://www.cwi.nl/%7Eguido/Python.html\', \'FAQ.html\')\n\'http://www.cwi.nl/%7Eguido/FAQ.html\'\nThe allow_fragments argument has the same meaning and default as for urlparse(). ® Note\nIf url is an absolute URL (that is, it starts with // or scheme://), the url’s hostname and/or scheme will\nbe present in the result. For example:\n>>> urljoin(\'http://www.cwi.nl/%7Eguido/Python.html\',\n...\n\'//www.python.org/%7Eguido\')\n\'http://www.python.org/%7Eguido\'\nIf you do not want that behavior, preprocess the url with urlsplit() and urlunsplit(), removing\npossible scheme and netloc parts. Á Warning\nBecause an absolute URL may be passed as the url parameter, it is generally not secure to use urljoin\nwith an attacker-controlled url. For example in, urljoin(""https://website.com/users/"",\nusername), if username can contain an absolute URL, the result of urljoin will be the absolute URL. Changed in version 3.5: Behavior updated to match the semantics defined in RFC 3986.\nurllib.parse.urldefrag(url)\nIf url contains a fragment identifier, return a modified version of url with no fragment identifier, and the\nfragment identifier as a separate string.\n\n[2] The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries\nshould be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The\ndefault false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default),\nerrors are silently ignored. If true, errors raise a ValueError exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode\ncharacters, as accepted by the bytes.decode() method. The optional argument max_num_fields is the maximum number of fields to read. If set, then throws a\nValueError if there are more than max_num_fields fields read. The optional argument separator is the symbol to use for separating the query arguments. It defaults to &. Use the urllib.parse.urlencode() function (with the doseq parameter set to True) to convert such\ndictionaries into query strings. Changed in version 3.2: Add encoding and errors parameters. Changed in version 3.8: Added max_num_fields parameter. Changed in version 3.10: Added separator parameter with the default value of &. Python versions earlier than\nPython 3.10 allowed using both ; and & as query parameter separator. This has been changed to allow only a\nsingle separator key, with & as the default separator. urllib.parse.parse_qsl(qs, keep_blank_values=False, strict_parsing=False, encoding=’utf-8’,\nerrors=’replace’, max_num_fields=None, separator=’&’)\nParse a query string given as a string argument (data of type application/x-www-form-urlencoded). Data are returned as a list of name, value pairs. The optional argument keep_blank_values is a flag indicating whether blank values in percent-encoded queries\nshould be treated as blank strings. A true value indicates that blanks should be retained as blank strings. The\ndefault false value indicates that blank values are to be ignored and treated as if they were not included. The optional argument strict_parsing is a flag indicating what to do with parsing errors. If false (the default),\nerrors are silently ignored. If true, errors raise a ValueError exception. The optional encoding and errors parameters specify how to decode percent-encoded sequences into Unicode\ncharacters, as accepted by the bytes.decode() method. The optional argument max_num_fields is the maximum number of fields to read. If set, then throws a\nValueError if there are more than max_num_fields fields read. The optional argument separator is the symbol to use for separating the query arguments. It defaults to &. Use the urllib.parse.urlencode() function to convert such lists of pairs into query strings. Changed in version 3.2: Add encoding and errors parameters. Changed in version 3.8: Added max_num_fields parameter. Changed in version 3.10: Added separator parameter with the default value of &. Python versions earlier than\nPython 3.10 allowed using both ; and & as query parameter separator. This has been changed to allow only a\nsingle separator key, with & as the default separator. 22.6. urllib.parse — Parse URLs into components\n1429\n\nThe Python Library Reference, Release 3.13.2\nurllib.parse.urlunparse(parts)\nConstruct a URL from a tuple as returned by urlparse(). The parts argument can be any six-item iter-\nable. This may result in a slightly different, but equivalent URL, if the URL that was parsed originally had\nunnecessary delimiters (for example, a ? with an empty query; the RFC states that these are equivalent). urllib.parse.urlsplit(urlstring, scheme=”, allow_fragments=True)\nThis is similar to urlparse(), but does not split the params from the URL. This should generally be used\ninstead of urlparse() if the more recent URL syntax allowing parameters to be applied to each segment of\nthe path portion of the URL (see RFC 2396) is wanted. A separate function is needed to separate the path\nsegments and parameters. This function returns a 5-item named tuple:\n(addressing scheme, network location, path, query, fragment identifier). The return value is a named tuple, its items can be accessed by index or as named attributes:\nAttribute\nIndex\nValue\nValue if not present\nscheme\n0\nURL scheme specifier\nscheme parameter\nnetloc\n1\nNetwork location part\nempty string\npath\n2\nHierarchical path\nempty string\nquery\n3\nQuery component\nempty string\nfragment\n4\nFragment identifier\nempty string\nusername\nUser name\nNone\npassword\nPassword\nNone\nhostname\nHost name (lower case)\nNone\nport\nPort number as integer, if present\nNone\nReading the port attribute will raise a ValueError if an invalid port is specified in the URL. See section\nStructured Parse Results for more information on the result object. Unmatched square brackets in the netloc attribute will raise a ValueError. Characters in the netloc attribute that decompose under NFKC normalization (as used by the IDNA encod-\ning) into any of /, ?, #, @, or : will raise a ValueError. If the URL is decomposed before parsing, no error\nwill be raised. Following some of the WHATWG spec that updates RFC 3986, leading C0 control and space characters are\nstripped from the URL. \\n, \\r and tab \\t characters are removed from the URL at any position.\n\n[3] That is\nwhy when your application does not need values with empty lines, you should consider disallowing them. This\nwill make empty lines split keys every time. In the example above, it would produce two keys, key and this. • default_section, default value: configparser.DEFAULTSECT (that is: ""DEFAULT"")\nThe convention of allowing a special section of default values for other sections or interpolation purposes\nis a powerful concept of this library, letting users create complex declarative configurations. This section is\nnormally called ""DEFAULT"" but this can be customized to point to any other valid section name. Some typical\nvalues include: ""general"" or ""common"". The name provided is used for recognizing default sections when\nreading from any source and is used when writing configuration back to a file. Its current value can be retrieved\nusing the parser_instance.default_section attribute and may be modified at runtime (i.e. to convert\nfiles from one format to another). 14.2. configparser — Configuration file parser\n621\n\nThe Python Library Reference, Release 3.13.2\n• interpolation, default value: configparser.BasicInterpolation\nInterpolation behaviour may be customized by providing a custom handler through the interpolation argu-\nment. None can be used to turn off interpolation completely, ExtendedInterpolation() provides a more\nadvanced variant inspired by zc.buildout. More on the subject in the dedicated documentation section. RawConfigParser has a default value of None. • converters, default value: not set\nConfig parsers provide option value getters that perform type conversion. By default getint(),\ngetfloat(), and getboolean() are implemented. Should other getters be desirable, users may de-\nfine them in a subclass or pass a dictionary where each key is a name of the converter and each value\nis a callable implementing said conversion. For instance, passing {\'decimal\': decimal.Decimal}\nwould add getdecimal() on both the parser object and all section proxies. In other words, it will\nbe possible to write both parser_instance.getdecimal(\'section\', \'key\', fallback=0) and\nparser_instance[\'section\'].getdecimal(\'key\', 0). If the converter needs to access the state of the parser, it can be implemented as a method on a config parser\nsubclass. If the name of this method starts with get, it will be available on all section proxies, in the dict-\ncompatible form (see the getdecimal() example above). More advanced customization may be achieved by overriding default values of these parser attributes. The defaults\nare defined on the classes, so they may be overridden by subclasses or by attribute assignment. ConfigParser.BOOLEAN_STATES\nBy default when using getboolean(), config parsers consider the following values True: \'1\', \'yes\',\n\'true\', \'on\' and the following values False: \'0\', \'no\', \'false\', \'off\'. You can override this by\nspecifying a custom dictionary of strings and their Boolean outcomes. For example:\n>>> custom = configparser.ConfigParser()\n>>> custom[\'section1\'] = {\'funky\': \'nope\'}\n>>> custom[\'section1\'].getboolean(\'funky\')\nTraceback (most recent call last):\n...\nValueError: Not a boolean: nope\n>>> custom.BOOLEAN_STATES = {\'sure\': True, \'nope\': False}\n>>> custom[\'section1\'].getboolean(\'funky\')\nFalse\nOther typical Boolean pairs include accept/reject or enabled/disabled. ConfigParser.optionxform(option)\nThis method transforms option names on every read, get, or set operation. The default converts the name to\nlowercase. This also means that when a configuration file gets written, all keys will be lowercase. Override this\nmethod if that’s unsuitable. For example:\n>>> config = """"""\n... [Section1]\n... Key = Value\n...\n... [Section2]\n... AnotherKey = Value\n... """"""\n>>> typical = configparser.ConfigParser()\n>>> typical.read_string(config)\n>>> list(typical[\'Section1\'].keys())\n[\'key\']\n>>> list(typical[\'Section2\'].keys())\n[\'anotherkey\']\n>>> custom = configparser.RawConfigParser()\n>>> custom.optionxform = lambda option: option\n(continues on next page)\n622\nChapter 14. File Formats\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n>>> custom.read_string(config)\n>>> list(custom[\'Section1\'].keys())\n[\'Key\']\n>>> list(custom[\'Section2\'].keys())\n[\'AnotherKey\']\n® Note\nThe optionxform function transforms option names to a canonical form. This should be an idempotent\nfunction: if the name is already in canonical form, it should be returned unchanged. ConfigParser.SECTCRE\nA compiled regular expression used to parse section headers. The default matches [section] to the name\n""section"". Whitespace is considered part of the section name, thus [ larch ] will be read as a section of\nname "" larch "". Override this attribute if that’s unsuitable. For example:\n>>> import re\n>>> config = """"""\n... [Section 1]\n... option = value\n...\n... [\nSection 2\n]\n... another = val\n... """"""\n>>> typical = configparser.ConfigParser()\n>>> typical.read_string(config)\n>>> typical.sections()\n[\'Section 1\', \'\nSection 2\n\']\n>>> custom = configparser.ConfigParser()\n>>> custom.SECTCRE = re.compile(r""\\[ *(?P<header>[^]]+?) *\\]"")\n>>> custom.read_string(config)\n>>> custom.sections()\n[\'Section 1\', \'Section 2\']\n® Note\nWhile ConfigParser objects also use an OPTCRE attribute for recognizing option lines, it’s not recommended\nto override it because that would interfere with constructor options allow_no_value and delimiters. 14.2.9 Legacy API Examples\nMainly because of backwards compatibility concerns, configparser provides also a legacy API with explicit\nget/set methods. While there are valid use cases for the methods outlined below, mapping protocol access is\npreferred for new projects. The legacy API is at times more advanced, low-level and downright counterintuitive. An example of writing to a configuration file:\nimport configparser\nconfig = configparser.RawConfigParser()\n# Please note that using RawConfigParser\'s set functions, you can assign\n# non-string values to keys internally, but will receive an error when\n# attempting to write to a file or when you get it in non-raw mode. Setting\n(continues on next page)\n14.2. configparser — Configuration file parser\n623\n\nThe Python Library Reference, Release 3.13.2\n(continued from previous page)\n# values using the mapping protocol or ConfigParser\'s set() does not allow\n# such assignments to take place. config.add_section(\'Section1\')\nconfig.set(\'Section1\', \'an_int\', \'15\')\nconfig.set(\'Section1\', \'a_bool\', \'true\')\nconfig.set(\'Section1\', \'a_float\', \'3.1415\')\nconfig.set(\'Section1\', \'baz\', \'fun\')\nconfig.set(\'Section1\', \'bar\', \'Python\')\nconfig.set(\'Section1\', \'foo\', \'%(bar)s is %(baz)s!\') # Writing our configuration file to \'example.cfg\'\nwith open(\'example.cfg\', \'w\') as configfile:\nconfig.write(configfile)\nAn example of reading the configuration file again:\nimport configparser\nconfig = configparser.RawConfigParser()\nconfig.read(\'example.cfg\')\n# getfloat() raises an exception if the value is not a float\n# getint() and getboolean() also do this for their respective types\na_float = config.getfloat(\'Section1\', \'a_float\')\nan_int = config.getint(\'Section1\', \'an_int\')\nprint(a_float + an_int)\n# Notice that the next output does not interpolate \'%(bar)s\' or \'%(baz)s\'. # This is because we are using a RawConfigParser(). if config.getboolean(\'Section1\', \'a_bool\'):\nprint(config.get(\'Section1\', \'foo\'))\nTo get interpolation, use ConfigParser:\nimport configparser\ncfg = configparser.ConfigParser()\ncfg.read(\'example.cfg\')\n# Set the optional *raw* argument of get() to True if you wish to disable\n# interpolation in a single get operation. print(cfg.get(\'Section1\', \'foo\', raw=False))\n# -> ""Python is fun!"" print(cfg.get(\'Section1\', \'foo\', raw=True))\n# -> ""%(bar)s is %(baz)s!"" # The optional *vars* argument is a dict with members that will take\n# precedence in interpolation. print(cfg.get(\'Section1\', \'foo\', vars={\'bar\': \'Documentation\',\n\'baz\': \'evil\'}))\n# The optional *fallback* argument can be used to provide a fallback value\nprint(cfg.get(\'Section1\', \'foo\'))\n# -> ""Python is fun!""')",2.185233763514267e-155,0.055882352941176466,0.1773648648648649,0.5421818494796753,0.32222164
Create a Pandas Dataframe by appending one row at a time,"You can use 
df.loc[i]
, where the row with index 
i
 will be what you specify it to be in the dataframe.


>>> import pandas as pd
>>> from numpy.random import randint

>>> df = pd.DataFrame(columns=['lib', 'qty1', 'qty2'])
>>> for i in range(5):
>>>     df.loc[i] = ['name' + str(i)] + list(randint(10, size=2))

>>> df
     lib qty1 qty2
0  name0    3    3
1  name1    2    4
2  name2    2    8
3  name3    2    1
4  name4    9    6


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.41 tempfile . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.42 time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.43 tkinter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n5.44 traceback\n. . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.1\nHow do I convert between tuples and lists? . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",1.053426230191672e-155,0.12206572769953052,0.10435301132975554,0.45369869470596313,0.10782085
How do I check if a variable exists?,"To check the existence of a local variable:


if 'myVar' in locals():
  # myVar exists.



To check the existence of a global variable:


if 'myVar' in globals():
  # myVar exists.



To check if an object has an attribute:


if hasattr(obj, 'attr_name'):
  # obj.attr_name exists.


","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . 117\n8.1.1\nType Objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n8.1.2\nThe None Object\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n8.2\nNumeric Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n8.2.1\nInteger Objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123\n8.2.2\nBoolean Objects . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . 3\n1.3\nUseful macros\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.4\nObjects, Types and Reference Counts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.4.1\nReference Counts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n1.4.2\nTypes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n1.5\nExceptions\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . 40\n5.7\nMore on Conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n5.8\nComparing Sequences and Other Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n6\nModules\n43\n6.1\nMore on Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n6.1.1\nExecuting modules as scripts\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n6.1.2\nThe Module Search Path\n. . . . . . .')",4.4015566638878774e-232,0.03529411764705882,0.061951907827222694,0.4416877329349518,0.12067302
How does the @property decorator work in Python?,"The 
property()
 function returns a special 
descriptor object
:


>>> property()





It is this object that has 
extra
 methods:


>>> property().getter


>>> property().setter


>>> property().deleter





These act as decorators 
too
. They return a new property object:


>>> property().getter(None)





that is a copy of the old object, but with one of the functions replaced.


Remember, that the 
@decorator
 syntax is just syntactic sugar; the syntax:


@property
def foo(self): return self._foo



really means the same thing as


def foo(self): return self._foo
foo = property(foo)



so 
foo
 the function is replaced by 
property(foo)
, which we saw above is a special object. Then when you use 
@foo.setter()
, what you are doing is call that 
property().setter
 method I showed you above, which returns a new copy of the property, but this time with the setter function replaced with the decorated method.


The following sequence also creates a full-on property, by using those decorator methods.


First we create some functions:


>>> def getter(self): print('Get!')
... 
>>> def setter(self, value): print('Set to {!r}!'.format(value))
... 
>>> def deleter(self): print('Delete!')
... 



Then, we create a 
property
 object with only a getter:


>>> prop = property(getter)
>>> prop.fget is getter
True
>>> prop.fset is None
True
>>> prop.fdel is None
True



Next we use the 
.setter()
 method to add a setter:


>>> prop = prop.setter(setter)
>>> prop.fget is getter
True
>>> prop.fset is setter
True
>>> prop.fdel is None
True



Last we add a deleter with the 
.deleter()
 method:


>>> prop = prop.deleter(deleter)
>>> prop.fget is getter
True
>>> prop.fset is setter
True
>>> prop.fdel is deleter
True



Last but not least, the 
property
 object acts as a 
descriptor object
, so it has 
.__get__()
, 
.__set__()
 and 
.__delete__()
 methods to hook into instance attribute getting, setting and deleting:


>>> class Foo: pass
... 
>>> prop.__get__(Foo(), Foo)
Get!
>>> prop.__set__(Foo(), 'bar')
Set to 'bar'!
>>> prop.__delete__(Foo())
Delete!



The Descriptor Howto includes a 
pure Python sample implementation
 of the 
property()
 type:




class Property:
    ""Emulate PyProperty_Type() in Objects/descrobject.c""

    def __init__(self, fget=None, fset=None, fdel=None, doc=None):
        self.fget = fget
        self.fset = fset
        self.fdel = fdel
        if doc is None and fget is not None:
            doc = fget.__doc__
        self.__doc__ = doc

    def __get__(self, obj, objtype=None):
        if obj is None:
            return self
        if self.fget is None:
            raise AttributeError(""unreadable attribute"")
        return self.fget(obj)

    def __set__(self, obj, value):
        if self.fset is None:
            raise AttributeError(""can't set attribute"")
        self.fset(obj, value)

    def __delete__(self, obj):
        if self.fdel is None:
            raise AttributeError(""can't delete attribute"")
        self.fdel(obj)

    def getter(self, fget):
        return type(self)(fget, self.fset, self.fdel, self.__doc__)

    def setter(self, fset):
        return type(self)(self.fget, fset, self.fdel, self.__doc__)

    def deleter(self, fdel):
        return type(self)(self.fget, self.fset, fdel, self.__doc__)




","(""Answer: The `@property` decorator in Python is a way to build a data descriptor, triggering a function call upon attribute access. It is useful when you want to grant attribute access in a user interface and later changes require a method's intervention, without affecting existing client code.\n\nReferences: [1, 2, 3]\n"", '[1] Properties, bound methods, static methods, class methods, and __slots__ are\nall based on the descriptor protocol. 4.1 Properties\nCalling property() is a succinct way of building a data descriptor that triggers a function call upon access to an\nattribute. Its signature is:\nproperty(fget=None, fset=None, fdel=None, doc=None) -> property\nThe documentation shows a typical use to define a managed attribute x:\nclass C:\ndef getx(self): return self.__x\ndef setx(self, value): self.__x = value\ndef delx(self): del self.__x\nx = property(getx, setx, delx, ""I\'m the \'x\' property."") To see how property() is implemented in terms of the descriptor protocol, here is a pure Python equivalent that\nimplements most of the core functionality:\nclass Property:\n""Emulate PyProperty_Type() in Objects/descrobject.c""\ndef __init__(self, fget=None, fset=None, fdel=None, doc=None):\nself.fget = fget\nself.fset = fset\nself.fdel = fdel\nif doc is None and fget is not None:\ndoc = fget.__doc__\nself.__doc__ = doc\ndef __set_name__(self, owner, name):\nself.__name__ = name\ndef __get__(self, obj, objtype=None):\nif obj is None:\nreturn self\nif self.fget is None:\nraise AttributeError\nreturn self.fget(obj)\ndef __set__(self, obj, value):\nif self.fset is None:\nraise AttributeError\nself.fset(obj, value)\ndef __delete__(self, obj):\nif self.fdel is None:\nraise AttributeError\n(continues on next page)\n13\n\n(continued from previous page)\nself.fdel(obj)\ndef getter(self, fget):\nreturn type(self)(fget, self.fset, self.fdel, self.__doc__)\ndef setter(self, fset):\nreturn type(self)(self.fget, fset, self.fdel, self.__doc__)\ndef deleter(self, fdel):\nreturn type(self)(self.fget, self.fset, fdel, self.__doc__)\nThe property() builtin helps whenever a user interface has granted attribute access and then subsequent changes\nrequire the intervention of a method. For instance, a spreadsheet class may grant access to a cell value through Cell(\'b10\').value. Subsequent im-\nprovements to the program require the cell to be recalculated on every access; however, the programmer does not\nwant to affect existing client code accessing the attribute directly. The solution is to wrap access to the value attribute\nin a property data descriptor:\nclass Cell:\n...\n@property\ndef value(self):\n""Recalculate the cell before returning value""\nself.recalc()\nreturn self._value\nEither the built-in property() or our Property() equivalent would work in this example. 4.2 Functions and methods\nPython’s object oriented features are built upon a function based environment. Using non-data descriptors, the two\nare merged seamlessly. Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular func-\ntions in that the object instance is prepended to the other arguments. By convention, the instance is called self but\ncould be called this or any other variable name. Methods can be created manually with types.MethodType which is roughly equivalent to:\nclass MethodType:\n""Emulate PyMethod_Type in Objects/classobject.c""\ndef __init__(self, func, obj):\nself.__func__ = func\nself.__self__ = obj\ndef __call__(self, *args, **kwargs):\nfunc = self.__func__\nobj = self.__self__\nreturn func(obj, *args, **kwargs)\ndef __getattribute__(self, name):\n""Emulate method_getset() in Objects/classobject.c""\nif name == \'__doc__\':\nreturn self.__func__.__doc__\nreturn object.__getattribute__(self, name)\n(continues on next page)\n14\n\n(continued from previous page)\ndef __getattr__(self, name):\n""Emulate method_getattro() in Objects/classobject.c""\nreturn getattr(self.__func__, name)\ndef __get__(self, obj, objtype=None):\n""Emulate method_descr_get() in Objects/classobject.c""\nreturn self\nTo support automatic creation of methods, functions include the __get__() method for binding methods during\nattribute access. This means that functions are non-data descriptors that return bound methods during dotted lookup\nfrom an instance. Here’s how it works:\nclass Function:\n...\ndef __get__(self, obj, objtype=None):\n""Simulate func_descr_get() in Objects/funcobject.c""\nif obj is None:\nreturn self\nreturn MethodType(self, obj)\nRunning the following class in the interpreter shows how the function descriptor works in practice:\nclass D:\ndef f(self):\nreturn self\nclass D2:\npass\nThe function has a qualified name attribute to support introspection:\n>>> D.f.__qualname__\n\'D.f\'\nAccessing the function through the class dictionary does not invoke __get__(). Instead, it just returns the underlying\nfunction object:\n>>> D.__dict__[\'f\']\n<function D.f at 0x00C45070>\nDotted access from a class calls __get__() which just returns the underlying function unchanged:\n>>> D.f\n<function D.f at 0x00C45070>\nThe interesting behavior occurs during dotted access from an instance. The dotted lookup calls __get__() which\nreturns a bound method object:\n>>> d = D()\n>>> d.f\n<bound method D.f of <__main__.D object at 0x00B18C90>>\nInternally, the bound method stores the underlying function and the bound instance:\n>>> d.f.__func__\n<function D.f at 0x00C45070>\n(continues on next page)\n15\n\n(continued from previous page)\n>>> d.f.__self__\n<__main__.D object at 0x00B18C90>\nIf you have ever wondered where self comes from in regular methods or where cls comes from in class methods, this\nis it! 4.3 Kinds of methods\nNon-data descriptors provide a simple mechanism for variations on the usual patterns of binding functions into meth-\nods. To recap, functions have a __get__() method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an obj.f(*args) call into f(obj, *args). Calling cls.f(*args) be-\ncomes f(*args). This chart summarizes the binding and its two most useful variants:\nTransformation\nCalled from an object\nCalled from a class\nfunction\nf(obj, *args)\nf(*args)\nstaticmethod\nf(*args)\nf(*args)\nclassmethod\nf(type(obj), *args)\nf(cls, *args)\n4.4 Static methods\nStatic methods return the underlying function without changes. Calling either c.f or C.f is the equivalent of a direct\nlookup into object.__getattribute__(c, ""f"") or object.__getattribute__(C, ""f""). As a result,\nthe function becomes identically accessible from either an object or a class. Good candidates for static methods are methods that do not reference the self variable. For instance, a statistics package may include a container class for experimental data. The class provides normal\nmethods for computing the average, mean, median, and other descriptive statistics that depend on the data. However,\nthere may be useful functions which are conceptually related but do not depend on the data. For instance, erf(x) is\nhandy conversion routine that comes up in statistical work but does not directly depend on a particular dataset. It can\nbe called either from an object or the class: s.erf(1.5) --> 0.9332 or Sample.erf(1.5) --> 0.9332. Since static methods return the underlying function with no changes, the example calls are unexciting:\nclass E:\n@staticmethod\ndef f(x):\nreturn x * 10\n>>> E.f(3)\n30\n>>> E().f(3)\n30\nUsing the non-data descriptor protocol, a pure Python version of staticmethod() would look like this:\nimport functools\nclass StaticMethod:\n""Emulate PyStaticMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n16\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, objtype=None):\nreturn self.f\ndef __call__(self, *args, **kwds):\nreturn self.f(*args, **kwds)\nThe functools.update_wrapper() call adds a __wrapped__ attribute that refers to the underlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped function: __name__,\n__qualname__, __doc__, and __annotations__. 4.5 Class methods\nUnlike static methods, class methods prepend the class reference to the argument list before calling the function. This\nformat is the same for whether the caller is an object or a class:\nclass F:\n@classmethod\ndef f(cls, x):\nreturn cls.__name__, x\n>>> F.f(3)\n(\'F\', 3)\n>>> F().f(3)\n(\'F\', 3)\nThis behavior is useful whenever the method only needs to have a class reference and does not rely on data stored in\na specific instance. One use for class methods is to create alternate class constructors. For example, the classmethod\ndict.fromkeys() creates a new dictionary from a list of keys. The pure Python equivalent is:\nclass Dict(dict):\n@classmethod\ndef fromkeys(cls, iterable, value=None):\n""Emulate dict_fromkeys() in Objects/dictobject.c""\nd = cls()\nfor key in iterable:\nd[key] = value\nreturn d\nNow a new dictionary of unique keys can be constructed like this:\n>>> d = Dict.fromkeys(\'abracadabra\')\n>>> type(d) is Dict\nTrue\n>>> d\n{\'a\': None, \'b\': None, \'r\': None, \'c\': None, \'d\': None}\nUsing the non-data descriptor protocol, a pure Python version of classmethod() would look like this:\nimport functools\nclass ClassMethod:\n""Emulate PyClassMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n17\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, cls=None):\nif cls is None:\ncls = type(obj)\nreturn MethodType(self.f, cls)\nThe functools.update_wrapper() call in ClassMethod adds a __wrapped__ attribute that refers to the\nunderlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped\nfunction: __name__, __qualname__, __doc__, and __annotations__. 4.6 Member objects and __slots__\nWhen a class defines __slots__, it replaces instance dictionaries with a fixed-length array of slot values. From a\nuser point of view that has several effects:\n1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute names specified in\n__slots__ are allowed:\nclass Vehicle:\n__slots__ = (\'id_number\', \'make\', \'model\')\n>>> auto = Vehicle()\n>>> auto.id_nubmer = \'VYE483814LQEX\'\nTraceback (most recent call last):\n...\nAttributeError: \'Vehicle\' object has no attribute \'id_nubmer\'\n2. Helps create immutable objects where descriptors manage access to private attributes stored in __slots__:\nclass Immutable:\n__slots__ = (\'_dept\', \'_name\')\n# Replace the instance dictionary\ndef __init__(self, dept, name):\nself._dept = dept\n# Store to private attribute\nself._name = name\n# Store to private attribute\n@property\n# Read-only descriptor\ndef dept(self):\nreturn self._dept\n@property\ndef name(self):\n# Read-only descriptor\nreturn self._name\n>>> mark = Immutable(\'Botany\', \'Mark Watney\')\n>>> mark.dept\n\'Botany\'\n>>> mark.dept = \'Space Pirate\'\nTraceback (most recent call last):\n...\nAttributeError: property \'dept\' of \'Immutable\' object has no setter\n>>> mark.location = \'Mars\'\nTraceback (most recent call last):\n(continues on next page)\n18\n\n(continued from previous page)\n...\nAttributeError: \'Immutable\' object has no attribute \'location\'\n3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with __slots__ and 152\nbytes without. This flyweight design pattern likely only matters when a large number of instances are going to be\ncreated. 4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with Python 3.10 on an\nApple M1 processor). 5. Blocks tools like functools.cached_property() which require an instance dictionary to function correctly:\nfrom functools import cached_property\nclass CP:\n__slots__ = ()\n# Eliminates the instance dict\n@cached_property\n# Requires an instance dict\ndef pi(self):\nreturn 4 * sum((-1.0)**n / (2.0*n + 1.0)\nfor n in reversed(range(100_000)))\n>>> CP().pi\nTraceback (most recent call last):\n...\nTypeError: No \'__dict__\' attribute on \'CP\' instance to cache \'pi\' property.\n\n[2] Several use cases are so common that they have\nbeen prepackaged into built-in tools. Properties, bound methods, static methods, class methods, and __slots__ are\nall based on the descriptor protocol. 4.1 Properties\nCalling property() is a succinct way of building a data descriptor that triggers a function call upon access to an\nattribute. Its signature is:\nproperty(fget=None, fset=None, fdel=None, doc=None) -> property\nThe documentation shows a typical use to define a managed attribute x:\nclass C:\ndef getx(self): return self.__x\ndef setx(self, value): self.__x = value\ndef delx(self): del self.__x\nx = property(getx, setx, delx, ""I\'m the \'x\' property."") To see how property() is implemented in terms of the descriptor protocol, here is a pure Python equivalent that\nimplements most of the core functionality:\nclass Property:\n""Emulate PyProperty_Type() in Objects/descrobject.c""\ndef __init__(self, fget=None, fset=None, fdel=None, doc=None):\nself.fget = fget\nself.fset = fset\nself.fdel = fdel\nif doc is None and fget is not None:\ndoc = fget.__doc__\nself.__doc__ = doc\ndef __set_name__(self, owner, name):\nself.__name__ = name\ndef __get__(self, obj, objtype=None):\nif obj is None:\nreturn self\nif self.fget is None:\nraise AttributeError\nreturn self.fget(obj)\ndef __set__(self, obj, value):\nif self.fset is None:\nraise AttributeError\nself.fset(obj, value)\ndef __delete__(self, obj):\nif self.fdel is None:\nraise AttributeError\n(continues on next page)\n13\n\n(continued from previous page)\nself.fdel(obj)\ndef getter(self, fget):\nreturn type(self)(fget, self.fset, self.fdel, self.__doc__)\ndef setter(self, fset):\nreturn type(self)(self.fget, fset, self.fdel, self.__doc__)\ndef deleter(self, fdel):\nreturn type(self)(self.fget, self.fset, fdel, self.__doc__)\nThe property() builtin helps whenever a user interface has granted attribute access and then subsequent changes\nrequire the intervention of a method. For instance, a spreadsheet class may grant access to a cell value through Cell(\'b10\').value. Subsequent im-\nprovements to the program require the cell to be recalculated on every access; however, the programmer does not\nwant to affect existing client code accessing the attribute directly. The solution is to wrap access to the value attribute\nin a property data descriptor:\nclass Cell:\n...\n@property\ndef value(self):\n""Recalculate the cell before returning value""\nself.recalc()\nreturn self._value\nEither the built-in property() or our Property() equivalent would work in this example. 4.2 Functions and methods\nPython’s object oriented features are built upon a function based environment. Using non-data descriptors, the two\nare merged seamlessly. Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular func-\ntions in that the object instance is prepended to the other arguments. By convention, the instance is called self but\ncould be called this or any other variable name. Methods can be created manually with types.MethodType which is roughly equivalent to:\nclass MethodType:\n""Emulate PyMethod_Type in Objects/classobject.c""\ndef __init__(self, func, obj):\nself.__func__ = func\nself.__self__ = obj\ndef __call__(self, *args, **kwargs):\nfunc = self.__func__\nobj = self.__self__\nreturn func(obj, *args, **kwargs)\ndef __getattribute__(self, name):\n""Emulate method_getset() in Objects/classobject.c""\nif name == \'__doc__\':\nreturn self.__func__.__doc__\nreturn object.__getattribute__(self, name)\n(continues on next page)\n14\n\n(continued from previous page)\ndef __getattr__(self, name):\n""Emulate method_getattro() in Objects/classobject.c""\nreturn getattr(self.__func__, name)\ndef __get__(self, obj, objtype=None):\n""Emulate method_descr_get() in Objects/classobject.c""\nreturn self\nTo support automatic creation of methods, functions include the __get__() method for binding methods during\nattribute access. This means that functions are non-data descriptors that return bound methods during dotted lookup\nfrom an instance. Here’s how it works:\nclass Function:\n...\ndef __get__(self, obj, objtype=None):\n""Simulate func_descr_get() in Objects/funcobject.c""\nif obj is None:\nreturn self\nreturn MethodType(self, obj)\nRunning the following class in the interpreter shows how the function descriptor works in practice:\nclass D:\ndef f(self):\nreturn self\nclass D2:\npass\nThe function has a qualified name attribute to support introspection:\n>>> D.f.__qualname__\n\'D.f\'\nAccessing the function through the class dictionary does not invoke __get__(). Instead, it just returns the underlying\nfunction object:\n>>> D.__dict__[\'f\']\n<function D.f at 0x00C45070>\nDotted access from a class calls __get__() which just returns the underlying function unchanged:\n>>> D.f\n<function D.f at 0x00C45070>\nThe interesting behavior occurs during dotted access from an instance. The dotted lookup calls __get__() which\nreturns a bound method object:\n>>> d = D()\n>>> d.f\n<bound method D.f of <__main__.D object at 0x00B18C90>>\nInternally, the bound method stores the underlying function and the bound instance:\n>>> d.f.__func__\n<function D.f at 0x00C45070>\n(continues on next page)\n15\n\n(continued from previous page)\n>>> d.f.__self__\n<__main__.D object at 0x00B18C90>\nIf you have ever wondered where self comes from in regular methods or where cls comes from in class methods, this\nis it! 4.3 Kinds of methods\nNon-data descriptors provide a simple mechanism for variations on the usual patterns of binding functions into meth-\nods. To recap, functions have a __get__() method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an obj.f(*args) call into f(obj, *args). Calling cls.f(*args) be-\ncomes f(*args). This chart summarizes the binding and its two most useful variants:\nTransformation\nCalled from an object\nCalled from a class\nfunction\nf(obj, *args)\nf(*args)\nstaticmethod\nf(*args)\nf(*args)\nclassmethod\nf(type(obj), *args)\nf(cls, *args)\n4.4 Static methods\nStatic methods return the underlying function without changes. Calling either c.f or C.f is the equivalent of a direct\nlookup into object.__getattribute__(c, ""f"") or object.__getattribute__(C, ""f""). As a result,\nthe function becomes identically accessible from either an object or a class. Good candidates for static methods are methods that do not reference the self variable. For instance, a statistics package may include a container class for experimental data. The class provides normal\nmethods for computing the average, mean, median, and other descriptive statistics that depend on the data. However,\nthere may be useful functions which are conceptually related but do not depend on the data. For instance, erf(x) is\nhandy conversion routine that comes up in statistical work but does not directly depend on a particular dataset. It can\nbe called either from an object or the class: s.erf(1.5) --> 0.9332 or Sample.erf(1.5) --> 0.9332. Since static methods return the underlying function with no changes, the example calls are unexciting:\nclass E:\n@staticmethod\ndef f(x):\nreturn x * 10\n>>> E.f(3)\n30\n>>> E().f(3)\n30\nUsing the non-data descriptor protocol, a pure Python version of staticmethod() would look like this:\nimport functools\nclass StaticMethod:\n""Emulate PyStaticMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n16\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, objtype=None):\nreturn self.f\ndef __call__(self, *args, **kwds):\nreturn self.f(*args, **kwds)\nThe functools.update_wrapper() call adds a __wrapped__ attribute that refers to the underlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped function: __name__,\n__qualname__, __doc__, and __annotations__. 4.5 Class methods\nUnlike static methods, class methods prepend the class reference to the argument list before calling the function. This\nformat is the same for whether the caller is an object or a class:\nclass F:\n@classmethod\ndef f(cls, x):\nreturn cls.__name__, x\n>>> F.f(3)\n(\'F\', 3)\n>>> F().f(3)\n(\'F\', 3)\nThis behavior is useful whenever the method only needs to have a class reference and does not rely on data stored in\na specific instance. One use for class methods is to create alternate class constructors. For example, the classmethod\ndict.fromkeys() creates a new dictionary from a list of keys. The pure Python equivalent is:\nclass Dict(dict):\n@classmethod\ndef fromkeys(cls, iterable, value=None):\n""Emulate dict_fromkeys() in Objects/dictobject.c""\nd = cls()\nfor key in iterable:\nd[key] = value\nreturn d\nNow a new dictionary of unique keys can be constructed like this:\n>>> d = Dict.fromkeys(\'abracadabra\')\n>>> type(d) is Dict\nTrue\n>>> d\n{\'a\': None, \'b\': None, \'r\': None, \'c\': None, \'d\': None}\nUsing the non-data descriptor protocol, a pure Python version of classmethod() would look like this:\nimport functools\nclass ClassMethod:\n""Emulate PyClassMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n17\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, cls=None):\nif cls is None:\ncls = type(obj)\nreturn MethodType(self.f, cls)\nThe functools.update_wrapper() call in ClassMethod adds a __wrapped__ attribute that refers to the\nunderlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped\nfunction: __name__, __qualname__, __doc__, and __annotations__. 4.6 Member objects and __slots__\nWhen a class defines __slots__, it replaces instance dictionaries with a fixed-length array of slot values. From a\nuser point of view that has several effects:\n1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute names specified in\n__slots__ are allowed:\nclass Vehicle:\n__slots__ = (\'id_number\', \'make\', \'model\')\n>>> auto = Vehicle()\n>>> auto.id_nubmer = \'VYE483814LQEX\'\nTraceback (most recent call last):\n...\nAttributeError: \'Vehicle\' object has no attribute \'id_nubmer\'\n2. Helps create immutable objects where descriptors manage access to private attributes stored in __slots__:\nclass Immutable:\n__slots__ = (\'_dept\', \'_name\')\n# Replace the instance dictionary\ndef __init__(self, dept, name):\nself._dept = dept\n# Store to private attribute\nself._name = name\n# Store to private attribute\n@property\n# Read-only descriptor\ndef dept(self):\nreturn self._dept\n@property\ndef name(self):\n# Read-only descriptor\nreturn self._name\n>>> mark = Immutable(\'Botany\', \'Mark Watney\')\n>>> mark.dept\n\'Botany\'\n>>> mark.dept = \'Space Pirate\'\nTraceback (most recent call last):\n...\nAttributeError: property \'dept\' of \'Immutable\' object has no setter\n>>> mark.location = \'Mars\'\nTraceback (most recent call last):\n(continues on next page)\n18\n\n(continued from previous page)\n...\nAttributeError: \'Immutable\' object has no attribute \'location\'\n3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with __slots__ and 152\nbytes without. This flyweight design pattern likely only matters when a large number of instances are going to be\ncreated. 4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with Python 3.10 on an\nApple M1 processor). 5.\n\n[3] Its signature is:\nproperty(fget=None, fset=None, fdel=None, doc=None) -> property\nThe documentation shows a typical use to define a managed attribute x:\nclass C:\ndef getx(self): return self.__x\ndef setx(self, value): self.__x = value\ndef delx(self): del self.__x\nx = property(getx, setx, delx, ""I\'m the \'x\' property."") To see how property() is implemented in terms of the descriptor protocol, here is a pure Python equivalent that\nimplements most of the core functionality:\nclass Property:\n""Emulate PyProperty_Type() in Objects/descrobject.c""\ndef __init__(self, fget=None, fset=None, fdel=None, doc=None):\nself.fget = fget\nself.fset = fset\nself.fdel = fdel\nif doc is None and fget is not None:\ndoc = fget.__doc__\nself.__doc__ = doc\ndef __set_name__(self, owner, name):\nself.__name__ = name\ndef __get__(self, obj, objtype=None):\nif obj is None:\nreturn self\nif self.fget is None:\nraise AttributeError\nreturn self.fget(obj)\ndef __set__(self, obj, value):\nif self.fset is None:\nraise AttributeError\nself.fset(obj, value)\ndef __delete__(self, obj):\nif self.fdel is None:\nraise AttributeError\n(continues on next page)\n13\n\n(continued from previous page)\nself.fdel(obj)\ndef getter(self, fget):\nreturn type(self)(fget, self.fset, self.fdel, self.__doc__)\ndef setter(self, fset):\nreturn type(self)(self.fget, fset, self.fdel, self.__doc__)\ndef deleter(self, fdel):\nreturn type(self)(self.fget, self.fset, fdel, self.__doc__)\nThe property() builtin helps whenever a user interface has granted attribute access and then subsequent changes\nrequire the intervention of a method. For instance, a spreadsheet class may grant access to a cell value through Cell(\'b10\').value. Subsequent im-\nprovements to the program require the cell to be recalculated on every access; however, the programmer does not\nwant to affect existing client code accessing the attribute directly. The solution is to wrap access to the value attribute\nin a property data descriptor:\nclass Cell:\n...\n@property\ndef value(self):\n""Recalculate the cell before returning value""\nself.recalc()\nreturn self._value\nEither the built-in property() or our Property() equivalent would work in this example. 4.2 Functions and methods\nPython’s object oriented features are built upon a function based environment. Using non-data descriptors, the two\nare merged seamlessly. Functions stored in class dictionaries get turned into methods when invoked. Methods only differ from regular func-\ntions in that the object instance is prepended to the other arguments. By convention, the instance is called self but\ncould be called this or any other variable name. Methods can be created manually with types.MethodType which is roughly equivalent to:\nclass MethodType:\n""Emulate PyMethod_Type in Objects/classobject.c""\ndef __init__(self, func, obj):\nself.__func__ = func\nself.__self__ = obj\ndef __call__(self, *args, **kwargs):\nfunc = self.__func__\nobj = self.__self__\nreturn func(obj, *args, **kwargs)\ndef __getattribute__(self, name):\n""Emulate method_getset() in Objects/classobject.c""\nif name == \'__doc__\':\nreturn self.__func__.__doc__\nreturn object.__getattribute__(self, name)\n(continues on next page)\n14\n\n(continued from previous page)\ndef __getattr__(self, name):\n""Emulate method_getattro() in Objects/classobject.c""\nreturn getattr(self.__func__, name)\ndef __get__(self, obj, objtype=None):\n""Emulate method_descr_get() in Objects/classobject.c""\nreturn self\nTo support automatic creation of methods, functions include the __get__() method for binding methods during\nattribute access. This means that functions are non-data descriptors that return bound methods during dotted lookup\nfrom an instance. Here’s how it works:\nclass Function:\n...\ndef __get__(self, obj, objtype=None):\n""Simulate func_descr_get() in Objects/funcobject.c""\nif obj is None:\nreturn self\nreturn MethodType(self, obj)\nRunning the following class in the interpreter shows how the function descriptor works in practice:\nclass D:\ndef f(self):\nreturn self\nclass D2:\npass\nThe function has a qualified name attribute to support introspection:\n>>> D.f.__qualname__\n\'D.f\'\nAccessing the function through the class dictionary does not invoke __get__(). Instead, it just returns the underlying\nfunction object:\n>>> D.__dict__[\'f\']\n<function D.f at 0x00C45070>\nDotted access from a class calls __get__() which just returns the underlying function unchanged:\n>>> D.f\n<function D.f at 0x00C45070>\nThe interesting behavior occurs during dotted access from an instance. The dotted lookup calls __get__() which\nreturns a bound method object:\n>>> d = D()\n>>> d.f\n<bound method D.f of <__main__.D object at 0x00B18C90>>\nInternally, the bound method stores the underlying function and the bound instance:\n>>> d.f.__func__\n<function D.f at 0x00C45070>\n(continues on next page)\n15\n\n(continued from previous page)\n>>> d.f.__self__\n<__main__.D object at 0x00B18C90>\nIf you have ever wondered where self comes from in regular methods or where cls comes from in class methods, this\nis it! 4.3 Kinds of methods\nNon-data descriptors provide a simple mechanism for variations on the usual patterns of binding functions into meth-\nods. To recap, functions have a __get__() method so that they can be converted to a method when accessed as attributes. The non-data descriptor transforms an obj.f(*args) call into f(obj, *args). Calling cls.f(*args) be-\ncomes f(*args). This chart summarizes the binding and its two most useful variants:\nTransformation\nCalled from an object\nCalled from a class\nfunction\nf(obj, *args)\nf(*args)\nstaticmethod\nf(*args)\nf(*args)\nclassmethod\nf(type(obj), *args)\nf(cls, *args)\n4.4 Static methods\nStatic methods return the underlying function without changes. Calling either c.f or C.f is the equivalent of a direct\nlookup into object.__getattribute__(c, ""f"") or object.__getattribute__(C, ""f""). As a result,\nthe function becomes identically accessible from either an object or a class. Good candidates for static methods are methods that do not reference the self variable. For instance, a statistics package may include a container class for experimental data. The class provides normal\nmethods for computing the average, mean, median, and other descriptive statistics that depend on the data. However,\nthere may be useful functions which are conceptually related but do not depend on the data. For instance, erf(x) is\nhandy conversion routine that comes up in statistical work but does not directly depend on a particular dataset. It can\nbe called either from an object or the class: s.erf(1.5) --> 0.9332 or Sample.erf(1.5) --> 0.9332. Since static methods return the underlying function with no changes, the example calls are unexciting:\nclass E:\n@staticmethod\ndef f(x):\nreturn x * 10\n>>> E.f(3)\n30\n>>> E().f(3)\n30\nUsing the non-data descriptor protocol, a pure Python version of staticmethod() would look like this:\nimport functools\nclass StaticMethod:\n""Emulate PyStaticMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n16\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, objtype=None):\nreturn self.f\ndef __call__(self, *args, **kwds):\nreturn self.f(*args, **kwds)\nThe functools.update_wrapper() call adds a __wrapped__ attribute that refers to the underlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped function: __name__,\n__qualname__, __doc__, and __annotations__. 4.5 Class methods\nUnlike static methods, class methods prepend the class reference to the argument list before calling the function. This\nformat is the same for whether the caller is an object or a class:\nclass F:\n@classmethod\ndef f(cls, x):\nreturn cls.__name__, x\n>>> F.f(3)\n(\'F\', 3)\n>>> F().f(3)\n(\'F\', 3)\nThis behavior is useful whenever the method only needs to have a class reference and does not rely on data stored in\na specific instance. One use for class methods is to create alternate class constructors. For example, the classmethod\ndict.fromkeys() creates a new dictionary from a list of keys. The pure Python equivalent is:\nclass Dict(dict):\n@classmethod\ndef fromkeys(cls, iterable, value=None):\n""Emulate dict_fromkeys() in Objects/dictobject.c""\nd = cls()\nfor key in iterable:\nd[key] = value\nreturn d\nNow a new dictionary of unique keys can be constructed like this:\n>>> d = Dict.fromkeys(\'abracadabra\')\n>>> type(d) is Dict\nTrue\n>>> d\n{\'a\': None, \'b\': None, \'r\': None, \'c\': None, \'d\': None}\nUsing the non-data descriptor protocol, a pure Python version of classmethod() would look like this:\nimport functools\nclass ClassMethod:\n""Emulate PyClassMethod_Type() in Objects/funcobject.c""\ndef __init__(self, f):\n(continues on next page)\n17\n\n(continued from previous page)\nself.f = f\nfunctools.update_wrapper(self, f)\ndef __get__(self, obj, cls=None):\nif cls is None:\ncls = type(obj)\nreturn MethodType(self.f, cls)\nThe functools.update_wrapper() call in ClassMethod adds a __wrapped__ attribute that refers to the\nunderlying function. Also it carries forward the attributes necessary to make the wrapper look like the wrapped\nfunction: __name__, __qualname__, __doc__, and __annotations__. 4.6 Member objects and __slots__\nWhen a class defines __slots__, it replaces instance dictionaries with a fixed-length array of slot values. From a\nuser point of view that has several effects:\n1. Provides immediate detection of bugs due to misspelled attribute assignments. Only attribute names specified in\n__slots__ are allowed:\nclass Vehicle:\n__slots__ = (\'id_number\', \'make\', \'model\')\n>>> auto = Vehicle()\n>>> auto.id_nubmer = \'VYE483814LQEX\'\nTraceback (most recent call last):\n...\nAttributeError: \'Vehicle\' object has no attribute \'id_nubmer\'\n2. Helps create immutable objects where descriptors manage access to private attributes stored in __slots__:\nclass Immutable:\n__slots__ = (\'_dept\', \'_name\')\n# Replace the instance dictionary\ndef __init__(self, dept, name):\nself._dept = dept\n# Store to private attribute\nself._name = name\n# Store to private attribute\n@property\n# Read-only descriptor\ndef dept(self):\nreturn self._dept\n@property\ndef name(self):\n# Read-only descriptor\nreturn self._name\n>>> mark = Immutable(\'Botany\', \'Mark Watney\')\n>>> mark.dept\n\'Botany\'\n>>> mark.dept = \'Space Pirate\'\nTraceback (most recent call last):\n...\nAttributeError: property \'dept\' of \'Immutable\' object has no setter\n>>> mark.location = \'Mars\'\nTraceback (most recent call last):\n(continues on next page)\n18\n\n(continued from previous page)\n...\nAttributeError: \'Immutable\' object has no attribute \'location\'\n3. Saves memory. On a 64-bit Linux build, an instance with two attributes takes 48 bytes with __slots__ and 152\nbytes without. This flyweight design pattern likely only matters when a large number of instances are going to be\ncreated. 4. Improves speed. Reading instance variables is 35% faster with __slots__ (as measured with Python 3.10 on an\nApple M1 processor). 5. Blocks tools like functools.cached_property() which require an instance dictionary to function correctly:\nfrom functools import cached_property\nclass CP:\n__slots__ = ()\n# Eliminates the instance dict\n@cached_property\n# Requires an instance dict\ndef pi(self):\nreturn 4 * sum((-1.0)**n / (2.0*n + 1.0)\nfor n in reversed(range(100_000)))\n>>> CP().pi\nTraceback (most recent call last):\n...\nTypeError: No \'__dict__\' attribute on \'CP\' instance to cache \'pi\' property. It is not possible to create an exact drop-in pure Python version of __slots__ because it requires direct access to\nC structures and control over object memory allocation. However, we can build a mostly faithful simulation where\nthe actual C structure for slots is emulated by a private _slotvalues list.')",0.006262289958668172,0.07382442625581769,0.26275804863785696,0.6049870848655701,0.7165355
How can I do a line break (line continuation) in Python (split up a long line of source code)?,"What is the line?  You can just have arguments on the next line without any problems:


a = dostuff(blahblah1, blahblah2, blahblah3, blahblah4, blahblah5, 
            blahblah6, blahblah7)



Otherwise you can do something like this:


if (a == True and
    b == False):



or with explicit line break:


if a == True and \
   b == False:



Check the 
style guide
 for more information.


Using parentheses, your example can be written over multiple lines:


a = ('1' + '2' + '3' +
    '4' + '5')



The same effect can be obtained using explicit line break:


a = '1' + '2' + '3' + \
    '4' + '5'



Note that the style guide says that using the implicit continuation with parentheses is preferred, but in this particular case just adding parentheses around your expression is probably the wrong way to go.

","('Answer: You can break up long lines of code using either explicit or implicit line joining. Explicit line joining uses a backslash (\\) at the end of a physical line to join it with the next line, which is interpreted as a single logical line. Implicit line joining allows you to split expressions within parentheses, square brackets, or curly braces across multiple lines without a backslash.\n\nReferences: [2, 3]', ""[1] In source files and strings, any\nof the standard platform line termination sequences can be used - the Unix form using ASCII LF (linefeed), the\nWindows form using the ASCII sequence CR LF (return followed by linefeed), or the old Macintosh form using the\nASCII CR (return) character. All of these forms can be used equally, regardless of platform. The end of input also\nserves as an implicit terminator for the final physical line. When embedding Python, source code strings should be passed to Python APIs using the standard C conventions for\nnewline characters (the \\n character, representing ASCII LF, is the line terminator). 2.1.3 Comments\nA comment starts with a hash character (#) that is not part of a string literal, and ends at the end of the physical\nline. A comment signifies the end of the logical line unless the implicit line joining rules are invoked. Comments are\nignored by the syntax. 2.1.4 Encoding declarations\nIf a comment in the first or second line of the Python script matches the regular expression coding[=:]\\s*([-\\\nw.]+), this comment is processed as an encoding declaration; the first group of this expression names the encoding\nof the source code file. The encoding declaration must appear on a line of its own. If it is the second line, the first\nline must also be a comment-only line. The recommended forms of an encoding expression are\n# -*- coding: <encoding-name> -*-\nwhich is recognized also by GNU Emacs, and\n5\n\nThe Python Language Reference, Release 3.13.2\n# vim:fileencoding=<encoding-name>\nwhich is recognized by Bram Moolenaar’s VIM. If no encoding declaration is found, the default encoding is UTF-8. If the implicit or explicit encoding of a file is\nUTF-8, an initial UTF-8 byte-order mark (b’xefxbbxbf’) is ignored rather than being a syntax error. If an encoding is declared, the encoding name must be recognized by Python (see standard-encodings). The encoding\nis used for all lexical analysis, including string literals, comments and identifiers. 2.1.5 Explicit line joining\nTwo or more physical lines may be joined into logical lines using backslash characters (\\), as follows: when a physical\nline ends in a backslash that is not part of a string literal or comment, it is joined with the following forming a single\nlogical line, deleting the backslash and the following end-of-line character. For example:\nif 1900 < year < 2100 and 1 <= month <= 12 \\\nand 1 <= day <= 31 and 0 <= hour < 24 \\\nand 0 <= minute < 60 and 0 <= second < 60:\n# Looks like a valid date\nreturn 1\nA line ending in a backslash cannot carry a comment. A backslash does not continue a comment. A backslash does\nnot continue a token except for string literals (i.e., tokens other than string literals cannot be split across physical lines\nusing a backslash). A backslash is illegal elsewhere on a line outside a string literal. 2.1.6 Implicit line joining\nExpressions in parentheses, square brackets or curly braces can be split over more than one physical line without\nusing backslashes. For example:\nmonth_names = ['Januari', 'Februari', 'Maart',\n# These are the\n'April',\n'Mei',\n'Juni',\n# Dutch names\n'Juli',\n'Augustus', 'September',\n# for the months\n'Oktober', 'November', 'December']\n# of the year\nImplicitly continued lines can carry comments. The indentation of the continuation lines is not important. Blank con-\ntinuation lines are allowed. There is no NEWLINE token between implicit continuation lines. Implicitly continued\nlines can also occur within triple-quoted strings (see below); in that case they cannot carry comments. 2.1.7 Blank lines\nA logical line that contains only spaces, tabs, formfeeds and possibly a comment, is ignored (i.e., no NEWLINE\ntoken is generated). During interactive input of statements, handling of a blank line may differ depending on the\nimplementation of the read-eval-print loop. In the standard interactive interpreter, an entirely blank logical line (i.e. one containing not even whitespace or a comment) terminates a multi-line statement. 2.1.8 Indentation\nLeading whitespace (spaces and tabs) at the beginning of a logical line is used to compute the indentation level of\nthe line, which in turn is used to determine the grouping of statements. Tabs are replaced (from left to right) by one to eight spaces such that the total number of characters up to and including\nthe replacement is a multiple of eight (this is intended to be the same rule as used by Unix). The total number of\nspaces preceding the first non-blank character then determines the line’s indentation. Indentation cannot be split over\nmultiple physical lines using backslashes; the whitespace up to the first backslash determines the indentation. Indentation is rejected as inconsistent if a source file mixes tabs and spaces in a way that makes the meaning dependent\non the worth of a tab in spaces; a TabError is raised in that case. 6\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nCross-platform compatibility note: because of the nature of text editors on non-UNIX platforms, it is unwise to\nuse a mixture of spaces and tabs for the indentation in a single source file. It should also be noted that different\nplatforms may explicitly limit the maximum indentation level. A formfeed character may be present at the start of the line; it will be ignored for the indentation calculations above. Formfeed characters occurring elsewhere in the leading whitespace have an undefined effect (for instance, they may\nreset the space count to zero). The indentation levels of consecutive lines are used to generate INDENT and DEDENT tokens, using a stack, as\nfollows. Before the first line of the file is read, a single zero is pushed on the stack; this will never be popped off again. The\nnumbers pushed on the stack will always be strictly increasing from bottom to top. At the beginning of each logical\nline, the line’s indentation level is compared to the top of the stack. If it is equal, nothing happens. If it is larger, it is\npushed on the stack, and one INDENT token is generated. If it is smaller, it must be one of the numbers occurring\non the stack; all numbers on the stack that are larger are popped off, and for each number popped off a DEDENT\ntoken is generated. At the end of the file, a DEDENT token is generated for each number remaining on the stack that\nis larger than zero. Here is an example of a correctly (though confusingly) indented piece of Python code:\ndef perm(l):\n# Compute the list of all permutations of l\nif len(l) <= 1:\nreturn [l]\nr = []\nfor i in range(len(l)):\ns = l[:i] + l[i+1:]\np = perm(s)\nfor x in p:\nr.append(l[i:i+1] + x)\nreturn r\nThe following example shows various indentation errors:\ndef perm(l):\n# error: first line indented\nfor i in range(len(l)):\n# error: not indented\ns = l[:i] + l[i+1:]\np = perm(l[:i] + l[i+1:])\n# error: unexpected indent\nfor x in p:\nr.append(l[i:i+1] + x)\nreturn r\n# error: inconsistent dedent\n(Actually, the first three errors are detected by the parser; only the last error is found by the lexical analyzer — the\nindentation of return r does not match a level popped off the stack.) 2.1.9 Whitespace between tokens\nExcept at the beginning of a logical line or in string literals, the whitespace characters space, tab and formfeed can be\nused interchangeably to separate tokens. Whitespace is needed between two tokens only if their concatenation could\notherwise be interpreted as a different token (e.g., ab is one token, but a b is two tokens).\n\n[2] Python reads program text as Unicode code points; the encoding of a source file can be given by an encoding dec-\nlaration and defaults to UTF-8, see PEP 3120 for details. If the source file cannot be decoded, a SyntaxError is\nraised. 2.1 Line structure\nA Python program is divided into a number of logical lines. 2.1.1 Logical lines\nThe end of a logical line is represented by the token NEWLINE. Statements cannot cross logical line boundaries\nexcept where NEWLINE is allowed by the syntax (e.g., between statements in compound statements). A logical line\nis constructed from one or more physical lines by following the explicit or implicit line joining rules. 2.1.2 Physical lines\nA physical line is a sequence of characters terminated by an end-of-line sequence. In source files and strings, any\nof the standard platform line termination sequences can be used - the Unix form using ASCII LF (linefeed), the\nWindows form using the ASCII sequence CR LF (return followed by linefeed), or the old Macintosh form using the\nASCII CR (return) character. All of these forms can be used equally, regardless of platform. The end of input also\nserves as an implicit terminator for the final physical line. When embedding Python, source code strings should be passed to Python APIs using the standard C conventions for\nnewline characters (the \\n character, representing ASCII LF, is the line terminator). 2.1.3 Comments\nA comment starts with a hash character (#) that is not part of a string literal, and ends at the end of the physical\nline. A comment signifies the end of the logical line unless the implicit line joining rules are invoked. Comments are\nignored by the syntax. 2.1.4 Encoding declarations\nIf a comment in the first or second line of the Python script matches the regular expression coding[=:]\\s*([-\\\nw.]+), this comment is processed as an encoding declaration; the first group of this expression names the encoding\nof the source code file. The encoding declaration must appear on a line of its own. If it is the second line, the first\nline must also be a comment-only line. The recommended forms of an encoding expression are\n# -*- coding: <encoding-name> -*-\nwhich is recognized also by GNU Emacs, and\n5\n\nThe Python Language Reference, Release 3.13.2\n# vim:fileencoding=<encoding-name>\nwhich is recognized by Bram Moolenaar’s VIM. If no encoding declaration is found, the default encoding is UTF-8. If the implicit or explicit encoding of a file is\nUTF-8, an initial UTF-8 byte-order mark (b’xefxbbxbf’) is ignored rather than being a syntax error. If an encoding is declared, the encoding name must be recognized by Python (see standard-encodings). The encoding\nis used for all lexical analysis, including string literals, comments and identifiers. 2.1.5 Explicit line joining\nTwo or more physical lines may be joined into logical lines using backslash characters (\\), as follows: when a physical\nline ends in a backslash that is not part of a string literal or comment, it is joined with the following forming a single\nlogical line, deleting the backslash and the following end-of-line character. For example:\nif 1900 < year < 2100 and 1 <= month <= 12 \\\nand 1 <= day <= 31 and 0 <= hour < 24 \\\nand 0 <= minute < 60 and 0 <= second < 60:\n# Looks like a valid date\nreturn 1\nA line ending in a backslash cannot carry a comment. A backslash does not continue a comment. A backslash does\nnot continue a token except for string literals (i.e., tokens other than string literals cannot be split across physical lines\nusing a backslash). A backslash is illegal elsewhere on a line outside a string literal. 2.1.6 Implicit line joining\nExpressions in parentheses, square brackets or curly braces can be split over more than one physical line without\nusing backslashes. For example:\nmonth_names = ['Januari', 'Februari', 'Maart',\n# These are the\n'April',\n'Mei',\n'Juni',\n# Dutch names\n'Juli',\n'Augustus', 'September',\n# for the months\n'Oktober', 'November', 'December']\n# of the year\nImplicitly continued lines can carry comments. The indentation of the continuation lines is not important. Blank con-\ntinuation lines are allowed. There is no NEWLINE token between implicit continuation lines. Implicitly continued\nlines can also occur within triple-quoted strings (see below); in that case they cannot carry comments. 2.1.7 Blank lines\nA logical line that contains only spaces, tabs, formfeeds and possibly a comment, is ignored (i.e., no NEWLINE\ntoken is generated). During interactive input of statements, handling of a blank line may differ depending on the\nimplementation of the read-eval-print loop. In the standard interactive interpreter, an entirely blank logical line (i.e. one containing not even whitespace or a comment) terminates a multi-line statement. 2.1.8 Indentation\nLeading whitespace (spaces and tabs) at the beginning of a logical line is used to compute the indentation level of\nthe line, which in turn is used to determine the grouping of statements. Tabs are replaced (from left to right) by one to eight spaces such that the total number of characters up to and including\nthe replacement is a multiple of eight (this is intended to be the same rule as used by Unix). The total number of\nspaces preceding the first non-blank character then determines the line’s indentation. Indentation cannot be split over\nmultiple physical lines using backslashes; the whitespace up to the first backslash determines the indentation. Indentation is rejected as inconsistent if a source file mixes tabs and spaces in a way that makes the meaning dependent\non the worth of a tab in spaces; a TabError is raised in that case. 6\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nCross-platform compatibility note: because of the nature of text editors on non-UNIX platforms, it is unwise to\nuse a mixture of spaces and tabs for the indentation in a single source file. It should also be noted that different\nplatforms may explicitly limit the maximum indentation level. A formfeed character may be present at the start of the line; it will be ignored for the indentation calculations above. Formfeed characters occurring elsewhere in the leading whitespace have an undefined effect (for instance, they may\nreset the space count to zero). The indentation levels of consecutive lines are used to generate INDENT and DEDENT tokens, using a stack, as\nfollows. Before the first line of the file is read, a single zero is pushed on the stack; this will never be popped off again. The\nnumbers pushed on the stack will always be strictly increasing from bottom to top. At the beginning of each logical\nline, the line’s indentation level is compared to the top of the stack.\n\n[3] If the source file cannot be decoded, a SyntaxError is\nraised. 2.1 Line structure\nA Python program is divided into a number of logical lines. 2.1.1 Logical lines\nThe end of a logical line is represented by the token NEWLINE. Statements cannot cross logical line boundaries\nexcept where NEWLINE is allowed by the syntax (e.g., between statements in compound statements). A logical line\nis constructed from one or more physical lines by following the explicit or implicit line joining rules. 2.1.2 Physical lines\nA physical line is a sequence of characters terminated by an end-of-line sequence. In source files and strings, any\nof the standard platform line termination sequences can be used - the Unix form using ASCII LF (linefeed), the\nWindows form using the ASCII sequence CR LF (return followed by linefeed), or the old Macintosh form using the\nASCII CR (return) character. All of these forms can be used equally, regardless of platform. The end of input also\nserves as an implicit terminator for the final physical line. When embedding Python, source code strings should be passed to Python APIs using the standard C conventions for\nnewline characters (the \\n character, representing ASCII LF, is the line terminator). 2.1.3 Comments\nA comment starts with a hash character (#) that is not part of a string literal, and ends at the end of the physical\nline. A comment signifies the end of the logical line unless the implicit line joining rules are invoked. Comments are\nignored by the syntax. 2.1.4 Encoding declarations\nIf a comment in the first or second line of the Python script matches the regular expression coding[=:]\\s*([-\\\nw.]+), this comment is processed as an encoding declaration; the first group of this expression names the encoding\nof the source code file. The encoding declaration must appear on a line of its own. If it is the second line, the first\nline must also be a comment-only line. The recommended forms of an encoding expression are\n# -*- coding: <encoding-name> -*-\nwhich is recognized also by GNU Emacs, and\n5\n\nThe Python Language Reference, Release 3.13.2\n# vim:fileencoding=<encoding-name>\nwhich is recognized by Bram Moolenaar’s VIM. If no encoding declaration is found, the default encoding is UTF-8. If the implicit or explicit encoding of a file is\nUTF-8, an initial UTF-8 byte-order mark (b’xefxbbxbf’) is ignored rather than being a syntax error. If an encoding is declared, the encoding name must be recognized by Python (see standard-encodings). The encoding\nis used for all lexical analysis, including string literals, comments and identifiers. 2.1.5 Explicit line joining\nTwo or more physical lines may be joined into logical lines using backslash characters (\\), as follows: when a physical\nline ends in a backslash that is not part of a string literal or comment, it is joined with the following forming a single\nlogical line, deleting the backslash and the following end-of-line character. For example:\nif 1900 < year < 2100 and 1 <= month <= 12 \\\nand 1 <= day <= 31 and 0 <= hour < 24 \\\nand 0 <= minute < 60 and 0 <= second < 60:\n# Looks like a valid date\nreturn 1\nA line ending in a backslash cannot carry a comment. A backslash does not continue a comment. A backslash does\nnot continue a token except for string literals (i.e., tokens other than string literals cannot be split across physical lines\nusing a backslash). A backslash is illegal elsewhere on a line outside a string literal. 2.1.6 Implicit line joining\nExpressions in parentheses, square brackets or curly braces can be split over more than one physical line without\nusing backslashes. For example:\nmonth_names = ['Januari', 'Februari', 'Maart',\n# These are the\n'April',\n'Mei',\n'Juni',\n# Dutch names\n'Juli',\n'Augustus', 'September',\n# for the months\n'Oktober', 'November', 'December']\n# of the year\nImplicitly continued lines can carry comments. The indentation of the continuation lines is not important. Blank con-\ntinuation lines are allowed. There is no NEWLINE token between implicit continuation lines. Implicitly continued\nlines can also occur within triple-quoted strings (see below); in that case they cannot carry comments. 2.1.7 Blank lines\nA logical line that contains only spaces, tabs, formfeeds and possibly a comment, is ignored (i.e., no NEWLINE\ntoken is generated). During interactive input of statements, handling of a blank line may differ depending on the\nimplementation of the read-eval-print loop. In the standard interactive interpreter, an entirely blank logical line (i.e. one containing not even whitespace or a comment) terminates a multi-line statement. 2.1.8 Indentation\nLeading whitespace (spaces and tabs) at the beginning of a logical line is used to compute the indentation level of\nthe line, which in turn is used to determine the grouping of statements. Tabs are replaced (from left to right) by one to eight spaces such that the total number of characters up to and including\nthe replacement is a multiple of eight (this is intended to be the same rule as used by Unix). The total number of\nspaces preceding the first non-blank character then determines the line’s indentation. Indentation cannot be split over\nmultiple physical lines using backslashes; the whitespace up to the first backslash determines the indentation. Indentation is rejected as inconsistent if a source file mixes tabs and spaces in a way that makes the meaning dependent\non the worth of a tab in spaces; a TabError is raised in that case. 6\nChapter 2. Lexical analysis\n\nThe Python Language Reference, Release 3.13.2\nCross-platform compatibility note: because of the nature of text editors on non-UNIX platforms, it is unwise to\nuse a mixture of spaces and tabs for the indentation in a single source file. It should also be noted that different\nplatforms may explicitly limit the maximum indentation level. A formfeed character may be present at the start of the line; it will be ignored for the indentation calculations above. Formfeed characters occurring elsewhere in the leading whitespace have an undefined effect (for instance, they may\nreset the space count to zero). The indentation levels of consecutive lines are used to generate INDENT and DEDENT tokens, using a stack, as\nfollows. Before the first line of the file is read, a single zero is pushed on the stack; this will never be popped off again. The\nnumbers pushed on the stack will always be strictly increasing from bottom to top. At the beginning of each logical\nline, the line’s indentation level is compared to the top of the stack. If it is equal, nothing happens."")",1.3657331275398118e-155,0.029574861367837338,0.12530789704398265,0.5300194621086121,0.40104884
How can I read a text file into a string variable and strip newlines?,"You could use:


with open('data.txt', 'r') as file:
    data = file.read().replace('\n', '')



Or if the file content is guaranteed to be one line:


with open('data.txt', 'r') as file:
    data = file.read().rstrip()


","('Answer: To read a text file into a string variable and remove trailing newlines, you can use `S.rstrip(""\\r\\n"")` to remove line terminators from the end of the string `S` without affecting other whitespace.\n\nReferences: [1]\n', '[1] You can use S.rstrip(""\\r\\n"") to remove all occurrences of any line terminator from the end of the string S\nwithout removing other trailing whitespace. If the string S represents more than one line, with several empty lines at\nthe end, the line terminators for all the blank lines will be removed:\n>>> lines = (""line 1 \\r\\n""\n...\n""\\r\\n""\n...\n""\\r\\n"")\n>>> lines.rstrip(""\\n\\r"")\n\'line 1 \'\nSince this is typically only desired when reading text one line at a time, using S.rstrip() this way works well. 2.3.9 Is there a scanf() or sscanf() equivalent? Not as such. For simple input parsing, the easiest approach is usually to split the line into whitespace-delimited words using the\nsplit() method of string objects and then convert decimal strings to numeric values using int() or float(). split() supports an optional “sep” parameter which is useful if the line uses something other than whitespace as a\nseparator. 20\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\nFor more complicated input parsing, regular expressions are more powerful than C’s sscanf and better suited for\nthe task. 2.3.10 What does UnicodeDecodeError or UnicodeEncodeError error mean? See the unicode-howto. 2.3.11 Can I end a raw string with an odd number of backslashes? A raw string ending with an odd number of backslashes will escape the string’s quote:\n>>> r\'C:\\this\\will\\not\\work\\\'\nFile ""<stdin>"", line 1\nr\'C:\\this\\will\\not\\work\\\'\n^\nSyntaxError: unterminated string literal (detected at line 1)\nThere are several workarounds for this. One is to use regular strings and double the backslashes:\n>>> \'C:\\\\this\\\\will\\\\work\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nAnother is to concatenate a regular string containing an escaped backslash to the raw string:\n>>> r\'C:\\this\\will\\work\' \'\\\\\'\n\'C:\\\\this\\\\will\\\\work\\\\\'\nIt is also possible to use os.path.join() to append a backslash on Windows:\n>>> os.path.join(r\'C:\\this\\will\\work\', \'\')\n\'C:\\\\this\\\\will\\\\work\\\\\'\nNote that while a backslash will “escape” a quote for the purposes of determining where the raw string ends, no\nescaping occurs when interpreting the value of the raw string. That is, the backslash remains present in the value of\nthe raw string:\n>>> r\'backslash\\\'preserved\'\n""backslash\\\\\'preserved""\nAlso see the specification in the language reference. 2.4 Performance\n2.4.1 My program is too slow. How do I speed it up? That’s a tough one, in general. First, here are a list of things to remember before diving further:\n• Performance characteristics vary across Python implementations. This FAQ focuses on CPython. • Behaviour can vary across operating systems, especially when talking about I/O or multi-threading. • You should always find the hot spots in your program before attempting to optimize any code (see the profile\nmodule). • Writing benchmark scripts will allow you to iterate quickly when searching for improvements (see the timeit\nmodule). • It is highly recommended to have good code coverage (through unit testing or any other technique) before\npotentially introducing regressions hidden in sophisticated optimizations. That being said, there are many tricks to speed up Python code. Here are some general principles which go a long\nway towards reaching acceptable performance levels:\n2.4. Performance\n21\n\nPython Frequently Asked Questions, Release 3.13.2\n• Making your algorithms faster (or changing to faster ones) can yield much larger benefits than trying to sprinkle\nmicro-optimization tricks all over your code. • Use the right data structures. Study documentation for the bltin-types and the collections module. • When the standard library provides a primitive for doing something, it is likely (although not guaranteed) to\nbe faster than any alternative you may come up with. This is doubly true for primitives written in C, such as\nbuiltins and some extension types. For example, be sure to use either the list.sort() built-in method or\nthe related sorted() function to do sorting (and see the sortinghowto for examples of moderately advanced\nusage). • Abstractions tend to create indirections and force the interpreter to work more. If the levels of indirection\noutweigh the amount of useful work done, your program will be slower. You should avoid excessive abstraction,\nespecially under the form of tiny functions or methods (which are also often detrimental to readability). If you have reached the limit of what pure Python can allow, there are tools to take you further away. For example,\nCython can compile a slightly modified version of Python code into a C extension, and can be used on many different\nplatforms. Cython can take advantage of compilation (and optional type annotations) to make your code significantly\nfaster than when interpreted. If you are confident in your C programming skills, you can also write a C extension\nmodule yourself. µ See also\nThe wiki page devoted to performance tips. 2.4.2 What is the most efficient way to concatenate many strings together? str and bytes objects are immutable, therefore concatenating many strings together is inefficient as each concate-\nnation creates a new object. In the general case, the total runtime cost is quadratic in the total string length. To accumulate many str objects, the recommended idiom is to place them into a list and call str.join() at the\nend:\nchunks = []\nfor s in my_strings:\nchunks.append(s)\nresult = \'\'.join(chunks)\n(another reasonably efficient idiom is to use io.StringIO)\nTo accumulate many bytes objects, the recommended idiom is to extend a bytearray object using in-place con-\ncatenation (the += operator):\nresult = bytearray()\nfor b in my_bytes_objects:\nresult += b\n2.5 Sequences (Tuples/Lists)\n2.5.1 How do I convert between tuples and lists? The type constructor tuple(seq) converts any sequence (actually, any iterable) into a tuple with the same items in\nthe same order. For example, tuple([1, 2, 3]) yields (1, 2, 3) and tuple(\'abc\') yields (\'a\', \'b\', \'c\'). If the ar-\ngument is a tuple, it does not make a copy but returns the same object, so it is cheap to call tuple() when you aren’t\nsure that an object is already a tuple. The type constructor list(seq) converts any sequence or iterable into a list with the same items in the same\norder. For example, list((1, 2, 3)) yields [1, 2, 3] and list(\'abc\') yields [\'a\', \'b\', \'c\']. If the\nargument is a list, it makes a copy just like seq[:] would. 22\nChapter 2. Programming FAQ\n\nPython Frequently Asked Questions, Release 3.13.2\n2.5.2 What’s a negative index?\n\n[2] . . . . . . . . . . . . . . . . 53\n7.1.1\nFormatted String Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n7.1.2\nThe String format() Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n7.1.3\nManual String Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n7.1.4\nOld string formatting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2\nReading and Writing Files\n. . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.8\nIs there an equivalent to Perl’s chomp() for removing trailing newlines from strings? . . . 20\n2.3.9\nIs there a scanf() or sscanf() equivalent? . . . . . . . . . . . . . . . . . . . . . . . 20\n2.3.10\nWhat does UnicodeDecodeError or UnicodeEncodeError error mean? . . . . . . . 21\n2.3.11\nCan I end a raw string with an odd number of backslashes? . . . . . . . . . . . . . . . . 21\n2.4\nPerformance\n. . . . . . . . . . . . . . . . . . . . . . . . . .')",8.14655641935218e-156,0.023023791250959325,0.10181496237273131,0.5475835204124451,0.63691723
How do I reverse a list or loop over it backwards?,"To get a 
new
 reversed list, apply the 
reversed
 function and collect the items into a 
list
:


>>> xs = [0, 10, 20, 40]
>>> list(reversed(xs))
[40, 20, 10, 0]



To iterate backwards through a list:


>>> xs = [0, 10, 20, 40]
>>> for x in reversed(xs):
...     print(x)
40
20
10
0


","('Answer: To reverse a list in place, use `list.reverse()`.\n\nReferences: [1]\n', '[1] list.reverse()\nReverse the elements of the list in place. 33\n\nPython Tutorial, Release 3.13.2\nlist.copy()\nReturn a shallow copy of the list. Similar to a[:]. An example that uses most of the list methods:\n>>> fruits = [\'orange\', \'apple\', \'pear\', \'banana\', \'kiwi\', \'apple\', \'banana\']\n>>> fruits.count(\'apple\')\n2\n>>> fruits.count(\'tangerine\')\n0\n>>> fruits.index(\'banana\')\n3\n>>> fruits.index(\'banana\', 4)\n# Find next banana starting at position 4\n6\n>>> fruits.reverse()\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\']\n>>> fruits.append(\'grape\')\n>>> fruits\n[\'banana\', \'apple\', \'kiwi\', \'banana\', \'pear\', \'apple\', \'orange\', \'grape\']\n>>> fruits.sort()\n>>> fruits\n[\'apple\', \'apple\', \'banana\', \'banana\', \'grape\', \'kiwi\', \'orange\', \'pear\']\n>>> fruits.pop()\n\'pear\'\nYou might have noticed that methods like insert, remove or sort that only modify the list have no return value\nprinted – they return the default None.1 This is a design principle for all mutable data structures in Python. Another thing you might notice is that not all data can be sorted or compared. For instance, [None, \'hello\',\n10] doesn’t sort because integers can’t be compared to strings and None can’t be compared to other types. Also, there\nare some types that don’t have a defined ordering relation. For example, 3+4j < 5+7j isn’t a valid comparison. 5.1.1 Using Lists as Stacks\nThe list methods make it very easy to use a list as a stack, where the last element added is the first element retrieved\n(“last-in, first-out”). To add an item to the top of the stack, use append(). To retrieve an item from the top of the\nstack, use pop() without an explicit index. For example:\n>>> stack = [3, 4, 5]\n>>> stack.append(6)\n>>> stack.append(7)\n>>> stack\n[3, 4, 5, 6, 7]\n>>> stack.pop()\n7\n>>> stack\n[3, 4, 5, 6]\n>>> stack.pop()\n6\n>>> stack.pop()\n5\n>>> stack\n[3, 4]\n1 Other languages may return the mutated object, which allows method chaining, such as d->insert(""a"")->remove(""b"")->sort();. 34\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\n5.1.2 Using Lists as Queues\nIt is also possible to use a list as a queue, where the first element added is the first element retrieved (“first-in, first-\nout”); however, lists are not efficient for this purpose. While appends and pops from the end of list are fast, doing\ninserts or pops from the beginning of a list is slow (because all of the other elements have to be shifted by one). To implement a queue, use collections.deque which was designed to have fast appends and pops from both\nends. For example:\n>>> from collections import deque\n>>> queue = deque([""Eric"", ""John"", ""Michael""])\n>>> queue.append(""Terry"")\n# Terry arrives\n>>> queue.append(""Graham"")\n# Graham arrives\n>>> queue.popleft()\n# The first to arrive now leaves\n\'Eric\'\n>>> queue.popleft()\n# The second to arrive now leaves\n\'John\'\n>>> queue\n# Remaining queue in order of arrival\ndeque([\'Michael\', \'Terry\', \'Graham\'])\n5.1.3 List Comprehensions\nList comprehensions provide a concise way to create lists. Common applications are to make new lists where each\nelement is the result of some operations applied to each member of another sequence or iterable, or to create a\nsubsequence of those elements that satisfy a certain condition. For example, assume we want to create a list of squares, like:\n>>> squares = []\n>>> for x in range(10):\n...\nsquares.append(x**2)\n...\n>>> squares\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\nNote that this creates (or overwrites) a variable named x that still exists after the loop completes. We can calculate\nthe list of squares without any side effects using:\nsquares = list(map(lambda x: x**2, range(10)))\nor, equivalently:\nsquares = [x**2 for x in range(10)]\nwhich is more concise and readable. A list comprehension consists of brackets containing an expression followed by a for clause, then zero or more for\nor if clauses. The result will be a new list resulting from evaluating the expression in the context of the for and if\nclauses which follow it. For example, this listcomp combines the elements of two lists if they are not equal:\n>>> [(x, y) for x in [1,2,3] for y in [3,1,4] if x != y]\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nand it’s equivalent to:\n>>> combs = []\n>>> for x in [1,2,3]:\n...\nfor y in [3,1,4]:\n...\nif x != y:\n...\ncombs.append((x, y))\n(continues on next page)\n5.1. More on Lists\n35\n\nPython Tutorial, Release 3.13.2\n(continued from previous page)\n...\n>>> combs\n[(1, 3), (1, 4), (2, 3), (2, 1), (2, 4), (3, 1), (3, 4)]\nNote how the order of the for and if statements is the same in both these snippets. If the expression is a tuple (e.g. the (x, y) in the previous example), it must be parenthesized. >>> vec = [-4, -2, 0, 2, 4]\n>>> # create a new list with the values doubled\n>>> [x*2 for x in vec]\n[-8, -4, 0, 4, 8]\n>>> # filter the list to exclude negative numbers\n>>> [x for x in vec if x >= 0]\n[0, 2, 4]\n>>> # apply a function to all the elements\n>>> [abs(x) for x in vec]\n[4, 2, 0, 2, 4]\n>>> # call a method on each element\n>>> freshfruit = [\'\nbanana\', \'\nloganberry \', \'passion fruit\n\']\n>>> [weapon.strip() for weapon in freshfruit]\n[\'banana\', \'loganberry\', \'passion fruit\']\n>>> # create a list of 2-tuples like (number, square)\n>>> [(x, x**2) for x in range(6)]\n[(0, 0), (1, 1), (2, 4), (3, 9), (4, 16), (5, 25)]\n>>> # the tuple must be parenthesized, otherwise an error is raised\n>>> [x, x**2 for x in range(6)]\nFile ""<stdin>"", line 1\n[x, x**2 for x in range(6)]\n^^^^^^^\nSyntaxError: did you forget parentheses around the comprehension target? >>> # flatten a list using a listcomp with two \'for\'\n>>> vec = [[1,2,3], [4,5,6], [7,8,9]]\n>>> [num for elem in vec for num in elem]\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\nList comprehensions can contain complex expressions and nested functions:\n>>> from math import pi\n>>> [str(round(pi, i)) for i in range(1, 6)]\n[\'3.1\', \'3.14\', \'3.142\', \'3.1416\', \'3.14159\']\n5.1.4 Nested List Comprehensions\nThe initial expression in a list comprehension can be any arbitrary expression, including another list comprehension. Consider the following example of a 3x4 matrix implemented as a list of 3 lists of length 4:\n>>> matrix = [\n...\n[1, 2, 3, 4],\n...\n[5, 6, 7, 8],\n...\n[9, 10, 11, 12],\n... ]\nThe following list comprehension will transpose rows and columns:\n>>> [[row[i] for row in matrix] for i in range(4)]\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\n36\nChapter 5. Data Structures\n\nPython Tutorial, Release 3.13.2\nAs we saw in the previous section, the inner list comprehension is evaluated in the context of the for that follows it,\nso this example is equivalent to:\n>>> transposed = []\n>>> for i in range(4):\n...\ntransposed.append([row[i] for row in matrix])\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nwhich, in turn, is the same as:\n>>> transposed = []\n>>> for i in range(4):\n...\n# the following 3 lines implement the nested listcomp\n...\ntransposed_row = []\n...\nfor row in matrix:\n...\ntransposed_row.append(row[i])\n...\ntransposed.append(transposed_row)\n...\n>>> transposed\n[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]\nIn the real world, you should prefer built-in functions to complex flow statements. The zip() function would do a\ngreat job for this use case:\n>>> list(zip(*matrix))\n[(1, 5, 9), (2, 6, 10), (3, 7, 11), (4, 8, 12)]\nSee Unpacking Argument Lists for details on the asterisk in this line. 5.2 The del statement\nThere is a way to remove an item from a list given its index instead of its value: the del statement. This differs from\nthe pop() method which returns a value. The del statement can also be used to remove slices from a list or clear\nthe entire list (which we did earlier by assignment of an empty list to the slice). For example:\n>>> a = [-1, 1, 66.25, 333, 333, 1234.5]\n>>> del a[0]\n>>> a\n[1, 66.25, 333, 333, 1234.5]\n>>> del a[2:4]\n>>> a\n[1, 66.25, 1234.5]\n>>> del a[:]\n>>> a\n[]\ndel can also be used to delete entire variables:\n>>> del a\nReferencing the name a hereafter is an error (at least until another value is assigned to it). We’ll find other uses for\ndel later. 5.2. The del statement\n37\n\nPython Tutorial, Release 3.13.2\n5.3 Tuples and Sequences\nWe saw that lists and strings have many common properties, such as indexing and slicing operations. They are two\nexamples of sequence data types (see typesseq). Since Python is an evolving language, other sequence data types may\nbe added. There is also another standard sequence data type: the tuple. A tuple consists of a number of values separated by commas, for instance:\n>>> t = 12345, 54321, \'hello!\' >>> t[0]\n12345\n>>> t\n(12345, 54321, \'hello!\') >>> # Tuples may be nested:\n>>> u = t, (1, 2, 3, 4, 5)\n>>> u\n((12345, 54321, \'hello! \'), (1, 2, 3, 4, 5))\n>>> # Tuples are immutable:\n>>> t[0] = 88888\nTraceback (most recent call last):\nFile ""<stdin>"", line 1, in <module>\nTypeError: \'tuple\' object does not support item assignment\n>>> # but they can contain mutable objects:\n>>> v = ([1, 2, 3], [3, 2, 1])\n>>> v\n([1, 2, 3], [3, 2, 1])\nAs you see, on output tuples are always enclosed in parentheses, so that nested tuples are interpreted correctly; they\nmay be input with or without surrounding parentheses, although often parentheses are necessary anyway (if the tuple\nis part of a larger expression). It is not possible to assign to the individual items of a tuple, however it is possible to\ncreate tuples which contain mutable objects, such as lists. Though tuples may seem similar to lists, they are often used in different situations and for different purposes. Tuples\nare immutable, and usually contain a heterogeneous sequence of elements that are accessed via unpacking (see later\nin this section) or indexing (or even by attribute in the case of namedtuples). Lists are mutable, and their elements\nare usually homogeneous and are accessed by iterating over the list. A special problem is the construction of tuples containing 0 or 1 items: the syntax has some extra quirks to accom-\nmodate these. Empty tuples are constructed by an empty pair of parentheses; a tuple with one item is constructed\nby following a value with a comma (it is not sufficient to enclose a single value in parentheses).\n\n[2] . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.3\nHow do I iterate over a sequence in reverse order? . . . . . . . . . . . . . . . . . . . . . 23\n2.5.4\nHow do you remove duplicates from a list? . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .')",1.361998088178638e-79,0.023786869647954328,0.11197848410757946,0.5323892831802368,0.565806
What is a mixin and why is it useful?,"A mixin is a special kind of multiple inheritance.  There are two main situations where mixins are used:




You want to provide a lot of optional features for a class.


You want to use one particular feature in a lot of different classes.




For an example of number one, consider 
werkzeug's request and response system
.  I can make a plain old request object by saying:


from werkzeug import BaseRequest

class Request(BaseRequest):
    pass



If I want to add accept header support, I would make that


from werkzeug import BaseRequest, AcceptMixin

class Request(AcceptMixin, BaseRequest):
    pass



If I wanted to make a request object that supports accept headers, etags, authentication, and user agent support, I could do this:


from werkzeug import BaseRequest, AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin

class Request(AcceptMixin, ETagRequestMixin, UserAgentMixin, AuthenticationMixin, BaseRequest):
    pass



The difference is subtle, but in the above examples, the mixin classes weren't made to stand on their own.  In more traditional multiple inheritance, the 
AuthenticationMixin
 (for example) would probably be something more like 
Authenticator
.  That is, the class would probably be designed to stand on its own.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . . . 18\n3.2.5\nSequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n3.2.6\nSet types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n3.2.7\nMappings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.2.8\nCallable types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.2.9\nModules . . . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n4.14\nOther Built-in Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.1\nModules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.2\nClasses and Class Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.3\nFunctions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n4.14.4\nMethods . .\n\n[3] . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n7.3\nbuiltins . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n7.4\nconfigparser . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n7.5\nimportlib.metadata\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n7.6\nlocale\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",9.282817904188722e-156,0.042704626334519574,0.046564985916364876,0.38732150197029114,0.103596814
Putting a simple if-then-else statement on one line,"That's more specifically a 
ternary operator
 expression than an if-then, here's the python syntax


value_when_true if condition else value_when_false



Better Example:
 (thanks 
Mr. Burns
)


'Yes' if fruit == 'Apple' else 'No'



Now with assignment and contrast with if syntax


fruit = 'Apple'
isApple = True if fruit == 'Apple' else False



vs


fruit = 'Apple'
isApple = False
if fruit == 'Apple' : isApple = True


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . 107\n7.14\nThe type statement\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n8\nCompound statements\n109\n8.1\nThe if statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n8.2\nThe while statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110\n8.3\nThe for statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[2] . . . . . 17\n4.2\nfor Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n4.3\nThe range() Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n4.4\nbreak and continue Statements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.5\nelse Clauses on Loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n4.6\npass Statements . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . . . . 90\n6.10.2\nMembership test operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n6.10.3\nIdentity comparisons\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.11\nBoolean operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.12\nAssignment expressions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.13\nConditional expressions .')",4.8920927685389496e-232,0.034682080924855495,0.03816793893129772,0.4018643796443939,0.36273435
Correct way to write line to file?,"This should be as simple as:


with open('somefile.txt', 'a') as the_file:
    the_file.write('Hello\n')



From The Documentation:




Do not use 
os.linesep
 as a line terminator when writing files opened in text mode (the default); use a single 
'\n'
 instead, on all platforms.




Some useful reading:




The 
with
 statement


open()




'a'
 is for append, or use


'w'
 to write with truncation






os
 (particularly 
os.linesep
)



","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . . . . 53\n7.1.1\nFormatted String Literals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n7.1.2\nThe String format() Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n7.1.3\nManual String Formatting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\n7.1.4\nOld string formatting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2\nReading and Writing Files\n. . . . . . . . . . . . .\n\n[2] . 56\n7.1.4\nOld string formatting\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2\nReading and Writing Files\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n7.2.1\nMethods of File Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n7.2.2\nSaving structured data with json . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n8\nErrors and Exceptions\n61\n8.1\nSyntax Errors . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . . 5\n2.1.3\nComments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.4\nEncoding declarations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n2.1.5\nExplicit line joining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.6\nImplicit line joining . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2.1.7\nBlank lines . . . . . . . . . . . . . . . . . . . . . . . . . . .')",4.915690480357354e-232,0.06896551724137931,0.056777856635912005,0.44970136880874634,0.16115084
Use a list of values to select rows from a Pandas dataframe,"You can use the 
isin
 method:


In [1]: df = pd.DataFrame({'A': [5,6,3,4], 'B': [1,2,3,5]})

In [2]: df
Out[2]:
   A  B
0  5  1
1  6  2
2  3  3
3  4  5

In [3]: df[df['A'].isin([3, 6])]
Out[3]:
   A  B
1  6  2
2  3  3



And to get the opposite use 
~
:


In [4]: df[~df['A'].isin([3, 6])]
Out[4]:
   A  B
0  5  1
3  4  5


","(""I'm sorry, I couldn't find relevant information in the provided context."", '[1] . . . . . . . . . . . . . . . . 23\n2.5.5\nHow do you remove multiple items from a list\n. . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.6\nHow do you make an array in Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n2.5.7\nHow do I create a multidimensional list? . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n2.5.8\nHow do I apply a method or function to a sequence of objects? . . . . . . . . . . . . . . .\n\n[2] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method.\n\n[3] Sorting Techniques\nRelease 3.13.2\nGuido van Rossum and the Python development team\nApril 01, 2025\nPython Software Foundation\nEmail: docs@python.org\nContents\n1\nSorting Basics\n1\n2\nKey Functions\n2\n3\nOperator Module Functions and Partial Function Evaluation\n3\n4\nAscending and Descending\n3\n5\nSort Stability and Complex Sorts\n3\n6\nDecorate-Sort-Undecorate\n4\n7\nComparison Functions\n5\n8\nOdds and Ends\n5\n9\nPartial Sorts\n6\nIndex\n7\nAuthor\nAndrew Dalke and Raymond Hettinger\nPython lists have a built-in list.sort() method that modifies the list in-place. There is also a sorted() built-in\nfunction that builds a new sorted list from an iterable. In this document, we explore the various techniques for sorting data using Python. 1 Sorting Basics\nA simple ascending sort is very easy: just call the sorted() function. It returns a new sorted list:\n>>> sorted([5, 2, 3, 1, 4])\n[1, 2, 3, 4, 5]\nYou can also use the list.sort() method. It modifies the list in-place (and returns None to avoid confusion).')",1.3475241059521003e-155,0.1155378486055777,0.21387283236994217,0.48157259821891785,0.23089263
"Extract file name from path, no matter what the os/path format","Using 
os.path.split
 or 
os.path.basename
 as others suggest won't work in all cases: if you're running the script on Linux and attempt to process a classic windows-style path, it will fail.


Windows paths can use either backslash or forward slash as path separator. Therefore, the 
ntpath
 module (which is equivalent to os.path when running on windows) will work for all
(1)
 paths on all platforms.


import ntpath
ntpath.basename(""a/b/c"")



Of course, if the file ends with a slash, the basename will be empty, so make your own function to deal with it:


def path_leaf(path):
    head, tail = ntpath.split(path)
    return tail or ntpath.basename(head)



Verification:


>>> paths = ['a/b/c/', 'a/b/c', '\\a\\b\\c', '\\a\\b\\c\\', 'a\\b\\c', 
...     'a/b/../../a/b/c/', 'a/b/../../a/b/c']
>>> [path_leaf(path) for path in paths]
['c', 'c', 'c', 'c', 'c', 'c', 'c']





(1) There's one caveat: Linux filenames 
may contain backslashes
. So on linux, 
r'a/b\c'
 always refers to the file 
b\c
 in the 
a
 folder, while on Windows, it always refers to the 
c
 file in the 
b
 subfolder of the 
a
 folder. So when both forward and backward slashes are used in a path, you 
need
 to know the associated platform to be able to interpret it correctly. In practice it's usually safe to assume it's a windows path since backslashes are seldom used in Linux filenames, but keep this in mind when you code so you don't create accidental security holes.

","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . . . . . . . . . 477\n11.5\ntempfile — Generate temporary files and directories . . . . . . . . . . . . . . . . . . . . . . . 478\n11.5.1\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 482\n11.5.2\nDeprecated functions and variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483\n11.6\nglob — Unix style pathname pattern expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 484\n11.6.1\nExamples\n. . . . . . . . . . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . 436\n11 File and Directory Access\n439\n11.1\npathlib — Object-oriented filesystem paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439\n11.1.1\nBasic use\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 440\n11.1.2\nExceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441\n11.1.3\nPure paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n[3] . . . . . . . 483\n11.6\nglob — Unix style pathname pattern expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . 484\n11.6.1\nExamples\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 485\n11.7\nfnmatch — Unix filename pattern matching\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 486\n11.8\nlinecache — Random access to text lines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487\nv\n\n11.9\nshutil — High-level file operations . . . . . . .')",1.1206791826947822e-155,0.06483790523690773,0.051560758082497216,0.5325281620025635,0.31597102
Get a list from Pandas DataFrame column headers,"You can get the values as a list by doing:


list(my_dataframe.columns.values)



Also you can simply use (as shown in 
Ed Chum's answer
):


list(my_dataframe)


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] . . . . . 32\n5\nData Structures\n33\n5.1\nMore on Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5.1.1\nUsing Lists as Stacks\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\n5.1.2\nUsing Lists as Queues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.3\nList Comprehensions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n5.1.4\nNested List Comprehensions\n. . . . . . . .\n\n[2] . . . . . . . . . . . . . . . . . . . . . . . . . . 259\n8.4.4\ndefaultdict objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\n8.4.5\nnamedtuple() Factory Function for Tuples with Named Fields\n. . . . . . . . . . . . . 264\n8.4.6\nOrderedDict objects\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267\n8.4.7\nUserDict objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\n8.4.8\nUserList objects . . . . . . . . . . . .\n\n[3] . . . . . . . . . . . . . . . . 21\n2.4.2\nWhat is the most efficient way to concatenate many strings together? . . . . . . . . . . . . 22\n2.5\nSequences (Tuples/Lists) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.1\nHow do I convert between tuples and lists? . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.5.2\nWhat’s a negative index? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .')",5.4084337486948925e-232,0.06896551724137931,0.09953161592505856,0.4393026530742645,0.037857633
How do I trim whitespace from a string?,"To remove all whitespace surrounding a string, use 
.strip()
. Examples:


>>> ' Hello '.strip()
'Hello'
>>> ' Hello'.strip()
'Hello'
>>> 'Bob has a cat'.strip()
'Bob has a cat'
>>> '   Hello   '.strip()  # ALL consecutive spaces at both ends removed
'Hello'



Note that 
str.strip()
 removes all whitespace characters, including tabs and newlines. To remove only spaces, specify the specific character to remove as an argument to 
strip
:


>>> ""  Hello\n  "".strip("" "")
'Hello\n'





To remove only one space at most:


def strip_one_space(s):
    if s.endswith("" ""): s = s[:-1]
    if s.startswith("" ""): s = s[1:]
    return s

>>> strip_one_space(""   Hello "")
'  Hello'


","('Answer: You can use the `strip()`, `lstrip()`, or `rstrip()` methods to remove whitespace from a string. `strip()` removes both leading and trailing whitespace, `lstrip()` removes leading whitespace, and `rstrip()` removes trailing whitespace. If you want to remove specific characters, you can pass them as an argument to these methods.\n\nReferences: [1, 2]', '[1] str.rjust(width[, fillchar])\nReturn the string right justified in a string of length width. Padding is done using the specified fillchar (default\nis an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep)\nSplit the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two\nempty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except\nfor splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars])\nReturn a copy of the string with trailing characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a suffix; rather, all combinations of its values are stripped:\n4.8. Text Sequence Type — str\n57\n\nThe Python Library Reference, Release 3.13.2\n>>> \'\nspacious\n\'.rstrip()\n\'\nspacious\'\n>>> \'mississippi\'.rstrip(\'ipz\')\n\'mississ\'\nSee str.removesuffix() for a method that will remove a single suffix string rather than all of a set of\ncharacters. For example:\n>>> \'Monty Python\'.rstrip(\' Python\')\n\'M\'\n>>> \'Monty Python\'.removesuffix(\' Python\')\n\'Monty\'\nstr.split(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then\nthere is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for\nexample, \'1,,2\'.split(\',\') returns [\'1\', \'\', \'2\']). The sep argument may consist of multiple char-\nacters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with\na specified separator returns [\'\']. For example:\n>>> \'1,2,3\'.split(\',\')\n[\'1\', \'2\', \'3\']\n>>> \'1,2,3\'.split(\',\', maxsplit=1)\n[\'1\', \'2,3\']\n>>> \'1,2,,3,\'.split(\',\')\n[\'1\', \'2\', \'\', \'3\', \'\']\n>>> \'1<>2<>3<4\'.split(\'<>\')\n[\'1\', \'2\', \'3<4\']\nIf sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are\nregarded as a single separator, and the result will contain no empty strings at the start or end if the string has\nleading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace\nwith a None separator returns []. For example:\n>>> \'1 2 3\'.split()\n[\'1\', \'2\', \'3\']\n>>> \'1 2 3\'.split(maxsplit=1)\n[\'1\', \'2 3\']\n>>> \'\n1\n2\n3\n\'.split()\n[\'1\', \'2\', \'3\']\nstr.splitlines(keepends=False)\nReturn a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting\nlist unless keepends is given and true. This method splits on the following line boundaries. In particular, the boundaries are a superset of universal\nnewlines. 58\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nRepresentation\nDescription\n\\n\nLine Feed\n\\r\nCarriage Return\n\\r\\n\nCarriage Return + Line Feed\n\\v or \\x0b\nLine Tabulation\n\\f or \\x0c\nForm Feed\n\\x1c\nFile Separator\n\\x1d\nGroup Separator\n\\x1e\nRecord Separator\n\\x85\nNext Line (C1 Control Code)\n\\u2028\nLine Separator\n\\u2029\nParagraph Separator\nChanged in version 3.2: \\v and \\f added to list of line boundaries. For example:\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines()\n[\'ab c\', \'\', \'de fg\', \'kl\']\n>>> \'ab c\\n\\nde fg\\rkl\\r\\n\'.splitlines(keepends=True)\n[\'ab c\\n\', \'\\n\', \'de fg\\r\', \'kl\\r\\n\']\nUnlike split() when a delimiter string sep is given, this method returns an empty list for the empty string,\nand a terminal line break does not result in an extra line:\n>>> """".splitlines()\n[]\n>>> ""One line\\n"".splitlines()\n[\'One line\']\nFor comparison, split(\'\\n\') gives:\n>>> \'\'.split(\'\\n\')\n[\'\']\n>>> \'Two lines\\n\'.split(\'\\n\')\n[\'Two lines\', \'\']\nstr.startswith(prefix[, start[, end]])\nReturn True if string starts with the prefix, otherwise return False. prefix can also be a tuple of prefixes to\nlook for. With optional start, test string beginning at that position. With optional end, stop comparing string\nat that position. str.strip([chars])\nReturn a copy of the string with the leading and trailing characters removed. The chars argument is a string\nspecifying the set of characters to be removed. If omitted or None, the chars argument defaults to removing\nwhitespace. The chars argument is not a prefix or suffix; rather, all combinations of its values are stripped:\n>>> \'\nspacious\n\'.strip()\n\'spacious\'\n>>> \'www.example.com\'.strip(\'cmowz.\') \'example\'\nThe outermost leading and trailing chars argument values are stripped from the string. Characters are removed\nfrom the leading end until reaching a string character that is not contained in the set of characters in chars. A\nsimilar action takes place on the trailing end. For example:\n4.8. Text Sequence Type — str\n59\n\nThe Python Library Reference, Release 3.13.2\n>>> comment_string = \'#....... Section 3.2.1 Issue #32 .......\'\n>>> comment_string.strip(\'.#! \') \'Section 3.2.1 Issue #32\'\nstr.swapcase()\nReturn a copy of the string with uppercase characters converted to lowercase and vice versa. Note that it is\nnot necessarily true that s.swapcase().swapcase() == s.\nstr.title()\nReturn a titlecased version of the string where words start with an uppercase character and the remaining\ncharacters are lowercase. For example:\n>>> \'Hello world\'.title()\n\'Hello World\'\nThe algorithm uses a simple language-independent definition of a word as groups of consecutive letters. The\ndefinition works in many contexts but it means that apostrophes in contractions and possessives form word\nboundaries, which may not be the desired result:\n>>> ""they\'re bill\'s friends from the UK"".title()\n""They\'Re Bill\'S Friends From The Uk""\nThe string.capwords() function does not have this problem, as it splits words on spaces only. Alternatively, a workaround for apostrophes can be constructed using regular expressions:\n>>> import re\n>>> def titlecase(s):\n...\nreturn re.sub(r""[A-Za-z]+(\'[A-Za-z]+)? "",\n...\nlambda mo: mo.group(0).capitalize(),\n...\ns)\n...\n>>> titlecase(""they\'re bill\'s friends."") ""They\'re Bill\'s Friends."" str.translate(table)\nReturn a copy of the string in which each character has been mapped through the given translation table. The table must be an object that implements indexing via __getitem__(), typically a mapping or sequence.\n\n[2] str.lstrip([chars])\nReturn a copy of the string with leading characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a prefix; rather, all combinations of its values are stripped:\n>>> \'\nspacious\n\'.lstrip()\n\'spacious\n\'\n>>> \'www.example.com\'.lstrip(\'cmowz.\') \'example.com\'\nSee str.removeprefix() for a method that will remove a single prefix string rather than all of a set of\ncharacters. For example:\n>>> \'Arthur: three! \'.lstrip(\'Arthur: \')\n\'ee!\' >>> \'Arthur: three! \'.removeprefix(\'Arthur: \')\n\'three!\' static str.maketrans(x[, y[, z]])\nThis static method returns a translation table usable for str.translate(). If there is only one argument, it must be a dictionary mapping Unicode ordinals (integers) or characters (strings\nof length 1) to Unicode ordinals, strings (of arbitrary lengths) or None. Character keys will then be converted\nto ordinals. If there are two arguments, they must be strings of equal length, and in the resulting dictionary, each character\nin x will be mapped to the character at the same position in y. If there is a third argument, it must be a string,\nwhose characters will be mapped to None in the result. 56\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nstr.partition(sep)\nSplit the string at the first occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing the\nstring itself, followed by two empty strings. str.removeprefix(prefix, /)\nIf the string starts with the prefix string, return string[len(prefix):]. Otherwise, return a copy of the\noriginal string:\n>>> \'TestHook\'.removeprefix(\'Test\')\n\'Hook\'\n>>> \'BaseTestCase\'.removeprefix(\'Test\')\n\'BaseTestCase\'\nAdded in version 3.9.\nstr.removesuffix(suffix, /)\nIf the string ends with the suffix string and that suffix is not empty, return string[:-len(suffix)]. Oth-\nerwise, return a copy of the original string:\n>>> \'MiscTests\'.removesuffix(\'Tests\')\n\'Misc\'\n>>> \'TmpDirMixin\'.removesuffix(\'Tests\')\n\'TmpDirMixin\'\nAdded in version 3.9.\nstr.replace(old, new, count=-1)\nReturn a copy of the string with all occurrences of substring old replaced by new. If count is given, only the\nfirst count occurrences are replaced. If count is not specified or -1, then all occurrences are replaced. Changed in version 3.13: count is now supported as a keyword argument. str.rfind(sub[, start[, end]])\nReturn the highest index in the string where substring sub is found, such that sub is contained within\ns[start:end]. Optional arguments start and end are interpreted as in slice notation. Return -1 on fail-\nure. str.rindex(sub[, start[, end]])\nLike rfind() but raises ValueError when the substring sub is not found. str.rjust(width[, fillchar])\nReturn the string right justified in a string of length width. Padding is done using the specified fillchar (default\nis an ASCII space). The original string is returned if width is less than or equal to len(s). str.rpartition(sep)\nSplit the string at the last occurrence of sep, and return a 3-tuple containing the part before the separator, the\nseparator itself, and the part after the separator. If the separator is not found, return a 3-tuple containing two\nempty strings, followed by the string itself. str.rsplit(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done, the rightmost ones. If sep is not specified or None, any whitespace string is a separator. Except\nfor splitting from the right, rsplit() behaves like split() which is described in detail below. str.rstrip([chars])\nReturn a copy of the string with trailing characters removed. The chars argument is a string specifying the set\nof characters to be removed. If omitted or None, the chars argument defaults to removing whitespace. The\nchars argument is not a suffix; rather, all combinations of its values are stripped:\n4.8. Text Sequence Type — str\n57\n\nThe Python Library Reference, Release 3.13.2\n>>> \'\nspacious\n\'.rstrip()\n\'\nspacious\'\n>>> \'mississippi\'.rstrip(\'ipz\')\n\'mississ\'\nSee str.removesuffix() for a method that will remove a single suffix string rather than all of a set of\ncharacters. For example:\n>>> \'Monty Python\'.rstrip(\' Python\')\n\'M\'\n>>> \'Monty Python\'.removesuffix(\' Python\')\n\'Monty\'\nstr.split(sep=None, maxsplit=-1)\nReturn a list of the words in the string, using sep as the delimiter string. If maxsplit is given, at most maxsplit\nsplits are done (thus, the list will have at most maxsplit+1 elements). If maxsplit is not specified or -1, then\nthere is no limit on the number of splits (all possible splits are made). If sep is given, consecutive delimiters are not grouped together and are deemed to delimit empty strings (for\nexample, \'1,,2\'.split(\',\') returns [\'1\', \'\', \'2\']). The sep argument may consist of multiple char-\nacters as a single delimiter (to split with multiple delimiters, use re.split()). Splitting an empty string with\na specified separator returns [\'\']. For example:\n>>> \'1,2,3\'.split(\',\')\n[\'1\', \'2\', \'3\']\n>>> \'1,2,3\'.split(\',\', maxsplit=1)\n[\'1\', \'2,3\']\n>>> \'1,2,,3,\'.split(\',\')\n[\'1\', \'2\', \'\', \'3\', \'\']\n>>> \'1<>2<>3<4\'.split(\'<>\')\n[\'1\', \'2\', \'3<4\']\nIf sep is not specified or is None, a different splitting algorithm is applied: runs of consecutive whitespace are\nregarded as a single separator, and the result will contain no empty strings at the start or end if the string has\nleading or trailing whitespace. Consequently, splitting an empty string or a string consisting of just whitespace\nwith a None separator returns []. For example:\n>>> \'1 2 3\'.split()\n[\'1\', \'2\', \'3\']\n>>> \'1 2 3\'.split(maxsplit=1)\n[\'1\', \'2 3\']\n>>> \'\n1\n2\n3\n\'.split()\n[\'1\', \'2\', \'3\']\nstr.splitlines(keepends=False)\nReturn a list of the lines in the string, breaking at line boundaries. Line breaks are not included in the resulting\nlist unless keepends is given and true.\n\n[3] . . . . . . . . . . . . . . . . 19\n2.3.6\nHow do I modify a string in place? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.7\nHow do I use strings to call functions/methods? . . . . . . . . . . . . . . . . . . . . . . . 19\n2.3.8\nIs there an equivalent to Perl’s chomp() for removing trailing newlines from strings? . . . 20\n2.3.9\nIs there a scanf() or sscanf() equivalent? . . . . . . . . . . . . . . . . . . . . . . .')",0.0025064911222934896,0.03688524590163935,0.173078919496468,0.5832514762878418,0.6713147
How do I remove all packages installed by pip?,"I've found this snippet as an alternative solution. It's a more graceful removal of libraries than remaking the virtualenv:


pip freeze | xargs pip uninstall -y





In case you have packages installed via VCS, you need to exclude those lines and remove the packages manually (elevated from the comments below):


pip freeze --exclude-editable | xargs pip uninstall -y





If you have packages installed directly from github/gitlab, those will have 
@
.
Like:


django @ git+https://github.com/django.git@


You can add 
cut -d ""@"" -f1
 to get just the package name that is required to uninstall it.


pip freeze | cut -d ""@"" -f1 | xargs pip uninstall -y


","('Answer: To remove packages installed by pip, use the command `python -m pip uninstall` followed by one or more package names.\n\nReferences: [1]\n', '[1] 12.3 Managing Packages with pip\nYou can install, upgrade, and remove packages using a program called pip. By default pip will install packages from\nthe Python Package Index. You can browse the Python Package Index by going to it in your web browser. pip has a number of subcommands: “install”, “uninstall”, “freeze”, etc. (Consult the installing-index guide for\ncomplete documentation for pip.) You can install the latest version of a package by specifying a package’s name:\n(tutorial-env) $ python -m pip install novas\nCollecting novas\nDownloading novas-3.1.1.3.tar.gz (136kB)\nInstalling collected packages: novas\nRunning setup.py install for novas\nSuccessfully installed novas-3.1.1.3\nYou can also install a specific version of a package by giving the package name followed by == and the version\nnumber:\n(tutorial-env) $ python -m pip install requests==2.6.0\nCollecting requests==2.6.0\nUsing cached requests-2.6.0-py2.py3-none-any.whl\nInstalling collected packages: requests\nSuccessfully installed requests-2.6.0\nIf you re-run this command, pip will notice that the requested version is already installed and do nothing. You can\nsupply a different version number to get that version, or you can run python -m pip install --upgrade to\nupgrade the package to the latest version:\n(tutorial-env) $ python -m pip install --upgrade requests\nCollecting requests\nInstalling collected packages: requests\nFound existing installation: requests 2.6.0\nUninstalling requests-2.6.0:\nSuccessfully uninstalled requests-2.6.0\nSuccessfully installed requests-2.7.0\npython -m pip uninstall followed by one or more package names will remove the packages from the virtual\nenvironment. 102\nChapter 12. Virtual Environments and Packages\n\nPython Tutorial, Release 3.13.2\npython -m pip show will display information about a particular package:\n(tutorial-env) $ python -m pip show requests\n---\nMetadata-Version: 2.0\nName: requests\nVersion: 2.7.0\nSummary: Python HTTP for Humans. Home-page: http://python-requests.org\nAuthor: Kenneth Reitz\nAuthor-email: me@kennethreitz.com\nLicense: Apache 2.0\nLocation: /Users/akuchling/envs/tutorial-env/lib/python3.4/site-packages\nRequires:\npython -m pip list will display all of the packages installed in the virtual environment:\n(tutorial-env) $ python -m pip list\nnovas (3.1.1.3)\nnumpy (1.9.2)\npip (7.0.3)\nrequests (2.7.0)\nsetuptools (16.0)\npython -m pip freeze will produce a similar list of the installed packages, but the output uses the format that\npython -m pip install expects. A common convention is to put this list in a requirements.txt file:\n(tutorial-env) $ python -m pip freeze > requirements.txt\n(tutorial-env) $ cat requirements.txt\nnovas==3.1.1.3\nnumpy==1.9.2\nrequests==2.7.0\nThe requirements.txt can then be committed to version control and shipped as part of an application. Users can\nthen install all the necessary packages with install -r:\n(tutorial-env) $ python -m pip install -r requirements.txt\nCollecting novas==3.1.1.3 (from -r requirements.txt (line 1))\n... Collecting numpy==1.9.2 (from -r requirements.txt (line 2))\n... Collecting requests==2.7.0 (from -r requirements.txt (line 3))\n... Installing collected packages: novas, numpy, requests\nRunning setup.py install for novas\nSuccessfully installed novas-3.1.1.3 numpy-1.9.2 requests-2.7.0\npip has many more options. Consult the installing-index guide for complete documentation for pip. When you’ve\nwritten a package and want to make it available on the Python Package Index, consult the Python packaging user\nguide. 12.3. Managing Packages with pip\n103\n\nPython Tutorial, Release 3.13.2\n104\nChapter 12. Virtual Environments and Packages\n\nCHAPTER\nTHIRTEEN\nWHAT NOW? Reading this tutorial has probably reinforced your interest in using Python — you should be eager to apply Python to\nsolving your real-world problems. Where should you go to learn more? This tutorial is part of Python’s documentation set. Some other documents in the set are:\n• library-index:\nYou should browse through this manual, which gives complete (though terse) reference material about types,\nfunctions, and the modules in the standard library. The standard Python distribution includes a lot of additional\ncode. There are modules to read Unix mailboxes, retrieve documents via HTTP, generate random numbers,\nparse command-line options, compress data, and many other tasks. Skimming through the Library Reference\nwill give you an idea of what’s available. • installing-index explains how to install additional modules written by other Python users. • reference-index: A detailed explanation of Python’s syntax and semantics. It’s heavy reading, but is useful as\na complete guide to the language itself. More Python resources:\n• https://www.python.org: The major Python web site. It contains code, documentation, and pointers to Python-\nrelated pages around the web. • https://docs.python.org: Fast access to Python’s documentation. • https://pypi.org: The Python Package Index, previously also nicknamed the Cheese Shop1, is an index of user-\ncreated Python modules that are available for download. Once you begin releasing code, you can register it\nhere so that others can find it. • https://code.activestate.com/recipes/langs/python/: The Python Cookbook is a sizable collection of code ex-\namples, larger modules, and useful scripts. Particularly notable contributions are collected in a book also titled\nPython Cookbook (O’Reilly & Associates, ISBN 0-596-00797-3.) • https://pyvideo.org collects links to Python-related videos from conferences and user-group meetings. • https://scipy.org: The Scientific Python project includes modules for fast array computations and manipulations\nplus a host of packages for such things as linear algebra, Fourier transforms, non-linear solvers, random number\ndistributions, statistical analysis and the like. For Python-related questions and problem reports, you can post to the newsgroup comp.lang.python, or send\nthem to the mailing list at python-list@python.org. The newsgroup and mailing list are gatewayed, so messages\nposted to one will automatically be forwarded to the other. There are hundreds of postings a day, asking (and\nanswering) questions, suggesting new features, and announcing new modules. Mailing list archives are available at\nhttps://mail.python.org/pipermail/. Before posting, be sure to check the list of Frequently Asked Questions (also called the FAQ). The FAQ answers\nmany of the questions that come up again and again, and may already contain the solution for your problem. 1 “Cheese Shop” is a Monty Python’s sketch: a customer enters a cheese shop, but whatever cheese he asks for, the clerk says it’s missing. 105\n\nPython Tutorial, Release 3.13.2\n106\nChapter 13. What Now? CHAPTER\nFOURTEEN\nINTERACTIVE INPUT EDITING AND HISTORY SUBSTITUTION\nSome versions of the Python interpreter support editing of the current input line and history substitution, similar to\nfacilities found in the Korn shell and the GNU Bash shell. This is implemented using the GNU Readline library,\nwhich supports various styles of editing. This library has its own documentation which we won’t duplicate here.\n\n[2] . . . . 7\n3.2\n… install packages just for the current user? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.3\n… install scientific Python packages? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n3.4\n… work with multiple versions of Python installed in parallel? . . . . . . . . . . . . . . . . . . . 7\n4\nCommon installation issues\n9\n4.1\nInstalling into the system Python on Linux . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n4.2\nPip not installed .\n\n[3] . . . . . . 48\nD Copyright\n51\nIndex\n53\nii\n\nInstalling Python Modules, Release 3.13.2\nEmail\ndistutils-sig@python.org\nAs a popular open source development project, Python has an active supporting community of contributors and users\nthat also make their software available for other Python developers to use under open source license terms. This allows Python users to share and collaborate effectively, benefiting from the solutions others have already created\nto common (and sometimes even rare!) problems, as well as potentially contributing their own solutions to the\ncommon pool. This guide covers the installation part of the process. For a guide to creating and sharing your own Python projects,\nrefer to the Python packaging user guide. ® Note\nFor corporate and other institutional users, be aware that many organisations have their own policies around\nusing and contributing to open source software. Please take such policies into account when making use of the\ndistribution and installation tools provided with Python. CONTENTS\n1\n\nInstalling Python Modules, Release 3.13.2\n2\nCONTENTS\n\nCHAPTER\nONE\nKEY TERMS\n• pip is the preferred installer program. Starting with Python 3.4, it is included by default with the Python\nbinary installers. • A virtual environment is a semi-isolated Python environment that allows packages to be installed for use by a\nparticular application, rather than being installed system wide. • venv is the standard tool for creating virtual environments, and has been part of Python since Python 3.3. Starting with Python 3.4, it defaults to installing pip into all created virtual environments. • virtualenv is a third party alternative (and predecessor) to venv. It allows virtual environments to be used\non versions of Python prior to 3.4, which either don’t provide venv at all, or aren’t able to automatically install\npip into created environments. • The Python Package Index is a public repository of open source licensed packages made available for use by\nother Python users. • the Python Packaging Authority is the group of developers and documentation authors responsible for the\nmaintenance and evolution of the standard packaging tools and the associated metadata and file format stan-\ndards. They maintain a variety of tools, documentation, and issue trackers on GitHub. • distutils is the original build and distribution system first added to the Python standard library in 1998. While direct use of distutils is being phased out, it still laid the foundation for the current packaging and\ndistribution infrastructure, and it not only remains part of the standard library, but its name lives on in other\nways (such as the name of the mailing list used to coordinate Python packaging standards development). Changed in version 3.5: The use of venv is now recommended for creating virtual environments. µ See also\nPython Packaging User Guide: Creating and using virtual environments\n3\n\nInstalling Python Modules, Release 3.13.2\n4\nChapter 1. Key terms\n\nCHAPTER\nTWO\nBASIC USAGE\nThe standard packaging tools are all designed to be used from the command line. The following command will install the latest version of a module and its dependencies from the Python Package\nIndex:\npython -m pip install SomePackage\n® Note\nFor POSIX users (including macOS and Linux users), the examples in this guide assume the use of a virtual\nenvironment. For Windows users, the examples in this guide assume that the option to adjust the system PATH environment\nvariable was selected when installing Python. It’s also possible to specify an exact or minimum version directly on the command line. When using comparator\noperators such as >, < or some other special character which get interpreted by shell, the package name and the\nversion should be enclosed within double quotes:\npython -m pip install SomePackage==1.0.4\n# specific version\npython -m pip install ""SomePackage>=1.0.4""\n# minimum version\nNormally, if a suitable module is already installed, attempting to install it again will have no effect. Upgrading existing\nmodules must be requested explicitly:\npython -m pip install --upgrade SomePackage\nMore information and resources regarding pip and its capabilities can be found in the Python Packaging User Guide. Creation of virtual environments is done through the venv module. Installing packages into an active virtual envi-\nronment uses the commands shown above. µ See also\nPython Packaging User Guide: Installing Python Distribution Packages\n5\n\nInstalling Python Modules, Release 3.13.2\n6\nChapter 2. Basic usage\n\nCHAPTER\nTHREE\nHOW DO I …? These are quick answers or links for some common tasks. 3.1 … install pip in versions of Python prior to Python 3.4? Python only started bundling pip with Python 3.4. For earlier versions, pip needs to be “bootstrapped” as described\nin the Python Packaging User Guide. µ See also\nPython Packaging User Guide: Requirements for Installing Packages\n3.2 … install packages just for the current user? Passing the --user option to python -m pip install will install a package just for the current user, rather than\nfor all users of the system. 3.3 … install scientific Python packages? A number of scientific Python packages have complex binary dependencies, and aren’t currently easy to install using\npip directly. At this point in time, it will often be easier for users to install these packages by other means rather\nthan attempting to install them with pip. µ See also\nPython Packaging User Guide: Installing Scientific Packages\n3.4 … work with multiple versions of Python installed in parallel? On Linux, macOS, and other POSIX systems, use the versioned Python commands in combination with the -m switch\nto run the appropriate copy of pip:\npython2\n-m pip install SomePackage\n# default Python 2\npython2.7 -m pip install SomePackage\n# specifically Python 2.7\npython3\n-m pip install SomePackage\n# default Python 3\npython3.4 -m pip install SomePackage\n# specifically Python 3.4\nAppropriately versioned pip commands may also be available. On Windows, use the py Python launcher in combination with the -m switch:\n7\n\nInstalling Python Modules, Release 3.13.2\npy -2\n-m pip install SomePackage\n# default Python 2\npy -2.7 -m pip install SomePackage\n# specifically Python 2.7\npy -3\n-m pip install SomePackage\n# default Python 3\npy -3.4 -m pip install SomePackage\n# specifically Python 3.4\n8\nChapter 3. How do I …? CHAPTER\nFOUR\nCOMMON INSTALLATION ISSUES\n4.1 Installing into the system Python on Linux\nOn Linux systems, a Python installation will typically be included as part of the distribution.')",2.5111684071949934e-79,0.030969845150774243,0.12720156555772996,0.5359369516372681,0.57343704
How does Python's super() work with multiple inheritance?,"This is detailed with a reasonable amount of detail by Guido himself in his blog post 
Method Resolution Order
 (including two earlier attempts).


In your example, 
Third()
 will call 
First.__init__
. Python looks for each attribute in the class's parents as they are listed left to right. In this case, we are looking for 
__init__
. So, if you define


class Third(First, Second):
    ...



Python will start by looking at 
First
, and, if 
First
 doesn't have the attribute, then it will look at 
Second
.


This situation becomes more complex when inheritance starts crossing paths (for example if 
First
 inherited from 
Second
). Read the link above for more details, but, in a nutshell, Python will try to maintain the order in which each class appears on the inheritance list, starting with the child class itself.


So, for instance, if you had:


class First(object):
    def __init__(self):
        print ""first""

class Second(First):
    def __init__(self):
        print ""second""

class Third(First):
    def __init__(self):
        print ""third""

class Fourth(Second, Third):
    def __init__(self):
        super(Fourth, self).__init__()
        print ""that's it""



the MRO would be 
[Fourth, Second, Third, First].


By the way: if Python cannot find a coherent method resolution order, it'll raise an exception, instead of falling back to behavior which might surprise the user.


Example of an ambiguous MRO:


class First(object):
    def __init__(self):
        print ""first""
        
class Second(First):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        print ""third""



Should 
Third
's MRO be 
[First, Second]
 or 
[Second, First]
? There's no obvious expectation, and Python will raise an error:


TypeError: Error when calling the metaclass bases
    Cannot create a consistent method resolution order (MRO) for bases Second, First



Why do the examples above lack 
super()
 calls? The point of the examples is to show how the MRO is constructed. They are 
not
 intended to print 
""first\nsecond\third""
 or whatever. You can – and should, of course, play around with the example, add 
super()
 calls, see what happens, and gain a deeper understanding of Python's inheritance model. But my goal here is to keep it simple and show how the MRO is built. And it is built as I explained:


>>> Fourth.__mro__
(
,
 
, 
,
 
,
 
)


","(""I'm sorry, I couldn't find relevant information in the provided context.\n"", '[1] int check_multi_interp_extensions\nIf this is 0 then all extension modules may be imported, including legacy (single-phase init) modules,\nin any thread where the sub-interpreter is currently active. Otherwise only multi-phase init extension\nmodules (see PEP 489) may be imported. (Also see Py_mod_multiple_interpreters.) This must be 1 (non-zero) if use_main_obmalloc is 0.\nint gil\nThis determines the operation of the GIL for the sub-interpreter. It may be one of the following:\nPyInterpreterConfig_DEFAULT_GIL\nUse the default selection (PyInterpreterConfig_SHARED_GIL). PyInterpreterConfig_SHARED_GIL\nUse (share) the main interpreter’s GIL. PyInterpreterConfig_OWN_GIL\nUse the sub-interpreter’s own GIL. If this is PyInterpreterConfig_OWN_GIL then PyInterpreterConfig.use_main_obmalloc\nmust be 0. PyStatus Py_NewInterpreterFromConfig(PyThreadState **tstate_p, const PyInterpreterConfig *config)\nCreate a new sub-interpreter. This is an (almost) totally separate environment for the execution of Python\ncode. In particular, the new interpreter has separate, independent versions of all imported modules, including\nthe fundamental modules builtins, __main__ and sys. The table of loaded modules (sys.modules) and\nthe module search path (sys.path) are also separate. The new environment has no sys.argv variable. It\nhas new standard I/O stream file objects sys.stdin, sys.stdout and sys.stderr (however these refer\nto the same underlying file descriptors). The given config controls the options with which the interpreter is initialized. Upon success, tstate_p will be set to the first thread state created in the new sub-interpreter. This thread state\nis made in the current thread state. Note that no actual thread is created; see the discussion of thread states\nbelow. If creation of the new interpreter is unsuccessful, tstate_p is set to NULL; no exception is set since the\nexception state is stored in the current thread state and there may not be a current thread state. Like all other Python/C API functions, the global interpreter lock must be held before calling this function\nand is still held when it returns. Likewise a current thread state must be set on entry. On success, the returned\nthread state will be set as current. If the sub-interpreter is created with its own GIL then the GIL of the calling\ninterpreter will be released. When the function returns, the new interpreter’s GIL will be held by the current\nthread and the previously interpreter’s GIL will remain released here. Added in version 3.12. Sub-interpreters are most effective when isolated from each other, with certain functionality restricted:\nPyInterpreterConfig config = {\n.use_main_obmalloc = 0,\n(continues on next page)\n9.6. Sub-interpreter support\n217\n\nThe Python/C API, Release 3.13.2\n(continued from previous page)\n.allow_fork = 0,\n.allow_exec = 0,\n.allow_threads = 1,\n.allow_daemon_threads = 0,\n.check_multi_interp_extensions = 1,\n.gil = PyInterpreterConfig_OWN_GIL,\n};\nPyThreadState *tstate = NULL;\nPyStatus status = Py_NewInterpreterFromConfig(&tstate, &config);\nif (PyStatus_Exception(status)) {\nPy_ExitStatusException(status);\n}\nNote that the config is used only briefly and does not get modified. During initialization the config’s values are\nconverted into various PyInterpreterState values. A read-only copy of the config may be stored internally\non the PyInterpreterState. Extension modules are shared between (sub-)interpreters as follows:\n• For modules using multi-phase initialization, e.g. PyModule_FromDefAndSpec(), a separate module\nobject is created and initialized for each interpreter. Only C-level static and global variables are shared\nbetween these module objects. • For modules using single-phase initialization, e.g. PyModule_Create(), the first time a particular ex-\ntension is imported, it is initialized normally, and a (shallow) copy of its module’s dictionary is squirreled\naway. When the same extension is imported by another (sub-)interpreter, a new module is initialized and\nfilled with the contents of this copy; the extension’s init function is not called. Objects in the module’s\ndictionary thus end up shared across (sub-)interpreters, which might cause unwanted behavior (see Bugs\nand caveats below). Note that this is different from what happens when an extension is imported after the interpreter has\nbeen completely re-initialized by calling Py_FinalizeEx() and Py_Initialize(); in that case, the\nextension’s initmodule function is called again. As with multi-phase initialization, this means that only\nC-level static and global variables are shared between these modules. PyThreadState *Py_NewInterpreter(void)\nPart of the Stable ABI. Create a new sub-interpreter. This is essentially just a wrapper around\nPy_NewInterpreterFromConfig() with a config that preserves the existing behavior. The result is an\nunisolated sub-interpreter that shares the main interpreter’s GIL, allows fork/exec, allows daemon threads, and\nallows single-phase init modules. void Py_EndInterpreter(PyThreadState *tstate)\nPart of the Stable ABI. Destroy the (sub-)interpreter represented by the given thread state. The given thread\nstate must be the current thread state. See the discussion of thread states below. When the call returns,\nthe current thread state is NULL. All thread states associated with this interpreter are destroyed. The global\ninterpreter lock used by the target interpreter must be held before calling this function. No GIL is held when\nit returns. Py_FinalizeEx() will destroy all sub-interpreters that haven’t been explicitly destroyed at that point.\n\n[2] It is usually the only Python interpreter in a\nprocess. Unlike sub-interpreters, the main interpreter has unique process-global responsibilities like signal handling. It is also responsible for execution during runtime initialization and is usually the active interpreter during runtime\nfinalization. The PyInterpreterState_Main() function returns a pointer to its state. You can switch between sub-interpreters using the PyThreadState_Swap() function. You can create and destroy\nthem using the following functions:\ntype PyInterpreterConfig\nStructure containing most parameters to configure a sub-interpreter. Its values are used only in\nPy_NewInterpreterFromConfig() and never modified by the runtime. Added in version 3.12. Structure fields:\nint use_main_obmalloc\nIf this is 0 then the sub-interpreter will use its own “object” allocator state. Otherwise it will use (share)\nthe main interpreter’s. If this is 0 then check_multi_interp_extensions must be 1 (non-zero). If this is 1 then gil must\nnot be PyInterpreterConfig_OWN_GIL. int allow_fork\nIf this is 0 then the runtime will not support forking the process in any thread where the sub-interpreter\nis currently active. Otherwise fork is unrestricted. Note that the subprocess module still works when fork is disallowed. 216\nChapter 9. Initialization, Finalization, and Threads\n\nThe Python/C API, Release 3.13.2\nint allow_exec\nIf this is 0 then the runtime will not support replacing the current process via exec (e.g. os.execv())\nin any thread where the sub-interpreter is currently active. Otherwise exec is unrestricted. Note that the subprocess module still works when exec is disallowed. int allow_threads\nIf this is 0 then the sub-interpreter’s threading module won’t create threads. Otherwise threads are\nallowed. int allow_daemon_threads\nIf this is 0 then the sub-interpreter’s threading module won’t create daemon threads. Otherwise daemon\nthreads are allowed (as long as allow_threads is non-zero). int check_multi_interp_extensions\nIf this is 0 then all extension modules may be imported, including legacy (single-phase init) modules,\nin any thread where the sub-interpreter is currently active. Otherwise only multi-phase init extension\nmodules (see PEP 489) may be imported. (Also see Py_mod_multiple_interpreters.) This must be 1 (non-zero) if use_main_obmalloc is 0.\nint gil\nThis determines the operation of the GIL for the sub-interpreter. It may be one of the following:\nPyInterpreterConfig_DEFAULT_GIL\nUse the default selection (PyInterpreterConfig_SHARED_GIL). PyInterpreterConfig_SHARED_GIL\nUse (share) the main interpreter’s GIL. PyInterpreterConfig_OWN_GIL\nUse the sub-interpreter’s own GIL. If this is PyInterpreterConfig_OWN_GIL then PyInterpreterConfig.use_main_obmalloc\nmust be 0. PyStatus Py_NewInterpreterFromConfig(PyThreadState **tstate_p, const PyInterpreterConfig *config)\nCreate a new sub-interpreter. This is an (almost) totally separate environment for the execution of Python\ncode. In particular, the new interpreter has separate, independent versions of all imported modules, including\nthe fundamental modules builtins, __main__ and sys. The table of loaded modules (sys.modules) and\nthe module search path (sys.path) are also separate. The new environment has no sys.argv variable. It\nhas new standard I/O stream file objects sys.stdin, sys.stdout and sys.stderr (however these refer\nto the same underlying file descriptors). The given config controls the options with which the interpreter is initialized. Upon success, tstate_p will be set to the first thread state created in the new sub-interpreter. This thread state\nis made in the current thread state. Note that no actual thread is created; see the discussion of thread states\nbelow. If creation of the new interpreter is unsuccessful, tstate_p is set to NULL; no exception is set since the\nexception state is stored in the current thread state and there may not be a current thread state. Like all other Python/C API functions, the global interpreter lock must be held before calling this function\nand is still held when it returns. Likewise a current thread state must be set on entry. On success, the returned\nthread state will be set as current. If the sub-interpreter is created with its own GIL then the GIL of the calling\ninterpreter will be released. When the function returns, the new interpreter’s GIL will be held by the current\nthread and the previously interpreter’s GIL will remain released here. Added in version 3.12. Sub-interpreters are most effective when isolated from each other, with certain functionality restricted:\nPyInterpreterConfig config = {\n.use_main_obmalloc = 0,\n(continues on next page)\n9.6. Sub-interpreter support\n217\n\nThe Python/C API, Release 3.13.2\n(continued from previous page)\n.allow_fork = 0,\n.allow_exec = 0,\n.allow_threads = 1,\n.allow_daemon_threads = 0,\n.check_multi_interp_extensions = 1,\n.gil = PyInterpreterConfig_OWN_GIL,\n};\nPyThreadState *tstate = NULL;\nPyStatus status = Py_NewInterpreterFromConfig(&tstate, &config);\nif (PyStatus_Exception(status)) {\nPy_ExitStatusException(status);\n}\nNote that the config is used only briefly and does not get modified.\n\n[3] Sub-interpreters allow you to do\nthat. The “main” interpreter is the first one created when the runtime initializes. It is usually the only Python interpreter in a\nprocess. Unlike sub-interpreters, the main interpreter has unique process-global responsibilities like signal handling. It is also responsible for execution during runtime initialization and is usually the active interpreter during runtime\nfinalization. The PyInterpreterState_Main() function returns a pointer to its state. You can switch between sub-interpreters using the PyThreadState_Swap() function. You can create and destroy\nthem using the following functions:\ntype PyInterpreterConfig\nStructure containing most parameters to configure a sub-interpreter. Its values are used only in\nPy_NewInterpreterFromConfig() and never modified by the runtime. Added in version 3.12. Structure fields:\nint use_main_obmalloc\nIf this is 0 then the sub-interpreter will use its own “object” allocator state. Otherwise it will use (share)\nthe main interpreter’s. If this is 0 then check_multi_interp_extensions must be 1 (non-zero). If this is 1 then gil must\nnot be PyInterpreterConfig_OWN_GIL. int allow_fork\nIf this is 0 then the runtime will not support forking the process in any thread where the sub-interpreter\nis currently active. Otherwise fork is unrestricted. Note that the subprocess module still works when fork is disallowed. 216\nChapter 9. Initialization, Finalization, and Threads\n\nThe Python/C API, Release 3.13.2\nint allow_exec\nIf this is 0 then the runtime will not support replacing the current process via exec (e.g. os.execv())\nin any thread where the sub-interpreter is currently active. Otherwise exec is unrestricted. Note that the subprocess module still works when exec is disallowed. int allow_threads\nIf this is 0 then the sub-interpreter’s threading module won’t create threads. Otherwise threads are\nallowed. int allow_daemon_threads\nIf this is 0 then the sub-interpreter’s threading module won’t create daemon threads. Otherwise daemon\nthreads are allowed (as long as allow_threads is non-zero). int check_multi_interp_extensions\nIf this is 0 then all extension modules may be imported, including legacy (single-phase init) modules,\nin any thread where the sub-interpreter is currently active. Otherwise only multi-phase init extension\nmodules (see PEP 489) may be imported. (Also see Py_mod_multiple_interpreters.) This must be 1 (non-zero) if use_main_obmalloc is 0.\nint gil\nThis determines the operation of the GIL for the sub-interpreter. It may be one of the following:\nPyInterpreterConfig_DEFAULT_GIL\nUse the default selection (PyInterpreterConfig_SHARED_GIL). PyInterpreterConfig_SHARED_GIL\nUse (share) the main interpreter’s GIL. PyInterpreterConfig_OWN_GIL\nUse the sub-interpreter’s own GIL. If this is PyInterpreterConfig_OWN_GIL then PyInterpreterConfig.use_main_obmalloc\nmust be 0. PyStatus Py_NewInterpreterFromConfig(PyThreadState **tstate_p, const PyInterpreterConfig *config)\nCreate a new sub-interpreter. This is an (almost) totally separate environment for the execution of Python\ncode. In particular, the new interpreter has separate, independent versions of all imported modules, including\nthe fundamental modules builtins, __main__ and sys. The table of loaded modules (sys.modules) and\nthe module search path (sys.path) are also separate. The new environment has no sys.argv variable. It\nhas new standard I/O stream file objects sys.stdin, sys.stdout and sys.stderr (however these refer\nto the same underlying file descriptors). The given config controls the options with which the interpreter is initialized. Upon success, tstate_p will be set to the first thread state created in the new sub-interpreter. This thread state\nis made in the current thread state. Note that no actual thread is created; see the discussion of thread states\nbelow. If creation of the new interpreter is unsuccessful, tstate_p is set to NULL; no exception is set since the\nexception state is stored in the current thread state and there may not be a current thread state. Like all other Python/C API functions, the global interpreter lock must be held before calling this function\nand is still held when it returns. Likewise a current thread state must be set on entry. On success, the returned\nthread state will be set as current. If the sub-interpreter is created with its own GIL then the GIL of the calling\ninterpreter will be released. When the function returns, the new interpreter’s GIL will be held by the current\nthread and the previously interpreter’s GIL will remain released here. Added in version 3.12.')",1.9135023169916004e-155,0.05644599303135888,0.21124962296009525,0.5360901951789856,0.3748162
How do I return dictionary keys as a list in Python?,"This will convert the 
dict_keys
 object to a 
list
:


list(newdict.keys())





On the other hand, you should ask yourself whether or not it matters. It is Pythonic to assume 
duck typing
 -- 
if it looks like a duck and it quacks like a duck, it is a duck
. The 
dict_keys
 object can be 
iterated
 over just like a 
list
. For instance:


for key in newdict.keys():
    print(key)



Note that 
dict_keys
 doesn't support insertion 
newdict[k] = v
, though you may not need it.

","('Answer: To return dictionary keys as a list, you can use `list(d)` or `list(d.keys())`.\n\nReferences: [1, 2]\n', '[1] classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nDictionaries and dictionary views are reversible. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(reversed(d))\n[\'four\', \'three\', \'two\', \'one\']\n>>> list(reversed(d.values()))\n[4, 3, 2, 1]\n>>> list(reversed(d.items()))\n[(\'four\', 4), (\'three\', 3), (\'two\', 2), (\'one\', 1)]\nChanged in version 3.8: Dictionaries are now reversible. µ See also\ntypes.MappingProxyType can be used to create a read-only view of a dict. 4.11.1 Dictionary view objects\nThe objects returned by dict.keys(), dict.values() and dict.items() are view objects. They provide a\ndynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these\nchanges. Dictionary views can be iterated over to yield their respective data, and support membership tests:\nlen(dictview)\nReturn the number of entries in the dictionary.\n\n[2] d[key] = value\nSet d[key] to value. del d[key]\nRemove d[key] from d. Raises a KeyError if key is not in the map. key in d\nReturn True if d has a key key, else False. key not in d\nEquivalent to not key in d.\niter(d)\nReturn an iterator over the keys of the dictionary. This is a shortcut for iter(d.keys()). clear()\nRemove all items from the dictionary. copy()\nReturn a shallow copy of the dictionary. classmethod fromkeys(iterable, value=None, /)\nCreate a new dictionary with keys from iterable and values set to value. fromkeys() is a class method that returns a new dictionary. value defaults to None. All of the values\nrefer to just a single instance, so it generally doesn’t make sense for value to be a mutable object such as\nan empty list. To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6.\n\n[3] To get distinct values, use a dict comprehension instead. get(key, default=None, /)\nReturn the value for key if key is in the dictionary, else default. If default is not given, it defaults to None,\nso that this method never raises a KeyError. items()\nReturn a new view of the dictionary’s items ((key, value) pairs). See the documentation of view\nobjects. keys()\nReturn a new view of the dictionary’s keys. See the documentation of view objects. pop(key[, default])\nIf key is in the dictionary, remove it and return its value, else return default. If default is not given and\nkey is not in the dictionary, a KeyError is raised. popitem()\nRemove and return a (key, value) pair from the dictionary. Pairs are returned in LIFO (last-in,\nfirst-out) order. popitem() is useful to destructively iterate over a dictionary, as often used in set algorithms. If the\ndictionary is empty, calling popitem() raises a KeyError. Changed in version 3.7: LIFO order is now guaranteed. In prior versions, popitem() would return an\narbitrary key/value pair. 4.11. Mapping Types — dict\n89\n\nThe Python Library Reference, Release 3.13.2\nreversed(d)\nReturn a reverse iterator over the keys of the dictionary. This is a shortcut for reversed(d.keys()). Added in version 3.8.\nsetdefault(key, default=None, /)\nIf key is in the dictionary, return its value. If not, insert key with a value of default and return default. default defaults to None. update([other])\nUpdate the dictionary with the key/value pairs from other, overwriting existing keys. Return None. update() accepts either another object with a keys() method (in which case __getitem__() is\ncalled with every key returned from the method) or an iterable of key/value pairs (as tuples or other\niterables of length two). If keyword arguments are specified, the dictionary is then updated with those\nkey/value pairs: d.update(red=1, blue=2). values()\nReturn a new view of the dictionary’s values. See the documentation of view objects. An equality comparison between one dict.values() view and another will always return False. This\nalso applies when comparing dict.values() to itself:\n>>> d = {\'a\': 1}\n>>> d.values() == d.values()\nFalse\nd | other\nCreate a new dictionary with the merged keys and values of d and other, which must both be dictionaries. The values of other take priority when d and other share keys. Added in version 3.9.\nd |= other\nUpdate the dictionary d with keys and values from other, which may be either a mapping or an iterable\nof key/value pairs. The values of other take priority when d and other share keys. Added in version 3.9. Dictionaries compare equal if and only if they have the same (key, value) pairs (regardless of ordering). Order comparisons (‘<’, ‘<=’, ‘>=’, ‘>’) raise TypeError. Dictionaries preserve insertion order. Note that updating a key does not affect the order. Keys added after\ndeletion are inserted at the end. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(d)\n[\'one\', \'two\', \'three\', \'four\']\n>>> list(d.values())\n[1, 2, 3, 4]\n>>> d[""one""] = 42\n>>> d\n{\'one\': 42, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> del d[""two""]\n>>> d[""two""] = None\n>>> d\n{\'one\': 42, \'three\': 3, \'four\': 4, \'two\': None}\nChanged in version 3.7: Dictionary order is guaranteed to be insertion order. This behavior was an implemen-\ntation detail of CPython from 3.6. 90\nChapter 4. Built-in Types\n\nThe Python Library Reference, Release 3.13.2\nDictionaries and dictionary views are reversible. >>> d = {""one"": 1, ""two"": 2, ""three"": 3, ""four"": 4}\n>>> d\n{\'one\': 1, \'two\': 2, \'three\': 3, \'four\': 4}\n>>> list(reversed(d))\n[\'four\', \'three\', \'two\', \'one\']\n>>> list(reversed(d.values()))\n[4, 3, 2, 1]\n>>> list(reversed(d.items()))\n[(\'four\', 4), (\'three\', 3), (\'two\', 2), (\'one\', 1)]\nChanged in version 3.8: Dictionaries are now reversible. µ See also\ntypes.MappingProxyType can be used to create a read-only view of a dict. 4.11.1 Dictionary view objects\nThe objects returned by dict.keys(), dict.values() and dict.items() are view objects. They provide a\ndynamic view on the dictionary’s entries, which means that when the dictionary changes, the view reflects these\nchanges. Dictionary views can be iterated over to yield their respective data, and support membership tests:\nlen(dictview)\nReturn the number of entries in the dictionary. iter(dictview)\nReturn an iterator over the keys, values or items (represented as tuples of (key, value)) in the dictionary. Keys and values are iterated over in insertion order. This allows the creation of (value, key) pairs using\nzip(): pairs = zip(d.values(), d.keys()). Another way to create the same list is pairs = [(v,\nk) for (k, v) in d.items()].')",0.0024156481691135208,0.03613006824568447,0.10077408614886516,0.5473042130470276,0.6425736
